[
  {
    "objectID": "docs/posts/GPU engineering/Tensors.html",
    "href": "docs/posts/GPU engineering/Tensors.html",
    "title": "Learning Basics of Tensors",
    "section": "",
    "text": "import torch\nimport numpy as np\na = torch.tensor(range(6))\na = a.reshape(2, 3)\na.shape, a.stride()\n\n(torch.Size([2, 3]), (3, 1))"
  },
  {
    "objectID": "docs/posts/GPU engineering/Tensors.html#data-blobs",
    "href": "docs/posts/GPU engineering/Tensors.html#data-blobs",
    "title": "Learning Basics of Tensors",
    "section": "Data BLOBs:",
    "text": "Data BLOBs:\n\nThe last tensor we’ve created has a very interesting proprety, first we created the number of elements we want 12 then we reshape it by repspecting 2 rules:\n\nthe total number of elements should be 12 exactly\nthese 12 elements should be distributed on 3 dimensions in order to call it tensor\nwe decided to ge with (2, 3, 2) but we could go with any distribution as long as we respect the 2 rules.\n\nThe 12 represent the data BLOB while the distribution represent the metadata that tells us how the data is shaped.\nData Blob is a large, row chunk of numerical data with no assumed structure untill interpreted, it’s shapeless untill we attach metadata to it.\nIn the context of Kernel engineering we are not working with well defined tensors shapes, but with:\n\npointers to data blobs in memory\nsome metadata (shape, strides, dtype)\na set of indexing rules to access the correct slice\n\nSo if we write a tensor:\n\n\nx = torch.tensor((3, 4, 5))\n\n\nUnder the hood the data is stored in a single flat buffer 60 floats\nThe shape tells us: This is 3 blocks of 4 rows of 5 elements.\n\n\nStride:\n\nIn the context of Kernel engineering the Stride is the most important key. Since data is stored in the memory as blobs, stride tells us how many elements to skip in memory to move to the next element along a specific dimension. Think of it as the “memory jump” for each axis.\n\n\nz = torch.tensor(range(6))\nz = z.reshape(3, 2)\nz.shape, z.stride()\n\n(torch.Size([3, 2]), (2, 1))\n\n\n\nThe stride says:\n\nto move one row: jump 3 elements stride[0]\nto move one column: jumpt one element stride[1]\n\nSo in our case the tensor z has a stride of (2, 1):\n\n2 is the number of jumps in order to get to the next row\nwhile 1 is the number of jump to get to the next column\n\n\n\n\nTransposed Stride:\n\nWhat if we transposed the tensor z? will the stride remain the same?\n\n\ny = z.t()\nz.stride(), y.stride()\n\n((2, 1), (1, 2))\n\n\n\nThe transpose changed the stride but the data blob remain the same:\n\n\nz.data_ptr() == y.data_ptr()\n\nTrue\n\n\n\n\nStride exercises:\n\nLearn how stride works with some simple Pytorch examples: #### Exercise 1: Basic 2D Tensor Create a 2D tensor and inspect its stride.\n\n\n# x is a 2D tensor\nx =  torch.tensor(range(6)).reshape(2, 3)\n# its shape:\nx.shape\n\ntorch.Size([2, 3])\n\n\n\nHow to think about its stride?:\n\nIn order to move to the next row how many element should we pass? ==&gt; 3\nIn order to get to the next column how many elements we need to jump? ==&gt; 1\n\nSo the stride is (3, 1)\n\n\nx, x.stride()\n\n(tensor([[0, 1, 2],\n         [3, 4, 5]]),\n (3, 1))\n\n\n\nExercise 2: Transposed Tensor\n\nTranspose the tensor and observe how the stride changes.\n\n\ny = x.t()\ny, y.shape\n\n(tensor([[0, 3],\n         [1, 4],\n         [2, 5]]),\n torch.Size([3, 2]))\n\n\n\nIn this case and since we reversed the shape, its obvious that the stride also will be reversed: (1, 3)\nWhat’s important is that Pytorch doesn’t create new copy of x when trasnposed, it only redefine the way the new tensor is viewed with creating new shape and new stride.\n\n\ny.stride()\n\n(1, 3)\n\n\n\n\nExercise 3: Unsqueezed Tensor\n\nAdd a new dimension and understand how stride adjusts.\n\n\nz = x.unsqueeze(0)\nx.shape, z.shape\n\n(torch.Size([2, 3]), torch.Size([1, 2, 3]))\n\n\n\nWhat happend here is that Pytorch pretend there’s a new outer dim, so the shape is changed from [2, 3] to [1, 2, 3].\nthe new dim dim[0] should have stride of 6, because in order to get to a new element in that dim (even that there’s only one element in that dim) we need to pass all other elements in both dimensions [1] and [2], which both contain 2*3 = 6.\nRULE: the stride of the new dim is always the product of the inner strides\n\nso the stride should be: (6, 3, 1)\n\n\n\nz.stride()\n\n(6, 3, 1)\n\n\n\nd = torch.tensor(range(8)).reshape(2, 4)\nd, d.shape\n\n(tensor([[0, 1, 2, 3],\n         [4, 5, 6, 7]]),\n torch.Size([2, 4]))\n\n\n\nd.stride()\n\n(4, 1)\n\n\n\nd1 = d.unsqueeze(1)\nd1\n\ntensor([[[0, 1, 2, 3]],\n\n        [[4, 5, 6, 7]]])\n\n\n\nd1.shape, d1.stride()\n\n(torch.Size([2, 1, 4]), (4, 4, 1))\n\n\n\n\nExercise 4: Expanded Tensor\n\nBroadcast a tensor without copying memory.\n\n\na = torch.ones(1, 3)\nb = a.expand(2, 3)\n\n\na.shape, b.shape\n\n(torch.Size([1, 3]), torch.Size([2, 3]))\n\n\n\na.stride()\n\n(3, 1)\n\n\n\nHere we have a tensor a of shape [1, 3] then we use expand to make tensor b with shape of [2, 3].\nthe method expand doesn’t create a new copy of the original tensor rather then virtually expanding a dimension by repeating it without chnaging the memory.\nIn this case the dim[0] will be virtually repeated 2 times.\nIn the original tensor a we have a stride of (3, 1):\n\nIn order to get to the next element along dim=0(rows) we have to move 3 steps in memory\nTo move to the next element along dim=1 (columns), step by 1 in memory.\n\nNow with tensor b, as we say expand add a virtuall element to the dim=0, it add a new row, but in memory we don’t change anything. So to move to the next row we don’t have to step at all, so the stride at that dimension will be 0.\nThe other dim=1 remain the same 1\n\n\nb.stride()\n\n(0, 1)\n\n\n\n\nExercise 5: Permuted Tensor\nChange dimension order and inspect stride layout.\n\nx3 = torch.randn(2, 3, 4)\ny3 = x3.permute(2, 0, 1)\n\n\nx3, x3.shape\n\n(tensor([[[-4.9521e-01, -1.5715e+00,  9.7796e-01, -2.6375e-01],\n          [ 1.0992e+00,  4.2912e-01,  7.5855e-02,  1.6052e+00],\n          [-7.1012e-01,  7.3460e-01, -3.9331e-01,  1.0008e+00]],\n \n         [[ 5.4850e-01, -1.6360e+00,  1.8978e-01, -1.3920e-01],\n          [ 1.4362e-01,  4.4029e-01, -2.0576e-01, -2.7227e-01],\n          [-1.2247e-03,  1.3967e+00, -5.3473e-01, -7.4465e-01]]]),\n torch.Size([2, 3, 4]))\n\n\n\nx3.stride()\n\n(12, 4, 1)\n\n\n\ny3, y3.shape\n\n(tensor([[[-4.9521e-01,  1.0992e+00, -7.1012e-01],\n          [ 5.4850e-01,  1.4362e-01, -1.2247e-03]],\n \n         [[-1.5715e+00,  4.2912e-01,  7.3460e-01],\n          [-1.6360e+00,  4.4029e-01,  1.3967e+00]],\n \n         [[ 9.7796e-01,  7.5855e-02, -3.9331e-01],\n          [ 1.8978e-01, -2.0576e-01, -5.3473e-01]],\n \n         [[-2.6375e-01,  1.6052e+00,  1.0008e+00],\n          [-1.3920e-01, -2.7227e-01, -7.4465e-01]]]),\n torch.Size([4, 2, 3]))\n\n\n\nTo move along the new dimension 0 (size 4, originally dim 2), you step by 1 in memory (same as original dim 2).\nTo move along the new dimension 1 (size 2, originally dim 0), you step by 12 in memory (same as original dim 0).\nTo move along the new dimension 2 (size 3, originally dim 1), you step by 4 in memory (same as original dim 1).\nThis shows that permutation changes the order of strides but not their values. The new strides correspond to the original strides in the permuted order."
  },
  {
    "objectID": "docs/posts/GPU engineering/Tensors.html#view",
    "href": "docs/posts/GPU engineering/Tensors.html#view",
    "title": "Learning Basics of Tensors",
    "section": "View:",
    "text": "View:\n\nIn PyTorch, viewing a tensor refers to creating a new tensor that shares the same underlying data storage as the original tensor but with a different shape, stride, or metadata. This means the viewed tensor does not copy the data; instead, it provides an alternative way to interpret the existing data in memory. 1- Memory:\nView allow tensors to share memory.\nModifying the viewed tensor will modifies the original tensor. 2- Shape and Stride adjustement:\nAs we saw earlier view can reinterpret a tensor shape end stride without copying it or changing the memory. 3- Zero-Cost Operation:\nViewing is efficient because it does not allocate new memory or copy data.\nOperations like view(), transpose(), permute(), expand(), and slicing often return views."
  },
  {
    "objectID": "docs/posts/GPU engineering/Tensors.html#broadcasting",
    "href": "docs/posts/GPU engineering/Tensors.html#broadcasting",
    "title": "Learning Basics of Tensors",
    "section": "Broadcasting:",
    "text": "Broadcasting:\n\nBroadcasting automatically expands smaller tensors to match the shape of larger tensors for element-wise operations by following specific rules:\n\nTensors are aligned from rights to left\nif sizes are equal then they are compatible\nIf one tensor size is 1, it’s streched to match the other\nIf one tensor is missing a dimension, it’s treated like size 1 dimension (then streched to match)\n\n\n\n# adding vector to scalar\nvec = torch.tensor([1, 2, 3])\nscal = torch.tensor(5)\nout =  vec + scal\n\n\nprint(vec, vec.shape)\nprint(scal, scal.shape)\nprint(out, out.shape)\n\ntensor([1, 2, 3]) torch.Size([3])\ntensor(5) torch.Size([])\ntensor([6, 7, 8]) torch.Size([3])\n\n\n\n# tensor size 1\nA = torch.tensor([[1, 2], [3, 4]])  # Shape (2, 2)\nB = torch.tensor([[10, 20]])         # Shape (1, 2)\nC = A + B\n\n\nprint(A, A.shape)\nprint(B, B.shape)\nprint(C, C.shape)\n\ntensor([[1, 2],\n        [3, 4]]) torch.Size([2, 2])\ntensor([[10, 20]]) torch.Size([1, 2])\ntensor([[11, 22],\n        [13, 24]]) torch.Size([2, 2])\n\n\n\n# tensor missing a dimension:\nD = torch.tensor([[1, 2], [3, 4]])  # Shape (2, 2)\nR = torch.tensor([10, 20])          # Shape (2,)\nS = D + R\n\n\nprint(D, D.shape)\nprint(R, R.shape)\nprint(S, S.shape)\n\ntensor([[1, 2],\n        [3, 4]]) torch.Size([2, 2])\ntensor([10, 20]) torch.Size([2])\ntensor([[11, 22],\n        [13, 24]]) torch.Size([2, 2])"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Description: Fine-tuned a small language model on the Manim dataset using instruction tuning methodology. The model generates executable Manim code that produces mathematical animations from natural language descriptions.\nTechnologies: - LLM Fine-tuning - Instruction Tuning - Code Generation - Manim\nStatus: Completed\nView Project"
  },
  {
    "objectID": "projects.html#featured-project",
    "href": "projects.html#featured-project",
    "title": "Projects",
    "section": "",
    "text": "Description: Fine-tuned a small language model on the Manim dataset using instruction tuning methodology. The model generates executable Manim code that produces mathematical animations from natural language descriptions.\nTechnologies: - LLM Fine-tuning - Instruction Tuning - Code Generation - Manim\nStatus: Completed\nView Project"
  },
  {
    "objectID": "projects.html#learning-journey",
    "href": "projects.html#learning-journey",
    "title": "Projects",
    "section": "Learning Journey",
    "text": "Learning Journey\nMy learning process and experiments are documented in the Blog section, covering topics like:\n\nDeep Learning fundamentals (fast.ai course)\nTransformers and NLP (Hugging Face course)\nBuilding LLMs from scratch\nGPU Programming and CUDA\nPyTorch internals"
  },
  {
    "objectID": "projects.html#coming-soon",
    "href": "projects.html#coming-soon",
    "title": "Projects",
    "section": "Coming Soon",
    "text": "Coming Soon\nMore projects are in development as I dive deeper into CUDA kernel engineering and low-level ML optimization. Check back soon or follow my progress in the blog!\n\nWant to collaborate or discuss ML/CUDA? Feel free to reach out."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "In this Blog I share my learning journey through machine learning and datascience."
  },
  {
    "objectID": "posts/junk/untitled.html",
    "href": "posts/junk/untitled.html",
    "title": "",
    "section": "",
    "text": "Code\nI’d be happy to continue with the Mini-GPT training code. Let’s finish the implementation:\nNow, let’s add a script that allows us to compare the two types of positional embeddings in the context of our Mini-GPT model, to see how they affect performance:\nLet me also provide a detailed explanation of the code implementation and key concepts:"
  },
  {
    "objectID": "posts/junk/untitled.html#positional-embeddings-implementation",
    "href": "posts/junk/untitled.html#positional-embeddings-implementation",
    "title": "",
    "section": "Positional Embeddings Implementation",
    "text": "Positional Embeddings Implementation\nThe first artifact implements two types of positional embeddings, which are crucial for transformer models like GPT:\n\n1. Learned Positional Embeddings\n\nImplementation: An embedding layer that maps position indices to vectors\nKey characteristics:\n\nParameters are learned during training\nMore flexible as they can adapt to specific patterns in the data\nRequires additional memory for storing parameters\nLimited to the maximum sequence length seen during training\n\n\n\n\n2. Sinusoidal Positional Embeddings\n\nImplementation: Mathematical functions (sine and cosine) with different frequencies\nKey characteristics:\n\nFixed pattern that doesn’t require training\nMore memory-efficient (no additional parameters)\nCan potentially generalize better to sequence lengths not seen during training\nUses alternating sine and cosine functions across dimensions\n\n\nThe code includes visualization capabilities to see how these different embeddings look across positions and dimensions."
  },
  {
    "objectID": "posts/junk/untitled.html#mini-gpt-implementation",
    "href": "posts/junk/untitled.html#mini-gpt-implementation",
    "title": "",
    "section": "Mini-GPT Implementation",
    "text": "Mini-GPT Implementation\nThe second artifact implements a simplified GPT model with these key components:\n\nKey Components:\n\nMulti-Head Attention: Allows the model to focus on different parts of the input sequence\n\nSplits embeddings into multiple heads for parallel attention computation\nComputes query, key, and value projections\nUses scaled dot-product attention with a causal mask for autoregressive generation\n\nFeed-Forward Networks: Processes the attention outputs\n\nTwo linear transformations with a GELU activation\nExpands the dimension to d_ff and then back to d_model\n\nDecoder Blocks: The fundamental building blocks of GPT\n\nSelf-attention mechanism\nFeed-forward network\nLayer normalization and residual connections\n\nText Generation: Autoregressive sampling with temperature control\n\nSupports top-k and nucleus (top-p) sampling for diverse generation\nFollows the standard autoregressive text generation process\n\nSimple Tokenizer: A basic implementation for demonstration purposes\n\nHandles word tokenization\nBuilds vocabulary from input texts\nProvides encode/decode functionality"
  },
  {
    "objectID": "posts/junk/untitled.html#training-implementation",
    "href": "posts/junk/untitled.html#training-implementation",
    "title": "",
    "section": "Training Implementation",
    "text": "Training Implementation\nThe third artifact shows how to train the Mini-GPT model:\n\nSets up proper loss function (CrossEntropyLoss with padding ignored)\nUses the AdamW optimizer with learning rate scheduling\nImplements gradient clipping to prevent exploding gradients\nTracks and visualizes training metrics\nDemonstrates text generation with different temperature settings"
  },
  {
    "objectID": "posts/junk/untitled.html#comparison-of-positional-embeddings",
    "href": "posts/junk/untitled.html#comparison-of-positional-embeddings",
    "title": "",
    "section": "Comparison of Positional Embeddings",
    "text": "Comparison of Positional Embeddings\nThe final artifact compares both positional embedding types in a real training scenario:\n\nImplements both models with identical architectures except for the positional embedding type\nTrains both models on the same data with identical hyperparameters\nCompares training loss curves and training times\nTests text generation quality\nAssesses generalization to longer sequences (a key advantage of sinusoidal embeddings)"
  },
  {
    "objectID": "posts/junk/untitled.html#key-takeaways",
    "href": "posts/junk/untitled.html#key-takeaways",
    "title": "",
    "section": "Key Takeaways",
    "text": "Key Takeaways\n\nArchitectural Understanding: The code demonstrates the essential components of transformer decoder models like GPT.\nPositional Embeddings Trade-offs:\n\nLearned positional embeddings can adapt to specific patterns but require more parameters and may struggle with longer sequences.\nSinusoidal positional embeddings are parameter-efficient and theoretically better for generalization to unseen sequence lengths.\n\nPractical Implementation: The implementation includes training, evaluation, and text generation, forming a complete pipeline from data to generated text.\n\nThese implementations provide a foundation to understand how modern language models work at their core, with a focus on the critical role of positional information in sequence modeling.\nWould you like me to explain any specific part of these implementations in more detail?"
  },
  {
    "objectID": "posts/Fastai_ch2/2022_09_09_Fastai_Lesson2.html",
    "href": "posts/Fastai_ch2/2022_09_09_Fastai_Lesson2.html",
    "title": "Chapter 2: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "As we saw in the previous Chapter, we can create powerful model with only 6 lines of code\n\nAlthought we should understand the constraints of the process and not overestimate the capabilities of deep learnig, this may lead to frustaingtly poor result\n\nAlso we need to not overestimate the constraints, and underestimate what could do with deep learning"
  },
  {
    "objectID": "posts/Fastai_ch2/2022_09_09_Fastai_Lesson2.html#deep-learning-in-production",
    "href": "posts/Fastai_ch2/2022_09_09_Fastai_Lesson2.html#deep-learning-in-production",
    "title": "Chapter 2: Deep learning for coders with fastai and pytorch",
    "section": "Deep Learning In Production",
    "text": "Deep Learning In Production\nWhen we create a model that met our objectives, we can then pass to the Production phase, where we transform the model into an appliction/service etc..\nBut first we need to export the model into a file:\n\nlearn.export()\n\nLet’s check that the file exists, by using the ls method that fastai adds to Python’s Path class:\n\npath = Path()\npath.ls(file_exts='.pkl')\n\n(#1) [Path('export.pkl')]\n\n\n\nNow with the export.pkl file we can create normal program that takes inputs(images) and produce results (predictions) just like any traditional app\nAt this point we won’t call it a model anymore, we call it inference.\n\n &gt;Using the trained model as program\nThe export() function allow us to save the model in oreder to use it later, and as we know model is Architecture + Parameters, Fastai by default saves also the method of which we’ve created the DataLoaders, because otherwise we have to define it again in order to work with the new data we will feed to the model.\n\nFrom Model to Inference\nThis file export.pkl is allways needed wherever we will create an app from it, for now we will use it whithin this notebook in order to create a small app that can predict bears type from image we will provide.\nWhen we use a model for getting predictions, instead of training, we call it inference.\nTo create inference learner from export.pkl file we use load_learner:\n\nlearn_inf = load_learner(path/'export.pkl')\n\n\n# predicting one image\nlearn_inf.predict('images/bear.jpg')\n\n\n\n\n\n\n\n\n('grizzly', TensorBase(1), TensorBase([8.0130e-07, 1.0000e+00, 2.0153e-07]))\n\n\n\nThis has returned three things:\n\nthe predicted category(label) in the same format we originally provided (in this case that’s a string),\nthe index of the predicted category, and the probabilities of each category.\nthe last two are based on the order of categories in the vocab of the DataLoaders; that is, the stored list of all possible categories.\n\nAt inference time, you can access the DataLoaders as an attribute of the Learner:\n\n\nlearn_inf.dls.vocab\n\n['black', 'grizzly', 'teddy']\n\n\nWe can see here that if we index into the vocab with the integer returned by predict then we get back “grizzly,” as expected. Also, note that if we index into the list of probabilities, we see a nearly 1.00 probability that this is a grizzly.\n\n\nGradio + HugginFace Spaces\n\nIf we want to share our model with a broader audience, and showcase our skills we need to create a real app that can be used outside of the datascience/machine learning word where nobody know or have the ability to use jupyter notebook or python.. and that’s why we will show using a combination of python package Gradio that will allow us to build our app, then host it on HuggingFace\n\n\n# firstly install gradio\n!pip install gradio\n\nLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nCollecting gradio\n  Downloading gradio-3.6-py3-none-any.whl (5.3 MB)\n     |████████████████████████████████| 5.3 MB 5.2 MB/s \nRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gradio) (2.23.0)\nRequirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from gradio) (1.9.2)\nCollecting pydub\n  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\nCollecting paramiko\n  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\n     |████████████████████████████████| 212 kB 67.2 MB/s \nCollecting httpx\n  Downloading httpx-0.23.0-py3-none-any.whl (84 kB)\n     |████████████████████████████████| 84 kB 3.9 MB/s \nRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.3.5)\nCollecting orjson\n  Downloading orjson-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (270 kB)\n     |████████████████████████████████| 270 kB 62.9 MB/s \nCollecting ffmpy\n  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from gradio) (3.8.3)\nRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\nCollecting fastapi\n  Downloading fastapi-0.85.1-py3-none-any.whl (55 kB)\n     |████████████████████████████████| 55 kB 3.8 MB/s \nRequirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from gradio) (2.11.3)\nCollecting h11&lt;0.13,&gt;=0.11\n  Downloading h11-0.12.0-py3-none-any.whl (54 kB)\n     |████████████████████████████████| 54 kB 3.7 MB/s \nRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\nCollecting pycryptodome\n  Downloading pycryptodome-3.15.0-cp35-abi3-manylinux2010_x86_64.whl (2.3 MB)\n     |████████████████████████████████| 2.3 MB 47.6 MB/s \nRequirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from gradio) (2022.8.2)\nCollecting markdown-it-py[linkify,plugins]\n  Downloading markdown_it_py-2.1.0-py3-none-any.whl (84 kB)\n     |████████████████████████████████| 84 kB 3.9 MB/s \nRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.21.6)\nCollecting python-multipart\n  Downloading python-multipart-0.0.5.tar.gz (32 kB)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from gradio) (6.0)\nCollecting uvicorn\n  Downloading uvicorn-0.19.0-py3-none-any.whl (56 kB)\n     |████████████████████████████████| 56 kB 5.3 MB/s \nCollecting websockets\n  Downloading websockets-10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (112 kB)\n     |████████████████████████████████| 112 kB 70.9 MB/s \nRequirement already satisfied: frozenlist&gt;=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;gradio) (1.3.1)\nRequirement already satisfied: typing-extensions&gt;=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;gradio) (4.1.1)\nRequirement already satisfied: async-timeout&lt;5.0,&gt;=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;gradio) (4.0.2)\nRequirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;gradio) (22.1.0)\nRequirement already satisfied: charset-normalizer&lt;3.0,&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;gradio) (2.1.1)\nRequirement already satisfied: aiosignal&gt;=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;gradio) (1.2.0)\nRequirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;gradio) (6.0.2)\nRequirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;gradio) (1.8.1)\nRequirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;gradio) (0.13.0)\nRequirement already satisfied: idna&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl&lt;2.0,&gt;=1.0-&gt;aiohttp-&gt;gradio) (2.10)\nCollecting starlette==0.20.4\n  Downloading starlette-0.20.4-py3-none-any.whl (63 kB)\n     |████████████████████████████████| 63 kB 2.5 MB/s \nCollecting anyio&lt;5,&gt;=3.4.0\n  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n     |████████████████████████████████| 80 kB 10.6 MB/s \nCollecting sniffio&gt;=1.1\n  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\nRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx-&gt;gradio) (2022.9.24)\nCollecting httpcore&lt;0.16.0,&gt;=0.15.0\n  Downloading httpcore-0.15.0-py3-none-any.whl (68 kB)\n     |████████████████████████████████| 68 kB 6.7 MB/s \nCollecting rfc3986[idna2008]&lt;2,&gt;=1.3\n  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\nRequirement already satisfied: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2-&gt;gradio) (2.0.1)\nCollecting mdurl~=0.1\n  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\nCollecting mdit-py-plugins\n  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n     |████████████████████████████████| 46 kB 4.5 MB/s \nCollecting linkify-it-py~=1.0\n  Downloading linkify_it_py-1.0.3-py3-none-any.whl (19 kB)\nCollecting uc-micro-py\n  Downloading uc_micro_py-1.0.1-py3-none-any.whl (6.2 kB)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;gradio) (3.0.9)\nRequirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;gradio) (0.11.0)\nRequirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;gradio) (2.8.2)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;gradio) (1.4.4)\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.1-&gt;matplotlib-&gt;gradio) (1.15.0)\nRequirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas-&gt;gradio) (2022.4)\nCollecting pynacl&gt;=1.0.1\n  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n     |████████████████████████████████| 856 kB 63.6 MB/s \nCollecting cryptography&gt;=2.5\n  Downloading cryptography-38.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n     |████████████████████████████████| 4.0 MB 41.4 MB/s \nCollecting bcrypt&gt;=3.1.3\n  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (593 kB)\n     |████████████████████████████████| 593 kB 68.7 MB/s \nRequirement already satisfied: cffi&gt;=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography&gt;=2.5-&gt;paramiko-&gt;gradio) (1.15.1)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi&gt;=1.12-&gt;cryptography&gt;=2.5-&gt;paramiko-&gt;gradio) (2.21)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;gradio) (1.25.11)\nRequirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;gradio) (3.0.4)\nRequirement already satisfied: click&gt;=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn-&gt;gradio) (7.1.2)\nBuilding wheels for collected packages: ffmpy, python-multipart\n  Building wheel for ffmpy (setup.py) ... done\n  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4712 sha256=bf42b4bf9ba2633a885814063d3340770c60207e05f131d9e165fafd4a5e1aa5\n  Stored in directory: /root/.cache/pip/wheels/13/e4/6c/e8059816e86796a597c6e6b0d4c880630f51a1fcfa0befd5e6\n  Building wheel for python-multipart (setup.py) ... done\n  Created wheel for python-multipart: filename=python_multipart-0.0.5-py3-none-any.whl size=31678 sha256=f8ff9e663a939cd5bba16c9c7ce235f69c0fab5ae8199bbfce9b5fdb3361d05e\n  Stored in directory: /root/.cache/pip/wheels/2c/41/7c/bfd1c180534ffdcc0972f78c5758f89881602175d48a8bcd2c\nSuccessfully built ffmpy python-multipart\nInstalling collected packages: sniffio, mdurl, uc-micro-py, rfc3986, markdown-it-py, h11, anyio, starlette, pynacl, mdit-py-plugins, linkify-it-py, httpcore, cryptography, bcrypt, websockets, uvicorn, python-multipart, pydub, pycryptodome, paramiko, orjson, httpx, ffmpy, fastapi, gradio\nSuccessfully installed anyio-3.6.2 bcrypt-4.0.1 cryptography-38.0.1 fastapi-0.85.1 ffmpy-0.3.0 gradio-3.6 h11-0.12.0 httpcore-0.15.0 httpx-0.23.0 linkify-it-py-1.0.3 markdown-it-py-2.1.0 mdit-py-plugins-0.3.1 mdurl-0.1.2 orjson-3.8.0 paramiko-2.11.0 pycryptodome-3.15.0 pydub-0.25.1 pynacl-1.5.0 python-multipart-0.0.5 rfc3986-1.5.0 sniffio-1.3.0 starlette-0.20.4 uc-micro-py-1.0.1 uvicorn-0.19.0 websockets-10.3\n\n\n\n# create labels from dalaloaders vocab\nlabels = learn.dls.vocab\n# predicting function that take an image as input and use learn.predict to ouput:\n# prediction, prediction index, and probability.\ndef predict(img):\n    img = PILImage.create(img)\n    pred,pred_idx,probs = learn.predict(img)\n    return {labels[i]: float(probs[i]) for i in range(len(labels))}\n\n\nHere we will use gradio in order to create an app withing this notebook.\n\n\n\nimport gradio as gr\ngr.Interface(fn=predict, inputs=gr.inputs.Image(shape=(512, 512)), outputs=gr.outputs.Label(num_top_classes=3)).launch(share=True)\n\n/usr/local/lib/python3.7/dist-packages/gradio/inputs.py:257: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n  \"Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\",\n/usr/local/lib/python3.7/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n  warnings.warn(value)\n/usr/local/lib/python3.7/dist-packages/gradio/outputs.py:197: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n  \"Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\",\n/usr/local/lib/python3.7/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n  warnings.warn(value)\n\n\nColab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\nRunning on public URL: https://bbc80cb39aa58cc0.gradio.app\n\nThis share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n\n\n\n\n\n(&lt;gradio.routes.App at 0x7f45d2b49710&gt;,\n 'http://127.0.0.1:7860/',\n 'https://bbc80cb39aa58cc0.gradio.app')\n\n\n\nStill the best way of creating app for inference is to use Hugginface platform with help of gradio.\nHere is the app that classify bears types based the .pkl file we created from our model we trained: Here"
  },
  {
    "objectID": "posts/Data PreProcessing For NLP Problem/Multi_choice_with_SWAG.html",
    "href": "posts/Data PreProcessing For NLP Problem/Multi_choice_with_SWAG.html",
    "title": "Multi Choice with Swag Dataset",
    "section": "",
    "text": "Introduction:\n\nIn this notebook I will try to investigate the SWAG datasets.\nThe idea is to understand how to deal with multiple choice datasets and how to prepare them for the next step.\nMultiple choice is frequent problem in the filed of LLMs and NLP in general\nSo the preprocessing of data will have a huge effect on the success of any proposed solution\n\n\n# load the dataset\nfrom datasets import load_dataset\ndataset = load_dataset('swag', 'regular')\n\n\n# let's grab a sample\ndataset['train'][0]\n\n{'video-id': 'anetv_jkn6uvmqwh4',\n 'fold-ind': '3416',\n 'startphrase': 'Members of the procession walk down the street holding small horn brass instruments. A drum line',\n 'sent1': 'Members of the procession walk down the street holding small horn brass instruments.',\n 'sent2': 'A drum line',\n 'gold-source': 'gold',\n 'ending0': 'passes by walking down the street playing their instruments.',\n 'ending1': 'has heard approaching them.',\n 'ending2': \"arrives and they're outside dancing and asleep.\",\n 'ending3': 'turns the lead singer watches the performance.',\n 'label': 0}\n\n\n\nThese fields represent the idea begind this dataset\n\na situation where we have to predict the right ending\nsent1 and sent2 represent the given situation and they added up to startphrase\nendings 0 to 3 represent the the endings for that situation, only one is the right\nlabel index the right answer\n\nNow let’s initialized BERT and load its tokenizer.\n\n\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n\n\nThe idea here is to tokenize a start sentence with each one of the 4 choices,\n\n\nending_names = [\"ending0\", \"ending1\", \"ending2\", \"ending3\"]\n\n\ndef preprocess_function(examples):\n    first_sentences = [[context] * 4 for context in examples[\"sent1\"]]\n    question_headers = examples[\"sent2\"]\n    second_sentences = [\n        [f\"{header} {examples[end][i]}\" for end in ending_names]\n        for i, header in enumerate(question_headers)\n    ]\n\n    first_sentences = sum(first_sentences, [])\n    second_sentences = sum(second_sentences, [])\n\n    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n    return {k: [v[i : i + 4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}\n\n\nTo understand each operation of that function we will do it step-by-step:\n\nFirst let’s create a sub-set of the training set\nCreate a endings list that we will use later\n\n\n\nendings = [\"ending0\", \"ending1\", \"ending2\", \"ending3\"]\ntrain_ds = dataset['train']\nsmp = train_ds[:20]\n\n\nMultiply each sent1 by 4 and stack them all in a list:\n\n\nsent_1 = [[sent] * 4 for sent in smp['sent1']]\n\n\nLet’s retrieve the length of that list and see what’s inside one element of it.\n\n\nsent_1[2], len(sent_1)\n\n(['A group of members in green uniforms walks waving flags.',\n  'A group of members in green uniforms walks waving flags.',\n  'A group of members in green uniforms walks waving flags.',\n  'A group of members in green uniforms walks waving flags.'],\n 20)\n\n\n\nSo basically we have 4 copies of each first-sentence of the dataset.\nNow we will create a list of the second-sentence or the header.\n\n\nheaders = smp['sent2']\n\n\nAt this point we have:\n\nsent_1 which each element is multiplied by 4\nheaders that complete sent_1\n\nThe idea here is to create pairs of each header +sent_2 for each sent_1.\n\n\nsent_2 = [[f'{head}{smp[end][i]}' for end in endings] for i, head in enumerate(headers)]\n\n\n\n\nPre-processing\n\n\n\nNow we need to flatten the pair of sentences, so we could tokenize them:\n\n\nfrst_sent = sum(sent_1, [])\nscnd_sent = sum(sent_2, [])\ntok_smp = tokenizer(frst_sent, scnd_sent, truncation=True)\n\n\nWe tokenize the pair of list sentences which will return a dictionary with 3 keys:\n\n\ntok_smp.keys()\n\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n\n\n\nBut since we already flattend the pairs before the tokenization step, we need to get them unflatten again so we can pass it through the map() function in order to be computed by the model.\n\n\noutputs = {k: [v[i: i + 4] for i in range(0, len(v), 4)] for k, v in tok_smp.items()}\n\n\nLets check if we get the unflatten step right, we just need to make sure that the input_ids of the first sentence has the same values in both: tok_smp and outputs:\n\n\nflatten_smp = tok_smp['input_ids']\nunflatten_smp = outputs['input_ids']\n\n\nflatten_smp[0:4] == unflatten_smp[0]\n\nTrue"
  },
  {
    "objectID": "posts/Haystack_2/ch3_haystack.html",
    "href": "posts/Haystack_2/ch3_haystack.html",
    "title": "Utilizing Existing FAQs for Question Answering",
    "section": "",
    "text": "Introduction:\n\nUsually the Extractive Question Answering systems uses pure data-texts to generate answers, but in some cases it we could useful to use them on previous FAQs as dataset\nThis can be appealing for many reasons:\n\nWe already have data\nInference time is reduced\nMuch control over answers\n\nThe problem is that this can generalize good enough only on similar questions, which make this method good for certain situations only.\n\n\n\nCreate simple DocumentStore:\n\nAs we saw before InMemoryDocumentStore is an easy way for creating DocumentStore for simple prototyping.\n\n\nfrom haystack.document_stores import InMemoryDocumentStore\ndocument_store = InMemoryDocumentStore()\n\n\n\nCreate a Retriever using embeddings:\n\nThe idea here to create embeddings for questions we will get from users\nThis embeddings must match the FAQs we have\nFirst we need to create the embeddings from a model we use\nThen apply the same embeddings on the FAQs we will use as dataset\n\n\nfrom haystack.nodes import EmbeddingRetriever\n\nretriever = EmbeddingRetriever(document_store = document_store,\n                               embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\",\n                               use_gpu = True,\n                               scale_score = False)\n\n\nDownload FAQs dataset\n\n\n# download\nfrom haystack.utils import fetch_archive_from_http\ndoc_dir = 'data/tutorial'\nurls = 'https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/small_faq_covid.csv.zip'\nfetch_archive_from_http(url = urls, output_dir = doc_dir)\n\nTrue\n\n\n\nHere we use Pandas to manipulate the dataset we just downloaded.\nFirst create the dataframe\n\n\nimport pandas as pd\ndf = pd.read_csv(f'{doc_dir}/small_faq_covid.csv')\ndf.head()\n\n\n    \n\n\n\n\n\n\nquestion\nanswer\nanswer_html\nlink\nname\nsource\ncategory\ncountry\nregion\ncity\nlang\nlast_update\n\n\n\n\n0\nWhat is a novel coronavirus?\nA novel coronavirus is a new coronavirus that ...\n&lt;p&gt;A novel coronavirus is a new coronavirus th...\n\\nhttps://www.cdc.gov/coronavirus/2019-ncov/fa...\nFrequently Asked Questions\nCenter for Disease Control and Prevention (CDC)\nCoronavirus Disease 2019 Basics\nUSA\nNaN\nNaN\nen\n2020/03/17\n\n\n1\nWhy is the disease being called coronavirus di...\nOn February 11, 2020 the World Health Organiza...\n&lt;p&gt;On February 11, 2020 the World Health Organ...\n\\nhttps://www.cdc.gov/coronavirus/2019-ncov/fa...\nFrequently Asked Questions\nCenter for Disease Control and Prevention (CDC)\nCoronavirus Disease 2019 Basics\nUSA\nNaN\nNaN\nen\n2020/03/17\n\n\n2\nWhy might someone blame or avoid individuals a...\nPeople in the U.S. may be worried or anxious a...\n&lt;p&gt;People in the U.S. may be worried or anxiou...\n\\nhttps://www.cdc.gov/coronavirus/2019-ncov/fa...\nFrequently Asked Questions\nCenter for Disease Control and Prevention (CDC)\nCoronavirus Disease 2019 Basics\nUSA\nNaN\nNaN\nen\n2020/03/17\n\n\n3\nHow can people help stop stigma related to COV...\nPeople can fight stigma and help, not hurt, ot...\n&lt;p&gt;People can fight stigma and help, not hurt,...\n\\nhttps://www.cdc.gov/coronavirus/2019-ncov/fa...\nFrequently Asked Questions\nCenter for Disease Control and Prevention (CDC)\nHow It Spreads\nUSA\nNaN\nNaN\nen\n2020/03/17\n\n\n4\nWhat is the source of the virus?\nCoronaviruses are a large family of viruses. S...\n&lt;p&gt;Coronaviruses are a large family of viruses...\n\\nhttps://www.cdc.gov/coronavirus/2019-ncov/fa...\nFrequently Asked Questions\nCenter for Disease Control and Prevention (CDC)\nHow It Spreads\nUSA\nNaN\nNaN\nen\n2020/03/17\n\n\n\n\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\nSince we download the data from internet we should clean it properly before use in kind of data processing\n\n\ndf.fillna(value='', inplace= True)\ndf[\"question\"] = df[\"question\"].apply(lambda x: x.strip())\nquestions = list(df.question.values)\n\n\nCreate Embeddings on the questions\n\n\ndf.embedding = retriever.embed_queries(queries=questions).tolist()\nlen(df.embedding)\n\n\n\n\nUserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n  df.embedding = retriever.embed_queries(queries=questions).tolist()\n\n\n213\n\n\n\nRename the question series with content\n\n\ndf = df.rename(columns={'question':'content'})\n\n\nConvert te dataframe into a list of dics and index them in our DocumentStore\n\n\ndocs_to_index = df.to_dict(orient='records')\ndocument_store.write_documents(docs_to_index)\n\n\n\nAsk questions\n\nWe first need to initialize the pipeline:\n\n\nfrom haystack.pipelines import FAQPipeline\npipe = FAQPipeline(retriever=retriever)\n\n\nfrom haystack.utils import print_answers\n\n# Run any question and change top_k to see more or less answers\nprediction = pipe.run(query=\"How is the virus spreading?\", params={\"Retriever\": {\"top_k\": 1}})\n\nprint_answers(prediction, details=\"medium\")\n\n\n\n\nWARNING:haystack.document_stores.memory:Skipping some of your documents that don't have embeddings. To generate embeddings, run the document store's update_embeddings() method.\n\n\n'Query: How is the virus spreading?'\n'Answers:'\n[]"
  },
  {
    "objectID": "posts/Kaggling_0/Kaggling_Tutorial__0.html",
    "href": "posts/Kaggling_0/Kaggling_Tutorial__0.html",
    "title": "Kaggling Tutorial #0: Download A Dataset from Kaggle Using API-Key",
    "section": "",
    "text": "How To Download Dataset From Kaggle into Colab NoteBook:\n\nIn this mini tutorial we will create a colab notebook and download a Kaggle dataset using Kaggle API-key.\nHaving the possibility to work on different Free computing platform, gives us a wide choices to do multiple prototyping in parallel.\n\n\n\nGetting the API-Key:\n\nFirst we need to get API-Key form Kaggle website: settings:\n\nLink\n\nClick on Create New Token, it will download a json file: kaggle.json\n\nThen we need to upload this file into colab notebook where we will work with the dataset\nHere we create a new directory kaggle and copy the kaggle.json inside:\n\n\n!mkdir ~/.kaggle\n\n\n!cp kaggle.json ~/.kaggle\n\n\nNow we need to modify the permissions and access mode of kaggle.json:\n\n\n!chmod 600 ~/.kaggle/kaggle.json\n\n\n\nDownloading the Dataset:\n\nSince we have all ingredients, we can now download our dataset from kaggle:\n\n\n! kaggle competitions download linking-writing-processes-to-writing-quality\n\nDownloading linking-writing-processes-to-writing-quality.zip to /content\n 90% 97.0M/108M [00:00&lt;00:00, 137MB/s]\n100% 108M/108M [00:00&lt;00:00, 135MB/s] \n\n\n\nThe file we get after this command is .zip file, which contains all files and datasets we will work with\nIn order to unzip this file we will use zipfile:\n\n\nfrom zipfile import ZipFile\nfile = 'linking-writing-processes-to-writing-quality.zip'\nwith ZipFile(file, 'r') as zip:\n\n    # list all the contents of the zip file\n    zip.printdir()\n\n    # extract all files\n    print('extraction...')\n    zip.extractall()\n    print('Done!')\n\nFile Name                                             Modified             Size\nsample_submission.csv                          2023-10-02 17:22:24           48\ntest_logs.csv                                  2023-10-02 17:22:24          398\ntrain_logs.csv                                 2023-10-02 17:22:30    485679766\ntrain_scores.csv                               2023-10-02 17:23:10        32132\nextraction...\nDone!\n\n\n\n\nConclusion:\n\nWe succefully download a dataset from Kaggle using API-Key\nWe can take it from here and apply all kind of data manipulation, EDA, training model on it …"
  },
  {
    "objectID": "posts/Fastai_ch1/Chapter1.html",
    "href": "posts/Fastai_ch1/Chapter1.html",
    "title": "Chapter 1: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "! [ -e /content ] && pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\n\n     |████████████████████████████████| 719 kB 34.6 MB/s \n     |████████████████████████████████| 1.3 MB 53.8 MB/s \n     |████████████████████████████████| 5.3 MB 53.3 MB/s \n     |████████████████████████████████| 441 kB 65.8 MB/s \n     |████████████████████████████████| 1.6 MB 46.3 MB/s \n     |████████████████████████████████| 212 kB 71.6 MB/s \n     |████████████████████████████████| 115 kB 71.6 MB/s \n     |████████████████████████████████| 163 kB 73.8 MB/s \n     |████████████████████████████████| 127 kB 72.7 MB/s \n     |████████████████████████████████| 115 kB 73.2 MB/s \n     |████████████████████████████████| 7.6 MB 48.1 MB/s \nMounted at /content/gdrive"
  },
  {
    "objectID": "posts/Fastai_ch1/Chapter1.html#brief-history-of-neural-network",
    "href": "posts/Fastai_ch1/Chapter1.html#brief-history-of-neural-network",
    "title": "Chapter 1: Deep learning for coders with fastai and pytorch",
    "section": "Brief History of Neural Network",
    "text": "Brief History of Neural Network\n\nIn 1943 Warren McCulloch, a neurophysiologist, and Walter Pitts, a logician, both devoloped a concept called Artificial Neuron which is seen today as the first theorotical demonstration of a machine that’s “..capable of perceiving, recognizing and identifying its surrondings”\n\nIn the 50’s Frank Rossenblatt devoloped a device based on the principiles of Artificial Neuron\n\nRosenblatt invented The Perceptron which was capable of recognizing simple shapes and patterns\n\n\nIn 1969 Marvin minsky write a book called Perceptrons where he showed that Perceptron limits of solving critical math problem\n\n\nParallel Distributed Processing (PDP)\n\nAfter a long winter of Deep Learning, a group of researchers at MIT released a papper in 1986 released the most influencial papper in history of Neural Network\n\nAuthors claimed that PDP approach was closer to how human brain works\n\nPDP require some enviroments elements:\n\nSet of processing units\n\nA state of activation\n\nAn output function for each unit\n\nPattern of connectivity among units\n\nPropagation rule for propagating patterns of activities through the network of connectivities\n\nAn activation rule for combining the inputs impinging on a unit with the current state of that unit to produce an output for the unit\n\nLearning rule whereby patterns of connectivity are modified by experience\n\nAn environment within which the system must operate\n\n\n\n\n1980’s and 90’s\n\nDuring this epoch researcher started to build models with 2 layers of neurons\n\nWe saw real world application of Deep Learning"
  },
  {
    "objectID": "posts/Fastai_ch1/Chapter1.html#top-to-bottom-learning-approach",
    "href": "posts/Fastai_ch1/Chapter1.html#top-to-bottom-learning-approach",
    "title": "Chapter 1: Deep learning for coders with fastai and pytorch",
    "section": "Top to bottom learning approach",
    "text": "Top to bottom learning approach\n\nStart with the end point\n\nBuild a foundation of intuition through application then build on it with theory\nShow students how individuals pieces of theory are combined in a real-world application\n\nTeach through examples\n\nProvide a context and a purpose for abstract concepts\n\n\n\nWhat is Machine Learning?\nTraditional Programming:\n- It’s hard to explicitly code hard tasks specialy when you don’t know the exact steps\n\n\n\na-traditional-program.png\n\n\nMachine Learning\n- A program that need to be showed examples of the desired tasks so it can Learn from them\n- Demand sufficient amount of examples(Data)\n- In 1949 Arthur Samuel manage to build a machine that can play checker - This work introduced multiple concepts to the world of machine learning: - The idea of a weight assignment\n- The fact that every weight assignment has some actual performance\n- The requirement that there be an automatic means of testing that performance\n- The need for a mechanism (i.e., another automatic process) for improving the performance by changing the weight assignments\n- Update the weight values based on the performance with the current values\n\n\n\nprogram-using-weight-assignments.png\n\n\n\nA system that used Weight Assignment\n\n &gt;Training Machine Learning model with help of weights updating\n &gt;Using the trained model as program\nNow Let’s Build Our First Model!"
  },
  {
    "objectID": "posts/Fastai_ch1/Chapter1.html#first-deep-learning-model-its-a-bird",
    "href": "posts/Fastai_ch1/Chapter1.html#first-deep-learning-model-its-a-bird",
    "title": "Chapter 1: Deep learning for coders with fastai and pytorch",
    "section": "First Deep Learning Model: It’s a Bird!",
    "text": "First Deep Learning Model: It’s a Bird!\n\nImport Dependencies\n\n#Import fastai library\n#Import fastai computer vision library \nfrom fastbook import *\nfrom fastai.vision.all import *\n\n\n\nStart working with Data\n\n# Here we use search_images_ddg in order to download an url from ddg\n# search engine accornding to the keyword we choose: birds photo\nurls = search_images_ddg('birds photo', max_images=1)\nlen(urls), urls[0]\n\n(1,\n 'https://www.wallpapergeeks.com/wp-content/uploads/2014/02/Colorful-Bird-Perched-Wallpaper.jpg')\n\n\n\n# download the photo from the url\ndest = 'bird.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nPath('bird.jpg')\n\n\n\n# then show it\nim = Image.open(dest)\nim.to_thumb(256,256)\n\n\n\n\n\n\n\n\nNow we will do the same etapes we did with bird.jpg image but with forest picture\n\n# Download the url, download the image then open it\ndownload_url(search_images_ddg('forest photos', max_images=1)[0], 'forest.jpg', show_progress=False)\nImage.open('forest.jpg').to_thumb(256,256)\n\n\n\n\n\n\n\n\nThe idea here is to build a model that can classify pictures of birds and forests accuratly, but first we need to build the Dataset\n\n# create 2 directories, one for birds and other for forest, then do the same etapes we did earlier,\n# download the urls then the images\nsearches = 'forest','bird'\npath = Path('bird_or_not')\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images_ddg(f'{o} photo'))\n    resize_images(path/o, max_size=400, dest=path/o)\n\nSince we are dowlnloading images from the web, there is a chance that some of them are corrupted, so we need to clean the dataset from them\n\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n1\n\n\n\nNow we have two directories :\n\nbirds\nforests\n\nAs we saw before, machine learning model needs to be feed many examples in order to learn from them.\nThese examples are the images of birds and forests in our case\nWe need to tell the model bunch of informations about our data before the training process, this will be done with help of DataBlock\n\n\n\nCreating DataBlock and DataLoaders\nNow we need to build DataBlock in order to feed the dataset to the model for the training.it’s basically set of rules of how to organize the dataset for the model.\nI will write a BlogPost about this concept later\nThere’s also the concept of DataLoaders which is an iterator class that load data to the model according to the set of rules that we set earlier while creating DataBlock\n\n# create the dataBlock\n# tell the model what kind of data we'r dealing with\n# how to get the data\n# how to create validation and training set\n# how to get the labels\n# how to set tranformers(items in this case)\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path)\n\ndls.show_batch(max_n=6)\n\n\n\n\n\n\n\n\n\n\nTraining the Model\nNow we are ready to train our model and see if we could classify photo of birds and forests\nThe model we will use here is resenet18 which is a famous model that’s used widely among computer vision classification problem, 18 stands for how many layers does the model have.\nfastai comes with fine_tune() which uses the best practices of fine tuning process.\n\nlearn =  vision_learner(dls, resnet18, metrics= error_rate)\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.550929\n2.057105\n0.447368\n00:02\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nerror_rate\ntime\n\n\n\n\n0\n0.084728\n0.225560\n0.092105\n00:02\n\n\n1\n0.045721\n0.024148\n0.000000\n00:02\n\n\n2\n0.031065\n0.012299\n0.000000\n00:02\n\n\n\n\n\n\nWith help of fastai library, and less than 20 lines of code we managed to build a model that can predict images of birds and forests with accuracy of 100%!\n\n\n\nFine Tuning\nis a process where we start with a model that has already be trained and we use it on our problem and on our dataset, this operation needs to adapt the pre-trained model by a bit so it fit our system\nThis approach can save us money and time, all we need to do is adapt the pre-trained model and take advantage of set of weights and use them in our problem\n\n\n\nLearner\nIn Fastai we have the Learner which takes 2 things(For now!): firsly the Dataset, and secondly the Model.\nBecause Deep Learning is more mature now,there’s a small group of Architecture that can be used in nearly any problem, that’s why the actual work of deep learning practionaire is to work on data preparation, and model deploying, more than anything else.\nThis is why Fastai integrated a famous library Timm which collect all SOTA (State Of The Art) computer vision models.\n\n\nVisualizing layers of a trained neural network\n\nIt is possible to inspect deep learning models and get insights from them\n\ncan still be challenging to fully understand\n\nVisualizing and Understanding Convolutional Networks paper\n\npublished by PhD student Matt Zeiler and his supervisor Rob Fergus in 2013\nshowed how to visualize the neural network weights learned in each layer of a model\ndiscovered the early layers in a convolutional neural network recognize edges and simple patterns which are combined in later layers to detect more complex shapes\n\nWe will see this paper in details later, but for now we could show the model architecture.\n\n\n# show the model architecture\nm = learn.model\nm\n\nSequential(\n  (0): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (5): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (6): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (7): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (1): Sequential(\n    (0): AdaptiveConcatPool2d(\n      (ap): AdaptiveAvgPool2d(output_size=1)\n      (mp): AdaptiveMaxPool2d(output_size=1)\n    )\n    (1): fastai.layers.Flatten(full=False)\n    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=1024, out_features=512, bias=False)\n    (5): ReLU(inplace=True)\n    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.5, inplace=False)\n    (8): Linear(in_features=512, out_features=2, bias=False)\n  )\n)\n\n\n\n\nOther Deep Learning Applications\n\nImage Segmentation\n\ntraining a model to recognize the content of every single pixel in an image\n\n\n\n\n\noutput_47_2.png\n\n\n\nNatural Language Processing (NLP)\n\ngenerate text\ntranslate from one language to another\nanalyze comments\nlabel words in sentences\n\nTabular Data\n\ndata that in in the form of a table\n\nspreedsheets\ndatabases\nComma-separated Values (CSV) files\n\nmodel tries to predict the value of one column based on information in other columns\n\nRecommendation Systems\n\nmodel tries to predict the rating a user would give for something"
  },
  {
    "objectID": "posts/Learning_CPP/arrays_lesson.html",
    "href": "posts/Learning_CPP/arrays_lesson.html",
    "title": "Learning CPP As Pythonista: Day-4",
    "section": "",
    "text": "After learning how to control program flow with loops, I moved on to arrays which is a key concept that brings structure to repetitive data. Instead of creating separate variables for each value, arrays let me group them together and access each element using an index. This chapter helped me see how loops and arrays work hand in hand to process multiple pieces of data efficiently.\n\n\n\nLearned how to declare and initialize arrays of both strings and integers.\nPracticed indexing elements to store and access data.\nUsed a for loop to iterate over array elements.\nCombined two arrays (arr and yearOfBirth) using the same index to relate data.\nReinforced using input/output (cin, cout) with arrays.\nSaw how arrays can replace multiple separate variables efficiently.\n\n\n\nCode\n#include &lt;iostream&gt;                                                                \n#include &lt;string&gt;                                                                  \nusing namespace std;                                                               \n                                                                                   \nint main()                                                                         \n{                                                                                  \n  string arr[4];                                                                   \n  arr[0] = \"Ismail\";                                                               \n  arr[1] = \"Sarah\";                                                                \n  arr[2] = \"Sifao\";                                                                \n  arr[3] = \"Yuba\";                                                                 \n                                                                                   \n  int yearOfBirth[] = {1989, 2002, 2028, 2028};                                    \n  int currentYear;                                                                 \n  cout &lt;&lt; \"Enter in the current year: \" &lt;&lt; endl;                                   \n  cin &gt;&gt; currentYear;                                                              \n                                                                                   \n  for(int i = 0; i &lt; 4; i++)                                                       \n  {                                                                                \n    int age = currentYear - yearOfBirth[i];                                        \n    cout &lt;&lt; arr[i] &lt;&lt; \" born \" &lt;&lt; yearOfBirth[i] &lt;&lt; \" age: \" &lt;&lt; age &lt;&lt; endl;       \n  }                                                                                \n  return 0;                                                                        \n}                                                                                  \n\n\n\n\n\n\nIntroduced the idea of nested loops to compare array elements.\nUsed an inner loop to calculate relationships between all pairs (differences in ages).\nLearned how to avoid comparing an element to itself using an if (j != i) condition.\nPracticed loop logic with multiple arrays in a single program.\nUnderstood how nested loops quickly increase the number of operations (n²).\nStrengthened the mental model of outer vs. inner loop roles.\n\n\n\nCode\n#include &lt;iostream&gt;                                                              \n#include &lt;string&gt;                                                                \nusing namespace std;                                                             \n                                                                                 \n                                                                                 \nint main()                                                                       \n{                                                                                \n  string names[4];                                                               \n  names[0] = \"Ismail\";                                                           \n  names[1] = \"Sarah\";                                                            \n  names[2] = \"Sifao\";                                                            \n  names[3] = \"Yuba\";                                                             \n                                                                                 \n  int yearOfBirth[] = {1989, 2002, 2028, 2028};                                  \n  int currenYear;                                                                \n  cout &lt;&lt; \"Enter in the current year: \" &lt;&lt; endl;                                 \n  cin &gt;&gt; currenYear;                                                             \n                                                                                 \n  for(int i = 0; i &lt; 4; i++)                                                     \n  {                                                                              \n                                                                                 \n    cout &lt;&lt; \"Difference in ages: \" &lt;&lt; names[i] &lt;&lt; \" : \";                         \n    for(int j = 0; j &lt; 4; j++)                                                   \n    {                                                                            \n                                                                                 \n      if(j != i)                                                                 \n      {                                                                          \n        cout &lt;&lt; names[j] &lt;&lt; \" \" &lt;&lt; yearOfBirth[j] - yearOfBirth[i] &lt;&lt; \" \";       \n      }                                                                          \n    }                                                                            \n                                                                                 \n    cout &lt;&lt; endl;                                                                \n  }                                                                              \n                                                                                 \n  return 0;                                                                      \n}                                                                                \n\n\n\n\n\n\nLearned to fill arrays dynamically based on user input rather than predefined data.\nUsed a counter (numberOfElements) to track how many entries the user provided.\nPracticed calculating sum and average using array values.\nGot introduced to variance and standard deviation, reinforcing mathematical processing with arrays.\nUnderstood the importance of loop limits and correct variable initialization.\nReinforced using break statements and conditional user responses to stop input early.\n\n\n\nCode\n#include &lt;iostream&gt;                                                             \n#include &lt;string&gt;                                                               \n#include &lt;cmath&gt;                                                                \nusing namespace std;                                                            \n                                                                                \nint main()                                                                      \n{                                                                               \n  int nums[20];                                                                 \n  int num;                                                                      \n  int sum = 0;                                                                  \n  int numberOfElements;                                                         \n  char response;                                                                \n  for(int i = 0; i &lt; 20; i++)                                                   \n  {                                                                             \n    cout &lt;&lt; \"enter in a number: \" &lt;&lt; endl;                                      \n    cin &gt;&gt; num;                                                                 \n                                                                                \n    nums[i] = num;                                                              \n    numberOfElements++;                                                         \n                                                                                \n    if(i &lt; 19)                                                                  \n    {                                                                           \n      cout &lt;&lt; \"Would you like to add another number? (Y)es Or (N)o \" &lt;&lt; endl;   \n      cin &gt;&gt; response;                                                          \n      if( response != 'Y')                                                      \n      {                                                                         \n        break;                                                                  \n      }                                                                         \n    }                                                                           \n    sum = sum + nums[i];                                                        \n    cout &lt;&lt; sum &lt;&lt; \" \" &lt;&lt; nums[i] &lt;&lt; endl;                                      \n  }                                                                             \n  float avg = float(sum) / float(numberOfElements);                             \n  float sumSDV = 0.0;                                                           \n  cout &lt;&lt; \"The average is: \" &lt;&lt; avg &lt;&lt; endl;                                    \n  float diff;                                                                   \n                                                                                \n  for(int i=0; i&lt;=numberOfElements; i++)                                        \n  {                                                                             \n    diff = nums[i] - avg;                                                       \n    sumSDV = sumSDV + (diff * diff);                                            \n                                                                                \n  }                                                                             \n  float variance = float(diff) / float(numberOfElements);                       \n  float standardDV = sqrt(variance);                                            \n                                                                                \n  cout &lt;&lt; \"The variance is \" &lt;&lt; variance &lt;&lt; endl;                               \n  cout &lt;&lt; \"The standard deviation is \" &lt;&lt; standardDV &lt;&lt; endl;                   \n  return 0;                                                                     \n}                                                                               \n\n\n\n\n\n\nPracticed creating a 2D array to simulate a grid of coin flips.\nUsed rand() and **srand(time(0))** to generate random outcomes.\nReinforced nested loop iteration for 2D data structures (rows and columns).\nRepresented outcomes (H or T) with characters instead of numbers.\nDisplayed a 2D grid output neatly using nested cout loops.\nBuilt intuition for how 2D arrays represent tables, matrices, or grids.\n\n\n\nCode\n#include &lt;iostream&gt;                                  \n#include &lt;string&gt;                                    \n#include &lt;ctime&gt;                                     \nusing namespace std;                                 \n                                                     \n                                                     \nint main()                                           \n{                                                    \n  char coinFlip[10][10];                             \n  srand(time(0));                                    \n                                                     \n  for(int row = 0; row &lt; 10; row++)                  \n  {                                                  \n    for(int col = 0; col &lt; 10; col++)                \n    {                                                \n      if(rand() % 2 == 0)                            \n      {                                              \n        coinFlip[row][col] = 'H';                    \n      }                                              \n      else                                           \n      {                                              \n        coinFlip[row][col] = 'T';                    \n      }                                              \n    }                                                \n  }                                                  \n  for(int row = 0; row &lt; 10; row++)                  \n  {                                                  \n    for(int col = 0; col &lt; 10; col++)                \n    {                                                \n      cout &lt;&lt; coinFlip[row][col] &lt;&lt; \" \";             \n    }                                                \n    cout &lt;&lt; endl;                                    \n  }                                                  \n                                                     \n  return 0;                                          \n}                                                    \n\n\n\n\n\n\nImproved the previous coin flip simulation with constants for clearer structure.\nLearned to calculate row-based statistics (percent of heads and tails).\nPracticed using floating-point division and type casting for accuracy.\nReinforced using iomanip and setprecision() for formatted output.\nUnderstood how to store computed values in a separate array (percentageOfHeadsInARow).\nBuilt intuition for how arrays can represent probability distributions or statistics.\n\n\n\nCode\n#include &lt;iostream&gt;                                                                       \n#include &lt;string&gt;                                                                         \n#include &lt;ctime&gt;                                                                          \n#include &lt;iomanip&gt;                                                                        \nusing namespace std;                                                                      \n                                                                                          \n                                                                                          \nint main()                                                                                \n{                                                                                         \n  const int NUM_OF_ROWS = 10;                                                             \n  const int NUM_OF_FLIP_PER_ROW = 15;                                                     \n                                                                                          \n                                                                                          \n  char coinFlip[NUM_OF_ROWS][NUM_OF_FLIP_PER_ROW];                                        \n                                                                                          \n  srand(time(0));                                                                         \n  float  sumOfRowPercentages = 0.0;                                                       \n  for(int row = 0; row &lt; NUM_OF_ROWS; row++)                                              \n  {                                                                                       \n    cout &lt;&lt; fixed &lt;&lt; setprecision(2);                                                     \n                                                                                          \n    float percentageOfHeadsInARow[NUM_OF_ROWS];                                           \n    float sumOfRowPercentages = 0.0;                                                      \n    int numOfHeadsPerRow = 0;                                                             \n    for(int col = 0; col &lt; NUM_OF_FLIP_PER_ROW; col++)                                    \n    {                                                                                     \n      if(rand() % 2 == 0)                                                                 \n      {                                                                                   \n        coinFlip[row][col] = 'H';                                                         \n        numOfHeadsPerRow++;                                                               \n      }                                                                                   \n      else                                                                                \n      {                                                                                   \n        coinFlip[row][col] = 'T';                                                         \n      }                                                                                   \n      cout &lt;&lt; coinFlip[row][col] &lt;&lt; \" \";                                                  \n                                                                                          \n    }                                                                                     \n                                                                                          \n    percentageOfHeadsInARow[row] = (float)numOfHeadsPerRow / (float)NUM_OF_FLIP_PER_ROW;  \n    //sumOfRowPercentages += percentageOfHeadsInARow[row];                                \n                                                                                          \n                                                                                          \n    cout &lt;&lt; \" | Heads: \" &lt;&lt; percentageOfHeadsInARow[row] * 100 &lt;&lt; \"%.\";                   \n    cout &lt;&lt; \" | Tails: \" &lt;&lt; ((1 - percentageOfHeadsInARow[row]) * 100) &lt;&lt; \"%.\";           \n    //cout &lt;&lt; sumOfRowPercentages;                                                        \n    cout &lt;&lt; endl;                                                                         \n  }                                                                                       \n                                                                                          \n  return 0;                                                                               \n}                                                                                         \n\n\n\n\n\n\nIntroduced multi-dimensional arrays (3D) for complex data storage.\nModeled real-world hierarchical data: years → weeks → days.\nPracticed deep nested loops to initialize and process multi-level data.\nReinforced using input validation with range checks for each dimension.\nLearned to calculate aggregates (e.g., total sales per week, per day, across years).\nUnderstood how 3D arrays extend the same principles from 1D/2D to represent structured data.\n\n\n\nCode\n#include &lt;iostream&gt;                                                                                                                                                                     \n#include &lt;string&gt;                                                                                                                                                                       \nusing namespace std;                                                                                                                                                                    \n                                                                                                                                                                                        \nint main()                                                                                                                                                                              \n{                                                                                                                                                                                       \n  const int NUM_YEARS_IN_SALES = 10;                                                                                                                                                    \n  const int NUM_WEEKS_IN_YEAR = 52;                                                                                                                                                     \n  const int NUM_DAYS_IN_WEEKS = 7;                                                                                                                                                      \n                                                                                                                                                                                        \n  int numCarsSold[NUM_YEARS_IN_SALES][NUM_WEEKS_IN_YEAR][NUM_DAYS_IN_WEEKS];                                                                                                            \n                                                                                                                                                                                        \n  for(int year = 0; year &lt; NUM_YEARS_IN_SALES; year++)                                                                                                                                  \n  {                                                                                                                                                                                     \n    for(int week = 0; week &lt; NUM_WEEKS_IN_YEAR; week++)                                                                                                                                 \n    {                                                                                                                                                                                   \n      for(int day = 0; day &lt; NUM_DAYS_IN_WEEKS; day++)                                                                                                                                  \n      {                                                                                                                                                                                 \n        numCarsSold[year][week][day] = 0;                                                                                                                                               \n      }                                                                                                                                                                                 \n    }                                                                                                                                                                                   \n  }                                                                                                                                                                                     \n  cout &lt;&lt; \"Enter in the car sales for the 10 years. \";                                                                                                                                  \n  int enteredYear;                                                                                                                                                                      \n  int enteredWeek;                                                                                                                                                                      \n  int enteredDay;                                                                                                                                                                       \n  int numCarsSoldInADay;                                                                                                                                                                \n                                                                                                                                                                                        \n  char answer = 'y';                                                                                                                                                                    \n  while(answer == 'y')                                                                                                                                                                  \n  {                                                                                                                                                                                     \n    cout &lt;&lt; \"Enter in a year number: \" &lt;&lt; endl;                                                                                                                                         \n    cin &gt;&gt; enteredYear;                                                                                                                                                                 \n                                                                                                                                                                                        \n    cout &lt;&lt; \"Enter in a week number\" &lt;&lt; endl;                                                                                                                                           \n    cin &gt;&gt; enteredWeek;                                                                                                                                                                 \n                                                                                                                                                                                        \n    cout &lt;&lt; \"Enter in a day number: \" &lt;&lt; endl;                                                                                                                                          \n    cin &gt;&gt; enteredDay;                                                                                                                                                                  \n                                                                                                                                                                                        \n    cout &lt;&lt; \"Enter in number of cars were sold in that particular day: \" &lt;&lt; endl;                                                                                                       \n    cin &gt;&gt; numCarsSoldInADay;                                                                                                                                                           \n                                                                                                                                                                                        \n    if((enteredYear &gt;= 0 && enteredYear &lt; NUM_YEARS_IN_SALES) &&                                                                                                                        \n       (enteredWeek &gt;= 0 && enteredWeek &lt; NUM_WEEKS_IN_YEAR) &&                                                                                                                         \n       (enteredDay &gt;= 0 && enteredDay &lt; NUM_DAYS_IN_WEEKS))                                                                                                                             \n    {                                                                                                                                                                                   \n      numCarsSold[NUM_YEARS_IN_SALES][NUM_WEEKS_IN_YEAR][NUM_DAYS_IN_WEEKS] = numCarsSoldInADay;                                                                                        \n    }                                                                                                                                                                                   \n    else                                                                                                                                                                                \n    {                                                                                                                                                                                   \n      cout &lt;&lt; \"You entered invalid year/week/day combination\" &lt;&lt; endl;                                                                                                                  \n    }                                                                                                                                                                                   \n                                                                                                                                                                                        \n    cout &lt;&lt; \"Would you like to enter another sales day (y or n):  \" &lt;&lt; endl;                                                                                                            \n    cin &gt;&gt; answer;                                                                                                                                                                      \n  }                                                                                                                                                                                     \n  int weeklySaleYearNumber;                                                                                                                                                             \n  int weeklySaleWeekNumber;                                                                                                                                                             \n                                                                                                                                                                                        \n                                                                                                                                                                                        \n  cout &lt;&lt; \"Enter in the year number: \" &lt;&lt; endl;                                                                                                                                         \n  cin &gt;&gt; weeklySaleYearNumber;                                                                                                                                                          \n                                                                                                                                                                                        \n  cout &lt;&lt; \"Enter in the week number: \" &lt;&lt; endl;                                                                                                                                         \n  cin &gt;&gt; weeklySaleWeekNumber;                                                                                                                                                          \n  if((weeklySaleYearNumber &gt;= 0 && weeklySaleYearNumber &lt; NUM_YEARS_IN_SALES) &&                                                                                                        \n     (weeklySaleWeekNumber &gt;= 0 && weeklySaleWeekNumber &lt; NUM_WEEKS_IN_YEAR))                                                                                                           \n  {                                                                                                                                                                                     \n    int sum = 0;                                                                                                                                                                        \n    for(int day = 0; day &lt; weeklySaleYearNumber; day++)                                                                                                                                 \n    {                                                                                                                                                                                   \n      sum += numCarsSold[weeklySaleYearNumber][weeklySaleWeekNumber][day];                                                                                                              \n    }                                                                                                                                                                                   \n    cout &lt;&lt; \"The sum of cars sold in the week: \" &lt;&lt; sum &lt;&lt; endl;                                                                                                                        \n  }                                                                                                                                                                                     \n  else                                                                                                                                                                                  \n  {                                                                                                                                                                                     \n    cout &lt;&lt; \"Couldn't find sales for the same day with those inputs.\" &lt;&lt; endl;                                                                                                          \n  }                                                                                                                                                                                     \n                                                                                                                                                                                        \n                                                                                                                                                                                        \n  int allSameDaySalesYear;                                                                                                                                                              \n  int allSameDaySalesDay;                                                                                                                                                               \n                                                                                                                                                                                        \n  cout &lt;&lt; \"Enter in the year number: \" &lt;&lt; endl;                                                                                                                                         \n  cin &gt;&gt; allSameDaySalesYear;                                                                                                                                                           \n  cout &lt;&lt; \"Enter in a day number (0 for sunday, 1 for monday ..etc): \" &lt;&lt; endl;                                                                                                         \n  cin &gt;&gt; allSameDaySalesDay;                                                                                                                                                            \n                                                                                                                                                                                        \n                                                                                                                                                                                        \n  if((allSameDaySalesYear &gt;= 0 && allSameDaySalesYear &lt; NUM_YEARS_IN_SALES) &&                                                                                                          \n     (allSameDaySalesDay &gt;= 0 && allSameDaySalesDay &lt; NUM_DAYS_IN_WEEKS))                                                                                                               \n  {                                                                                                                                                                                     \n                                                                                                                                                                                        \n    int sum = 0;                                                                                                                                                                        \n    for(int week= 0; week &lt; NUM_WEEKS_IN_YEAR; week++)                                                                                                                                  \n    {                                                                                                                                                                                   \n      sum += numCarsSold[allSameDaySalesYear][week][allSameDaySalesDay];                                                                                                                \n    }                                                                                                                                                                                   \n    cout &lt;&lt; \"The sum of cars sold in day of the week \" &lt;&lt; allSameDaySalesDay &lt;&lt; \" during year number: \" &lt;&lt; allSameDaySalesYear &lt;&lt; \" is \" &lt;&lt; sum &lt;&lt; endl;                                \n  }                                                                                                                                                                                     \n  else                                                                                                                                                                                  \n  {                                                                                                                                                                                     \n    cout &lt;&lt; \"Cannot find the sales for the same day of the year with those inputs.\"&lt;&lt;endl;                                                                                              \n  }                                                                                                                                                                                     \n  int weekentered;                                                                                                                                                                      \n                                                                                                                                                                                        \n  cout &lt;&lt; \"Enter in the week number: \" &lt;&lt; endl;                                                                                                                                         \n  cin &gt;&gt; weekentered;                                                                                                                                                                   \n  if(weekentered &gt;= 0 && weekentered &lt; NUM_WEEKS_IN_YEAR)                                                                                                                               \n  {                                                                                                                                                                                     \n    int sum = 0;                                                                                                                                                                        \n    for(int year= 0; year &lt; NUM_YEARS_IN_SALES; year++)                                                                                                                                 \n    {                                                                                                                                                                                   \n      for(int day= 0; day &lt; NUM_DAYS_IN_WEEKS; day++)                                                                                                                                   \n      {                                                                                                                                                                                 \n        sum += numCarsSold[year][weekentered][day];                                                                                                                                     \n      }                                                                                                                                                                                 \n    }                                                                                                                                                                                   \n                                                                                                                                                                                        \n    cout &lt;&lt; \"The sum of cars sold in that speific week during all years is: \" &lt;&lt; sum &lt;&lt; endl;                                                                                           \n  }                                                                                                                                                                                     \n  else                                                                                                                                                                                  \n  {                                                                                                                                                                                     \n    cout &lt;&lt; \"Cannot find the sales for the same day of the year with those inputs.\"&lt;&lt;endl;                                                                                              \n  }                                                                                                                                                                                     \n                                                                                                                                                                                        \n                                                                                                                                                                                        \n  return 0;"
  },
  {
    "objectID": "posts/Learning_CPP/arrays_lesson.html#introduction",
    "href": "posts/Learning_CPP/arrays_lesson.html#introduction",
    "title": "Learning CPP As Pythonista: Day-4",
    "section": "",
    "text": "After learning how to control program flow with loops, I moved on to arrays which is a key concept that brings structure to repetitive data. Instead of creating separate variables for each value, arrays let me group them together and access each element using an index. This chapter helped me see how loops and arrays work hand in hand to process multiple pieces of data efficiently.\n\n\n\nLearned how to declare and initialize arrays of both strings and integers.\nPracticed indexing elements to store and access data.\nUsed a for loop to iterate over array elements.\nCombined two arrays (arr and yearOfBirth) using the same index to relate data.\nReinforced using input/output (cin, cout) with arrays.\nSaw how arrays can replace multiple separate variables efficiently.\n\n\n\nCode\n#include &lt;iostream&gt;                                                                \n#include &lt;string&gt;                                                                  \nusing namespace std;                                                               \n                                                                                   \nint main()                                                                         \n{                                                                                  \n  string arr[4];                                                                   \n  arr[0] = \"Ismail\";                                                               \n  arr[1] = \"Sarah\";                                                                \n  arr[2] = \"Sifao\";                                                                \n  arr[3] = \"Yuba\";                                                                 \n                                                                                   \n  int yearOfBirth[] = {1989, 2002, 2028, 2028};                                    \n  int currentYear;                                                                 \n  cout &lt;&lt; \"Enter in the current year: \" &lt;&lt; endl;                                   \n  cin &gt;&gt; currentYear;                                                              \n                                                                                   \n  for(int i = 0; i &lt; 4; i++)                                                       \n  {                                                                                \n    int age = currentYear - yearOfBirth[i];                                        \n    cout &lt;&lt; arr[i] &lt;&lt; \" born \" &lt;&lt; yearOfBirth[i] &lt;&lt; \" age: \" &lt;&lt; age &lt;&lt; endl;       \n  }                                                                                \n  return 0;                                                                        \n}                                                                                  \n\n\n\n\n\n\nIntroduced the idea of nested loops to compare array elements.\nUsed an inner loop to calculate relationships between all pairs (differences in ages).\nLearned how to avoid comparing an element to itself using an if (j != i) condition.\nPracticed loop logic with multiple arrays in a single program.\nUnderstood how nested loops quickly increase the number of operations (n²).\nStrengthened the mental model of outer vs. inner loop roles.\n\n\n\nCode\n#include &lt;iostream&gt;                                                              \n#include &lt;string&gt;                                                                \nusing namespace std;                                                             \n                                                                                 \n                                                                                 \nint main()                                                                       \n{                                                                                \n  string names[4];                                                               \n  names[0] = \"Ismail\";                                                           \n  names[1] = \"Sarah\";                                                            \n  names[2] = \"Sifao\";                                                            \n  names[3] = \"Yuba\";                                                             \n                                                                                 \n  int yearOfBirth[] = {1989, 2002, 2028, 2028};                                  \n  int currenYear;                                                                \n  cout &lt;&lt; \"Enter in the current year: \" &lt;&lt; endl;                                 \n  cin &gt;&gt; currenYear;                                                             \n                                                                                 \n  for(int i = 0; i &lt; 4; i++)                                                     \n  {                                                                              \n                                                                                 \n    cout &lt;&lt; \"Difference in ages: \" &lt;&lt; names[i] &lt;&lt; \" : \";                         \n    for(int j = 0; j &lt; 4; j++)                                                   \n    {                                                                            \n                                                                                 \n      if(j != i)                                                                 \n      {                                                                          \n        cout &lt;&lt; names[j] &lt;&lt; \" \" &lt;&lt; yearOfBirth[j] - yearOfBirth[i] &lt;&lt; \" \";       \n      }                                                                          \n    }                                                                            \n                                                                                 \n    cout &lt;&lt; endl;                                                                \n  }                                                                              \n                                                                                 \n  return 0;                                                                      \n}                                                                                \n\n\n\n\n\n\nLearned to fill arrays dynamically based on user input rather than predefined data.\nUsed a counter (numberOfElements) to track how many entries the user provided.\nPracticed calculating sum and average using array values.\nGot introduced to variance and standard deviation, reinforcing mathematical processing with arrays.\nUnderstood the importance of loop limits and correct variable initialization.\nReinforced using break statements and conditional user responses to stop input early.\n\n\n\nCode\n#include &lt;iostream&gt;                                                             \n#include &lt;string&gt;                                                               \n#include &lt;cmath&gt;                                                                \nusing namespace std;                                                            \n                                                                                \nint main()                                                                      \n{                                                                               \n  int nums[20];                                                                 \n  int num;                                                                      \n  int sum = 0;                                                                  \n  int numberOfElements;                                                         \n  char response;                                                                \n  for(int i = 0; i &lt; 20; i++)                                                   \n  {                                                                             \n    cout &lt;&lt; \"enter in a number: \" &lt;&lt; endl;                                      \n    cin &gt;&gt; num;                                                                 \n                                                                                \n    nums[i] = num;                                                              \n    numberOfElements++;                                                         \n                                                                                \n    if(i &lt; 19)                                                                  \n    {                                                                           \n      cout &lt;&lt; \"Would you like to add another number? (Y)es Or (N)o \" &lt;&lt; endl;   \n      cin &gt;&gt; response;                                                          \n      if( response != 'Y')                                                      \n      {                                                                         \n        break;                                                                  \n      }                                                                         \n    }                                                                           \n    sum = sum + nums[i];                                                        \n    cout &lt;&lt; sum &lt;&lt; \" \" &lt;&lt; nums[i] &lt;&lt; endl;                                      \n  }                                                                             \n  float avg = float(sum) / float(numberOfElements);                             \n  float sumSDV = 0.0;                                                           \n  cout &lt;&lt; \"The average is: \" &lt;&lt; avg &lt;&lt; endl;                                    \n  float diff;                                                                   \n                                                                                \n  for(int i=0; i&lt;=numberOfElements; i++)                                        \n  {                                                                             \n    diff = nums[i] - avg;                                                       \n    sumSDV = sumSDV + (diff * diff);                                            \n                                                                                \n  }                                                                             \n  float variance = float(diff) / float(numberOfElements);                       \n  float standardDV = sqrt(variance);                                            \n                                                                                \n  cout &lt;&lt; \"The variance is \" &lt;&lt; variance &lt;&lt; endl;                               \n  cout &lt;&lt; \"The standard deviation is \" &lt;&lt; standardDV &lt;&lt; endl;                   \n  return 0;                                                                     \n}                                                                               \n\n\n\n\n\n\nPracticed creating a 2D array to simulate a grid of coin flips.\nUsed rand() and **srand(time(0))** to generate random outcomes.\nReinforced nested loop iteration for 2D data structures (rows and columns).\nRepresented outcomes (H or T) with characters instead of numbers.\nDisplayed a 2D grid output neatly using nested cout loops.\nBuilt intuition for how 2D arrays represent tables, matrices, or grids.\n\n\n\nCode\n#include &lt;iostream&gt;                                  \n#include &lt;string&gt;                                    \n#include &lt;ctime&gt;                                     \nusing namespace std;                                 \n                                                     \n                                                     \nint main()                                           \n{                                                    \n  char coinFlip[10][10];                             \n  srand(time(0));                                    \n                                                     \n  for(int row = 0; row &lt; 10; row++)                  \n  {                                                  \n    for(int col = 0; col &lt; 10; col++)                \n    {                                                \n      if(rand() % 2 == 0)                            \n      {                                              \n        coinFlip[row][col] = 'H';                    \n      }                                              \n      else                                           \n      {                                              \n        coinFlip[row][col] = 'T';                    \n      }                                              \n    }                                                \n  }                                                  \n  for(int row = 0; row &lt; 10; row++)                  \n  {                                                  \n    for(int col = 0; col &lt; 10; col++)                \n    {                                                \n      cout &lt;&lt; coinFlip[row][col] &lt;&lt; \" \";             \n    }                                                \n    cout &lt;&lt; endl;                                    \n  }                                                  \n                                                     \n  return 0;                                          \n}                                                    \n\n\n\n\n\n\nImproved the previous coin flip simulation with constants for clearer structure.\nLearned to calculate row-based statistics (percent of heads and tails).\nPracticed using floating-point division and type casting for accuracy.\nReinforced using iomanip and setprecision() for formatted output.\nUnderstood how to store computed values in a separate array (percentageOfHeadsInARow).\nBuilt intuition for how arrays can represent probability distributions or statistics.\n\n\n\nCode\n#include &lt;iostream&gt;                                                                       \n#include &lt;string&gt;                                                                         \n#include &lt;ctime&gt;                                                                          \n#include &lt;iomanip&gt;                                                                        \nusing namespace std;                                                                      \n                                                                                          \n                                                                                          \nint main()                                                                                \n{                                                                                         \n  const int NUM_OF_ROWS = 10;                                                             \n  const int NUM_OF_FLIP_PER_ROW = 15;                                                     \n                                                                                          \n                                                                                          \n  char coinFlip[NUM_OF_ROWS][NUM_OF_FLIP_PER_ROW];                                        \n                                                                                          \n  srand(time(0));                                                                         \n  float  sumOfRowPercentages = 0.0;                                                       \n  for(int row = 0; row &lt; NUM_OF_ROWS; row++)                                              \n  {                                                                                       \n    cout &lt;&lt; fixed &lt;&lt; setprecision(2);                                                     \n                                                                                          \n    float percentageOfHeadsInARow[NUM_OF_ROWS];                                           \n    float sumOfRowPercentages = 0.0;                                                      \n    int numOfHeadsPerRow = 0;                                                             \n    for(int col = 0; col &lt; NUM_OF_FLIP_PER_ROW; col++)                                    \n    {                                                                                     \n      if(rand() % 2 == 0)                                                                 \n      {                                                                                   \n        coinFlip[row][col] = 'H';                                                         \n        numOfHeadsPerRow++;                                                               \n      }                                                                                   \n      else                                                                                \n      {                                                                                   \n        coinFlip[row][col] = 'T';                                                         \n      }                                                                                   \n      cout &lt;&lt; coinFlip[row][col] &lt;&lt; \" \";                                                  \n                                                                                          \n    }                                                                                     \n                                                                                          \n    percentageOfHeadsInARow[row] = (float)numOfHeadsPerRow / (float)NUM_OF_FLIP_PER_ROW;  \n    //sumOfRowPercentages += percentageOfHeadsInARow[row];                                \n                                                                                          \n                                                                                          \n    cout &lt;&lt; \" | Heads: \" &lt;&lt; percentageOfHeadsInARow[row] * 100 &lt;&lt; \"%.\";                   \n    cout &lt;&lt; \" | Tails: \" &lt;&lt; ((1 - percentageOfHeadsInARow[row]) * 100) &lt;&lt; \"%.\";           \n    //cout &lt;&lt; sumOfRowPercentages;                                                        \n    cout &lt;&lt; endl;                                                                         \n  }                                                                                       \n                                                                                          \n  return 0;                                                                               \n}                                                                                         \n\n\n\n\n\n\nIntroduced multi-dimensional arrays (3D) for complex data storage.\nModeled real-world hierarchical data: years → weeks → days.\nPracticed deep nested loops to initialize and process multi-level data.\nReinforced using input validation with range checks for each dimension.\nLearned to calculate aggregates (e.g., total sales per week, per day, across years).\nUnderstood how 3D arrays extend the same principles from 1D/2D to represent structured data.\n\n\n\nCode\n#include &lt;iostream&gt;                                                                                                                                                                     \n#include &lt;string&gt;                                                                                                                                                                       \nusing namespace std;                                                                                                                                                                    \n                                                                                                                                                                                        \nint main()                                                                                                                                                                              \n{                                                                                                                                                                                       \n  const int NUM_YEARS_IN_SALES = 10;                                                                                                                                                    \n  const int NUM_WEEKS_IN_YEAR = 52;                                                                                                                                                     \n  const int NUM_DAYS_IN_WEEKS = 7;                                                                                                                                                      \n                                                                                                                                                                                        \n  int numCarsSold[NUM_YEARS_IN_SALES][NUM_WEEKS_IN_YEAR][NUM_DAYS_IN_WEEKS];                                                                                                            \n                                                                                                                                                                                        \n  for(int year = 0; year &lt; NUM_YEARS_IN_SALES; year++)                                                                                                                                  \n  {                                                                                                                                                                                     \n    for(int week = 0; week &lt; NUM_WEEKS_IN_YEAR; week++)                                                                                                                                 \n    {                                                                                                                                                                                   \n      for(int day = 0; day &lt; NUM_DAYS_IN_WEEKS; day++)                                                                                                                                  \n      {                                                                                                                                                                                 \n        numCarsSold[year][week][day] = 0;                                                                                                                                               \n      }                                                                                                                                                                                 \n    }                                                                                                                                                                                   \n  }                                                                                                                                                                                     \n  cout &lt;&lt; \"Enter in the car sales for the 10 years. \";                                                                                                                                  \n  int enteredYear;                                                                                                                                                                      \n  int enteredWeek;                                                                                                                                                                      \n  int enteredDay;                                                                                                                                                                       \n  int numCarsSoldInADay;                                                                                                                                                                \n                                                                                                                                                                                        \n  char answer = 'y';                                                                                                                                                                    \n  while(answer == 'y')                                                                                                                                                                  \n  {                                                                                                                                                                                     \n    cout &lt;&lt; \"Enter in a year number: \" &lt;&lt; endl;                                                                                                                                         \n    cin &gt;&gt; enteredYear;                                                                                                                                                                 \n                                                                                                                                                                                        \n    cout &lt;&lt; \"Enter in a week number\" &lt;&lt; endl;                                                                                                                                           \n    cin &gt;&gt; enteredWeek;                                                                                                                                                                 \n                                                                                                                                                                                        \n    cout &lt;&lt; \"Enter in a day number: \" &lt;&lt; endl;                                                                                                                                          \n    cin &gt;&gt; enteredDay;                                                                                                                                                                  \n                                                                                                                                                                                        \n    cout &lt;&lt; \"Enter in number of cars were sold in that particular day: \" &lt;&lt; endl;                                                                                                       \n    cin &gt;&gt; numCarsSoldInADay;                                                                                                                                                           \n                                                                                                                                                                                        \n    if((enteredYear &gt;= 0 && enteredYear &lt; NUM_YEARS_IN_SALES) &&                                                                                                                        \n       (enteredWeek &gt;= 0 && enteredWeek &lt; NUM_WEEKS_IN_YEAR) &&                                                                                                                         \n       (enteredDay &gt;= 0 && enteredDay &lt; NUM_DAYS_IN_WEEKS))                                                                                                                             \n    {                                                                                                                                                                                   \n      numCarsSold[NUM_YEARS_IN_SALES][NUM_WEEKS_IN_YEAR][NUM_DAYS_IN_WEEKS] = numCarsSoldInADay;                                                                                        \n    }                                                                                                                                                                                   \n    else                                                                                                                                                                                \n    {                                                                                                                                                                                   \n      cout &lt;&lt; \"You entered invalid year/week/day combination\" &lt;&lt; endl;                                                                                                                  \n    }                                                                                                                                                                                   \n                                                                                                                                                                                        \n    cout &lt;&lt; \"Would you like to enter another sales day (y or n):  \" &lt;&lt; endl;                                                                                                            \n    cin &gt;&gt; answer;                                                                                                                                                                      \n  }                                                                                                                                                                                     \n  int weeklySaleYearNumber;                                                                                                                                                             \n  int weeklySaleWeekNumber;                                                                                                                                                             \n                                                                                                                                                                                        \n                                                                                                                                                                                        \n  cout &lt;&lt; \"Enter in the year number: \" &lt;&lt; endl;                                                                                                                                         \n  cin &gt;&gt; weeklySaleYearNumber;                                                                                                                                                          \n                                                                                                                                                                                        \n  cout &lt;&lt; \"Enter in the week number: \" &lt;&lt; endl;                                                                                                                                         \n  cin &gt;&gt; weeklySaleWeekNumber;                                                                                                                                                          \n  if((weeklySaleYearNumber &gt;= 0 && weeklySaleYearNumber &lt; NUM_YEARS_IN_SALES) &&                                                                                                        \n     (weeklySaleWeekNumber &gt;= 0 && weeklySaleWeekNumber &lt; NUM_WEEKS_IN_YEAR))                                                                                                           \n  {                                                                                                                                                                                     \n    int sum = 0;                                                                                                                                                                        \n    for(int day = 0; day &lt; weeklySaleYearNumber; day++)                                                                                                                                 \n    {                                                                                                                                                                                   \n      sum += numCarsSold[weeklySaleYearNumber][weeklySaleWeekNumber][day];                                                                                                              \n    }                                                                                                                                                                                   \n    cout &lt;&lt; \"The sum of cars sold in the week: \" &lt;&lt; sum &lt;&lt; endl;                                                                                                                        \n  }                                                                                                                                                                                     \n  else                                                                                                                                                                                  \n  {                                                                                                                                                                                     \n    cout &lt;&lt; \"Couldn't find sales for the same day with those inputs.\" &lt;&lt; endl;                                                                                                          \n  }                                                                                                                                                                                     \n                                                                                                                                                                                        \n                                                                                                                                                                                        \n  int allSameDaySalesYear;                                                                                                                                                              \n  int allSameDaySalesDay;                                                                                                                                                               \n                                                                                                                                                                                        \n  cout &lt;&lt; \"Enter in the year number: \" &lt;&lt; endl;                                                                                                                                         \n  cin &gt;&gt; allSameDaySalesYear;                                                                                                                                                           \n  cout &lt;&lt; \"Enter in a day number (0 for sunday, 1 for monday ..etc): \" &lt;&lt; endl;                                                                                                         \n  cin &gt;&gt; allSameDaySalesDay;                                                                                                                                                            \n                                                                                                                                                                                        \n                                                                                                                                                                                        \n  if((allSameDaySalesYear &gt;= 0 && allSameDaySalesYear &lt; NUM_YEARS_IN_SALES) &&                                                                                                          \n     (allSameDaySalesDay &gt;= 0 && allSameDaySalesDay &lt; NUM_DAYS_IN_WEEKS))                                                                                                               \n  {                                                                                                                                                                                     \n                                                                                                                                                                                        \n    int sum = 0;                                                                                                                                                                        \n    for(int week= 0; week &lt; NUM_WEEKS_IN_YEAR; week++)                                                                                                                                  \n    {                                                                                                                                                                                   \n      sum += numCarsSold[allSameDaySalesYear][week][allSameDaySalesDay];                                                                                                                \n    }                                                                                                                                                                                   \n    cout &lt;&lt; \"The sum of cars sold in day of the week \" &lt;&lt; allSameDaySalesDay &lt;&lt; \" during year number: \" &lt;&lt; allSameDaySalesYear &lt;&lt; \" is \" &lt;&lt; sum &lt;&lt; endl;                                \n  }                                                                                                                                                                                     \n  else                                                                                                                                                                                  \n  {                                                                                                                                                                                     \n    cout &lt;&lt; \"Cannot find the sales for the same day of the year with those inputs.\"&lt;&lt;endl;                                                                                              \n  }                                                                                                                                                                                     \n  int weekentered;                                                                                                                                                                      \n                                                                                                                                                                                        \n  cout &lt;&lt; \"Enter in the week number: \" &lt;&lt; endl;                                                                                                                                         \n  cin &gt;&gt; weekentered;                                                                                                                                                                   \n  if(weekentered &gt;= 0 && weekentered &lt; NUM_WEEKS_IN_YEAR)                                                                                                                               \n  {                                                                                                                                                                                     \n    int sum = 0;                                                                                                                                                                        \n    for(int year= 0; year &lt; NUM_YEARS_IN_SALES; year++)                                                                                                                                 \n    {                                                                                                                                                                                   \n      for(int day= 0; day &lt; NUM_DAYS_IN_WEEKS; day++)                                                                                                                                   \n      {                                                                                                                                                                                 \n        sum += numCarsSold[year][weekentered][day];                                                                                                                                     \n      }                                                                                                                                                                                 \n    }                                                                                                                                                                                   \n                                                                                                                                                                                        \n    cout &lt;&lt; \"The sum of cars sold in that speific week during all years is: \" &lt;&lt; sum &lt;&lt; endl;                                                                                           \n  }                                                                                                                                                                                     \n  else                                                                                                                                                                                  \n  {                                                                                                                                                                                     \n    cout &lt;&lt; \"Cannot find the sales for the same day of the year with those inputs.\"&lt;&lt;endl;                                                                                              \n  }                                                                                                                                                                                     \n                                                                                                                                                                                        \n                                                                                                                                                                                        \n  return 0;"
  },
  {
    "objectID": "posts/Learning_CPP/arrays_lesson.html#summary",
    "href": "posts/Learning_CPP/arrays_lesson.html#summary",
    "title": "Learning CPP As Pythonista: Day-4",
    "section": "Summary:",
    "text": "Summary:\nThroughout these exercises, I explored how arrays store and manage collections of related data. I learned to combine loops with arrays to process values efficiently, calculate results like averages and variances, and represent more complex structures such as 2D grids and 3D datasets. This chapter strengthened my understanding of how data can be organized and accessed systematically, setting the stage for more advanced programming concepts."
  },
  {
    "objectID": "posts/Learning_CPP/loops_Lesson.html",
    "href": "posts/Learning_CPP/loops_Lesson.html",
    "title": "Learning CPP As Pythonista: Day-3",
    "section": "",
    "text": "Today I learned how to repeat actions in C++ using while and for loops. I practiced printing values multiple times, validating input, summing ranges of numbers, using nested loops for a multiplication table, and even modifying characters inside a string. I also learned how break and continue can control the flow inside a loop.\n\n\nConcept: Counter-controlled loop\nWhat it does: Asks the user how many times to print their name, then uses a while loop to repeat the output.\nKey learning: Loop structure, incrementing counters.\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\nint main()\n{\n  int numberOfIterations;\n  string name;\n\n  cout &lt;&lt; \"Enter number of times your name will be printed: \" &lt;&lt; endl;\n  cin &gt;&gt; numberOfIterations;\n  cout &lt;&lt; \"Enter your name: \" &lt;&lt; endl;\n  cin &gt;&gt; name;\n\n  int count = 1;\n  while( count &lt;= numberOfIterations)\n  {\n    cout &lt;&lt; name &lt;&lt; endl;\n    count++;\n  }    \n  return 0;\n}  \n\n\n\n\n\nConcept: Boolean condition control (bool + while)\nWhat it does: Keeps asking the user a Yes/No question until the correct answer is given.\nKey learning: Using a flag (doneYet) to control loop exit, if/else inside a loop.\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\nint main()\n{\n  bool doneYet = false;\n  char answer;\n\n  while(!doneYet)\n  {\n    cout &lt;&lt; \"Are you Ismail Taghouchti?:(Y or N)  \" &lt;&lt; endl;\n    cin &gt;&gt; answer;\n    \n    if(answer == 'Y')\n    {\n      doneYet = true;\n      cout &lt;&lt; \"access granted ..\" &lt;&lt; endl;\n    }\n    else \n    {\n      cout &lt;&lt; \"Only Ismail Taghouchti could access.\" &lt;&lt; endl;\n    }\n    \n  }    \n  return 0;\n}  \n\n\n\n\n\nConcepts: Input validation + running total\nWhat it does: Ensures the ending value is larger than the starting value, then calculates the sum step by step.\nKey learning: Nested logic using validation loop followed by a counting accumulation loop.\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\nint main()\n{\n  int startingV;\n  int endingV;\n\n  cout &lt;&lt; \"Enter in a starting value: \";\n  cin &gt;&gt; startingV;\n\n  cout &lt;&lt; \"Enter in an ending value:  \";\n  cin &gt;&gt; endingV;\n\n\n  while( endingV &lt;= startingV)\n  {\n    cout &lt;&lt; \"Please enter starting value larger then ending value. Try again.\" &lt;&lt; endl;\n    cout &lt;&lt; \"Enter in a starting value: \";\n    cin  &gt;&gt; startingV;\n    cout &lt;&lt; \"Enter in a ending value: \" &lt;&lt; endl;\n    cin &gt;&gt; endingV;\n  }\n   \n  int count = startingV + 1;\n  int totalSum = startingV;\n  while(count &lt;= endingV)\n  {\n      cout &lt;&lt; totalSum &lt;&lt; \" + \" &lt;&lt; count &lt;&lt; \" = \";\n      totalSum = totalSum + count;\n      cout &lt;&lt; totalSum &lt;&lt; endl;\n      count ++;\n  }\n    \n  cout &lt;&lt; \"The Sum of the numbers from \" &lt;&lt; startingV &lt;&lt; \" to \" &lt;&lt; endingV &lt;&lt; \" is \";\n  cout &lt;&lt; totalSum &lt;&lt; endl;\n     \n  return 0;\n}\n\n\n\n\n\nConcept: Nested while loops\nWhat it does: Prints a full 9×9 multiplication table by looping rows and columns.\nKey learning: Inner loop runs completely for each iteration of the outer loop.\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\n\nint main()\n{\n  int left;\n  int right;\n  int product;\n  \n\n  left = 1;\n  while(left &lt; 10)\n  {\n    right = 1;\n    while(right &lt; 10)\n    {\n      product = left * right;\n      cout &lt;&lt; left &lt;&lt; \"X\" &lt;&lt; right &lt;&lt; \"=\" &lt;&lt; product &lt;&lt; \" \";\n      right++;\n    }\n    left++;\n    cout &lt;&lt; endl;\n  }\n\n  return 0;\n}\n\n\n\n\n\nConcept: Comparison between for and while for counting\nWhat it does: Same task as Program 3, but uses a for loop for cleaner counting logic.\nKey learning: When iteration count is known → for loop is simpler and more readable.\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\nusing namespace std;\n\nint main()\n{\n  int startingV;\n  int endingV;\n  int sum;\n  \n  cout &lt;&lt; \"Enter in starting value: \" &lt;&lt; endl;\n  cin &gt;&gt; startingV;\n\n  cout &lt;&lt; \"Enter in endingV: \" &lt;&lt; endl;\n  cin &gt;&gt; endingV;\n\n  while(endingV &lt; startingV)\n  {\n    cout &lt;&lt; \"The ending value must be greater than or equal to starting value \" &lt;&lt; startingV &lt;&lt; \"Please enter again: \"&lt;&lt; endl;\n    cin &gt;&gt; startingV;\n\n    cout &lt;&lt; \"Enter in ending value: \" &lt;&lt; endl;\n    cin  &gt;&gt; endingV;\n\n  }    \n  sum = startingV;\n  for(int count = startingV + 1; count &lt;= endingV; count++)\n  {\n    cout &lt;&lt; sum &lt;&lt; \" + \" &lt;&lt; count &lt;&lt; \" = \";\n    sum = sum + count;\n    cout &lt;&lt; sum &lt;&lt; endl;\n  \n  }\n  cout &lt;&lt; \"the summation of numbers from \" &lt;&lt; startingV &lt;&lt; \" to \" &lt;&lt; endingV &lt;&lt; \" is: \" &lt;&lt; sum &lt;&lt; endl;\n  return 0;\n}\n\n\n\n\n\nConcept: Looping through strings using indexes\nWhat it does: Detects spaces and capitalizes the next character.\nKey learning: Boolean flag (isCap) + character processing using toupper().\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\nusing namespace std;\n\nint main()\n{\n  string sentence = \"Today was a bit sunny.\";\n  cout &lt;&lt; sentence &lt;&lt; endl;\n  cout &lt;&lt; \"After Capitalization: \" &lt;&lt; endl;\n  bool isCap = false;\n  for(int i=0; i &lt; sentence.length(); i++)\n  {\n    if(isCap)\n    {\n      char capL = toupper(sentence[i]);\n      cout &lt;&lt; capL;\n      isCap = false;\n    }\n    else \n    {\n      cout &lt;&lt; sentence[i];\n    }\n    if(sentence[i] == ' ')\n    {\n      isCap = true;\n    }\n      \n  }\n  cout &lt;&lt; endl;\n  return 0;\n}\n\n\n\n\n\nConcept: Loop flow control\nWhat it does: Loops from 0 to 49 but:\ncontinue skips printing even numbers\nbreak stops when i == 21\nKey learning: Adjusting loop behavior without changing loop condition.\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\nusing namespace std;\n\n\nint main()\n{\n  for(int i = 0; i &lt; 50; i++)\n  {\n    if(i == 21)\n    {\n      break;\n    }  \n\n    if(i % 2 == 0)\n    {\n      continue;\n    }  \n    cout &lt;&lt; i &lt;&lt; endl;\n  }  \n  return 0;  \n}"
  },
  {
    "objectID": "posts/Learning_CPP/loops_Lesson.html#repeating-output-with-a-while-loop",
    "href": "posts/Learning_CPP/loops_Lesson.html#repeating-output-with-a-while-loop",
    "title": "Learning CPP As Pythonista: Day-3",
    "section": "",
    "text": "Concept: Counter-controlled loop\nWhat it does: Asks the user how many times to print their name, then uses a while loop to repeat the output.\nKey learning: Loop structure, incrementing counters.\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\nint main()\n{\n  int numberOfIterations;\n  string name;\n\n  cout &lt;&lt; \"Enter number of times your name will be printed: \" &lt;&lt; endl;\n  cin &gt;&gt; numberOfIterations;\n  cout &lt;&lt; \"Enter your name: \" &lt;&lt; endl;\n  cin &gt;&gt; name;\n\n  int count = 1;\n  while( count &lt;= numberOfIterations)\n  {\n    cout &lt;&lt; name &lt;&lt; endl;\n    count++;\n  }    \n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/loops_Lesson.html#validating-user-input-in-a-loop",
    "href": "posts/Learning_CPP/loops_Lesson.html#validating-user-input-in-a-loop",
    "title": "Learning CPP As Pythonista: Day-3",
    "section": "",
    "text": "Concept: Boolean condition control (bool + while)\nWhat it does: Keeps asking the user a Yes/No question until the correct answer is given.\nKey learning: Using a flag (doneYet) to control loop exit, if/else inside a loop.\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\nint main()\n{\n  bool doneYet = false;\n  char answer;\n\n  while(!doneYet)\n  {\n    cout &lt;&lt; \"Are you Ismail Taghouchti?:(Y or N)  \" &lt;&lt; endl;\n    cin &gt;&gt; answer;\n    \n    if(answer == 'Y')\n    {\n      doneYet = true;\n      cout &lt;&lt; \"access granted ..\" &lt;&lt; endl;\n    }\n    else \n    {\n      cout &lt;&lt; \"Only Ismail Taghouchti could access.\" &lt;&lt; endl;\n    }\n    \n  }    \n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/loops_Lesson.html#summing-a-range-of-numbers-using-while",
    "href": "posts/Learning_CPP/loops_Lesson.html#summing-a-range-of-numbers-using-while",
    "title": "Learning CPP As Pythonista: Day-3",
    "section": "",
    "text": "Concepts: Input validation + running total\nWhat it does: Ensures the ending value is larger than the starting value, then calculates the sum step by step.\nKey learning: Nested logic using validation loop followed by a counting accumulation loop.\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\nint main()\n{\n  int startingV;\n  int endingV;\n\n  cout &lt;&lt; \"Enter in a starting value: \";\n  cin &gt;&gt; startingV;\n\n  cout &lt;&lt; \"Enter in an ending value:  \";\n  cin &gt;&gt; endingV;\n\n\n  while( endingV &lt;= startingV)\n  {\n    cout &lt;&lt; \"Please enter starting value larger then ending value. Try again.\" &lt;&lt; endl;\n    cout &lt;&lt; \"Enter in a starting value: \";\n    cin  &gt;&gt; startingV;\n    cout &lt;&lt; \"Enter in a ending value: \" &lt;&lt; endl;\n    cin &gt;&gt; endingV;\n  }\n   \n  int count = startingV + 1;\n  int totalSum = startingV;\n  while(count &lt;= endingV)\n  {\n      cout &lt;&lt; totalSum &lt;&lt; \" + \" &lt;&lt; count &lt;&lt; \" = \";\n      totalSum = totalSum + count;\n      cout &lt;&lt; totalSum &lt;&lt; endl;\n      count ++;\n  }\n    \n  cout &lt;&lt; \"The Sum of the numbers from \" &lt;&lt; startingV &lt;&lt; \" to \" &lt;&lt; endingV &lt;&lt; \" is \";\n  cout &lt;&lt; totalSum &lt;&lt; endl;\n     \n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/loops_Lesson.html#multiplication-table-nested-loops",
    "href": "posts/Learning_CPP/loops_Lesson.html#multiplication-table-nested-loops",
    "title": "Learning CPP As Pythonista: Day-3",
    "section": "",
    "text": "Concept: Nested while loops\nWhat it does: Prints a full 9×9 multiplication table by looping rows and columns.\nKey learning: Inner loop runs completely for each iteration of the outer loop.\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\n\nint main()\n{\n  int left;\n  int right;\n  int product;\n  \n\n  left = 1;\n  while(left &lt; 10)\n  {\n    right = 1;\n    while(right &lt; 10)\n    {\n      product = left * right;\n      cout &lt;&lt; left &lt;&lt; \"X\" &lt;&lt; right &lt;&lt; \"=\" &lt;&lt; product &lt;&lt; \" \";\n      right++;\n    }\n    left++;\n    cout &lt;&lt; endl;\n  }\n\n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/loops_Lesson.html#summing-a-range-of-numbers-using-for",
    "href": "posts/Learning_CPP/loops_Lesson.html#summing-a-range-of-numbers-using-for",
    "title": "Learning CPP As Pythonista: Day-3",
    "section": "",
    "text": "Concept: Comparison between for and while for counting\nWhat it does: Same task as Program 3, but uses a for loop for cleaner counting logic.\nKey learning: When iteration count is known → for loop is simpler and more readable.\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\nusing namespace std;\n\nint main()\n{\n  int startingV;\n  int endingV;\n  int sum;\n  \n  cout &lt;&lt; \"Enter in starting value: \" &lt;&lt; endl;\n  cin &gt;&gt; startingV;\n\n  cout &lt;&lt; \"Enter in endingV: \" &lt;&lt; endl;\n  cin &gt;&gt; endingV;\n\n  while(endingV &lt; startingV)\n  {\n    cout &lt;&lt; \"The ending value must be greater than or equal to starting value \" &lt;&lt; startingV &lt;&lt; \"Please enter again: \"&lt;&lt; endl;\n    cin &gt;&gt; startingV;\n\n    cout &lt;&lt; \"Enter in ending value: \" &lt;&lt; endl;\n    cin  &gt;&gt; endingV;\n\n  }    \n  sum = startingV;\n  for(int count = startingV + 1; count &lt;= endingV; count++)\n  {\n    cout &lt;&lt; sum &lt;&lt; \" + \" &lt;&lt; count &lt;&lt; \" = \";\n    sum = sum + count;\n    cout &lt;&lt; sum &lt;&lt; endl;\n  \n  }\n  cout &lt;&lt; \"the summation of numbers from \" &lt;&lt; startingV &lt;&lt; \" to \" &lt;&lt; endingV &lt;&lt; \" is: \" &lt;&lt; sum &lt;&lt; endl;\n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/loops_Lesson.html#capitalizing-letters-after-spaces",
    "href": "posts/Learning_CPP/loops_Lesson.html#capitalizing-letters-after-spaces",
    "title": "Learning CPP As Pythonista: Day-3",
    "section": "",
    "text": "Concept: Looping through strings using indexes\nWhat it does: Detects spaces and capitalizes the next character.\nKey learning: Boolean flag (isCap) + character processing using toupper().\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\nusing namespace std;\n\nint main()\n{\n  string sentence = \"Today was a bit sunny.\";\n  cout &lt;&lt; sentence &lt;&lt; endl;\n  cout &lt;&lt; \"After Capitalization: \" &lt;&lt; endl;\n  bool isCap = false;\n  for(int i=0; i &lt; sentence.length(); i++)\n  {\n    if(isCap)\n    {\n      char capL = toupper(sentence[i]);\n      cout &lt;&lt; capL;\n      isCap = false;\n    }\n    else \n    {\n      cout &lt;&lt; sentence[i];\n    }\n    if(sentence[i] == ' ')\n    {\n      isCap = true;\n    }\n      \n  }\n  cout &lt;&lt; endl;\n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/loops_Lesson.html#using-break-and-continue",
    "href": "posts/Learning_CPP/loops_Lesson.html#using-break-and-continue",
    "title": "Learning CPP As Pythonista: Day-3",
    "section": "",
    "text": "Concept: Loop flow control\nWhat it does: Loops from 0 to 49 but:\ncontinue skips printing even numbers\nbreak stops when i == 21\nKey learning: Adjusting loop behavior without changing loop condition.\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\nusing namespace std;\n\n\nint main()\n{\n  for(int i = 0; i &lt; 50; i++)\n  {\n    if(i == 21)\n    {\n      break;\n    }  \n\n    if(i % 2 == 0)\n    {\n      continue;\n    }  \n    cout &lt;&lt; i &lt;&lt; endl;\n  }  \n  return 0;  \n}"
  },
  {
    "objectID": "posts/Learning_CPP/arrayslesson.html",
    "href": "posts/Learning_CPP/arrayslesson.html",
    "title": "Learning CPP As Pythonista: Day-4",
    "section": "",
    "text": "After learning how to control program flow with loops, I moved on to arrays which is a key concept that brings structure to repetitive data. Instead of creating separate variables for each value, arrays let me group them together and access each element using an index. This chapter helped me see how loops and arrays work hand in hand to process multiple pieces of data efficiently.\n\n\n\nLearned how to declare and initialize arrays of both strings and integers.\nPracticed indexing elements to store and access data.\nUsed a for loop to iterate over array elements.\nCombined two arrays (arr and yearOfBirth) using the same index to relate data.\nReinforced using input/output (cin, cout) with arrays.\nSaw how arrays can replace multiple separate variables efficiently.\n\n#include &lt;iostream&gt;                                                                \n#include &lt;string&gt;                                                                  \nusing namespace std;                                                               \n                                                                                   \nint main()                                                                         \n{                                                                                  \n  string arr[4];                                                                   \n  arr[0] = \"Ismail\";                                                               \n  arr[1] = \"Sarah\";                                                                \n  arr[2] = \"Sifao\";                                                                \n  arr[3] = \"Yuba\";                                                                 \n                                                                                   \n  int yearOfBirth[] = {1989, 2002, 2028, 2028};                                    \n  int currentYear;                                                                 \n  cout &lt;&lt; \"Enter in the current year: \" &lt;&lt; endl;                                   \n  cin &gt;&gt; currentYear;                                                              \n                                                                                   \n  for(int i = 0; i &lt; 4; i++)                                                       \n  {                                                                                \n    int age = currentYear - yearOfBirth[i];                                        \n    cout &lt;&lt; arr[i] &lt;&lt; \" born \" &lt;&lt; yearOfBirth[i] &lt;&lt; \" age: \" &lt;&lt; age &lt;&lt; endl;       \n  }                                                                                \n  return 0;                                                                        \n}                                                                                  \n\n\n\n\nIntroduced the idea of nested loops to compare array elements.\nUsed an inner loop to calculate relationships between all pairs (differences in ages).\nLearned how to avoid comparing an element to itself using an if (j != i) condition.\nPracticed loop logic with multiple arrays in a single program.\nUnderstood how nested loops quickly increase the number of operations (n²).\nStrengthened the mental model of outer vs. inner loop roles.\n\n#include &lt;iostream&gt;                                                              \n#include &lt;string&gt;                                                                \nusing namespace std;                                                             \n                                                                                 \n                                                                                 \nint main()                                                                       \n{                                                                                \n  string names[4];                                                               \n  names[0] = \"Ismail\";                                                           \n  names[1] = \"Sarah\";                                                            \n  names[2] = \"Sifao\";                                                            \n  names[3] = \"Yuba\";                                                             \n                                                                                 \n  int yearOfBirth[] = {1989, 2002, 2028, 2028};                                  \n  int currenYear;                                                                \n  cout &lt;&lt; \"Enter in the current year: \" &lt;&lt; endl;                                 \n  cin &gt;&gt; currenYear;                                                             \n                                                                                 \n  for(int i = 0; i &lt; 4; i++)                                                     \n  {                                                                              \n                                                                                 \n    cout &lt;&lt; \"Difference in ages: \" &lt;&lt; names[i] &lt;&lt; \" : \";                         \n    for(int j = 0; j &lt; 4; j++)                                                   \n    {                                                                            \n                                                                                 \n      if(j != i)                                                                 \n      {                                                                          \n        cout &lt;&lt; names[j] &lt;&lt; \" \" &lt;&lt; yearOfBirth[j] - yearOfBirth[i] &lt;&lt; \" \";       \n      }                                                                          \n    }                                                                            \n                                                                                 \n    cout &lt;&lt; endl;                                                                \n  }                                                                              \n                                                                                 \n  return 0;                                                                      \n}                                                                                \n\n\n\n\nLearned to fill arrays dynamically based on user input rather than predefined data.\nUsed a counter (numberOfElements) to track how many entries the user provided.\nPracticed calculating sum and average using array values.\nGot introduced to variance and standard deviation, reinforcing mathematical processing with arrays.\nUnderstood the importance of loop limits and correct variable initialization.\nReinforced using break statements and conditional user responses to stop input early.\n\n#include &lt;iostream&gt;                                                             \n#include &lt;string&gt;                                                               \n#include &lt;cmath&gt;                                                                \nusing namespace std;                                                            \n                                                                                \nint main()                                                                      \n{                                                                               \n  int nums[20];                                                                 \n  int num;                                                                      \n  int sum = 0;                                                                  \n  int numberOfElements;                                                         \n  char response;                                                                \n  for(int i = 0; i &lt; 20; i++)                                                   \n  {                                                                             \n    cout &lt;&lt; \"enter in a number: \" &lt;&lt; endl;                                      \n    cin &gt;&gt; num;                                                                 \n                                                                                \n    nums[i] = num;                                                              \n    numberOfElements++;                                                         \n                                                                                \n    if(i &lt; 19)                                                                  \n    {                                                                           \n      cout &lt;&lt; \"Would you like to add another number? (Y)es Or (N)o \" &lt;&lt; endl;   \n      cin &gt;&gt; response;                                                          \n      if( response != 'Y')                                                      \n      {                                                                         \n        break;                                                                  \n      }                                                                         \n    }                                                                           \n    sum = sum + nums[i];                                                        \n    cout &lt;&lt; sum &lt;&lt; \" \" &lt;&lt; nums[i] &lt;&lt; endl;                                      \n  }                                                                             \n  float avg = float(sum) / float(numberOfElements);                             \n  float sumSDV = 0.0;                                                           \n  cout &lt;&lt; \"The average is: \" &lt;&lt; avg &lt;&lt; endl;                                    \n  float diff;                                                                   \n                                                                                \n  for(int i=0; i&lt;=numberOfElements; i++)                                        \n  {                                                                             \n    diff = nums[i] - avg;                                                       \n    sumSDV = sumSDV + (diff * diff);                                            \n                                                                                \n  }                                                                             \n  float variance = float(diff) / float(numberOfElements);                       \n  float standardDV = sqrt(variance);                                            \n                                                                                \n  cout &lt;&lt; \"The variance is \" &lt;&lt; variance &lt;&lt; endl;                               \n  cout &lt;&lt; \"The standard deviation is \" &lt;&lt; standardDV &lt;&lt; endl;                   \n  return 0;                                                                     \n}                                                                               \n\n\n\n\nPracticed creating a 2D array to simulate a grid of coin flips.\nUsed rand() and **srand(time(0))** to generate random outcomes.\nReinforced nested loop iteration for 2D data structures (rows and columns).\nRepresented outcomes (H or T) with characters instead of numbers.\nDisplayed a 2D grid output neatly using nested cout loops.\nBuilt intuition for how 2D arrays represent tables, matrices, or grids.\n\n#include &lt;iostream&gt;                                  \n#include &lt;string&gt;                                    \n#include &lt;ctime&gt;                                     \nusing namespace std;                                 \n                                                     \n                                                     \nint main()                                           \n{                                                    \n  char coinFlip[10][10];                             \n  srand(time(0));                                    \n                                                     \n  for(int row = 0; row &lt; 10; row++)                  \n  {                                                  \n    for(int col = 0; col &lt; 10; col++)                \n    {                                                \n      if(rand() % 2 == 0)                            \n      {                                              \n        coinFlip[row][col] = 'H';                    \n      }                                              \n      else                                           \n      {                                              \n        coinFlip[row][col] = 'T';                    \n      }                                              \n    }                                                \n  }                                                  \n  for(int row = 0; row &lt; 10; row++)                  \n  {                                                  \n    for(int col = 0; col &lt; 10; col++)                \n    {                                                \n      cout &lt;&lt; coinFlip[row][col] &lt;&lt; \" \";             \n    }                                                \n    cout &lt;&lt; endl;                                    \n  }                                                  \n                                                     \n  return 0;                                          \n}                                                    \n\n\n\n\nImproved the previous coin flip simulation with constants for clearer structure.\nLearned to calculate row-based statistics (percent of heads and tails).\nPracticed using floating-point division and type casting for accuracy.\nReinforced using iomanip and setprecision() for formatted output.\nUnderstood how to store computed values in a separate array (percentageOfHeadsInARow).\nBuilt intuition for how arrays can represent probability distributions or statistics.\n\n#include &lt;iostream&gt;                                                                       \n#include &lt;string&gt;                                                                         \n#include &lt;ctime&gt;                                                                          \n#include &lt;iomanip&gt;                                                                        \nusing namespace std;                                                                      \n                                                                                          \n                                                                                          \nint main()                                                                                \n{                                                                                         \n  const int NUM_OF_ROWS = 10;                                                             \n  const int NUM_OF_FLIP_PER_ROW = 15;                                                     \n                                                                                          \n                                                                                          \n  char coinFlip[NUM_OF_ROWS][NUM_OF_FLIP_PER_ROW];                                        \n                                                                                          \n  srand(time(0));                                                                         \n  float  sumOfRowPercentages = 0.0;                                                       \n  for(int row = 0; row &lt; NUM_OF_ROWS; row++)                                              \n  {                                                                                       \n    cout &lt;&lt; fixed &lt;&lt; setprecision(2);                                                     \n                                                                                          \n    float percentageOfHeadsInARow[NUM_OF_ROWS];                                           \n    float sumOfRowPercentages = 0.0;                                                      \n    int numOfHeadsPerRow = 0;                                                             \n    for(int col = 0; col &lt; NUM_OF_FLIP_PER_ROW; col++)                                    \n    {                                                                                     \n      if(rand() % 2 == 0)                                                                 \n      {                                                                                   \n        coinFlip[row][col] = 'H';                                                         \n        numOfHeadsPerRow++;                                                               \n      }                                                                                   \n      else                                                                                \n      {                                                                                   \n        coinFlip[row][col] = 'T';                                                         \n      }                                                                                   \n      cout &lt;&lt; coinFlip[row][col] &lt;&lt; \" \";                                                  \n                                                                                          \n    }                                                                                     \n                                                                                          \n    percentageOfHeadsInARow[row] = (float)numOfHeadsPerRow / (float)NUM_OF_FLIP_PER_ROW;  \n    //sumOfRowPercentages += percentageOfHeadsInARow[row];                                \n                                                                                          \n                                                                                          \n    cout &lt;&lt; \" | Heads: \" &lt;&lt; percentageOfHeadsInARow[row] * 100 &lt;&lt; \"%.\";                   \n    cout &lt;&lt; \" | Tails: \" &lt;&lt; ((1 - percentageOfHeadsInARow[row]) * 100) &lt;&lt; \"%.\";           \n    //cout &lt;&lt; sumOfRowPercentages;                                                        \n    cout &lt;&lt; endl;                                                                         \n  }                                                                                       \n                                                                                          \n  return 0;                                                                               \n}                                                                                         \n\n\n\n\nIntroduced multi-dimensional arrays (3D) for complex data storage.\nModeled real-world hierarchical data: years → weeks → days.\nPracticed deep nested loops to initialize and process multi-level data.\nReinforced using input validation with range checks for each dimension.\nLearned to calculate aggregates (e.g., total sales per week, per day, across years).\nUnderstood how 3D arrays extend the same principles from 1D/2D to represent structured data.\n\n#include &lt;iostream&gt;                                                                                                                                                                     \n#include &lt;string&gt;                                                                                                                                                                       \nusing namespace std;                                                                                                                                                                    \n                                                                                                                                                                                        \nint main()                                                                                                                                                                              \n{                                                                                                                                                                                       \n  const int NUM_YEARS_IN_SALES = 10;                                                                                                                                                    \n  const int NUM_WEEKS_IN_YEAR = 52;                                                                                                                                                     \n  const int NUM_DAYS_IN_WEEKS = 7;                                                                                                                                                      \n                                                                                                                                                                                        \n  int numCarsSold[NUM_YEARS_IN_SALES][NUM_WEEKS_IN_YEAR][NUM_DAYS_IN_WEEKS];                                                                                                            \n                                                                                                                                                                                        \n  for(int year = 0; year &lt; NUM_YEARS_IN_SALES; year++)                                                                                                                                  \n  {                                                                                                                                                                                     \n    for(int week = 0; week &lt; NUM_WEEKS_IN_YEAR; week++)                                                                                                                                 \n    {                                                                                                                                                                                   \n      for(int day = 0; day &lt; NUM_DAYS_IN_WEEKS; day++)                                                                                                                                  \n      {                                                                                                                                                                                 \n        numCarsSold[year][week][day] = 0;                                                                                                                                               \n      }                                                                                                                                                                                 \n    }                                                                                                                                                                                   \n  }                                                                                                                                                                                     \n  cout &lt;&lt; \"Enter in the car sales for the 10 years. \";                                                                                                                                  \n  int enteredYear;                                                                                                                                                                      \n  int enteredWeek;                                                                                                                                                                      \n  int enteredDay;                                                                                                                                                                       \n  int numCarsSoldInADay;                                                                                                                                                                \n                                                                                                                                                                                        \n  char answer = 'y';                                                                                                                                                                    \n  while(answer == 'y')                                                                                                                                                                  \n  {                                                                                                                                                                                     \n    cout &lt;&lt; \"Enter in a year number: \" &lt;&lt; endl;                                                                                                                                         \n    cin &gt;&gt; enteredYear;                                                                                                                                                                 \n                                                                                                                                                                                        \n    cout &lt;&lt; \"Enter in a week number\" &lt;&lt; endl;                                                                                                                                           \n    cin &gt;&gt; enteredWeek;                                                                                                                                                                 \n                                                                                                                                                                                        \n    cout &lt;&lt; \"Enter in a day number: \" &lt;&lt; endl;                                                                                                                                          \n    cin &gt;&gt; enteredDay;                                                                                                                                                                  \n                                                                                                                                                                                        \n    cout &lt;&lt; \"Enter in number of cars were sold in that particular day: \" &lt;&lt; endl;                                                                                                       \n    cin &gt;&gt; numCarsSoldInADay;                                                                                                                                                           \n                                                                                                                                                                                        \n    if((enteredYear &gt;= 0 && enteredYear &lt; NUM_YEARS_IN_SALES) &&                                                                                                                        \n       (enteredWeek &gt;= 0 && enteredWeek &lt; NUM_WEEKS_IN_YEAR) &&                                                                                                                         \n       (enteredDay &gt;= 0 && enteredDay &lt; NUM_DAYS_IN_WEEKS))                                                                                                                             \n    {                                                                                                                                                                                   \n      numCarsSold[NUM_YEARS_IN_SALES][NUM_WEEKS_IN_YEAR][NUM_DAYS_IN_WEEKS] = numCarsSoldInADay;                                                                                        \n    }                                                                                                                                                                                   \n    else                                                                                                                                                                                \n    {                                                                                                                                                                                   \n      cout &lt;&lt; \"You entered invalid year/week/day combination\" &lt;&lt; endl;                                                                                                                  \n    }                                                                                                                                                                                   \n                                                                                                                                                                                        \n    cout &lt;&lt; \"Would you like to enter another sales day (y or n):  \" &lt;&lt; endl;                                                                                                            \n    cin &gt;&gt; answer;                                                                                                                                                                      \n  }                                                                                                                                                                                     \n  int weeklySaleYearNumber;                                                                                                                                                             \n  int weeklySaleWeekNumber;                                                                                                                                                             \n                                                                                                                                                                                        \n                                                                                                                                                                                        \n  cout &lt;&lt; \"Enter in the year number: \" &lt;&lt; endl;                                                                                                                                         \n  cin &gt;&gt; weeklySaleYearNumber;                                                                                                                                                          \n                                                                                                                                                                                        \n  cout &lt;&lt; \"Enter in the week number: \" &lt;&lt; endl;                                                                                                                                         \n  cin &gt;&gt; weeklySaleWeekNumber;                                                                                                                                                          \n  if((weeklySaleYearNumber &gt;= 0 && weeklySaleYearNumber &lt; NUM_YEARS_IN_SALES) &&                                                                                                        \n     (weeklySaleWeekNumber &gt;= 0 && weeklySaleWeekNumber &lt; NUM_WEEKS_IN_YEAR))                                                                                                           \n  {                                                                                                                                                                                     \n    int sum = 0;                                                                                                                                                                        \n    for(int day = 0; day &lt; weeklySaleYearNumber; day++)                                                                                                                                 \n    {                                                                                                                                                                                   \n      sum += numCarsSold[weeklySaleYearNumber][weeklySaleWeekNumber][day];                                                                                                              \n    }                                                                                                                                                                                   \n    cout &lt;&lt; \"The sum of cars sold in the week: \" &lt;&lt; sum &lt;&lt; endl;                                                                                                                        \n  }                                                                                                                                                                                     \n  else                                                                                                                                                                                  \n  {                                                                                                                                                                                     \n    cout &lt;&lt; \"Couldn't find sales for the same day with those inputs.\" &lt;&lt; endl;                                                                                                          \n  }                                                                                                                                                                                     \n                                                                                                                                                                                        \n                                                                                                                                                                                        \n  int allSameDaySalesYear;                                                                                                                                                              \n  int allSameDaySalesDay;                                                                                                                                                               \n                                                                                                                                                                                        \n  cout &lt;&lt; \"Enter in the year number: \" &lt;&lt; endl;                                                                                                                                         \n  cin &gt;&gt; allSameDaySalesYear;                                                                                                                                                           \n  cout &lt;&lt; \"Enter in a day number (0 for sunday, 1 for monday ..etc): \" &lt;&lt; endl;                                                                                                         \n  cin &gt;&gt; allSameDaySalesDay;                                                                                                                                                            \n                                                                                                                                                                                        \n                                                                                                                                                                                        \n  if((allSameDaySalesYear &gt;= 0 && allSameDaySalesYear &lt; NUM_YEARS_IN_SALES) &&                                                                                                          \n     (allSameDaySalesDay &gt;= 0 && allSameDaySalesDay &lt; NUM_DAYS_IN_WEEKS))                                                                                                               \n  {                                                                                                                                                                                     \n                                                                                                                                                                                        \n    int sum = 0;                                                                                                                                                                        \n    for(int week= 0; week &lt; NUM_WEEKS_IN_YEAR; week++)                                                                                                                                  \n    {                                                                                                                                                                                   \n      sum += numCarsSold[allSameDaySalesYear][week][allSameDaySalesDay];                                                                                                                \n    }                                                                                                                                                                                   \n    cout &lt;&lt; \"The sum of cars sold in day of the week \" &lt;&lt; allSameDaySalesDay &lt;&lt; \" during year number: \" &lt;&lt; allSameDaySalesYear &lt;&lt; \" is \" &lt;&lt; sum &lt;&lt; endl;                                \n  }                                                                                                                                                                                     \n  else                                                                                                                                                                                  \n  {                                                                                                                                                                                     \n    cout &lt;&lt; \"Cannot find the sales for the same day of the year with those inputs.\"&lt;&lt;endl;                                                                                              \n  }                                                                                                                                                                                     \n  int weekentered;                                                                                                                                                                      \n                                                                                                                                                                                        \n  cout &lt;&lt; \"Enter in the week number: \" &lt;&lt; endl;                                                                                                                                         \n  cin &gt;&gt; weekentered;                                                                                                                                                                   \n  if(weekentered &gt;= 0 && weekentered &lt; NUM_WEEKS_IN_YEAR)                                                                                                                               \n  {                                                                                                                                                                                     \n    int sum = 0;                                                                                                                                                                        \n    for(int year= 0; year &lt; NUM_YEARS_IN_SALES; year++)                                                                                                                                 \n    {                                                                                                                                                                                   \n      for(int day= 0; day &lt; NUM_DAYS_IN_WEEKS; day++)                                                                                                                                   \n      {                                                                                                                                                                                 \n        sum += numCarsSold[year][weekentered][day];                                                                                                                                     \n      }                                                                                                                                                                                 \n    }                                                                                                                                                                                   \n                                                                                                                                                                                        \n    cout &lt;&lt; \"The sum of cars sold in that speific week during all years is: \" &lt;&lt; sum &lt;&lt; endl;                                                                                           \n  }                                                                                                                                                                                     \n  else                                                                                                                                                                                  \n  {                                                                                                                                                                                     \n    cout &lt;&lt; \"Cannot find the sales for the same day of the year with those inputs.\"&lt;&lt;endl;                                                                                              \n  }                                                                                                                                                                                     \n                                                                                                                                                                                        \n                                                                                                                                                                                        \n  return 0;"
  },
  {
    "objectID": "posts/Learning_CPP/arrayslesson.html#introduction",
    "href": "posts/Learning_CPP/arrayslesson.html#introduction",
    "title": "Learning CPP As Pythonista: Day-4",
    "section": "",
    "text": "After learning how to control program flow with loops, I moved on to arrays which is a key concept that brings structure to repetitive data. Instead of creating separate variables for each value, arrays let me group them together and access each element using an index. This chapter helped me see how loops and arrays work hand in hand to process multiple pieces of data efficiently.\n\n\n\nLearned how to declare and initialize arrays of both strings and integers.\nPracticed indexing elements to store and access data.\nUsed a for loop to iterate over array elements.\nCombined two arrays (arr and yearOfBirth) using the same index to relate data.\nReinforced using input/output (cin, cout) with arrays.\nSaw how arrays can replace multiple separate variables efficiently.\n\n#include &lt;iostream&gt;                                                                \n#include &lt;string&gt;                                                                  \nusing namespace std;                                                               \n                                                                                   \nint main()                                                                         \n{                                                                                  \n  string arr[4];                                                                   \n  arr[0] = \"Ismail\";                                                               \n  arr[1] = \"Sarah\";                                                                \n  arr[2] = \"Sifao\";                                                                \n  arr[3] = \"Yuba\";                                                                 \n                                                                                   \n  int yearOfBirth[] = {1989, 2002, 2028, 2028};                                    \n  int currentYear;                                                                 \n  cout &lt;&lt; \"Enter in the current year: \" &lt;&lt; endl;                                   \n  cin &gt;&gt; currentYear;                                                              \n                                                                                   \n  for(int i = 0; i &lt; 4; i++)                                                       \n  {                                                                                \n    int age = currentYear - yearOfBirth[i];                                        \n    cout &lt;&lt; arr[i] &lt;&lt; \" born \" &lt;&lt; yearOfBirth[i] &lt;&lt; \" age: \" &lt;&lt; age &lt;&lt; endl;       \n  }                                                                                \n  return 0;                                                                        \n}                                                                                  \n\n\n\n\nIntroduced the idea of nested loops to compare array elements.\nUsed an inner loop to calculate relationships between all pairs (differences in ages).\nLearned how to avoid comparing an element to itself using an if (j != i) condition.\nPracticed loop logic with multiple arrays in a single program.\nUnderstood how nested loops quickly increase the number of operations (n²).\nStrengthened the mental model of outer vs. inner loop roles.\n\n#include &lt;iostream&gt;                                                              \n#include &lt;string&gt;                                                                \nusing namespace std;                                                             \n                                                                                 \n                                                                                 \nint main()                                                                       \n{                                                                                \n  string names[4];                                                               \n  names[0] = \"Ismail\";                                                           \n  names[1] = \"Sarah\";                                                            \n  names[2] = \"Sifao\";                                                            \n  names[3] = \"Yuba\";                                                             \n                                                                                 \n  int yearOfBirth[] = {1989, 2002, 2028, 2028};                                  \n  int currenYear;                                                                \n  cout &lt;&lt; \"Enter in the current year: \" &lt;&lt; endl;                                 \n  cin &gt;&gt; currenYear;                                                             \n                                                                                 \n  for(int i = 0; i &lt; 4; i++)                                                     \n  {                                                                              \n                                                                                 \n    cout &lt;&lt; \"Difference in ages: \" &lt;&lt; names[i] &lt;&lt; \" : \";                         \n    for(int j = 0; j &lt; 4; j++)                                                   \n    {                                                                            \n                                                                                 \n      if(j != i)                                                                 \n      {                                                                          \n        cout &lt;&lt; names[j] &lt;&lt; \" \" &lt;&lt; yearOfBirth[j] - yearOfBirth[i] &lt;&lt; \" \";       \n      }                                                                          \n    }                                                                            \n                                                                                 \n    cout &lt;&lt; endl;                                                                \n  }                                                                              \n                                                                                 \n  return 0;                                                                      \n}                                                                                \n\n\n\n\nLearned to fill arrays dynamically based on user input rather than predefined data.\nUsed a counter (numberOfElements) to track how many entries the user provided.\nPracticed calculating sum and average using array values.\nGot introduced to variance and standard deviation, reinforcing mathematical processing with arrays.\nUnderstood the importance of loop limits and correct variable initialization.\nReinforced using break statements and conditional user responses to stop input early.\n\n#include &lt;iostream&gt;                                                             \n#include &lt;string&gt;                                                               \n#include &lt;cmath&gt;                                                                \nusing namespace std;                                                            \n                                                                                \nint main()                                                                      \n{                                                                               \n  int nums[20];                                                                 \n  int num;                                                                      \n  int sum = 0;                                                                  \n  int numberOfElements;                                                         \n  char response;                                                                \n  for(int i = 0; i &lt; 20; i++)                                                   \n  {                                                                             \n    cout &lt;&lt; \"enter in a number: \" &lt;&lt; endl;                                      \n    cin &gt;&gt; num;                                                                 \n                                                                                \n    nums[i] = num;                                                              \n    numberOfElements++;                                                         \n                                                                                \n    if(i &lt; 19)                                                                  \n    {                                                                           \n      cout &lt;&lt; \"Would you like to add another number? (Y)es Or (N)o \" &lt;&lt; endl;   \n      cin &gt;&gt; response;                                                          \n      if( response != 'Y')                                                      \n      {                                                                         \n        break;                                                                  \n      }                                                                         \n    }                                                                           \n    sum = sum + nums[i];                                                        \n    cout &lt;&lt; sum &lt;&lt; \" \" &lt;&lt; nums[i] &lt;&lt; endl;                                      \n  }                                                                             \n  float avg = float(sum) / float(numberOfElements);                             \n  float sumSDV = 0.0;                                                           \n  cout &lt;&lt; \"The average is: \" &lt;&lt; avg &lt;&lt; endl;                                    \n  float diff;                                                                   \n                                                                                \n  for(int i=0; i&lt;=numberOfElements; i++)                                        \n  {                                                                             \n    diff = nums[i] - avg;                                                       \n    sumSDV = sumSDV + (diff * diff);                                            \n                                                                                \n  }                                                                             \n  float variance = float(diff) / float(numberOfElements);                       \n  float standardDV = sqrt(variance);                                            \n                                                                                \n  cout &lt;&lt; \"The variance is \" &lt;&lt; variance &lt;&lt; endl;                               \n  cout &lt;&lt; \"The standard deviation is \" &lt;&lt; standardDV &lt;&lt; endl;                   \n  return 0;                                                                     \n}                                                                               \n\n\n\n\nPracticed creating a 2D array to simulate a grid of coin flips.\nUsed rand() and **srand(time(0))** to generate random outcomes.\nReinforced nested loop iteration for 2D data structures (rows and columns).\nRepresented outcomes (H or T) with characters instead of numbers.\nDisplayed a 2D grid output neatly using nested cout loops.\nBuilt intuition for how 2D arrays represent tables, matrices, or grids.\n\n#include &lt;iostream&gt;                                  \n#include &lt;string&gt;                                    \n#include &lt;ctime&gt;                                     \nusing namespace std;                                 \n                                                     \n                                                     \nint main()                                           \n{                                                    \n  char coinFlip[10][10];                             \n  srand(time(0));                                    \n                                                     \n  for(int row = 0; row &lt; 10; row++)                  \n  {                                                  \n    for(int col = 0; col &lt; 10; col++)                \n    {                                                \n      if(rand() % 2 == 0)                            \n      {                                              \n        coinFlip[row][col] = 'H';                    \n      }                                              \n      else                                           \n      {                                              \n        coinFlip[row][col] = 'T';                    \n      }                                              \n    }                                                \n  }                                                  \n  for(int row = 0; row &lt; 10; row++)                  \n  {                                                  \n    for(int col = 0; col &lt; 10; col++)                \n    {                                                \n      cout &lt;&lt; coinFlip[row][col] &lt;&lt; \" \";             \n    }                                                \n    cout &lt;&lt; endl;                                    \n  }                                                  \n                                                     \n  return 0;                                          \n}                                                    \n\n\n\n\nImproved the previous coin flip simulation with constants for clearer structure.\nLearned to calculate row-based statistics (percent of heads and tails).\nPracticed using floating-point division and type casting for accuracy.\nReinforced using iomanip and setprecision() for formatted output.\nUnderstood how to store computed values in a separate array (percentageOfHeadsInARow).\nBuilt intuition for how arrays can represent probability distributions or statistics.\n\n#include &lt;iostream&gt;                                                                       \n#include &lt;string&gt;                                                                         \n#include &lt;ctime&gt;                                                                          \n#include &lt;iomanip&gt;                                                                        \nusing namespace std;                                                                      \n                                                                                          \n                                                                                          \nint main()                                                                                \n{                                                                                         \n  const int NUM_OF_ROWS = 10;                                                             \n  const int NUM_OF_FLIP_PER_ROW = 15;                                                     \n                                                                                          \n                                                                                          \n  char coinFlip[NUM_OF_ROWS][NUM_OF_FLIP_PER_ROW];                                        \n                                                                                          \n  srand(time(0));                                                                         \n  float  sumOfRowPercentages = 0.0;                                                       \n  for(int row = 0; row &lt; NUM_OF_ROWS; row++)                                              \n  {                                                                                       \n    cout &lt;&lt; fixed &lt;&lt; setprecision(2);                                                     \n                                                                                          \n    float percentageOfHeadsInARow[NUM_OF_ROWS];                                           \n    float sumOfRowPercentages = 0.0;                                                      \n    int numOfHeadsPerRow = 0;                                                             \n    for(int col = 0; col &lt; NUM_OF_FLIP_PER_ROW; col++)                                    \n    {                                                                                     \n      if(rand() % 2 == 0)                                                                 \n      {                                                                                   \n        coinFlip[row][col] = 'H';                                                         \n        numOfHeadsPerRow++;                                                               \n      }                                                                                   \n      else                                                                                \n      {                                                                                   \n        coinFlip[row][col] = 'T';                                                         \n      }                                                                                   \n      cout &lt;&lt; coinFlip[row][col] &lt;&lt; \" \";                                                  \n                                                                                          \n    }                                                                                     \n                                                                                          \n    percentageOfHeadsInARow[row] = (float)numOfHeadsPerRow / (float)NUM_OF_FLIP_PER_ROW;  \n    //sumOfRowPercentages += percentageOfHeadsInARow[row];                                \n                                                                                          \n                                                                                          \n    cout &lt;&lt; \" | Heads: \" &lt;&lt; percentageOfHeadsInARow[row] * 100 &lt;&lt; \"%.\";                   \n    cout &lt;&lt; \" | Tails: \" &lt;&lt; ((1 - percentageOfHeadsInARow[row]) * 100) &lt;&lt; \"%.\";           \n    //cout &lt;&lt; sumOfRowPercentages;                                                        \n    cout &lt;&lt; endl;                                                                         \n  }                                                                                       \n                                                                                          \n  return 0;                                                                               \n}                                                                                         \n\n\n\n\nIntroduced multi-dimensional arrays (3D) for complex data storage.\nModeled real-world hierarchical data: years → weeks → days.\nPracticed deep nested loops to initialize and process multi-level data.\nReinforced using input validation with range checks for each dimension.\nLearned to calculate aggregates (e.g., total sales per week, per day, across years).\nUnderstood how 3D arrays extend the same principles from 1D/2D to represent structured data.\n\n#include &lt;iostream&gt;                                                                                                                                                                     \n#include &lt;string&gt;                                                                                                                                                                       \nusing namespace std;                                                                                                                                                                    \n                                                                                                                                                                                        \nint main()                                                                                                                                                                              \n{                                                                                                                                                                                       \n  const int NUM_YEARS_IN_SALES = 10;                                                                                                                                                    \n  const int NUM_WEEKS_IN_YEAR = 52;                                                                                                                                                     \n  const int NUM_DAYS_IN_WEEKS = 7;                                                                                                                                                      \n                                                                                                                                                                                        \n  int numCarsSold[NUM_YEARS_IN_SALES][NUM_WEEKS_IN_YEAR][NUM_DAYS_IN_WEEKS];                                                                                                            \n                                                                                                                                                                                        \n  for(int year = 0; year &lt; NUM_YEARS_IN_SALES; year++)                                                                                                                                  \n  {                                                                                                                                                                                     \n    for(int week = 0; week &lt; NUM_WEEKS_IN_YEAR; week++)                                                                                                                                 \n    {                                                                                                                                                                                   \n      for(int day = 0; day &lt; NUM_DAYS_IN_WEEKS; day++)                                                                                                                                  \n      {                                                                                                                                                                                 \n        numCarsSold[year][week][day] = 0;                                                                                                                                               \n      }                                                                                                                                                                                 \n    }                                                                                                                                                                                   \n  }                                                                                                                                                                                     \n  cout &lt;&lt; \"Enter in the car sales for the 10 years. \";                                                                                                                                  \n  int enteredYear;                                                                                                                                                                      \n  int enteredWeek;                                                                                                                                                                      \n  int enteredDay;                                                                                                                                                                       \n  int numCarsSoldInADay;                                                                                                                                                                \n                                                                                                                                                                                        \n  char answer = 'y';                                                                                                                                                                    \n  while(answer == 'y')                                                                                                                                                                  \n  {                                                                                                                                                                                     \n    cout &lt;&lt; \"Enter in a year number: \" &lt;&lt; endl;                                                                                                                                         \n    cin &gt;&gt; enteredYear;                                                                                                                                                                 \n                                                                                                                                                                                        \n    cout &lt;&lt; \"Enter in a week number\" &lt;&lt; endl;                                                                                                                                           \n    cin &gt;&gt; enteredWeek;                                                                                                                                                                 \n                                                                                                                                                                                        \n    cout &lt;&lt; \"Enter in a day number: \" &lt;&lt; endl;                                                                                                                                          \n    cin &gt;&gt; enteredDay;                                                                                                                                                                  \n                                                                                                                                                                                        \n    cout &lt;&lt; \"Enter in number of cars were sold in that particular day: \" &lt;&lt; endl;                                                                                                       \n    cin &gt;&gt; numCarsSoldInADay;                                                                                                                                                           \n                                                                                                                                                                                        \n    if((enteredYear &gt;= 0 && enteredYear &lt; NUM_YEARS_IN_SALES) &&                                                                                                                        \n       (enteredWeek &gt;= 0 && enteredWeek &lt; NUM_WEEKS_IN_YEAR) &&                                                                                                                         \n       (enteredDay &gt;= 0 && enteredDay &lt; NUM_DAYS_IN_WEEKS))                                                                                                                             \n    {                                                                                                                                                                                   \n      numCarsSold[NUM_YEARS_IN_SALES][NUM_WEEKS_IN_YEAR][NUM_DAYS_IN_WEEKS] = numCarsSoldInADay;                                                                                        \n    }                                                                                                                                                                                   \n    else                                                                                                                                                                                \n    {                                                                                                                                                                                   \n      cout &lt;&lt; \"You entered invalid year/week/day combination\" &lt;&lt; endl;                                                                                                                  \n    }                                                                                                                                                                                   \n                                                                                                                                                                                        \n    cout &lt;&lt; \"Would you like to enter another sales day (y or n):  \" &lt;&lt; endl;                                                                                                            \n    cin &gt;&gt; answer;                                                                                                                                                                      \n  }                                                                                                                                                                                     \n  int weeklySaleYearNumber;                                                                                                                                                             \n  int weeklySaleWeekNumber;                                                                                                                                                             \n                                                                                                                                                                                        \n                                                                                                                                                                                        \n  cout &lt;&lt; \"Enter in the year number: \" &lt;&lt; endl;                                                                                                                                         \n  cin &gt;&gt; weeklySaleYearNumber;                                                                                                                                                          \n                                                                                                                                                                                        \n  cout &lt;&lt; \"Enter in the week number: \" &lt;&lt; endl;                                                                                                                                         \n  cin &gt;&gt; weeklySaleWeekNumber;                                                                                                                                                          \n  if((weeklySaleYearNumber &gt;= 0 && weeklySaleYearNumber &lt; NUM_YEARS_IN_SALES) &&                                                                                                        \n     (weeklySaleWeekNumber &gt;= 0 && weeklySaleWeekNumber &lt; NUM_WEEKS_IN_YEAR))                                                                                                           \n  {                                                                                                                                                                                     \n    int sum = 0;                                                                                                                                                                        \n    for(int day = 0; day &lt; weeklySaleYearNumber; day++)                                                                                                                                 \n    {                                                                                                                                                                                   \n      sum += numCarsSold[weeklySaleYearNumber][weeklySaleWeekNumber][day];                                                                                                              \n    }                                                                                                                                                                                   \n    cout &lt;&lt; \"The sum of cars sold in the week: \" &lt;&lt; sum &lt;&lt; endl;                                                                                                                        \n  }                                                                                                                                                                                     \n  else                                                                                                                                                                                  \n  {                                                                                                                                                                                     \n    cout &lt;&lt; \"Couldn't find sales for the same day with those inputs.\" &lt;&lt; endl;                                                                                                          \n  }                                                                                                                                                                                     \n                                                                                                                                                                                        \n                                                                                                                                                                                        \n  int allSameDaySalesYear;                                                                                                                                                              \n  int allSameDaySalesDay;                                                                                                                                                               \n                                                                                                                                                                                        \n  cout &lt;&lt; \"Enter in the year number: \" &lt;&lt; endl;                                                                                                                                         \n  cin &gt;&gt; allSameDaySalesYear;                                                                                                                                                           \n  cout &lt;&lt; \"Enter in a day number (0 for sunday, 1 for monday ..etc): \" &lt;&lt; endl;                                                                                                         \n  cin &gt;&gt; allSameDaySalesDay;                                                                                                                                                            \n                                                                                                                                                                                        \n                                                                                                                                                                                        \n  if((allSameDaySalesYear &gt;= 0 && allSameDaySalesYear &lt; NUM_YEARS_IN_SALES) &&                                                                                                          \n     (allSameDaySalesDay &gt;= 0 && allSameDaySalesDay &lt; NUM_DAYS_IN_WEEKS))                                                                                                               \n  {                                                                                                                                                                                     \n                                                                                                                                                                                        \n    int sum = 0;                                                                                                                                                                        \n    for(int week= 0; week &lt; NUM_WEEKS_IN_YEAR; week++)                                                                                                                                  \n    {                                                                                                                                                                                   \n      sum += numCarsSold[allSameDaySalesYear][week][allSameDaySalesDay];                                                                                                                \n    }                                                                                                                                                                                   \n    cout &lt;&lt; \"The sum of cars sold in day of the week \" &lt;&lt; allSameDaySalesDay &lt;&lt; \" during year number: \" &lt;&lt; allSameDaySalesYear &lt;&lt; \" is \" &lt;&lt; sum &lt;&lt; endl;                                \n  }                                                                                                                                                                                     \n  else                                                                                                                                                                                  \n  {                                                                                                                                                                                     \n    cout &lt;&lt; \"Cannot find the sales for the same day of the year with those inputs.\"&lt;&lt;endl;                                                                                              \n  }                                                                                                                                                                                     \n  int weekentered;                                                                                                                                                                      \n                                                                                                                                                                                        \n  cout &lt;&lt; \"Enter in the week number: \" &lt;&lt; endl;                                                                                                                                         \n  cin &gt;&gt; weekentered;                                                                                                                                                                   \n  if(weekentered &gt;= 0 && weekentered &lt; NUM_WEEKS_IN_YEAR)                                                                                                                               \n  {                                                                                                                                                                                     \n    int sum = 0;                                                                                                                                                                        \n    for(int year= 0; year &lt; NUM_YEARS_IN_SALES; year++)                                                                                                                                 \n    {                                                                                                                                                                                   \n      for(int day= 0; day &lt; NUM_DAYS_IN_WEEKS; day++)                                                                                                                                   \n      {                                                                                                                                                                                 \n        sum += numCarsSold[year][weekentered][day];                                                                                                                                     \n      }                                                                                                                                                                                 \n    }                                                                                                                                                                                   \n                                                                                                                                                                                        \n    cout &lt;&lt; \"The sum of cars sold in that speific week during all years is: \" &lt;&lt; sum &lt;&lt; endl;                                                                                           \n  }                                                                                                                                                                                     \n  else                                                                                                                                                                                  \n  {                                                                                                                                                                                     \n    cout &lt;&lt; \"Cannot find the sales for the same day of the year with those inputs.\"&lt;&lt;endl;                                                                                              \n  }                                                                                                                                                                                     \n                                                                                                                                                                                        \n                                                                                                                                                                                        \n  return 0;"
  },
  {
    "objectID": "posts/Learning_CPP/arrayslesson.html#summary",
    "href": "posts/Learning_CPP/arrayslesson.html#summary",
    "title": "Learning CPP As Pythonista: Day-4",
    "section": "Summary:",
    "text": "Summary:\nThroughout these exercises, I explored how arrays store and manage collections of related data. I learned to combine loops with arrays to process values efficiently, calculate results like averages and variances, and represent more complex structures such as 2D grids and 3D datasets. This chapter strengthened my understanding of how data can be organized and accessed systematically, setting the stage for more advanced programming concepts."
  },
  {
    "objectID": "posts/Learning_CPP/Untitled Folder/Untitled.html",
    "href": "posts/Learning_CPP/Untitled Folder/Untitled.html",
    "title": "Ismail's Learning Journey",
    "section": "",
    "text": "``` {.c++17 .cell-code} #include  using namespace std;\n:::\n\n\n::: {#8f501184-3001-45fc-bc0f-247ff11025b9 .cell execution_count=6}\n``` {.c++17 .cell-code}\nint main()\n{\n    int var = 5;\n    int* ptr;\n    \n    // Show the variable\n    cout &lt;&lt; \"Value of var: \" &lt;&lt; var &lt;&lt; endl;\n    cout &lt;&lt; \"Address of var: \" &lt;&lt; &var &lt;&lt; endl;\n    \n    // Uninitialized pointer (contains garbage)\n    cout &lt;&lt; \"Uninitialized pointer (garbage address): \" &lt;&lt; ptr &lt;&lt; endl;\n\n    int var1;\n    // point ptr to var1\n    ptr = &var1;\n    cout &lt;&lt; \"Pointer stores address of: \" &lt;&lt; ptr &lt;&lt; endl;\n    // print the value stored in var1:\n    cout &lt;&lt; \"Deferencing pointer at var1:  \" &lt;&lt; *ptr &lt;&lt; endl;\n    \n    // Point ptr to var\n    ptr = &var;\n    cout &lt;&lt; \"Pointer now stores address (same address as var): \" &lt;&lt; ptr &lt;&lt; endl;\n    cout &lt;&lt; \"Dereferencing pointer (*ptr): \" &lt;&lt; *ptr &lt;&lt; endl;\n\n    // change the value of var = 5 \n    *ptr = 10;\n    // print var and check the value is changed 5 -&gt; 10\n    cout &lt;&lt; \"New value of var:  \" &lt;&lt; var &lt;&lt; endl;\n    return 0;\n}\n\n\n{.c++17 .cell-code} main()\n\nValue of var: 5\nAddress of var: 0x7ffc1f3be1d8\nUninitialized pointer (garbage address): 0x2\nPointer stores address of: 0x7ffc1f3be1cc\nDeferencing pointer at var1:  -1\nPointer now stores address (same address as var): 0x7ffc1f3be1d8\nDereferencing pointer (*ptr): 5\nNew value of var:  10\n\n\n0"
  },
  {
    "objectID": "posts/Fastai_ch5/Fastai-Ch5.html",
    "href": "posts/Fastai_ch5/Fastai-Ch5.html",
    "title": "Chapter 5: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "Since we now familiar the whole process of creating deep learning model, using pre-built model, building them from scratch, handling data, and putting these model into web apps, we will now to go deeper and keep focus on details that make model accurate and reliable.\nIt takes many tweaks and parameters changing in order to “polish” a model.\nIn order to achieve this goal we need to be familiar with many concepts and technics, different types of layers, regularization methods, optimizers, how to put layers together into architectures, labeling techniques, and much more.\n\n\n! [ -e /content ] && pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\n\n\nfrom fastbook import *\nfrom fastai.vision.widgets import *\n\n\n\n\nIn real world scenarios, the first thing we do is we get in contact with data, usualy at this phase we know nothing about the dataset. We then start to look how to extract the data we want from it, and what the data looks like, and how it is structured.\nUsually data is provided in one of two ways:\n\nIndividual files representing items of data, possibly organized into folder or with filenames representing information about those items\n\ntext documents\n\nimages\n\n\nA table of data in which each row is an item and may include filenames providing connections between the data in the table and data in other formats\n\nCSV files\n\n\n\nExceptions:\n\nDomains like Genomics\n\nbinary database formats\n\nnetwork streams\n\n\n\n# download the dataset\nfrom fastai.vision.all import *\npath = untar_data(URLs.PETS)\n\n\n#get the path as variable, and see what inside\nPath.BASE_PATH = path\npath.ls()\n\n\nAs we notice here, the data is provided with 2 directories:\n\nimages\nannotations\n\n\n\n#take a look at what inside the images directory\n(path/'images').ls()\n\n\nWhen we took a look at these names, we see some paterns: we already know from chapter1 that cats name are uppercase, here we see that after the breed’s name there is a (_) then a number, and finally the extension.\nThis may help us to write some code that extract the breed from a single Path.\n\n\n#pick one \nfname = (path/\"images\").ls()[0]\nfname\n\n\nThe best way to work with strings and extract patterns from them is to use Regex, which stands for Regular Expression.\n\n\nre.findall(r'(.+)_\\d+.jpg$', fname.name)\n\n\nNow we need to label the whole dataset using this code.\nFastai comes with many classes for labeling, in this case when we need to label with help of regex we could use RegexLabeller class within DataBlaock API.\n\n\npets = DataBlock(blocks = (ImageBlock, CategoryBlock),\n                 get_items=get_image_files, \n                 splitter=RandomSplitter(seed=42),\n                 get_y=using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n                 item_tfms=Resize(460),\n                 batch_tfms=aug_transforms(size=224, min_scale=0.75))\ndls = pets.dataloaders(path/\"images\")\n\n\n\n\n\nFastai has this method of presizing the images in a way that conserve its quality after the data augmentation, so it helps the model to learn more lessons from data, and also it helps our dataset to be more varies\nThe idea behind the presizing is we crop the image and resize it to 460 by 460 first, which is a big size by deep learning norms, this operation is done on CPU, then we do the data augmentation in batches, by cropping a rotated random part of that 460^2 image, and taking the cropped image then resize again to a 224 by 224 image, all this operation are done on batch level, which mean on GPU.**\n\n\nitem_tfms=Resize(460),  \nbatch_tfms=aug_transforms(size=224, min_scale=0.75))\n\n![REsize_method](1.png)\n\n* Usually all the augmentation operations we do on a image reduce the quality of the image, but with this approach we could say we can preserve big part of informations of that image so the model can learn better \n\n### Checking and Debugging a DataBlock\n\n* `DataBlock` is just a blueprint for orginizing data before we feed it to the model, you have no guarantee that your template is going to work on your data source as you intend.\n* So, before training a model you should always check your data. You can do this using the show_batch method:\n\n::: {#cell-23 .cell quarto-private-1='{\"key\":\"colab\",\"value\":{\"base_uri\":\"https://localhost:8080/\",\"height\":193}}' outputId='0f1711e2-f2c6-4703-ed64-1ea456f04a2d'}\n``` {.python .cell-code}\ndls.show_batch(nrows=1, ncols=4 ,unique= True)\n:::\n\nIn case we made a mistake in the process of creating datablock, we could use .summary to track the problem.Here we didn’t resize the images in one formm, so couldn’t use the batch transform\nAs we see here the .summary gives us precise diagnostic of the problem:\n\nat least two tensors in the batch are not the same size.\n\n\n\n\n\nOnce we feel like the datablock is well created, we better begin train the model, and use it as a tool of cleaning the data. If there’s a problem with data or the model, we better know that before we lost lot of time and energy on data cleaning even before testing the model.\n\n\n# train the model\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(2)\n\n\n\n\n\nAs we saw before in Chapter 2 the best tool to clean the data is basically the model itself\nAfter creating the datablock and dataloader we better train the model and get some feedback so we know if something is wrong very early, and if not we start to use the model as tool to investigate the data\nUsually before we train the model we have to decide the function that will update the parameters, a Loss Function. But here we didn’t create any loss function?\nIf we didn’t decide the way by which we update the paramters, Fastai by default will chose a loss function for us.\n\nthe chosen loss function will suite the kind of model we build, and the type of dataset we have.\n\n\n\n# check the loss function\nlearn.loss_func\n\n\nThe loss function used to train this model is Cross Entropy Loss\n\n\n\n\n\n\nThe Cross-Entropy Loss is a function similar to what we saw in the previous chapter, when we created the mnist_loss function:\n\ndef mnist_loss(predictions, targets):\n    prediction = prediction.sigmoid()\n    return torch.where(targets==1, 1-prediction, predictions).mean()\n\nThe problem with this function is, it only takes 2 categories(3, 7) but here we have 37 types of breeds.but here we have multiple classes.\n\nit can takes more than 2 categories\n\n\n\n\n\nIn order to understand the cross-entropy loss, let’s grab a batch of data\n\n\nx,y = dls.one_batch()\n\n\nIt return the activations of dependent and independent variable of one mini-batch\n\n\n# independent variable\ny, len(y)\n\n\nIt return 64 number, each represent on of the 37 breeds index\n\n\n# all indepent variables\ndls.vocab, len(dls.vocab)\n\n\nHere we use get_preds to get the predictions for each image in the dataset or mini-batch (like in this example).\n\n\npreds,_ = learn.get_preds(dl=[(x,y)])\n\n\n# prediction for image [0] in the mini-batch\npreds[0]\n\n\nThe 37 predictions refer to the probability of each breed to match the image[0].\n\nif we sum() them up they add up to 1:\n\n\n\npreds[0].sum()\n\n\nIn order to transform the activations of our model into prediction, we use Soft-Max\n\n\n\n\n\nAs we said before, Softmax is similar to sigmoid function we use before, but it only can handel more than 2 classes.\n\n\n# reminder of sigmoid\nplot_function(torch.sigmoid, min=-4,max=4)\n\n\nThis function allow us to predict whether a activation number is pointing to each category of the two, by calculating which activation is big and by much. But in our case today we have 37 category, which means by this logic we need a activation for each one.\nFirst let’s create a similar situation where we have only 2 categories, but we won’t solve it as it’s a binary problem (it's 3) but as 2 categories problem, each has it’s activation, and their probabilty sum up to 1.\n\n\ntorch.random.manual_seed(42);\n\n\nacts = torch.randn((6,2))*2\nacts\n\n\nWe can’t just take the sigmoid of this directly, since we don’t get rows that add to 1 (i.e., we want the probability of being a 3 plus the probability of being a 7 to add up to 1):\n\n\nsigmoid(acts)\n\n\nEevn though we try different approach to solve the same problem, we still have some similarities.\nWe will use sigmoid on each activation.\nAnd we still need to substract an activation from another beacuse that represent how much the model sure about an image is assigned to each category, thats for first column.\nIn the second colun we just use 1 - prediction (activation of the second column)\n\n\ndiffs = acts[:, 0] - acts[:, 1]\n\n\n# create the sigmoid function of both categories\nsigm_ver = torch.stack([diffs.sigmoid(), 1-diffs.sigmoid()], dim=1)\n\n\nWe can express the softmax function as:\n\ndef softmax(x): return exp(x) / exp(x).sum(dim=1, keepdim=True)\n\n\nLet’s check that softmax returns the same values as sigmoid for the first column, and those values subtracted from 1 for the second column:\n\n\nsm_acts = torch.softmax(acts, dim=1)\nsm_acts, sigm_ver\n\n\nSoftmax calculate the \\(exp^{x}\\) and divide it by sum \\(exp^{x}\\) of all activations of other categories.\n\nthe exp make sure the biggest activation is way bigger than others\ndividing by the sum is what make softmax values add up to 1\n\n\n\n\n\n\nIn the previous chapter when we created mnis_loss, we used torch.where to select between the input and 1-input.\nWith softmax, we will use indexing.\n\n\n# the pretended targets\ntargs = tensor([0, 1, 0, 1, 1, 0])\n\n\n# create an index\nidx = range(6)\n\n\n# the softmax activations\nsm_acts\n\n\nHere we make the targs decide which activation we pick in each row\n\n\nsm_acts[idx, targs]\n\n\nlet’s display what we just did :\n\n\nfrom IPython.display import HTML\ndf = pd.DataFrame(sm_acts, columns=[\"3\",\"7\"])\ndf['targs'] = targs\ndf['idx'] = idx\ndf['result'] = sm_acts[range(6), targs]\nt = df.style.hide_index()\n#To have html code compatible with our script\nhtml = t._repr_html_().split('&lt;/style&gt;')[1]\nhtml = re.sub(r'&lt;table id=\"([^\"]+)\"\\s*&gt;', r'&lt;table &gt;', html)\ndisplay(HTML(html))\n\n\nBut idea here is not to use it in a simple binary problem, because torch.where could did the same job here, but is to use it in order to solve a multi-categorie problem\n\nPyTorch provides a function that does exactly the same thing as sm_acts[range(n), targ] (except it takes the negative, because when applying the log afterward, we will have negative numbers), called nll_loss (NLL stands for negative log likelihood):\n\n-sm_acts[idx, targs]\n\n\nF.nll_loss(sm_acts, targs, reduction='none')\n\n\n\n\n\n\n\ncross-entropy-loss-function.png\n\n\n\nThe using of logarithms allow us to do all kind of multiplications without carring about the size of the output.\n\nthe nature of log functions make them increase lineary when the underlying signal increase exponentialy.\nlog(a*b) = log(a)+log(b)\nthe log of a number approaches negative infinity when the number approaches zero\n\nIn our case, since the result relfects the predicted probability of the correct label, we want our loss function to return a small value when the prediction is “good” (closer to 1) and a large value when the prediction is “bad” (closer to 0).\nNotice how the loss is very large in the third and fourth rows where the predictions are confident and wrong, or in other words have high probabilities on the wrong class. One benefit of using the log to calculate the loss is that our loss function penalizes predictions that are both confident and wrong. This kind of penalty works well in practice to aid in more effective model training.\n\nCalculating the loss pay attention only to the high softmax value.\n\n\n\n\n\nAfter taking the log of the softmax, we can then call the negative log likelihood.\n\nfirst : log_softmax\nthen : nll_loss\nor : nn.CrossEntropyLoss()\n\n\n\nloss_func = nn.CrossEntropyLoss()\n\n\nloss_func(acts, targs)\n\n\nnn.CrossEntropyLoss()(acts, targs)\n\n\nThe nn.CrossEntrpyLoss() make do all the steps for us, but if we want to go through all those steps one by one softmas+log then negative log we could do it also:\n\n\nF.nll_loss(nn.Softmax()(acts).log(), targs,)\n\n\nAdding the reduction='none' to this functions will return the loss of each row, if we didn’t add this aparameter the fuction will return the mean loss of all rows.\n\n\nnn.CrossEntropyLoss(reduction='none')(acts, targs)\n\n\n\n\n\n\nAs we saw in chapter 3 it’s hard for us to interpret the loss function, since it’s some the computers use in order to updates the parameters and optimize the performance.\nBut we can use some kind of demonstration that shows where the model did good, and where did bad.\n\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix(figsize=(12,12), dpi=60)\n\n\nIts was easy to understand what happened when they were only 3 classes in bears model, but here we have 37 breeds.\n\nthats why we will useinterp.most_confused(min_val=5) to output to most bad decisions the model taked\n\n\n\ninterp.most_confused(min_val=5)\n\n\nThe best way to understand what happend is to google the names of each breed and see why the model confused it with the other breed, so we know that the model is in the right track\n\n\n\n\n\nAt this point all we can do is improve the model by correcting some detaills that may optimize the final prefromance\n\n\n\n\nOne way of improving our model is by picking the right learning rate.\n\nit will help to get faster result per epoch\nminimize the loss and updating parameters with less steps\n\n\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(1, base_lr=0.1)\n\n\nHere we pick a learning rate 0.1 which is 5 times bigger than the last one 0.002 and we get bad results error rate at: 0.5\n\nbig learning rate may reduce the computation needed for the training process but the model performance will be bad\n\nAlso if we pick a small learning rate it will take forever to achieve something.\nThe answear for this dilemma is The Learning Rate Finder\n\nFastai library adopte this method created by the resaercher Leslie Smith in a paper in 2015.\n\nthe idea of Smith is to start with a small learning rate (very small), and use it for one mini-batch, see how much the loss changed, and then start increasing the learning rate by some percentage (doubling it since its very small anyway)\nrepeate this process again(track the loss, double the learning rate ..) until the loss get worse.\nat this point we just pick a learning rate smaller than the one that causes the loss to get worse.\n\nFastai course advice is either:\n\none order of magnitude less than where the minimun loss was achieved(divide by 10)\nthe last point where the loss was clearly decreasing\n\nBoth point are giving the same value usually.\n\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlr_min,lr_steep = learn.lr_find(suggest_funcs=(minimum, steep))\n\n\nprint(f\"Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}\")\n\n\nThe plot shows that the loss between 10e-6 and 10e-3 almost didn’t change, but after it start to decrease until it reachs the minimum at 10e-1.\nWe don’t want a learning rate bigger than 10e-1 because there where the loss get worse, and we don’t need learning rate at 10e-1 because at this value we’ve left the stage where the loss was decreasing.\n\nwe need to pick the learning rate where the just start to decrease all the way to the minimum: 1e-3\n\n\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(2, base_lr=3e-3)\n\n\nThe error rate get better 10 times just by using the learning rate methode. Loss also get better by this percentage.\n\n\n\n\n\nWe are familiar with the idea of Transfer Learning, where we use a pretrainned model on our dataset, by fine tuning it in a way that keep all the learned weights and use them in our task.\nWe know tha Convolutional Neural Network consist of many linear layers, and between each two of them there’s a nonlinear activation function (ReLU for example), followed by the final layer with an activation function such as Softmax. The final layer uses a matrix with enough columns such that the ouput size is has the number of classes our model trained to predict(assuming we have a classfication task) This final linear layer is unlikely to be of any use for us when we are fine-tuning in a transfer learning setting, because it is specifically designed to classify the categories in the original pretraining dataset.\nSo we first delete it when we start the transfer learning process, and replace it with a new linear layer with the correct number of outputs that matches our desired task(in this case 37 breeds, so 37 activations)\nThis new linear layer have total randome set of weights, but that doesn’t mean we should set all weights randomly even for the pretrained part.\n\nAll of the layers prior to the last one have been carefully trained to be good at image classification tasks in general. As we saw in the images from the Zeiler and Fergus paper, the first few layers encode very general concepts, such as finding gradients and edges, and later layers encode concepts that are still very useful for us, such as finding eyeballs and fur.\n\nWe want to build a model such as preserve all the learned weights, and apply them on our dataset, so only adjust them as required for the specifics of our particular task.\nSo, the idea is to keep the pretrained part’s weights intact, and only update the weights of the added part. This process is called Freezing\nWhen we create a model from a pretrained network fastai automatically freezes all of the pretrained layers for us. When we call the fine_tune method fastai does two things:\n\nTrains the randomly added layers for one epoch, with all other layers frozen\nUnfreezes all of the layers, and trains them all for the number of epochs requested\n\nOf Course this is just the default approach, fine_tune has many parameters that allow us to apply different tweaks for each specific situation.\nFor now, let’s do this process manually without using fine_tune\n\n\n# check fine_tune source acode\nlearn.fine_tune??\n\n\nFirst we create our learner from the dls and arch using vision_learner\n\nby default vision_learner will freeze the pre-trained part of the model (freeze the params)\n\nThen train the added layer with randome weights for number of epochs with a learning rate we pick\n\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fit_one_cycle(3, 3e-3)\n\n\nNow we need to unfreeze the model:\n\n\nlearn.unfreeze()\n\n\nNow we run lr_find again, because having more layers to train, and weights that have already been trained for three epochs, means our previously found learning rate isn’t appropriate any more:\n\n\nlearn.lr_find()\n\n\nAs we see here the graph is different than what we saw before when we use randome weights to train the model, because that the model has been trained already.\nThe approach to pick the right lr here is to chose a point before the sharp increase.\n\n\n34se3a\n\n\nlearn.fit_one_cycle(6 , lr_max=4.786300905834651e-06)\n\n\n\n\n\nAfter training the model for 6 epochs we get eror_rate at 6% which is fine, but we could do better.\nThe thing we could optimize here is to rethink the learning rate again.\n\npicking one learning rate value for the whole neural network isn’t a good idea.\nthe model is consisted of 2 parts as we know:\n\nthe pre-trained part contained good parameters that has been trained for many epochs\nthe last layer which we trained ourself for not more than 10 (3+6)\n\nso idea here is we shouldn’t trait both parts as if they are the same by picking one learning rate for the whole model\ninstead we could go with a small lr value for the first part, then aplly a slightly bigger one for the last layer.\n\nThis technic is devloped by Jason Yosinski and his team. They shows in 2014 that with transfer learning, different layer should be trained at different speed. \n\nFastai adopt this idea by using slice, which is a built-in object that let you pass 2 values:\n\nthe first define the learning rate of the earlier layer\nthe second for the last layers\n\nThe layers in between will have learning rates that are multiplicatively equidistant throughout that range\n\nLet’s see this technic in action\n\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fit_one_cycle(3, 3e-3)\nlearn.unfreeze()\nlearn.fit_one_cycle(14, lr_max=slice(1e-6,1e-4))\n\n\nWe can plot the training and the validation loss\n\n\nlearn.recorder.plot_loss()\n\n\n\n\n\nChoosing the right amount of epoch you will train the model on is also something we should address properly.\nWe need to keep eye on the train/val loss as shown above, but also on error rate (or any metric we pick).\nIf the loss and the netric are getting better significantly at the end of training, that’s mean we didn’t train for too long\nThe loss is just something we use to allow the optimizer to have something it can different and optimize, it’s not something we really should care about in practice.\n\nif the loss of the validation get worse at during the training because the model is getting over confident, only later it get worse because of overfitting, in practice we care only about the later issue\nIn case of overfitting, the easy solution is to retrain from scratch again, and this time select a total number of epochs based on where your previous best results were found\n\nIt’s not all about epochs, we could add more parameters to the model to get better result\n\n\n\n\n\nIn general, more parameters handle the date more accuratly.\nUsing a deeper model is going to require more GPU RAM, so you may need to lower the size of your batches to avoid an out-of-memory error.\n\nThe way to solve it is to use a smaller batch size, which means passing smaller groups of images at any given time through your model. You can pass the batch size you want to the call creating your DataLoaders with bs=\n\nThe other downside of deeper architectures is that they take quite a bit longer to train.\n\nOne technique that can speed things up a lot is mixed-precision training. This refers to using less-precise numbers (half-precision floating point, also called fp16) where possible during training.\nTo enable this feature in fastai, just add to_fp16() after your Learner creation (you also need to import the module).\n\nYou can’t really know ahead of time what the best architecture for your particular problem is you need to try training some. So let’s try a ResNet-50 now with mixed precision:\n\n\nfrom fastai.callback.fp16 import *\nlearn = vision_learner(dls, resnet50, metrics=error_rate).to_fp16()\nlearn.fine_tune(6, freeze_epochs=3)\n\n\nWe get better results, at less epochs, and less time per epochs only by usung deeper architecture.\n\nbut it’s allways better to start with small model, before scaling-up"
  },
  {
    "objectID": "posts/Fastai_ch5/Fastai-Ch5.html#from-dogs-and-cats-to-pet-breeds",
    "href": "posts/Fastai_ch5/Fastai-Ch5.html#from-dogs-and-cats-to-pet-breeds",
    "title": "Chapter 5: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "In real world scenarios, the first thing we do is we get in contact with data, usualy at this phase we know nothing about the dataset. We then start to look how to extract the data we want from it, and what the data looks like, and how it is structured.\nUsually data is provided in one of two ways:\n\nIndividual files representing items of data, possibly organized into folder or with filenames representing information about those items\n\ntext documents\n\nimages\n\n\nA table of data in which each row is an item and may include filenames providing connections between the data in the table and data in other formats\n\nCSV files\n\n\n\nExceptions:\n\nDomains like Genomics\n\nbinary database formats\n\nnetwork streams\n\n\n\n# download the dataset\nfrom fastai.vision.all import *\npath = untar_data(URLs.PETS)\n\n\n#get the path as variable, and see what inside\nPath.BASE_PATH = path\npath.ls()\n\n\nAs we notice here, the data is provided with 2 directories:\n\nimages\nannotations\n\n\n\n#take a look at what inside the images directory\n(path/'images').ls()\n\n\nWhen we took a look at these names, we see some paterns: we already know from chapter1 that cats name are uppercase, here we see that after the breed’s name there is a (_) then a number, and finally the extension.\nThis may help us to write some code that extract the breed from a single Path.\n\n\n#pick one \nfname = (path/\"images\").ls()[0]\nfname\n\n\nThe best way to work with strings and extract patterns from them is to use Regex, which stands for Regular Expression.\n\n\nre.findall(r'(.+)_\\d+.jpg$', fname.name)\n\n\nNow we need to label the whole dataset using this code.\nFastai comes with many classes for labeling, in this case when we need to label with help of regex we could use RegexLabeller class within DataBlaock API.\n\n\npets = DataBlock(blocks = (ImageBlock, CategoryBlock),\n                 get_items=get_image_files, \n                 splitter=RandomSplitter(seed=42),\n                 get_y=using_attr(RegexLabeller(r'(.+)_\\d+.jpg$'), 'name'),\n                 item_tfms=Resize(460),\n                 batch_tfms=aug_transforms(size=224, min_scale=0.75))\ndls = pets.dataloaders(path/\"images\")"
  },
  {
    "objectID": "posts/Fastai_ch5/Fastai-Ch5.html#presizing",
    "href": "posts/Fastai_ch5/Fastai-Ch5.html#presizing",
    "title": "Chapter 5: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "Fastai has this method of presizing the images in a way that conserve its quality after the data augmentation, so it helps the model to learn more lessons from data, and also it helps our dataset to be more varies\nThe idea behind the presizing is we crop the image and resize it to 460 by 460 first, which is a big size by deep learning norms, this operation is done on CPU, then we do the data augmentation in batches, by cropping a rotated random part of that 460^2 image, and taking the cropped image then resize again to a 224 by 224 image, all this operation are done on batch level, which mean on GPU.**\n\n\nitem_tfms=Resize(460),  \nbatch_tfms=aug_transforms(size=224, min_scale=0.75))\n\n![REsize_method](1.png)\n\n* Usually all the augmentation operations we do on a image reduce the quality of the image, but with this approach we could say we can preserve big part of informations of that image so the model can learn better \n\n### Checking and Debugging a DataBlock\n\n* `DataBlock` is just a blueprint for orginizing data before we feed it to the model, you have no guarantee that your template is going to work on your data source as you intend.\n* So, before training a model you should always check your data. You can do this using the show_batch method:\n\n::: {#cell-23 .cell quarto-private-1='{\"key\":\"colab\",\"value\":{\"base_uri\":\"https://localhost:8080/\",\"height\":193}}' outputId='0f1711e2-f2c6-4703-ed64-1ea456f04a2d'}\n``` {.python .cell-code}\ndls.show_batch(nrows=1, ncols=4 ,unique= True)\n:::\n\nIn case we made a mistake in the process of creating datablock, we could use .summary to track the problem.Here we didn’t resize the images in one formm, so couldn’t use the batch transform\nAs we see here the .summary gives us precise diagnostic of the problem:\n\nat least two tensors in the batch are not the same size.\n\n\n\n\n\nOnce we feel like the datablock is well created, we better begin train the model, and use it as a tool of cleaning the data. If there’s a problem with data or the model, we better know that before we lost lot of time and energy on data cleaning even before testing the model.\n\n\n# train the model\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(2)\n\n\n\n\n\nAs we saw before in Chapter 2 the best tool to clean the data is basically the model itself\nAfter creating the datablock and dataloader we better train the model and get some feedback so we know if something is wrong very early, and if not we start to use the model as tool to investigate the data\nUsually before we train the model we have to decide the function that will update the parameters, a Loss Function. But here we didn’t create any loss function?\nIf we didn’t decide the way by which we update the paramters, Fastai by default will chose a loss function for us.\n\nthe chosen loss function will suite the kind of model we build, and the type of dataset we have.\n\n\n\n# check the loss function\nlearn.loss_func\n\n\nThe loss function used to train this model is Cross Entropy Loss"
  },
  {
    "objectID": "posts/Fastai_ch5/Fastai-Ch5.html#cross-entropy-loss",
    "href": "posts/Fastai_ch5/Fastai-Ch5.html#cross-entropy-loss",
    "title": "Chapter 5: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "The Cross-Entropy Loss is a function similar to what we saw in the previous chapter, when we created the mnist_loss function:\n\ndef mnist_loss(predictions, targets):\n    prediction = prediction.sigmoid()\n    return torch.where(targets==1, 1-prediction, predictions).mean()\n\nThe problem with this function is, it only takes 2 categories(3, 7) but here we have 37 types of breeds.but here we have multiple classes.\n\nit can takes more than 2 categories\n\n\n\n\n\nIn order to understand the cross-entropy loss, let’s grab a batch of data\n\n\nx,y = dls.one_batch()\n\n\nIt return the activations of dependent and independent variable of one mini-batch\n\n\n# independent variable\ny, len(y)\n\n\nIt return 64 number, each represent on of the 37 breeds index\n\n\n# all indepent variables\ndls.vocab, len(dls.vocab)\n\n\nHere we use get_preds to get the predictions for each image in the dataset or mini-batch (like in this example).\n\n\npreds,_ = learn.get_preds(dl=[(x,y)])\n\n\n# prediction for image [0] in the mini-batch\npreds[0]\n\n\nThe 37 predictions refer to the probability of each breed to match the image[0].\n\nif we sum() them up they add up to 1:\n\n\n\npreds[0].sum()\n\n\nIn order to transform the activations of our model into prediction, we use Soft-Max\n\n\n\n\n\nAs we said before, Softmax is similar to sigmoid function we use before, but it only can handel more than 2 classes.\n\n\n# reminder of sigmoid\nplot_function(torch.sigmoid, min=-4,max=4)\n\n\nThis function allow us to predict whether a activation number is pointing to each category of the two, by calculating which activation is big and by much. But in our case today we have 37 category, which means by this logic we need a activation for each one.\nFirst let’s create a similar situation where we have only 2 categories, but we won’t solve it as it’s a binary problem (it's 3) but as 2 categories problem, each has it’s activation, and their probabilty sum up to 1.\n\n\ntorch.random.manual_seed(42);\n\n\nacts = torch.randn((6,2))*2\nacts\n\n\nWe can’t just take the sigmoid of this directly, since we don’t get rows that add to 1 (i.e., we want the probability of being a 3 plus the probability of being a 7 to add up to 1):\n\n\nsigmoid(acts)\n\n\nEevn though we try different approach to solve the same problem, we still have some similarities.\nWe will use sigmoid on each activation.\nAnd we still need to substract an activation from another beacuse that represent how much the model sure about an image is assigned to each category, thats for first column.\nIn the second colun we just use 1 - prediction (activation of the second column)\n\n\ndiffs = acts[:, 0] - acts[:, 1]\n\n\n# create the sigmoid function of both categories\nsigm_ver = torch.stack([diffs.sigmoid(), 1-diffs.sigmoid()], dim=1)\n\n\nWe can express the softmax function as:\n\ndef softmax(x): return exp(x) / exp(x).sum(dim=1, keepdim=True)\n\n\nLet’s check that softmax returns the same values as sigmoid for the first column, and those values subtracted from 1 for the second column:\n\n\nsm_acts = torch.softmax(acts, dim=1)\nsm_acts, sigm_ver\n\n\nSoftmax calculate the \\(exp^{x}\\) and divide it by sum \\(exp^{x}\\) of all activations of other categories.\n\nthe exp make sure the biggest activation is way bigger than others\ndividing by the sum is what make softmax values add up to 1\n\n\n\n\n\n\nIn the previous chapter when we created mnis_loss, we used torch.where to select between the input and 1-input.\nWith softmax, we will use indexing.\n\n\n# the pretended targets\ntargs = tensor([0, 1, 0, 1, 1, 0])\n\n\n# create an index\nidx = range(6)\n\n\n# the softmax activations\nsm_acts\n\n\nHere we make the targs decide which activation we pick in each row\n\n\nsm_acts[idx, targs]\n\n\nlet’s display what we just did :\n\n\nfrom IPython.display import HTML\ndf = pd.DataFrame(sm_acts, columns=[\"3\",\"7\"])\ndf['targs'] = targs\ndf['idx'] = idx\ndf['result'] = sm_acts[range(6), targs]\nt = df.style.hide_index()\n#To have html code compatible with our script\nhtml = t._repr_html_().split('&lt;/style&gt;')[1]\nhtml = re.sub(r'&lt;table id=\"([^\"]+)\"\\s*&gt;', r'&lt;table &gt;', html)\ndisplay(HTML(html))\n\n\nBut idea here is not to use it in a simple binary problem, because torch.where could did the same job here, but is to use it in order to solve a multi-categorie problem\n\nPyTorch provides a function that does exactly the same thing as sm_acts[range(n), targ] (except it takes the negative, because when applying the log afterward, we will have negative numbers), called nll_loss (NLL stands for negative log likelihood):\n\n-sm_acts[idx, targs]\n\n\nF.nll_loss(sm_acts, targs, reduction='none')\n\n\n\n\n\n\n\ncross-entropy-loss-function.png\n\n\n\nThe using of logarithms allow us to do all kind of multiplications without carring about the size of the output.\n\nthe nature of log functions make them increase lineary when the underlying signal increase exponentialy.\nlog(a*b) = log(a)+log(b)\nthe log of a number approaches negative infinity when the number approaches zero\n\nIn our case, since the result relfects the predicted probability of the correct label, we want our loss function to return a small value when the prediction is “good” (closer to 1) and a large value when the prediction is “bad” (closer to 0).\nNotice how the loss is very large in the third and fourth rows where the predictions are confident and wrong, or in other words have high probabilities on the wrong class. One benefit of using the log to calculate the loss is that our loss function penalizes predictions that are both confident and wrong. This kind of penalty works well in practice to aid in more effective model training.\n\nCalculating the loss pay attention only to the high softmax value.\n\n\n\n\n\nAfter taking the log of the softmax, we can then call the negative log likelihood.\n\nfirst : log_softmax\nthen : nll_loss\nor : nn.CrossEntropyLoss()\n\n\n\nloss_func = nn.CrossEntropyLoss()\n\n\nloss_func(acts, targs)\n\n\nnn.CrossEntropyLoss()(acts, targs)\n\n\nThe nn.CrossEntrpyLoss() make do all the steps for us, but if we want to go through all those steps one by one softmas+log then negative log we could do it also:\n\n\nF.nll_loss(nn.Softmax()(acts).log(), targs,)\n\n\nAdding the reduction='none' to this functions will return the loss of each row, if we didn’t add this aparameter the fuction will return the mean loss of all rows.\n\n\nnn.CrossEntropyLoss(reduction='none')(acts, targs)"
  },
  {
    "objectID": "posts/Fastai_ch5/Fastai-Ch5.html#model-interpretation",
    "href": "posts/Fastai_ch5/Fastai-Ch5.html#model-interpretation",
    "title": "Chapter 5: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "As we saw in chapter 3 it’s hard for us to interpret the loss function, since it’s some the computers use in order to updates the parameters and optimize the performance.\nBut we can use some kind of demonstration that shows where the model did good, and where did bad.\n\n\ninterp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix(figsize=(12,12), dpi=60)\n\n\nIts was easy to understand what happened when they were only 3 classes in bears model, but here we have 37 breeds.\n\nthats why we will useinterp.most_confused(min_val=5) to output to most bad decisions the model taked\n\n\n\ninterp.most_confused(min_val=5)\n\n\nThe best way to understand what happend is to google the names of each breed and see why the model confused it with the other breed, so we know that the model is in the right track"
  },
  {
    "objectID": "posts/Fastai_ch5/Fastai-Ch5.html#improving-our-model",
    "href": "posts/Fastai_ch5/Fastai-Ch5.html#improving-our-model",
    "title": "Chapter 5: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "At this point all we can do is improve the model by correcting some detaills that may optimize the final prefromance\n\n\n\n\nOne way of improving our model is by picking the right learning rate.\n\nit will help to get faster result per epoch\nminimize the loss and updating parameters with less steps\n\n\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(1, base_lr=0.1)\n\n\nHere we pick a learning rate 0.1 which is 5 times bigger than the last one 0.002 and we get bad results error rate at: 0.5\n\nbig learning rate may reduce the computation needed for the training process but the model performance will be bad\n\nAlso if we pick a small learning rate it will take forever to achieve something.\nThe answear for this dilemma is The Learning Rate Finder\n\nFastai library adopte this method created by the resaercher Leslie Smith in a paper in 2015.\n\nthe idea of Smith is to start with a small learning rate (very small), and use it for one mini-batch, see how much the loss changed, and then start increasing the learning rate by some percentage (doubling it since its very small anyway)\nrepeate this process again(track the loss, double the learning rate ..) until the loss get worse.\nat this point we just pick a learning rate smaller than the one that causes the loss to get worse.\n\nFastai course advice is either:\n\none order of magnitude less than where the minimun loss was achieved(divide by 10)\nthe last point where the loss was clearly decreasing\n\nBoth point are giving the same value usually.\n\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlr_min,lr_steep = learn.lr_find(suggest_funcs=(minimum, steep))\n\n\nprint(f\"Minimum/10: {lr_min:.2e}, steepest point: {lr_steep:.2e}\")\n\n\nThe plot shows that the loss between 10e-6 and 10e-3 almost didn’t change, but after it start to decrease until it reachs the minimum at 10e-1.\nWe don’t want a learning rate bigger than 10e-1 because there where the loss get worse, and we don’t need learning rate at 10e-1 because at this value we’ve left the stage where the loss was decreasing.\n\nwe need to pick the learning rate where the just start to decrease all the way to the minimum: 1e-3\n\n\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fine_tune(2, base_lr=3e-3)\n\n\nThe error rate get better 10 times just by using the learning rate methode. Loss also get better by this percentage.\n\n\n\n\n\nWe are familiar with the idea of Transfer Learning, where we use a pretrainned model on our dataset, by fine tuning it in a way that keep all the learned weights and use them in our task.\nWe know tha Convolutional Neural Network consist of many linear layers, and between each two of them there’s a nonlinear activation function (ReLU for example), followed by the final layer with an activation function such as Softmax. The final layer uses a matrix with enough columns such that the ouput size is has the number of classes our model trained to predict(assuming we have a classfication task) This final linear layer is unlikely to be of any use for us when we are fine-tuning in a transfer learning setting, because it is specifically designed to classify the categories in the original pretraining dataset.\nSo we first delete it when we start the transfer learning process, and replace it with a new linear layer with the correct number of outputs that matches our desired task(in this case 37 breeds, so 37 activations)\nThis new linear layer have total randome set of weights, but that doesn’t mean we should set all weights randomly even for the pretrained part.\n\nAll of the layers prior to the last one have been carefully trained to be good at image classification tasks in general. As we saw in the images from the Zeiler and Fergus paper, the first few layers encode very general concepts, such as finding gradients and edges, and later layers encode concepts that are still very useful for us, such as finding eyeballs and fur.\n\nWe want to build a model such as preserve all the learned weights, and apply them on our dataset, so only adjust them as required for the specifics of our particular task.\nSo, the idea is to keep the pretrained part’s weights intact, and only update the weights of the added part. This process is called Freezing\nWhen we create a model from a pretrained network fastai automatically freezes all of the pretrained layers for us. When we call the fine_tune method fastai does two things:\n\nTrains the randomly added layers for one epoch, with all other layers frozen\nUnfreezes all of the layers, and trains them all for the number of epochs requested\n\nOf Course this is just the default approach, fine_tune has many parameters that allow us to apply different tweaks for each specific situation.\nFor now, let’s do this process manually without using fine_tune\n\n\n# check fine_tune source acode\nlearn.fine_tune??\n\n\nFirst we create our learner from the dls and arch using vision_learner\n\nby default vision_learner will freeze the pre-trained part of the model (freeze the params)\n\nThen train the added layer with randome weights for number of epochs with a learning rate we pick\n\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fit_one_cycle(3, 3e-3)\n\n\nNow we need to unfreeze the model:\n\n\nlearn.unfreeze()\n\n\nNow we run lr_find again, because having more layers to train, and weights that have already been trained for three epochs, means our previously found learning rate isn’t appropriate any more:\n\n\nlearn.lr_find()\n\n\nAs we see here the graph is different than what we saw before when we use randome weights to train the model, because that the model has been trained already.\nThe approach to pick the right lr here is to chose a point before the sharp increase.\n\n\n34se3a\n\n\nlearn.fit_one_cycle(6 , lr_max=4.786300905834651e-06)\n\n\n\n\n\nAfter training the model for 6 epochs we get eror_rate at 6% which is fine, but we could do better.\nThe thing we could optimize here is to rethink the learning rate again.\n\npicking one learning rate value for the whole neural network isn’t a good idea.\nthe model is consisted of 2 parts as we know:\n\nthe pre-trained part contained good parameters that has been trained for many epochs\nthe last layer which we trained ourself for not more than 10 (3+6)\n\nso idea here is we shouldn’t trait both parts as if they are the same by picking one learning rate for the whole model\ninstead we could go with a small lr value for the first part, then aplly a slightly bigger one for the last layer.\n\nThis technic is devloped by Jason Yosinski and his team. They shows in 2014 that with transfer learning, different layer should be trained at different speed. \n\nFastai adopt this idea by using slice, which is a built-in object that let you pass 2 values:\n\nthe first define the learning rate of the earlier layer\nthe second for the last layers\n\nThe layers in between will have learning rates that are multiplicatively equidistant throughout that range\n\nLet’s see this technic in action\n\n\nlearn = vision_learner(dls, resnet34, metrics=error_rate)\nlearn.fit_one_cycle(3, 3e-3)\nlearn.unfreeze()\nlearn.fit_one_cycle(14, lr_max=slice(1e-6,1e-4))\n\n\nWe can plot the training and the validation loss\n\n\nlearn.recorder.plot_loss()\n\n\n\n\n\nChoosing the right amount of epoch you will train the model on is also something we should address properly.\nWe need to keep eye on the train/val loss as shown above, but also on error rate (or any metric we pick).\nIf the loss and the netric are getting better significantly at the end of training, that’s mean we didn’t train for too long\nThe loss is just something we use to allow the optimizer to have something it can different and optimize, it’s not something we really should care about in practice.\n\nif the loss of the validation get worse at during the training because the model is getting over confident, only later it get worse because of overfitting, in practice we care only about the later issue\nIn case of overfitting, the easy solution is to retrain from scratch again, and this time select a total number of epochs based on where your previous best results were found\n\nIt’s not all about epochs, we could add more parameters to the model to get better result\n\n\n\n\n\nIn general, more parameters handle the date more accuratly.\nUsing a deeper model is going to require more GPU RAM, so you may need to lower the size of your batches to avoid an out-of-memory error.\n\nThe way to solve it is to use a smaller batch size, which means passing smaller groups of images at any given time through your model. You can pass the batch size you want to the call creating your DataLoaders with bs=\n\nThe other downside of deeper architectures is that they take quite a bit longer to train.\n\nOne technique that can speed things up a lot is mixed-precision training. This refers to using less-precise numbers (half-precision floating point, also called fp16) where possible during training.\nTo enable this feature in fastai, just add to_fp16() after your Learner creation (you also need to import the module).\n\nYou can’t really know ahead of time what the best architecture for your particular problem is you need to try training some. So let’s try a ResNet-50 now with mixed precision:\n\n\nfrom fastai.callback.fp16 import *\nlearn = vision_learner(dls, resnet50, metrics=error_rate).to_fp16()\nlearn.fine_tune(6, freeze_epochs=3)\n\n\nWe get better results, at less epochs, and less time per epochs only by usung deeper architecture.\n\nbut it’s allways better to start with small model, before scaling-up"
  },
  {
    "objectID": "posts/HuggingFace_5/Hugging_Face_Cource_Ch5.html",
    "href": "posts/HuggingFace_5/Hugging_Face_Cource_Ch5.html",
    "title": "Hugging Face Course Notes: Chapter5",
    "section": "",
    "text": "!pip install datasets\n\n\nCollecting datasets\n\n  Downloading datasets-2.17.1-py3-none-any.whl (536 kB)\n\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.7/536.7 kB 8.0 MB/s eta 0:00:00\n\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n\nRequirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n\nRequirement already satisfied: pyarrow&gt;=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n\nRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n\nCollecting dill&lt;0.3.9,&gt;=0.3.0 (from datasets)\n\n  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 116.3/116.3 kB 14.0 MB/s eta 0:00:00\n\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n\nRequirement already satisfied: requests&gt;=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n\nRequirement already satisfied: tqdm&gt;=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n\nCollecting multiprocess (from datasets)\n\n  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 134.8/134.8 kB 16.7 MB/s eta 0:00:00\n\nRequirement already satisfied: fsspec[http]&lt;=2023.10.0,&gt;=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n\nRequirement already satisfied: huggingface-hub&gt;=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n\nRequirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n\nRequirement already satisfied: aiosignal&gt;=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets) (1.3.1)\n\nRequirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets) (23.2.0)\n\nRequirement already satisfied: frozenlist&gt;=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets) (1.4.1)\n\nRequirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets) (6.0.5)\n\nRequirement already satisfied: yarl&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets) (1.9.4)\n\nRequirement already satisfied: async-timeout&lt;5.0,&gt;=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;datasets) (4.0.3)\n\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&gt;=0.19.4-&gt;datasets) (4.9.0)\n\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.19.0-&gt;datasets) (3.3.2)\n\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.19.0-&gt;datasets) (3.6)\n\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.19.0-&gt;datasets) (2.0.7)\n\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests&gt;=2.19.0-&gt;datasets) (2024.2.2)\n\nRequirement already satisfied: python-dateutil&gt;=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas-&gt;datasets) (2.8.2)\n\nRequirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-&gt;datasets) (2023.4)\n\nRequirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil&gt;=2.8.1-&gt;pandas-&gt;datasets) (1.16.0)\n\nInstalling collected packages: dill, multiprocess, datasets\n\nSuccessfully installed datasets-2.17.1 dill-0.3.8 multiprocess-0.70.16\n!pip install transformers\n\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.37.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub&lt;1.0,&gt;=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\nRequirement already satisfied: numpy&gt;=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\nRequirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\nRequirement already satisfied: pyyaml&gt;=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers&lt;0.19,&gt;=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors&gt;=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm&gt;=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\nRequirement already satisfied: fsspec&gt;=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&lt;1.0,&gt;=0.19.3-&gt;transformers) (2023.6.0)\nRequirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&lt;1.0,&gt;=0.19.3-&gt;transformers) (4.9.0)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;transformers) (3.3.2)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;transformers) (3.6)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;transformers) (2.0.7)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;transformers) (2024.2.2)\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer"
  },
  {
    "objectID": "posts/HuggingFace_5/Hugging_Face_Cource_Ch5.html#intrudoction",
    "href": "posts/HuggingFace_5/Hugging_Face_Cource_Ch5.html#intrudoction",
    "title": "Hugging Face Course Notes: Chapter5",
    "section": "Intrudoction:",
    "text": "Intrudoction:\n\nIn chapter 3 we learn how to use the library datsets by loading datest from the hub and building a compute_metrics function, and using Dataset.map() function, however this functionalities doesn’t represent the whole picture about dataset library.\nIn this chapetr we will go deeper and try understand :\n\nHow to load a dataset when it’s not available on the Hub\nHow to slice and dice a dataset\nWhat to do when the datset is large\nWhat is “memory mapping” and Apache row?\nHow to create our own dataset and push it to the hub?"
  },
  {
    "objectID": "posts/HuggingFace_5/Hugging_Face_Cource_Ch5.html#what-if-my-dataset-isnt-on-the-hub",
    "href": "posts/HuggingFace_5/Hugging_Face_Cource_Ch5.html#what-if-my-dataset-isnt-on-the-hub",
    "title": "Hugging Face Course Notes: Chapter5",
    "section": "What if my dataset isn’t on the Hub?",
    "text": "What if my dataset isn’t on the Hub?\n\nMost of the time we will deal with situation when the dataset we want to work with isn’t on the HUB, In this section we’ll show you how huggingface Datasets can be used to load datasets that aren’t available on the Hugging Face Hub.\n\n\nWorking with local and remote datasets:\n\nHugging face Datasets provides loading scripts to handle the loading of local and remote datasets. It supports several common data formats, such as:\n\nload_dataset(\"csv\", data_files=\"my_file.csv\")\nload_dataset(\"text\", data_files=\"my_file.txt\")\nload_dataset(\"json\", data_files=\"my_file.jsonl\")\nload_dataset(\"pandas\", data_files=\"my_dataframe.pkl\")\n\n\n\n* As shown , for each data format we just need to specify the type of loading script in the `load_dataset()` function, along with a `data_files` argument that specifies the path to one or more files.\n* First we will deal with loading a dataset from local files; later we’ll see how to do the same with remote files.\n\n\n\n### Loading a local dataset\n\n* Here we'll use the [SQuAD-it](https://github.com/crux82/squad-it/) dataset, which is a large-scale dataset for question answering in Italian.\n\n    * The training and test splits are hosted on GitHub, so we can download them with a simple wget command:\n\n\n::: {#cell-9 .cell quarto-private-1='{\"key\":\"colab\",\"value\":{\"base_uri\":\"https://localhost:8080/\"}}' outputId='6433a784-3bd2-4b27-f0fc-3135e17e61bb'}\n``` {.python .cell-code}\n!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz\n!wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz\n\n--2024-02-27 13:44:06--  https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz\nResolving github.com (github.com)... 140.82.114.4\nConnecting to github.com (github.com)|140.82.114.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/crux82/squad-it/master/SQuAD_it-train.json.gz [following]\n--2024-02-27 13:44:06--  https://raw.githubusercontent.com/crux82/squad-it/master/SQuAD_it-train.json.gz\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 7725286 (7.4M) [application/octet-stream]\nSaving to: ‘SQuAD_it-train.json.gz’\n\nSQuAD_it-train.json 100%[===================&gt;]   7.37M  --.-KB/s    in 0.1s    \n\n2024-02-27 13:44:06 (68.4 MB/s) - ‘SQuAD_it-train.json.gz’ saved [7725286/7725286]\n\n--2024-02-27 13:44:06--  https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz\nResolving github.com (github.com)... 140.82.112.3\nConnecting to github.com (github.com)|140.82.112.3|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://raw.githubusercontent.com/crux82/squad-it/master/SQuAD_it-test.json.gz [following]\n--2024-02-27 13:44:07--  https://raw.githubusercontent.com/crux82/squad-it/master/SQuAD_it-test.json.gz\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1051245 (1.0M) [application/octet-stream]\nSaving to: ‘SQuAD_it-test.json.gz’\n\nSQuAD_it-test.json. 100%[===================&gt;]   1.00M  --.-KB/s    in 0.07s   \n\n2024-02-27 13:44:07 (15.1 MB/s) - ‘SQuAD_it-test.json.gz’ saved [1051245/1051245]\n\n\n:::\n\nWe need decompress them frist:\n\n\n!gzip -dkv SQuAD_it-*.json.gz\n\nSQuAD_it-test.json.gz:   87.5% -- created SQuAD_it-test.json\nSQuAD_it-train.json.gz:  82.3% -- created SQuAD_it-train.json\n\n\n\n!rm -rf SQuAD_it-*.json.gz\n\n\nNow we can download our dataset from local file as if it from the hub:\n\n\ndataset = load_dataset('json', data_files= \"SQuAD_it-train.json\", field= \"data\" )\n\n\n\n\n\nBe default downloading local file creates a DatasetDict with train split:\n\n\ndataset\n\nDatasetDict({\n    train: Dataset({\n        features: ['title', 'paragraphs'],\n        num_rows: 442\n    })\n})\n\n\n\nWe can view that we have 442 rows, let’s see one of them:\n\n\ndataset['train'][0]\n\n\nGreat, we’ve loaded our first local dataset! But while this worked for the training set, what we really want is to include both the train and test splits in a single DatasetDict object so we can apply Dataset.map() functions across both splits at once.\nTo do this, we can provide a dictionary to the data_files argument that maps each split name to a file associated with that split:\n\n\n# the proper way to load dataset from local file:\ndata_files = {\"train\": \"SQuAD_it-train.json\", \"test\": \"SQuAD_it-test.json\"}\nsquad_it_dataset = load_dataset(\"json\", data_files=data_files, field=\"data\")\nsquad_it_dataset\n\n\n\n\n\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['title', 'paragraphs'],\n        num_rows: 442\n    })\n    test: Dataset({\n        features: ['title', 'paragraphs'],\n        num_rows: 48\n    })\n})\n\n\n\nThis is exactly what we wanted. Now, we can apply various preprocessing techniques to clean up the data, tokenize the reviews, and so on.\nThe loading scripts in Datasets acually support the automatic decompression of the input files, we could have skipped the use of gzip by pointing the data_files argument directly to the compressed files:\n\n\ndata_files = {'train': 'SQuAD_it-train.json.gz', 'test': 'SQuAD_it-test.json.gz'}\ndataset = load_dataset('json', data_files=data_files, field= 'data')\ndataset\n\n\n\n\n\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['title', 'paragraphs'],\n        num_rows: 442\n    })\n    test: Dataset({\n        features: ['title', 'paragraphs'],\n        num_rows: 48\n    })\n})\n\n\n\nThe automatic decompression also applies to other common formats like ZIP and TAR, so you just need to point data_files to the compressed files and you’re good to go!\n\n\n\nLoading a remote dataset:\n\nLoading remote files is very similar to loading locally, we just need to point to data_file the url where the data is stored instead to providing the path to lacal files.\nFor example the SQuAD_it dataset is stored on github so we could build our dataset from that url directly:\n\n\ndata_files = {'train':'https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz',\n              'test': 'https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz'}\ndataset = load_dataset('json', data_files=data_files, field='data')"
  },
  {
    "objectID": "posts/HuggingFace_5/Hugging_Face_Cource_Ch5.html#time-to-slice-and-dice",
    "href": "posts/HuggingFace_5/Hugging_Face_Cource_Ch5.html#time-to-slice-and-dice",
    "title": "Hugging Face Course Notes: Chapter5",
    "section": "Time to slice and dice:",
    "text": "Time to slice and dice:\n\nIn this section we will explore various features Datasets provide in order to clean and prepare the dataset for the next steps.\n\n\nSlicing and dicing our data:\n\nLike Pandas Datasets provides several functions to manipulate the content of DatasetDict Data object, we already use the .map() method.\nHere we will use Drug Review Dataset from UC Irvine Machine Learning Repository which contains patient reviews on various drugs, along with the condition being treated and a 10-star rating of the patient’s satisfaction.\nFirst we need to download it and unzip it:\n\n\n!wget https://archive.ics.uci.edu/static/public/462/drug+review+dataset+drugs+com.zip\n\n--2024-02-27 14:22:46--  https://archive.ics.uci.edu/static/public/462/drug+review+dataset+drugs+com.zip\nResolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\nConnecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: unspecified\nSaving to: ‘drug+review+dataset+drugs+com.zip’\n\ndrug+review+dataset     [       &lt;=&gt;          ]  41.00M  30.7MB/s    in 1.3s    \n\n2024-02-27 14:22:48 (30.7 MB/s) - ‘drug+review+dataset+drugs+com.zip’ saved [42989872]\n\n\n\n\n!unzip drug+review+dataset+drugs+com.zip\n\nArchive:  drug+review+dataset+drugs+com.zip\n  inflating: drugsComTest_raw.tsv    \n  inflating: drugsComTrain_raw.tsv   \n\n\n\nWe will use csv arguments here even though we have tsv files, we just need to specifying the delimiter argument in the load_dataset() function as follows:\n\n\ndata_files = {'train': 'drugsComTrain_raw.tsv',\n              'test': 'drugsComTest_raw.tsv'}\ndataset = load_dataset('csv', data_files=data_files, delimiter= '\\t')\n\n\n\n\n\n\n\n\nA good practice when doing any sort of data analysis is to grab a small random sample to get a quick feel for the type of data you’re working with. In Datasets, we can create a random sample by chaining the Dataset.shuffle() and Dataset.select() functions together:\n\n\ndrug_sample = dataset['train'].shuffle(seed= 42).select(range(1000))\ndrug_sample[:2]\n\n{'Unnamed: 0': [87571, 178045],\n 'drugName': ['Naproxen', 'Duloxetine'],\n 'condition': ['Gout, Acute', 'ibromyalgia'],\n 'review': ['\"like the previous person mention, I&#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!\"',\n  '\"I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\\r\\nas a pain reducer and an anti-depressant, however, the side effects outweighed \\r\\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\\r\\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\\r\\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\\r\\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects.\"'],\n 'rating': [9.0, 3.0],\n 'date': ['September 2, 2015', 'November 7, 2011'],\n 'usefulCount': [36, 13]}\n\n\n\nHere we fixed the seed for reproducibility.\n.select() method works with iterator so we provide a range()\nThen we slice that sample the python way.\nFrom this sample we can already see a few quirks in our dataset:\n\nThe Unnamed: 0 column looks suspiciously like an anonymized ID for each patient.\nThe condition column includes a mix of uppercase and lowercase labels.\nThe reviews are of varying length and contain a mix of Python line separators () as well as HTML character codes like &#039;.\n\nWe will adress each issue with Dataset library:\nFirst the unnamed column may be just Id fro each patient, so we check if each one of those IDs is unique or not:\n\n\nfor split in dataset.keys():\n    assert len(dataset[split]) == len(dataset[split].unique(\"Unnamed: 0\"))\n\n\nIt’s better to rename that column to something more meaningfull:\n\n\ndataset = dataset.rename_column('Unnamed: 0', 'patient_id')\ndataset\n\nDatasetDict({\n    train: Dataset({\n        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n        num_rows: 161297\n    })\n    test: Dataset({\n        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n        num_rows: 53766\n    })\n})\n\n\n\nNow we have to lower case all the condition values. This can be easily achieved by .map() method:\n\n\ndef lower_case(example):\n  return {'condition': example['condition'].lower()}\n\n\ndataset.map(lower_case)\n\n\n\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\n&lt;ipython-input-27-b34dfc422493&gt; in &lt;cell line: 1&gt;()\n----&gt; 1 dataset.map(lower_case)\n\n/usr/local/lib/python3.10/dist-packages/datasets/dataset_dict.py in map(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\n    866             cache_file_names = {k: None for k in self}\n    867         return DatasetDict(\n--&gt; 868             {\n    869                 k: dataset.map(\n    870                     function=function,\n\n/usr/local/lib/python3.10/dist-packages/datasets/dataset_dict.py in &lt;dictcomp&gt;(.0)\n    867         return DatasetDict(\n    868             {\n--&gt; 869                 k: dataset.map(\n    870                     function=function,\n    871                     with_indices=with_indices,\n\n/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py in wrapper(*args, **kwargs)\n    591             self: \"Dataset\" = kwargs.pop(\"self\")\n    592         # apply actual function\n--&gt; 593         out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n    594         datasets: List[\"Dataset\"] = list(out.values()) if isinstance(out, dict) else [out]\n    595         for dataset in datasets:\n\n/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py in wrapper(*args, **kwargs)\n    556         }\n    557         # apply actual function\n--&gt; 558         out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n    559         datasets: List[\"Dataset\"] = list(out.values()) if isinstance(out, dict) else [out]\n    560         # re-apply format to the output\n\n/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py in map(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\n   3103                     desc=desc or \"Map\",\n   3104                 ) as pbar:\n-&gt; 3105                     for rank, done, content in Dataset._map_single(**dataset_kwargs):\n   3106                         if done:\n   3107                             shards_done += 1\n\n/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py in _map_single(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\n   3456                     _time = time.time()\n   3457                     for i, example in shard_iterable:\n-&gt; 3458                         example = apply_function_on_filtered_inputs(example, i, offset=offset)\n   3459                         if update_data:\n   3460                             if i == 0:\n\n/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py in apply_function_on_filtered_inputs(pa_inputs, indices, check_same_num_examples, offset)\n   3359             if with_rank:\n   3360                 additional_args += (rank,)\n-&gt; 3361             processed_inputs = function(*fn_args, *additional_args, **fn_kwargs)\n   3362             if isinstance(processed_inputs, LazyDict):\n   3363                 processed_inputs = {\n\n&lt;ipython-input-26-98b6e79f37ab&gt; in lower_case(example)\n      1 def lower_case(example):\n----&gt; 2   return {'condition': example['condition'].lower()}\n\nAttributeError: 'NoneType' object has no attribute 'lower'\n\n\n\n\nIts seems like some of condition values are NoneType, which the map function cannot support.\nLet’s drop these rows using Dataset.filter(), which works in a similar way to Dataset.map() and expects a function that receives a single example of the dataset.\nWe will use the lambda function:\n\n\ndataset = dataset.filter(lambda x: x['condition'] is not None)\n\n\n\n\n\n\n\n\nNow lets aplly .map() method on lower_case() funtion:\n\n\ndataset = dataset.map(lower_case)\n\n\n\n\n\n\n\n\n\nCreating new columns:\n\nWhen dealing with reviews datasets, its good practice to count the number of words in each review, so lets create a function that achieve that goal:\n\n\ndef compute_review_length(example):\n  return {'review_length': len(example['review'].split())}\n\n\ncompute_review_length() returns a dictionary whose key does not correspond to one of the column names in the dataset. In this case, when compute_review_length() is passed to Dataset.map(), it will be applied to all the rows in the dataset to create a new review_length column:\n\n\ndataset = dataset.map(compute_review_length)\n\n\n\n\n\n\n\n\ndataset['train'][2]\n\n{'patient_id': 92703,\n 'drugName': 'Lybrel',\n 'condition': 'birth control',\n 'review': '\"I used to take another oral contraceptive, which had 21 pill cycle, and was very happy- very light periods, max 5 days, no other side effects. But it contained hormone gestodene, which is not available in US, so I switched to Lybrel, because the ingredients are similar. When my other pills ended, I started Lybrel immediately, on my first day of period, as the instructions said. And the period lasted for two weeks. When taking the second pack- same two weeks. And now, with third pack things got even worse- my third period lasted for two weeks and now it&#039;s the end of the third week- I still have daily brown discharge.\\r\\nThe positive side is that I didn&#039;t have any other side effects. The idea of being period free was so tempting... Alas.\"',\n 'rating': 5.0,\n 'date': 'December 14, 2009',\n 'usefulCount': 17,\n 'review_length': 134}\n\n\n\nAs expected, we can see a review_length column has been added to our training set. We can sort this new column with Dataset.sort() to see what the extreme values look like:\n\n\ndataset['train'].sort('review_length')[:3]\n\n{'patient_id': [111469, 13653, 53602],\n 'drugName': ['Ledipasvir / sofosbuvir',\n  'Amphetamine / dextroamphetamine',\n  'Alesse'],\n 'condition': ['hepatitis c', 'adhd', 'birth control'],\n 'review': ['\"Headache\"', '\"Great\"', '\"Awesome\"'],\n 'rating': [10.0, 10.0, 10.0],\n 'date': ['February 3, 2015', 'October 20, 2009', 'November 23, 2015'],\n 'usefulCount': [41, 3, 0],\n 'review_length': [1, 1, 1]}\n\n\n\nWe could delete rows that countains review with less than 30 words, by using the combination of lambda function + .filter():\n\n\ndataset = dataset.filter(lambda x: x['review_length'] &gt; 30)\n\n\n\n\n\n\n\n\nThe last problemm we have to deal with is html characters, We can use Python’s html module to unescape these characters, like so:\n\n\nimport html\n\n\nWe’ll use Dataset.map() to unescape all the HTML characters in our corpus:\n\n\ndataset = dataset.map(lambda x: {'review': html.unescape(x['review'])})\n\n\n\n\n\n\n\n\n\nThe map() method’s superpowers:\n\nThe last mapping we apply on dataset takes almost 40s to execute, this duration can be reduced if we pass an argument to the .map() method: batched=True, this will create batches and lets the code applied in many elements at once, we could also construct the code in list comprehension instead of regular for loop, which also add preformance the operation:\n\n\nnew_dataset = dataset.map(lambda x: {'review': [html.unescape(o) for o in x['review']]}, batched= True)\n\n\n\n\n\n\n\n\nThis time our map() function execute in 1s, 40x time faster!\nUsing .map() with batched set to true is very powerful tool that will help us later with tokenizer()\nNow lets tokenize our dataset since we are done EDA part:\n\n\nmdl = 'bert-base-uncased'\ntokenizer = AutoTokenizer.from_pretrained(mdl)\ndef tokenizer_function(example):\n  return tokenizer(example['review'], truncation= True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntokenized_ds = dataset.map(tokenizer_function, batched=True)\n\n\n\n\n\n\n\n\nAll of this functionality condensed into a single method is already pretty amazing, but there’s more! With Dataset.map() and batched=True you can change the number of elements in your dataset. This is super useful in many situations where you want to create several training features from one example, and we will need to do this as part of the preprocessing for several of the NLP tasks we’ll undertake in Chapter 7.\nIn machine learning, an example is usually defined as the set of features that we feed to the model. In some contexts, these features will be the set of columns in a Dataset, but in others (like here and for question answering), multiple features can be extracted from a single example and belong to a single column.\nLet’s have a look at how it works! Here we will tokenize our examples and truncate them to a maximum length of 128, but we will ask the tokenizer to return all the chunks of the texts instead of just the first one. This can be done with return_overflowing_tokens=True:\n\n\ndef tokenize_split(example):\n  return tokenizer(\n      example['review'],\n      truncation= True,\n      max_length= 128,\n      return_overflowing_tokens= True\n  )\n\n\nLet’s test this before we pass it to the map() function:\n\n\nres = tokenize_split(dataset['train'][0])\n[len(inp) for inp in res['input_ids']]\n\n[128, 45]\n\n\n\nSo, our first example in the training set became two features because it was tokenized to more than the maximum number of tokens we specified: the first one of length 128 and the second one of length 45. Now let’s do this for all elements of the dataset!\n\n\ntokenized_ds = dataset.map(tokenize_split, batched= True)\n\n\n\n\n\n---------------------------------------------------------------------------\nArrowInvalid                              Traceback (most recent call last)\n&lt;ipython-input-47-4c142a3791ef&gt; in &lt;cell line: 1&gt;()\n----&gt; 1 tokenized_ds = dataset.map(tokenize_split, batched= True)\n\n/usr/local/lib/python3.10/dist-packages/datasets/dataset_dict.py in map(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\n    866             cache_file_names = {k: None for k in self}\n    867         return DatasetDict(\n--&gt; 868             {\n    869                 k: dataset.map(\n    870                     function=function,\n\n/usr/local/lib/python3.10/dist-packages/datasets/dataset_dict.py in &lt;dictcomp&gt;(.0)\n    867         return DatasetDict(\n    868             {\n--&gt; 869                 k: dataset.map(\n    870                     function=function,\n    871                     with_indices=with_indices,\n\n/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py in wrapper(*args, **kwargs)\n    591             self: \"Dataset\" = kwargs.pop(\"self\")\n    592         # apply actual function\n--&gt; 593         out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n    594         datasets: List[\"Dataset\"] = list(out.values()) if isinstance(out, dict) else [out]\n    595         for dataset in datasets:\n\n/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py in wrapper(*args, **kwargs)\n    556         }\n    557         # apply actual function\n--&gt; 558         out: Union[\"Dataset\", \"DatasetDict\"] = func(self, *args, **kwargs)\n    559         datasets: List[\"Dataset\"] = list(out.values()) if isinstance(out, dict) else [out]\n    560         # re-apply format to the output\n\n/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py in map(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\n   3103                     desc=desc or \"Map\",\n   3104                 ) as pbar:\n-&gt; 3105                     for rank, done, content in Dataset._map_single(**dataset_kwargs):\n   3106                         if done:\n   3107                             shards_done += 1\n\n/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py in _map_single(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\n   3499                                 writer.write_table(pa.Table.from_pandas(batch))\n   3500                             else:\n-&gt; 3501                                 writer.write_batch(batch)\n   3502                         num_examples_progress_update += num_examples_in_batch\n   3503                         if time.time() &gt; _time + config.PBAR_REFRESH_TIME_INTERVAL:\n\n/usr/local/lib/python3.10/dist-packages/datasets/arrow_writer.py in write_batch(self, batch_examples, writer_batch_size)\n    567                 inferred_features[col] = typed_sequence.get_inferred_type()\n    568         schema = inferred_features.arrow_schema if self.pa_writer is None else self.schema\n--&gt; 569         pa_table = pa.Table.from_arrays(arrays, schema=schema)\n    570         self.write_table(pa_table, writer_batch_size)\n    571 \n\n/usr/local/lib/python3.10/dist-packages/pyarrow/table.pxi in pyarrow.lib.Table.from_arrays()\n\n/usr/local/lib/python3.10/dist-packages/pyarrow/table.pxi in pyarrow.lib.Table.validate()\n\n/usr/local/lib/python3.10/dist-packages/pyarrow/error.pxi in pyarrow.lib.check_status()\n\nArrowInvalid: Column 8 named input_ids expected length 1000 but got length 1447\n\n\n\n\nLooking at the error message will give us a clue: there is a mismatch in the lengths of one of the columns, one being of length 1,463 and the other of length 1,000. here those 1,000 examples gave 1,463 new features, resulting in a shape error.\nThe problem is that we’re trying to mix two different datasets of different sizes: the drug_dataset columns will have a certain number of examples (the 1,000 in our error), but the tokenized_dataset we are building will have more (the 1,463 in the error message; it is more than 1,000 because we are tokenizing long reviews into more than one example by using return_overflowing_tokens=True). That doesn’t work for a Dataset, so we need to either remove the columns from the old dataset or make them the same size as they are in the new dataset. We can do the former with the remove_columns argument:\n\n\ntokenized_ds = dataset.map(tokenize_split, batched= True, remove_columns= dataset['train'].column_names)\n\n\n\n\n\n\n\n\nlen(tokenized_ds['train'])\n\n204198\n\n\n\nlen(dataset['train'])\n\n138514"
  },
  {
    "objectID": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html",
    "href": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html",
    "title": "Hugging Face Course Notes: Chapter2",
    "section": "",
    "text": "Transformer models are very large with Ms to 10s of Billions of parameters, which make the process of training and fine-tuning and deploying them very hard.\nHere comes the Hugging Face library which adress that problem, the goal is to provide a single API through which any transformer model can be loaded, trained and saved.\nWith Transformer library we can: - Download, load and use models for inference or fine-tuning with just couple lines of code - all models in the library are stored like any other model, at their core they are just a simple pytorch nn.Module class. - All components of the models are stored in one file, so no abstarctions or shared modules across files"
  },
  {
    "objectID": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#preprocessing-with-a-tokenizer",
    "href": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#preprocessing-with-a-tokenizer",
    "title": "Hugging Face Course Notes: Chapter2",
    "section": "Preprocessing with a Tokenizer:",
    "text": "Preprocessing with a Tokenizer:\n\nIn order to convert raw text to its numerical form before we feed it to the model, we use Tokenizer.\nHere is how we tokenize any input words:\n\n\nfrom transformers import AutoTokenizer\nmdl_ckpt = \"distilbert-base-uncased-finetuned-sst-2-english\"\ntokenizer = AutoTokenizer.from_pretrained(mdl_ckpt)\ninputs = 'My birthday is today!'\noutputs = tokenizer(inputs, padding=True, truncation=True, return_tensors='pt')\noutputs\n\n{'input_ids': tensor([[ 101, 2026, 5798, 2003, 2651,  999,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}\n\n\n\nFirst we pick a model distilbert-base-uncased-finetuned-sst-2-english which is basically the same model our pipeline used to classify the sentence.\nWe use AutoTokenizer to get to tokenization method according to that model, because each model has its own method of tokenizing words.\nThen we feed the text to the tokenizer, and we pick which type of tensors we want to get returned\n\npt stands for pytorch\nother parameters will be covered later\n\nWe get a dictionary with 2 keys: input_ids and attention_mask\nattention_mask will be covered later, input_ids contains one list of integers."
  },
  {
    "objectID": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#going-through-the-model",
    "href": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#going-through-the-model",
    "title": "Hugging Face Course Notes: Chapter2",
    "section": "Going through the model:",
    "text": "Going through the model:\n\nWe can download the pretraind model same we did with tokenizer, by usin AutoModel class which also has from_pretrained method.\nWe just need to download the same model as used in tokenization process.\n\n\nfrom transformers import AutoModel\nmodel = AutoModel.from_pretrained(mdl_ckpt)\n\n\nThis architecture we just downloaded conatins onlly the base transformer module: given some inputs, it outputs what we call Hidden_state.\nFor each model inputs we will retrieve a high-dimensional vector representing the contextual understanding of that input by the model\nThese Hidden_states can be used as it is, but usually it will be feeded as input to another part of the model called the Head.\nEach Head is a task_specific head."
  },
  {
    "objectID": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#a-high-dimensional-vector",
    "href": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#a-high-dimensional-vector",
    "title": "Hugging Face Course Notes: Chapter2",
    "section": "A high-dimensional vector?",
    "text": "A high-dimensional vector?\n\nUsually the model outputs a large vector with 3 dimensions:\n\nBatch-size: the number of sequence processed (in our case we pass only one sentence)\nSequence-length: The length of the numerical representation of the sequence (8 in our example)\nHidden size: The vector dimension of each model input.\n\nThe high-dimentionality of this vector comes from the last dimension, the hidden-size is very large dimension: usually ~700:\n\n\nouts = model(**outputs)\nouts.last_hidden_state.shape\n\ntorch.Size([1, 7, 768])"
  },
  {
    "objectID": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#model-heads-making-sense-out-of-numbers",
    "href": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#model-heads-making-sense-out-of-numbers",
    "title": "Hugging Face Course Notes: Chapter2",
    "section": "Model heads: Making sense out of numbers:",
    "text": "Model heads: Making sense out of numbers:\n\nSo to wrap-up the whole process: First get inputs converted input ID then the embedding layer convert them into tokenized vectors.\nThe subsequent layers manipulate thes vectors using attention mechanism to produce a contextual understanding of that input in form of High-dimensional-vector.\n\n\n\n\nmodel\n\n\n\nThere rae many architecture available in the Transformers library, each is designed to tackle specific task.\nFor example if we want a model for a sequence classification head, we will use AutoModelForSequenceClassification instead of AutoModel.\n\n\ntext = ['do you feel any better today?', 'I feel warm and cosy in my house']\ntokenizer = AutoTokenizer.from_pretrained(mdl_ckpt)\ninps = tokenizer(text, padding=True, truncation=True, return_tensors='pt')\n\n\nfrom transformers import AutoModelForSequenceClassification\nmdl_ckpt = \"distilbert-base-uncased-finetuned-sst-2-english\"\nmodel = AutoModelForSequenceClassification.from_pretrained(mdl_ckpt)\nouts = model(**inps)\nouts\n\nSequenceClassifierOutput(loss=None, logits=tensor([[-0.2121,  0.4987],\n        [-3.9382,  4.1996]], grad_fn=&lt;AddmmBackward0&gt;), hidden_states=None, attentions=None)\n\n\n\nouts.logits.shape\n\ntorch.Size([2, 2])\n\n\n\nIn this case we have 2 sentences and 2 labels negative positive.\nThe model will take the high dimensional vector as input and outputs a vector that match our task.\n\n\nPost processing:\n\nThe vector we get doesn’t make any sense as it is, so we need to make it meaningful for our task.\n\n\nouts.logits\n\ntensor([[-0.2121,  0.4987],\n        [-3.9382,  4.1996]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nthose are prediction for each sentence, and each prediction can be mapped to a label, so we need to know each label which, then convert those logits into some meaningful values.\nTo convert the logits into probabilies we will pass them through a softmax layer.\n\n\nimport torch\npreds = torch.nn.functional.softmax(outs.logits, dim=-1)\npreds\n\ntensor([[3.2942e-01, 6.7058e-01],\n        [2.9218e-04, 9.9971e-01]], grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nNow we need to know the label of each colomn:\n\n\nmodel.config.id2label\n\n{0: 'NEGATIVE', 1: 'POSITIVE'}\n\n\n\nSo the position [0] is negative where the position [1] positive"
  },
  {
    "objectID": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#saving-the-model",
    "href": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#saving-the-model",
    "title": "Hugging Face Course Notes: Chapter2",
    "section": "Saving the model:",
    "text": "Saving the model:\n\nTo save a model we are satisfied with its prformance:\n\n\nmdl.save_pretrained('path')\n\n\n!ls 'path'\n\nconfig.json  pytorch_model.bin  special_tokens_map.json  tokenizer_config.json  vocab.txt\n\n\n\nThis saves 2 files:\n\nconfig.json: contains all attributes necessary to build the model architecture, and also it contains some metadata\npytorch_model.bin: contains the learnable weights."
  },
  {
    "objectID": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#using-a-transformer-model-for-inference",
    "href": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#using-a-transformer-model-for-inference",
    "title": "Hugging Face Course Notes: Chapter2",
    "section": "Using a Transformer model for inference:",
    "text": "Using a Transformer model for inference:\n\nTokenizer convert input words into input ID:\n\n\nsequences = [\"Hello!\", \"Cool.\", \"Nice!\"]\ninps = tokenizer(sequences)\nencoded_sequences = inps.input_ids\nencoded_sequences\n\n[[101, 7592, 999, 102], [101, 4658, 1012, 102], [101, 3835, 999, 102]]\n\n\n\nThe output we get here is a list of list, the problem is that tensors accept only rectangular shapes.\nSo we nee to cenvert it into the targeted shape:\n\n\ninput = torch.tensor(encoded_sequences)\ninput\n\ntensor([[ 101, 7592,  999,  102],\n        [ 101, 4658, 1012,  102],\n        [ 101, 3835,  999,  102]])\n\n\n\nUsing the tensors as inputs to the model\n\nMaking use of this returned tensor is easy as pass it through the model:\n\n\noutputs= mdl(input)\noutputs\n\nBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 4.4496e-01,  4.8276e-01,  2.7797e-01,  ..., -5.4032e-02,\n           3.9394e-01, -9.4770e-02],\n         [ 2.4943e-01, -4.4093e-01,  8.1772e-01,  ..., -3.1917e-01,\n           2.2992e-01, -4.1172e-02],\n         [ 1.3668e-01,  2.2518e-01,  1.4502e-01,  ..., -4.6915e-02,\n           2.8224e-01,  7.5566e-02],\n         [ 1.1789e+00,  1.6738e-01, -1.8187e-01,  ...,  2.4671e-01,\n           1.0441e+00, -6.1970e-03]],\n\n        [[ 3.6436e-01,  3.2464e-02,  2.0258e-01,  ...,  6.0111e-02,\n           3.2451e-01, -2.0995e-02],\n         [ 7.1866e-01, -4.8725e-01,  5.1740e-01,  ..., -4.4012e-01,\n           1.4553e-01, -3.7545e-02],\n         [ 3.3223e-01, -2.3271e-01,  9.4877e-02,  ..., -2.5268e-01,\n           3.2172e-01,  8.1079e-04],\n         [ 1.2523e+00,  3.5754e-01, -5.1320e-02,  ..., -3.7840e-01,\n           1.0526e+00, -5.6255e-01]],\n\n        [[ 2.4042e-01,  1.4718e-01,  1.2110e-01,  ...,  7.6062e-02,\n           3.3564e-01,  2.8262e-01],\n         [ 6.5701e-01, -3.2787e-01,  2.4968e-01,  ..., -2.5920e-01,\n           2.0175e-01,  3.3275e-01],\n         [ 2.0160e-01,  1.5783e-01,  9.8974e-03,  ..., -3.8850e-01,\n           4.1308e-01,  3.9732e-01],\n         [ 1.0175e+00,  6.4387e-01, -7.8147e-01,  ..., -4.2109e-01,\n           1.0925e+00, -4.8456e-02]]], grad_fn=&lt;NativeLayerNormBackward0&gt;), pooler_output=tensor([[-0.6856,  0.5262,  1.0000,  ...,  1.0000, -0.6112,  0.9971],\n        [-0.6055,  0.4997,  0.9998,  ...,  0.9999, -0.6753,  0.9769],\n        [-0.7702,  0.5447,  0.9999,  ...,  1.0000, -0.4655,  0.9894]],\n       grad_fn=&lt;TanhBackward0&gt;), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
  },
  {
    "objectID": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#loading-and-saving",
    "href": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#loading-and-saving",
    "title": "Hugging Face Course Notes: Chapter2",
    "section": "Loading and Saving:",
    "text": "Loading and Saving:\n\nLoading and saving tokenizer is simple and very similar to how we load and save Models.\nBy using the same two methods: from_pretrained and save_pretrained.\nAlso we can load the tokenizer either by calling tokenizer class BertTokenizer or by just using AutoTokenizer, same as how we load models: AutoModel or BertModel:\n\n\nfrom transformers import BertTokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n\n\n# or the easy way\ntokenizer1 = AutoTokenizer.from_pretrained('bert-base-cased')\n\n\ntext = 'try to tokenize this text so I can see the difference between them!'\ninp = tokenizer(text, return_tensors='pt')\ninp1 = tokenizer1(text, return_tensors='pt')\n\n\ninp.input_ids, inp1.input_ids\n\n(tensor([[  101,  2222,  1106, 22559,  3708,  1142,  3087,  1177,   146,  1169,\n           1267,  1103,  3719,  1206,  1172,   106,   102]]),\n tensor([[  101,  2222,  1106, 22559,  3708,  1142,  3087,  1177,   146,  1169,\n           1267,  1103,  3719,  1206,  1172,   106,   102]]))\n\n\n\nSo both methods yield same results, but as we said before we prefer using the second method since its code agnostinc and can be applied with all model.\nSaving tokenizer is also similar to how we save models:\n\n\ntokenizer.save_pretrained('path')\n\n('path/tokenizer_config.json',\n 'path/special_tokens_map.json',\n 'path/vocab.txt',\n 'path/added_tokens.json')"
  },
  {
    "objectID": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#encoding",
    "href": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#encoding",
    "title": "Hugging Face Course Notes: Chapter2",
    "section": "Encoding:",
    "text": "Encoding:\n\nThe process of translating words to numbers is called encoding.\nThe encoding is done through 2 steps:\n\nTokenization\nconversion to input IDs\n\n\n * The first we create token-word, ,ostly complete words, but in some cases the one word will be splited to 2 or more parts. - this sub parts can be dentified by the ## preffix. * Then we need to convert those tokens into input IDs in order to feed them to the model. * To do that the tokenizer pass this tokens through a Vocabulary. - When we instentiate the tokenizer with from_pretrained() we already download that vocabulary the we can match ewach token against an ID. - we need to use the same checkpoint during the training. * Here we will explore these 2 steps seperatly:\n\ntext  = 'Using a transformer network is simple'\ntokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\ntokens = tokenizer.tokenize(text)\ntokens\n\n['Using', 'a', 'transform', '##er', 'network', 'is', 'simple']\n\n\n\nAs we see the word transformer get splited to 2 parts, the second one is represented with ## prefix\n\n\nids = tokenizer.convert_tokens_to_ids(tokens)\nids\n\n[7993, 170, 11303, 1200, 2443, 1110, 3014]"
  },
  {
    "objectID": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#decoding",
    "href": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#decoding",
    "title": "Hugging Face Course Notes: Chapter2",
    "section": "Decoding:",
    "text": "Decoding:\n\nThe idea of decoding is the exact opsite of encoding, its the process of converting ids to their text/word form\n\n\ndecoded_ids = tokenizer.decode(ids)\ndecoded_ids\n\n'Using a transformer network is simple'\n\n\n\nWe get the text we begin with back by using the decode() method."
  },
  {
    "objectID": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#padding",
    "href": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#padding",
    "title": "Hugging Face Course Notes: Chapter2",
    "section": "Padding:",
    "text": "Padding:\n\nSuppose we have this list of list as ids:\n\n\nbatched_ids = [[200, 200], [200, 200, 100]]\n\n\nWe need to get this list of list in rectangular shape before we convert it into tensor.\nThis is where we use padding\n\n\npadding_id = 100\nbatched_ids = [[200, 200, padding_id], [200, 200, 100]]\n\n\nThe padding token ID can be found in tokenizer.pad_token_id.\nNow let’s do a simple experience to see differences between 3 batches after going through a model: - first list - second list - both lists batched and padding applied\n\n\nmodel = AutoModelForSequenceClassification.from_pretrained(mdl_chkpt)\nsequence1_ids = [[200, 200]]\nsequence2_ids = [[200, 200, 200]]\nbatched_ids = [[200, 200,tokenizer.pad_token_id ], [200, 200, 200]]\n\n\nprint(model(torch.tensor(sequence1_ids)).logits)\nprint(model(torch.tensor(sequence2_ids)).logits)\nprint(model(torch.tensor(batched_ids)).logits)\n\ntensor([[ 0.5803, -0.4125]], grad_fn=&lt;AddmmBackward0&gt;)\ntensor([[ 1.5694, -1.3895]], grad_fn=&lt;AddmmBackward0&gt;)\ntensor([[ 1.3374, -1.2163],\n        [ 1.5694, -1.3895]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nThe thing we could observe here is that we get same logits for the second sequence ID compared with batched_ids but not the first one?\nThe first sequence id is where we applied padding, and as we know transformer models are very sensetive to any context of the words (in this case context of the ids) so the element that we added in order to get a rectangular shape, is also get computed by the transformer model, which influence the final prediction.\nWe need to tell the model to ignore these padding values during the computation\n\n\nAttention mask:\n\nAttention mask is what tell the model during the predecting phase to ignore padding values and not including them while computing the attention mechanism\n\n\nbatched_ids = [\n    [200, 200, 200],\n    [200, 200, tokenizer.pad_token_id],\n]\n\nattention_mask = [\n    [1, 1, 1],\n    [1, 1, 0],\n]\n\noutputs = model(torch.tensor(batched_ids), attention_mask=torch.tensor(attention_mask))\nprint(outputs.logits)\n\ntensor([[ 1.5694, -1.3895],\n        [ 0.5803, -0.4125]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nNow we get the same logits"
  },
  {
    "objectID": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#longer-sequences",
    "href": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#longer-sequences",
    "title": "Hugging Face Course Notes: Chapter2",
    "section": "Longer sequences:",
    "text": "Longer sequences:\n\nTransformer model cannot handle very long sentences, usually they have between 512 and 1024 tokens as maximum length for a sentence.\nI we have a situation where we need to deal with very large sequence we either:\n\nuse models that can handle long sentences\nuse truncation method\n\nTruncation is a way of making sequences of the same batch the same length, either by picking the length of the longest sequence or the short one"
  },
  {
    "objectID": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#special-tokens",
    "href": "posts/HuggingFace_2/HuggingFace_NLP_course_Notes_2.html#special-tokens",
    "title": "Hugging Face Course Notes: Chapter2",
    "section": "Special Tokens",
    "text": "Special Tokens\n\nIf we look closely to the input ID’s we get, we can spot a small difference from what we got earlier\nThe tokenizer added 2 ID’s to the list, one in the begining and another at the end.\n\nthey alwayas have the same value: 101 and 102\n\n\n\nseq = \"I've been waiting for a HuggingFace course my whole life.\"\ntoks1 = tokenizer(seq)\ntoks2 = tokenizer.tokenize(seq)\nids1= toks1.input_ids\nids2 = tokenizer.convert_tokens_to_ids(toks2)\nprint(f'normal: {ids1}')\nprint(f'hard_coded: {ids2}')\n\nnormal: [101, 1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012, 102]\nhard_coded: [1045, 1005, 2310, 2042, 3403, 2005, 1037, 17662, 12172, 2607, 2026, 2878, 2166, 1012]\n\n\n\nNow we will decode the different types of ID’s we will get different decoded sentences:\n\n\nprint(f'normal: {tokenizer.decode(ids1)}')\nprint(f'hard-coded: {tokenizer.decode(ids2)}')\n\nnormal: [CLS] i've been waiting for a huggingface course my whole life. [SEP]\nhard-coded: i've been waiting for a huggingface course my whole life.\n\n\n\nTokenizer added special tokens to the sentence [CLS] and [SEP], because the model was trained with this kind of architecture"
  },
  {
    "objectID": "posts/Fastai_ch7/Ch7.html",
    "href": "posts/Fastai_ch7/Ch7.html",
    "title": "Chapter 7: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "In this chapter we will discuss more advanced technics for training image classifier models and getting better results.\nIn this chapter we will see:\n\nWhat is Normalization?\nData augmentation with Mixup\nProgressive Risizing\nTest Time Augmentation\n\nTo implement all those technics, we will build model from scartch an train it on a subset of ImageNet called Imagenette\n\n\n\n\nThis dataset is created by Fastai community, the goal of it is to have a dataset that can train models that generelize well on the larger version (ImageNet), which will help Machine learning practitioners to build and experiment many ideas and projects with less computation power.\nImagenette has 10 classes, which are very different from one another.\nLet’s download the dataset\n\n\n! [ -e /content ] && pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\n\n     |████████████████████████████████| 719 kB 5.1 MB/s \n     |████████████████████████████████| 5.3 MB 26.5 MB/s \n     |████████████████████████████████| 1.3 MB 49.1 MB/s \n     |████████████████████████████████| 441 kB 16.3 MB/s \n     |████████████████████████████████| 163 kB 50.3 MB/s \n     |████████████████████████████████| 212 kB 56.5 MB/s \n     |████████████████████████████████| 115 kB 39.6 MB/s \n     |████████████████████████████████| 127 kB 50.6 MB/s \n     |████████████████████████████████| 7.6 MB 72.8 MB/s \nMounted at /content/gdrive\n\n\n\nfrom fastbook import *\n\n\nfrom fastai.vision.all import *\npath = untar_data(URLs.IMAGENETTE)\n\n\n\n\n\n\n    \n      \n      100.00% [1557168128/1557161267 00:38&lt;00:00]\n    \n    \n\n\n\nHere we create DataLoaders using the Resize technic we saw in CH5\n\n\ndblock = DataBlock(blocks=(ImageBlock(), CategoryBlock()),\n                   get_items=get_image_files,\n                   get_y=parent_label,\n                   item_tfms=Resize(460),\n                   batch_tfms=aug_transforms(size=224, min_scale=0.75))\ndls = dblock.dataloaders(path, bs=64)\n\n\nNow we do the training just to have something to begin with\n\n\nmodel = xresnet50(n_out=dls.c)\nlearn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\nlearn.fit_one_cycle(5, 3e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.615762\n1.960073\n0.446229\n02:59\n\n\n1\n1.231709\n1.436732\n0.542943\n03:01\n\n\n2\n0.946307\n0.957584\n0.703883\n03:01\n\n\n3\n0.710163\n0.686722\n0.788648\n02:59\n\n\n4\n0.581876\n0.551411\n0.833831\n02:57\n\n\n\n\n\n\nNot bad result considering that we didn’t use a pretrained model.\nThe aim of this chapter is to increase the peformance of this base-line model by implementing different technics\n\n\n\n\n\nNormalization means having a dataset with mean of 0 and standard diviation of 1.\nMost images and computer vision libraries use values between 0 and 255 for pixels, or between 0 and 1; in either case, your data is not going to have a mean of 0 and a standard deviation of 1.\nLet’s grab a batch of data and take the average of each axis except the channels axis (indx==1)\n\n\nx,y = dls.one_batch()\nx.mean(dim=[0,2,3]),x.std(dim=[0,2,3])\n\n(TensorImage([0.4573, 0.4509, 0.4188], device='cuda:0'),\n TensorImage([0.2730, 0.2652, 0.2803], device='cuda:0'))\n\n\n\nAs expected, the mean and std is different than what we desire.\nFastai provide the method Normalize which can be applied on the whole batch, so we could add it to batch_tfms section of the datablock, we just need to tell fastai which are the mean and the standard deviation we want to use (in this case we will use ImageNet stats) but even without giving these stats fastai will calculate them from one batch and use them.\nNotice here we build the datablock withing a function that take batch_size and size as parameters, we will see way later\n\n\ndef get_dls(bs, size):\n    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n                   get_items=get_image_files,\n                   get_y=parent_label,\n                   item_tfms=Resize(460),\n                   batch_tfms=[*aug_transforms(size=size, min_scale=0.75),\n                               Normalize.from_stats(*imagenet_stats)])\n    return dblock.dataloaders(path, bs=bs)\n\n\ndls = get_dls(64, 224)\n\n\nx,y = dls.one_batch()\nx.mean(dim=[0,2,3]),x.std(dim=[0,2,3])\n\n(TensorImage([-0.0920, -0.0490,  0.0548], device='cuda:0'),\n TensorImage([1.1969, 1.1888, 1.2855], device='cuda:0'))\n\n\n\nThis Normalize method help us to get close to the desired values for mean and std\nLet’s how this effect the performance of the model:\n\n\nmodel = xresnet50(n_out=dls.c)\nlearn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\nlearn.fit_one_cycle(5, 3e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.617465\n1.945767\n0.462285\n02:58\n\n\n1\n1.272744\n2.252786\n0.462659\n02:58\n\n\n2\n0.947452\n1.084139\n0.643017\n02:58\n\n\n3\n0.722699\n0.795408\n0.765123\n03:00\n\n\n4\n0.610676\n0.577560\n0.819642\n02:58\n\n\n\n\n\n\nImplementing the normalization didn’t help the model get better results, because this technic works better when using a pretrained model.\n\n\n\n\n\nThe idea behind Progressive Resizing is to start training the model with small images, and end the training fase with large images.\nAs we have seen, the image size doesn’t play a role in the learning process.\nAlthough changing the image size in the middel of training will effect how the model behave in a way or another.\nThe best way is to deal with the transition from small image to larger images as if we do transfer learning. After changing the images size we should fine_tune method.\nWe can look to Progressive Resizing as a form of data augmentation, which mean the model will generalize well.\nTo implement progressive resizing it is most convenient if you first create a get_dls function which takes an image size and a batch size as we did in the section before, and returns your DataLoaders:\nNow you can create your DataLoaders with a small size and use fit_one_cycle in the usual way, training for a few less epochs than you might otherwise do:\n\n\ndls = get_dls(128, 128)\nlearn = Learner(dls, xresnet50(n_out=dls.c), loss_func=CrossEntropyLossFlat(), \n                metrics=accuracy)\nlearn.fit_one_cycle(4, 3e-3)\n\n\nThen you can replace the DataLoaders inside the Learner, and fine-tune:\n\n\nlearn.dls = get_dls(64, 224)\nlearn.fine_tune(5, 1e-3)\n\n\nWe can increase the image size by a bit, untill we reach the normal size of the actual image in dataset.\nProgressive resizing can be good or bad depending many factors:\n\nFor transfer learning, if the model is already trained on similar task we will use it for, and on similar size of images, normally re-training it on smaller images will damage the performance.\nIn other hand if the model is trained on dataset with different size of images, and on dfferent task, using progressive resizing may help the model performance.\n\nThere’s no right answear for every situation, we just need to try and experiment different things.\n\n\n\n\n\nTill now all kind of data augmentations we implement are done on training set, while the validation set is taking the same images.\nThe idea behind Test Time Augmentation tta is to use some augmented images for the validation set to get predictions (for the same image) and average (or take the maximun) them.\nUsually fastai do center cropping for validation.\nThis method may cause the model to miss valuable lessons from edges of the cropped images.\nWe could avoid center cropping but instead to select a number of areas to crop from the original rectangular image, pass each of them through our model, then take the average of predictions or the maximum\nBy default, fastai will use the unaugmented center crop image plus four randomly augmented images.\nYou can pass any DataLoader to fastai’s tta method; by default, it will use your validation set:\n\n\npreds,targs = learn.tta()\naccuracy(preds, targs).item()\n\n\n\n\n\nThe idea of mixup is to take two data points (images) and mix them together with some percentage, then do the ine-hot encodings where the new image represented with the new values (percentages) instead of 0 or 1. The model here have to predict not only the right label, but also the percentage by which the label is represented in that image.\nWe can express this idea with code as:\n\n\nchurch = PILImage.create(get_image_files_sorted(path/'train'/'n03028079')[0])\ngas = PILImage.create(get_image_files_sorted(path/'train'/'n03425413')[0])\nchurch = church.resize((256,256))\ngas = gas.resize((256,256))\ntchurch = tensor(church).float() / 255.\ntgas = tensor(gas).float() / 255.\n\n_,axs = plt.subplots(1, 3, figsize=(12,4))\nshow_image(tchurch, ax=axs[0]);\nshow_image(tgas, ax=axs[1]);\nshow_image((0.3*tchurch + 0.7*tgas), ax=axs[2]);\n\n\nmodel = xresnet50(n_out=dls.c)\nlearn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), \n                metrics=accuracy, cbs=MixUp())\nlearn.fit_one_cycle(5, 3e-3)\n\n\nTraining a model with mixup techninx make it way hareder for the model to learn, because the model need to predict 2 labels for each image instead of one, plus predicting the righ percentage of each label.\nOverfitting seems less likely to be a problem when mixup is used.\nMixup tend to produce good results with 80 epochs of training or more.\nOne other benefit of using Mixup is when we have labels == 0, 1, because of using softmax and sigmoid the output can never be 0 or 1, thus our loss can never be perfect. With mixup labels cannot be 0 or 1 unless we mix 2 images with the same label, the rest of the time our labels will be linear combinations like 0.4, 0.6 ..\n\n\n\n\n\nIn classfication problems we usually have labels like 0 and 1, so the model job is to return them accuaratly, even 0.999 is not good enough where the label is 1!. this cuase the model to update the weights in order to get closer and closer to the right and unique answear, what will lead to overfitting.\nThe solution to this problem is to smooth the labels, by replacing 1 with a bit smaller number, and 0 with a bit bigger number. this will encourage the model to be less confident, which will help to better generalization.\nLabel Smoothing can be expressed mathematically:\n\n0: \\(\\frac{\\epsilon}{N}\\) where N is number of classes we have and epsilon represent a parameter usually 0.1(it’s like saying we’re 10% less confident about the label)\n1: \\(1-\\epsilon + \\frac{\\epsilon}{N}\\)\n\nIn our Imagenette example where we have 10 classes, the targets become something like (here for a target that corresponds to the index 3):\n\n[0.01, 0.01, 0.01, 0.91, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n\nTo use this in practice, we just have to change the loss function in our call to Learner:\n\n```python model = xresnet50(n_out=dls.c) learn = Learner(dls, model, loss_func=LabelSmoothingCrossEntropy(), metrics=accuracy) learn.fit_one_cycle(5, 3e-3)"
  },
  {
    "objectID": "posts/Fastai_ch7/Ch7.html#imagenette",
    "href": "posts/Fastai_ch7/Ch7.html#imagenette",
    "title": "Chapter 7: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "This dataset is created by Fastai community, the goal of it is to have a dataset that can train models that generelize well on the larger version (ImageNet), which will help Machine learning practitioners to build and experiment many ideas and projects with less computation power.\nImagenette has 10 classes, which are very different from one another.\nLet’s download the dataset\n\n\n! [ -e /content ] && pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\n\n     |████████████████████████████████| 719 kB 5.1 MB/s \n     |████████████████████████████████| 5.3 MB 26.5 MB/s \n     |████████████████████████████████| 1.3 MB 49.1 MB/s \n     |████████████████████████████████| 441 kB 16.3 MB/s \n     |████████████████████████████████| 163 kB 50.3 MB/s \n     |████████████████████████████████| 212 kB 56.5 MB/s \n     |████████████████████████████████| 115 kB 39.6 MB/s \n     |████████████████████████████████| 127 kB 50.6 MB/s \n     |████████████████████████████████| 7.6 MB 72.8 MB/s \nMounted at /content/gdrive\n\n\n\nfrom fastbook import *\n\n\nfrom fastai.vision.all import *\npath = untar_data(URLs.IMAGENETTE)\n\n\n\n\n\n\n    \n      \n      100.00% [1557168128/1557161267 00:38&lt;00:00]\n    \n    \n\n\n\nHere we create DataLoaders using the Resize technic we saw in CH5\n\n\ndblock = DataBlock(blocks=(ImageBlock(), CategoryBlock()),\n                   get_items=get_image_files,\n                   get_y=parent_label,\n                   item_tfms=Resize(460),\n                   batch_tfms=aug_transforms(size=224, min_scale=0.75))\ndls = dblock.dataloaders(path, bs=64)\n\n\nNow we do the training just to have something to begin with\n\n\nmodel = xresnet50(n_out=dls.c)\nlearn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\nlearn.fit_one_cycle(5, 3e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.615762\n1.960073\n0.446229\n02:59\n\n\n1\n1.231709\n1.436732\n0.542943\n03:01\n\n\n2\n0.946307\n0.957584\n0.703883\n03:01\n\n\n3\n0.710163\n0.686722\n0.788648\n02:59\n\n\n4\n0.581876\n0.551411\n0.833831\n02:57\n\n\n\n\n\n\nNot bad result considering that we didn’t use a pretrained model.\nThe aim of this chapter is to increase the peformance of this base-line model by implementing different technics"
  },
  {
    "objectID": "posts/Fastai_ch7/Ch7.html#normalization",
    "href": "posts/Fastai_ch7/Ch7.html#normalization",
    "title": "Chapter 7: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "Normalization means having a dataset with mean of 0 and standard diviation of 1.\nMost images and computer vision libraries use values between 0 and 255 for pixels, or between 0 and 1; in either case, your data is not going to have a mean of 0 and a standard deviation of 1.\nLet’s grab a batch of data and take the average of each axis except the channels axis (indx==1)\n\n\nx,y = dls.one_batch()\nx.mean(dim=[0,2,3]),x.std(dim=[0,2,3])\n\n(TensorImage([0.4573, 0.4509, 0.4188], device='cuda:0'),\n TensorImage([0.2730, 0.2652, 0.2803], device='cuda:0'))\n\n\n\nAs expected, the mean and std is different than what we desire.\nFastai provide the method Normalize which can be applied on the whole batch, so we could add it to batch_tfms section of the datablock, we just need to tell fastai which are the mean and the standard deviation we want to use (in this case we will use ImageNet stats) but even without giving these stats fastai will calculate them from one batch and use them.\nNotice here we build the datablock withing a function that take batch_size and size as parameters, we will see way later\n\n\ndef get_dls(bs, size):\n    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n                   get_items=get_image_files,\n                   get_y=parent_label,\n                   item_tfms=Resize(460),\n                   batch_tfms=[*aug_transforms(size=size, min_scale=0.75),\n                               Normalize.from_stats(*imagenet_stats)])\n    return dblock.dataloaders(path, bs=bs)\n\n\ndls = get_dls(64, 224)\n\n\nx,y = dls.one_batch()\nx.mean(dim=[0,2,3]),x.std(dim=[0,2,3])\n\n(TensorImage([-0.0920, -0.0490,  0.0548], device='cuda:0'),\n TensorImage([1.1969, 1.1888, 1.2855], device='cuda:0'))\n\n\n\nThis Normalize method help us to get close to the desired values for mean and std\nLet’s how this effect the performance of the model:\n\n\nmodel = xresnet50(n_out=dls.c)\nlearn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\nlearn.fit_one_cycle(5, 3e-3)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.617465\n1.945767\n0.462285\n02:58\n\n\n1\n1.272744\n2.252786\n0.462659\n02:58\n\n\n2\n0.947452\n1.084139\n0.643017\n02:58\n\n\n3\n0.722699\n0.795408\n0.765123\n03:00\n\n\n4\n0.610676\n0.577560\n0.819642\n02:58\n\n\n\n\n\n\nImplementing the normalization didn’t help the model get better results, because this technic works better when using a pretrained model."
  },
  {
    "objectID": "posts/Fastai_ch7/Ch7.html#progressive-resizing",
    "href": "posts/Fastai_ch7/Ch7.html#progressive-resizing",
    "title": "Chapter 7: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "The idea behind Progressive Resizing is to start training the model with small images, and end the training fase with large images.\nAs we have seen, the image size doesn’t play a role in the learning process.\nAlthough changing the image size in the middel of training will effect how the model behave in a way or another.\nThe best way is to deal with the transition from small image to larger images as if we do transfer learning. After changing the images size we should fine_tune method.\nWe can look to Progressive Resizing as a form of data augmentation, which mean the model will generalize well.\nTo implement progressive resizing it is most convenient if you first create a get_dls function which takes an image size and a batch size as we did in the section before, and returns your DataLoaders:\nNow you can create your DataLoaders with a small size and use fit_one_cycle in the usual way, training for a few less epochs than you might otherwise do:\n\n\ndls = get_dls(128, 128)\nlearn = Learner(dls, xresnet50(n_out=dls.c), loss_func=CrossEntropyLossFlat(), \n                metrics=accuracy)\nlearn.fit_one_cycle(4, 3e-3)\n\n\nThen you can replace the DataLoaders inside the Learner, and fine-tune:\n\n\nlearn.dls = get_dls(64, 224)\nlearn.fine_tune(5, 1e-3)\n\n\nWe can increase the image size by a bit, untill we reach the normal size of the actual image in dataset.\nProgressive resizing can be good or bad depending many factors:\n\nFor transfer learning, if the model is already trained on similar task we will use it for, and on similar size of images, normally re-training it on smaller images will damage the performance.\nIn other hand if the model is trained on dataset with different size of images, and on dfferent task, using progressive resizing may help the model performance.\n\nThere’s no right answear for every situation, we just need to try and experiment different things."
  },
  {
    "objectID": "posts/Fastai_ch7/Ch7.html#test-time-augmentation",
    "href": "posts/Fastai_ch7/Ch7.html#test-time-augmentation",
    "title": "Chapter 7: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "Till now all kind of data augmentations we implement are done on training set, while the validation set is taking the same images.\nThe idea behind Test Time Augmentation tta is to use some augmented images for the validation set to get predictions (for the same image) and average (or take the maximun) them.\nUsually fastai do center cropping for validation.\nThis method may cause the model to miss valuable lessons from edges of the cropped images.\nWe could avoid center cropping but instead to select a number of areas to crop from the original rectangular image, pass each of them through our model, then take the average of predictions or the maximum\nBy default, fastai will use the unaugmented center crop image plus four randomly augmented images.\nYou can pass any DataLoader to fastai’s tta method; by default, it will use your validation set:\n\n\npreds,targs = learn.tta()\naccuracy(preds, targs).item()"
  },
  {
    "objectID": "posts/Fastai_ch7/Ch7.html#mixup",
    "href": "posts/Fastai_ch7/Ch7.html#mixup",
    "title": "Chapter 7: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "The idea of mixup is to take two data points (images) and mix them together with some percentage, then do the ine-hot encodings where the new image represented with the new values (percentages) instead of 0 or 1. The model here have to predict not only the right label, but also the percentage by which the label is represented in that image.\nWe can express this idea with code as:\n\n\nchurch = PILImage.create(get_image_files_sorted(path/'train'/'n03028079')[0])\ngas = PILImage.create(get_image_files_sorted(path/'train'/'n03425413')[0])\nchurch = church.resize((256,256))\ngas = gas.resize((256,256))\ntchurch = tensor(church).float() / 255.\ntgas = tensor(gas).float() / 255.\n\n_,axs = plt.subplots(1, 3, figsize=(12,4))\nshow_image(tchurch, ax=axs[0]);\nshow_image(tgas, ax=axs[1]);\nshow_image((0.3*tchurch + 0.7*tgas), ax=axs[2]);\n\n\nmodel = xresnet50(n_out=dls.c)\nlearn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), \n                metrics=accuracy, cbs=MixUp())\nlearn.fit_one_cycle(5, 3e-3)\n\n\nTraining a model with mixup techninx make it way hareder for the model to learn, because the model need to predict 2 labels for each image instead of one, plus predicting the righ percentage of each label.\nOverfitting seems less likely to be a problem when mixup is used.\nMixup tend to produce good results with 80 epochs of training or more.\nOne other benefit of using Mixup is when we have labels == 0, 1, because of using softmax and sigmoid the output can never be 0 or 1, thus our loss can never be perfect. With mixup labels cannot be 0 or 1 unless we mix 2 images with the same label, the rest of the time our labels will be linear combinations like 0.4, 0.6 .."
  },
  {
    "objectID": "posts/Fastai_ch7/Ch7.html#label-smoothing",
    "href": "posts/Fastai_ch7/Ch7.html#label-smoothing",
    "title": "Chapter 7: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "In classfication problems we usually have labels like 0 and 1, so the model job is to return them accuaratly, even 0.999 is not good enough where the label is 1!. this cuase the model to update the weights in order to get closer and closer to the right and unique answear, what will lead to overfitting.\nThe solution to this problem is to smooth the labels, by replacing 1 with a bit smaller number, and 0 with a bit bigger number. this will encourage the model to be less confident, which will help to better generalization.\nLabel Smoothing can be expressed mathematically:\n\n0: \\(\\frac{\\epsilon}{N}\\) where N is number of classes we have and epsilon represent a parameter usually 0.1(it’s like saying we’re 10% less confident about the label)\n1: \\(1-\\epsilon + \\frac{\\epsilon}{N}\\)\n\nIn our Imagenette example where we have 10 classes, the targets become something like (here for a target that corresponds to the index 3):\n\n[0.01, 0.01, 0.01, 0.91, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n\nTo use this in practice, we just have to change the loss function in our call to Learner:\n\n```python model = xresnet50(n_out=dls.c) learn = Learner(dls, model, loss_func=LabelSmoothingCrossEntropy(), metrics=accuracy) learn.fit_one_cycle(5, 3e-3)"
  },
  {
    "objectID": "posts/Haystack_1/Haystack_1.html",
    "href": "posts/Haystack_1/Haystack_1.html",
    "title": "Building QAs System Using Haystack",
    "section": "",
    "text": "Haystack Library is an end-2-end framework that allow us orchesting many components in order to build LLM application with minimum lines of code."
  },
  {
    "objectID": "posts/Haystack_1/Haystack_1.html#initializing-the-documentstore",
    "href": "posts/Haystack_1/Haystack_1.html#initializing-the-documentstore",
    "title": "Building QAs System Using Haystack",
    "section": "Initializing the DocumentStore:",
    "text": "Initializing the DocumentStore:\n\nIn this tutorial we will use the basic type of the DocumentStore class, which is InMemoryDocumentStore\n\n\nfrom haystack.document_stores import InMemoryDocumentStore\ndocument_store= InMemoryDocumentStore(use_bm25=True)\n\n\nDocumentStore is a like a database or a warehouse that need to be filled with data/documents.\nHere we use the fetch_archive_from_http function to download our documents from the web.\nThe downloaded docements needed to be prepared and organized to be processed in the next step:\n\n\nfrom haystack.utils import fetch_archive_from_http\ndoc_dir='data/directory_project'\nfetch_archive_from_http(url='https://s3.eu-central-1.amazonaws.com/deepset.ai-farm-qa/datasets/documents/wiki_gameofthrones_txt1.zip', output_dir= doc_dir)\n\nTrue\n\n\n\nNow we have all our data stored in this path: data/directory_project and assigned to doc_dir\nAt this momment our data is raw and should be converted in Document objects according the HayStack standars. In order to do that we will use TextIndexingPipeline and write them into DocumentStore\n\n\nimport os\nfrom haystack.pipelines.standard_pipelines import TextIndexingPipeline\n\nfiles_to_index = [doc_dir + '/' + f for f in os.listdir(doc_dir)]\nindexing_pipeline = TextIndexingPipeline(document_store)\nindexing_pipeline.run_batch(file_paths=files_to_index)"
  },
  {
    "objectID": "posts/Haystack_1/Haystack_1.html#initializing-a-retriever",
    "href": "posts/Haystack_1/Haystack_1.html#initializing-a-retriever",
    "title": "Building QAs System Using Haystack",
    "section": "Initializing A Retriever:",
    "text": "Initializing A Retriever:\n\nA retriever will map through all documents we stored and find the more likely dosuments that contains possible answer to our question\nHere we initialize the BM25Retriever algorithm and make it access the InMemoryDocumentStore\n\n\nfrom haystack.nodes import BM25Retriever\nretriever= BM25Retriever(document_store=document_store)"
  },
  {
    "objectID": "posts/Haystack_1/Haystack_1.html#initializing-the-reader",
    "href": "posts/Haystack_1/Haystack_1.html#initializing-the-reader",
    "title": "Building QAs System Using Haystack",
    "section": "Initializing the Reader:",
    "text": "Initializing the Reader:\n\nThe Reader get access to all texts from Retriver and extracts candidates answers\nReader is based on LLM’s\nIn this turorial we used the roberta-base-squad2 model\n\n\nfrom haystack.nodes import FARMReader\nreader = FARMReader(model_name_or_path='deepset/roberta-base-squad2', use_gpu=True)"
  },
  {
    "objectID": "posts/Haystack_1/Haystack_1.html#creating-the-retriver-reader-pipeline",
    "href": "posts/Haystack_1/Haystack_1.html#creating-the-retriver-reader-pipeline",
    "title": "Building QAs System Using Haystack",
    "section": "Creating the Retriver-Reader Pipeline:",
    "text": "Creating the Retriver-Reader Pipeline:\n\nSince we have everything we need to build this Q/A system nom, all we have to do is put every piece together in one Pipeline\n\n\nfrom haystack.pipelines import ExtractiveQAPipeline\npipe = ExtractiveQAPipeline(reader, retriever)"
  },
  {
    "objectID": "posts/Haystack_1/Haystack_1.html#asking-questions",
    "href": "posts/Haystack_1/Haystack_1.html#asking-questions",
    "title": "Building QAs System Using Haystack",
    "section": "Asking Questions:",
    "text": "Asking Questions:\n\npredictions = pipe.run(query='who is the most powerful creature?', params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 5}})\n\nInferencing Samples: 100%|██████████| 1/1 [00:03&lt;00:00,  3.66s/ Batches]\n\n\n\nfrom haystack.utils import print_answers\nprint_answers(predictions, details='minimum')\n\n'Query: who is the most powerful creature?'\n'Answers:'\n[   {   'answer': 'Khal Drogo',\n        'context': '\\n'\n                   '\\n'\n                   \"'''Khal Drogo''' is a fictional character in the ''A Song \"\n                   \"of Ice and Fire'' series of fantasy novels by American \"\n                   'author George R. R. Martin and in t'},\n    {   'answer': 'Night King',\n        'context': '\\n'\n                   '\\n'\n                   \"The '''Night King''' is a fictional character appearing in \"\n                   \"the HBO high fantasy television series ''Game of \"\n                   \"Thrones'', based on George R. R. Martin'\"},\n    {   'answer': 'Drogo',\n        'context': ' prove to be fundamental to her growth as both a ruler and '\n                   'a conqueror.\\n'\n                   '\\n'\n                   'Drogo is portrayed by Jason Momoa in the HBO television '\n                   'adaptation.\\n'\n                   '\\n'\n                   '==Overvi'},\n    {   'answer': 'Jon Snow',\n        'context': 'rge and sinewy man that towers over others, such as Davos '\n                   'Seaworth and Jon Snow, a Baratheon trait. He lacks the '\n                   'long black hair of his brothers, and '},\n    {   'answer': 'Night King',\n        'context': 'urdik in seasons 6 to 8.\\n'\n                   '\\n'\n                   '==Description==\\n'\n                   \"In ''Game of Thrones'', the Night King is physically \"\n                   'distinguished from the other White Walkers by his \"crow'}]"
  },
  {
    "objectID": "posts/Fastai_ch4/Ch4.html",
    "href": "posts/Fastai_ch4/Ch4.html",
    "title": "Chapter 4: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "! [ -e /content ] && pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\n\n     |████████████████████████████████| 719 kB 27.5 MB/s \n     |████████████████████████████████| 5.3 MB 55.1 MB/s \n     |████████████████████████████████| 441 kB 70.9 MB/s \n     |████████████████████████████████| 1.3 MB 56.3 MB/s \n     |████████████████████████████████| 1.6 MB 57.3 MB/s \n     |████████████████████████████████| 115 kB 72.1 MB/s \n     |████████████████████████████████| 163 kB 71.5 MB/s \n     |████████████████████████████████| 212 kB 55.8 MB/s \n     |████████████████████████████████| 127 kB 75.4 MB/s \n     |████████████████████████████████| 115 kB 75.4 MB/s \n     |████████████████████████████████| 7.6 MB 56.7 MB/s \nMounted at /content/gdrive\nfrom fastbook import *\nfrom fastai.vision.widgets import *\nmatplotlib.rc('image', cmap='Greys')"
  },
  {
    "objectID": "posts/Fastai_ch4/Ch4.html#pixels-the-foundations-of-computer-vision",
    "href": "posts/Fastai_ch4/Ch4.html#pixels-the-foundations-of-computer-vision",
    "title": "Chapter 4: Deep learning for coders with fastai and pytorch",
    "section": "Pixels: The Foundations of Computer Vision",
    "text": "Pixels: The Foundations of Computer Vision\n\nComputer are good with numbers, thats why in order to make them do computer vision tasks we need to turn images to series of numbers\nWe will use a small version of the famous dataset MNIST which contains only 2 digits 3 and 7.\nOur task here is create a Neural Network from scratch that can calssify 3 from 7.\n\n\n#download the dataset;\n#MNIST_simple is a small mnist that contains only 7s and 3s\npath = untar_data(URLs.MNIST_SAMPLE)\n\n\n\n\n\n\n    \n      \n      100.14% [3219456/3214948 00:01&lt;00:00]\n    \n    \n\n\n\n#here is where the dataset is stored\npath\n\nPath('/root/.fastai/data/mnist_sample')\n\n\n\n# we can use ls() to investigate the dataset\n# we have 3 directories: train, valid, labels.csv\npath.ls()\n\n(#3) [Path('/root/.fastai/data/mnist_sample/labels.csv'),Path('/root/.fastai/data/mnist_sample/train'),Path('/root/.fastai/data/mnist_sample/valid')]\n\n\n\n#inside of train/valid folders, there's is 2 folders: 7, 3\n(path/'train').ls()\n\n(#2) [Path('/root/.fastai/data/mnist_sample/train/3'),Path('/root/.fastai/data/mnist_sample/train/7')]\n\n\n\n#let's have a look at what in those folders while we sorted them an put them into variables ('threes and sevens')\nthrees = (path/'train'/'3').ls().sorted()\nsevens = (path/'train'/'7').ls().sorted()\n\n\nthrees[-1], threes[22]\n\n(Path('/root/.fastai/data/mnist_sample/train/3/9991.png'),\n Path('/root/.fastai/data/mnist_sample/train/3/10210.png'))\n\n\n\n#let's open it \nimg_path = threes[1]\nimg = Image.open(img_path)\nimg\n\n\n\n\n\n\n\n\n\nIn a computer, everything is represented as a numbers.\nTo view the numbers that make up this image, we have to convert it to a NumPy array or a PyTorch tensor.\n\n\n# here we use numpy array to represent that image \"img\" as array (matrix) \n# the img here is represented as pixels\n# the darker pixel are 0 or have values colser to 0, and the lighter pixels have higher values\narray(img)[4:10, 4:10]\n\narray([[  0,   0,   0,   0,   0,   0],\n       [  0,   0,   0,   0,   0,  29],\n       [  0,   0,   0,  48, 166, 224],\n       [  0,  93, 244, 249, 253, 187],\n       [  0, 107, 253, 253, 230,  48],\n       [  0,   3,  20,  20,  15,   0]], dtype=uint8)\n\n\n\n#here we use Pytorch tensor which is the numpy array function of pytorch\n#they have the same code, and the behave basically the same (in most cases), \n#the main difference is tensors can be computed on GPu\na =tensor(img)[4:10, 4:10]\na\n\ntensor([[  0,   0,   0,   0,   0,   0],\n        [  0,   0,   0,   0,   0,  29],\n        [  0,   0,   0,  48, 166, 224],\n        [  0,  93, 244, 249, 253, 187],\n        [  0, 107, 253, 253, 230,  48],\n        [  0,   3,  20,  20,  15,   0]], dtype=torch.uint8)\n\n\n\nWe ciuld convert a image into array/tensor, then represent it as pandas DataFrame by coloring each pixel using background_gradient(), the darker the pixel is the closer it is to the highest value 252, this the image is the closer to 0.\n\n\n# here we demonstrate the image and pixels values\n# values of each pixel varies between 0 and 255\nimg_t= tensor(img)\ndf = pd.DataFrame(img_t)\ndf.style.set_properties(**{'font-size':'4pt'}).background_gradient('Greys')\n\n\n\n\n\n\n \n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n\n\n\n\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n2\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n3\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n4\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n5\n0\n0\n0\n0\n0\n0\n0\n0\n0\n29\n150\n195\n254\n255\n254\n176\n193\n150\n96\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n6\n0\n0\n0\n0\n0\n0\n0\n48\n166\n224\n253\n253\n234\n196\n253\n253\n253\n253\n233\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n7\n0\n0\n0\n0\n0\n93\n244\n249\n253\n187\n46\n10\n8\n4\n10\n194\n253\n253\n233\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n8\n0\n0\n0\n0\n0\n107\n253\n253\n230\n48\n0\n0\n0\n0\n0\n192\n253\n253\n156\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n9\n0\n0\n0\n0\n0\n3\n20\n20\n15\n0\n0\n0\n0\n0\n43\n224\n253\n245\n74\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n10\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n249\n253\n245\n126\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n11\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n14\n101\n223\n253\n248\n124\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n12\n0\n0\n0\n0\n0\n0\n0\n0\n0\n11\n166\n239\n253\n253\n253\n187\n30\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n13\n0\n0\n0\n0\n0\n0\n0\n0\n0\n16\n248\n250\n253\n253\n253\n253\n232\n213\n111\n2\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n14\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n43\n98\n98\n208\n253\n253\n253\n253\n187\n22\n0\n0\n0\n0\n0\n0\n0\n\n\n15\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n9\n51\n119\n253\n253\n253\n76\n0\n0\n0\n0\n0\n0\n0\n\n\n16\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n183\n253\n253\n139\n0\n0\n0\n0\n0\n0\n0\n\n\n17\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n182\n253\n253\n104\n0\n0\n0\n0\n0\n0\n0\n\n\n18\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n85\n249\n253\n253\n36\n0\n0\n0\n0\n0\n0\n0\n\n\n19\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n60\n214\n253\n253\n173\n11\n0\n0\n0\n0\n0\n0\n0\n\n\n20\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n98\n247\n253\n253\n226\n9\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n21\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n42\n150\n252\n253\n253\n233\n53\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n22\n0\n0\n0\n0\n0\n0\n42\n115\n42\n60\n115\n159\n240\n253\n253\n250\n175\n25\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n23\n0\n0\n0\n0\n0\n0\n187\n253\n253\n253\n253\n253\n253\n253\n197\n86\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n24\n0\n0\n0\n0\n0\n0\n103\n253\n253\n253\n253\n253\n232\n67\n1\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n25\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n26\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n27\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0"
  },
  {
    "objectID": "posts/Fastai_ch4/Ch4.html#base-line-model",
    "href": "posts/Fastai_ch4/Ch4.html#base-line-model",
    "title": "Chapter 4: Deep learning for coders with fastai and pytorch",
    "section": "Base-Line Model",
    "text": "Base-Line Model\n\nIs always good to start with a base-line model then try to build something more comlex on top of it\nBase-line model help us build intuition and understand the prespectives of the problem\nConsum less time to build\n\n\nPixel Similarity\n\nCalculate the average values for each pixel location across all images for each digit\n\nThis will generate a blurry image of the target digit\n\nCompare the values for each pixel location in a new image to the average\n\n\n# store all images of 7s and 3s as a list of tensors\nsevens_tensors = [tensor(Image.open(o)) for o in sevens]\nthrees_tensors = [tensor(Image.open(o)) for o in threes]\nlen(sevens_tensors), len(threes_tensors)\n\n(6265, 6131)\n\n\n\nso now we have bunch of tensors, since they’re not image object anymore, we will use show_image of fast ai instead of PILimage\nRemember we can always use show_image?? to read the documentation/ the code\n\n\n# show a image from the tensor list\nshow_image(threes_tensors[330]);\n\n\n\n\n\n\n\n\n\nNow we need to compute the value of each pixel in respect to all images (for that digit)\nPut all images in a list of 3 dimension tensors, then stack them into a single tensor.\n\nstack images via pytorch function torch.stack\nand scale pixel values from the range [0,255] to [0,1]\n\n\n\nstacked_threes= torch.stack(threes_tensors).float()/255\nstacked_sevens= torch.stack(sevens_tensors).float()/255\nstacked_threes.shape\n\ntorch.Size([6131, 28, 28])\n\n\n\n.shape attribute tells us about the lenth of each axis\n\nin this case we can see we have 6131 images, each of size 28*28 pixel\n\nCalculate the mean values for each pixel location across all images\n\n\nmean3 = stacked_threes.mean(0)\nmean7 = stacked_sevens.mean(0)\n\n\nSow our ideal 3 and 7\n\n\nshow_image(mean3)\nshow_image(mean7)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#pick a single 3, 7 to compare it with the ideal one\na_3 = stacked_threes[55]\na_7 = stacked_sevens[29]\n\n\nshow_image(a_3)\nshow_image(a_7)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nso now let’s say that we want to recognize if a_3 is a 3 or 7?\nto do that we can measure the distance between either of the two ideal 3 and 7**\n\nbecause just compunting the difference canot give us the right answear always since in some cases the difference will be negative!\n\n\nto avoide that we can take 2 approaches:\n* Take the mean of the absolute value of differences, this method called L1 norm or mean absolute difference .\n* Take the mean of the square of differences (which makes everything positive) and then take the square root (which undoes the squaring), this method called L2 norm or root mean squared error (RMSE)\n\n# Let's try both\ndis_3_abs = (a_3-mean3).abs().mean()\ndis_3_sqr = ((a_3-mean3)**2).mean().sqrt()\ndis_3_abs, dis_3_sqr\n\n(tensor(0.1280), tensor(0.2356))\n\n\n\ndist_7_abs = (a_3 - mean7).abs().mean()\ndist_7_sqr = ((a_3 - mean7)**2).mean().sqrt()\ndist_7_abs,dist_7_sqr\n\n(tensor(0.1832), tensor(0.3356))\n\n\n\nbased on those numbers the a_3 seems to be close to the ideal three than a_7to the ideal seven which seems to be right\nIn pytorch there’s a function that represent all of that for us:\n\ntorch.nn.functional, wich is recommended to be called as F(in fastai this recommendation is standarized!).\nl1_loss stand for l1 norm, and mse_loss stand for l2 norm\n\nmse_loss still need sqrt() to fully executed\n\n\n\n\nF.l1_loss(a_3.float(), mean7), F.mse_loss(a_3, mean7).sqrt()\n\n(tensor(0.1832), tensor(0.3356))\n\n\n\n\nComputing metrics using Broadcasting\n\nIf we want to test the accuracy of a model we better measure it on validation set\nso let’s create a tensor of 3’s and 7’s of validation set directory, then calculate the accuracy of our “model” based on every tensor(image) in validation set\n\n\n#create tensors from image in validation set, then stack all image together\nvalid_ten_3 = torch.stack([tensor(Image.open(o)) \n                           for o in (path/'valid'/'3').ls()])\n#turn them into float and devide them by 255\nvalid_ten_3 = valid_ten_3.float()/255\nvalid_ten_7 = torch.stack([tensor(Image.open(o))\n                           for o in (path/'valid'/'7').ls()])\nvalid_ten_7 = valid_ten_7.float()/255\nvalid_ten_3.shape,valid_ten_7.shape\n\n(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))\n\n\n\n#create a function that will calculate the mean absolute error\ndef min_abser(a, b): return (a-b).abs().mean((-1,-2))\nmin_abser(valid_ten_3[345], mean3)\n\ntensor(0.1123)\n\n\n\nBut this is only the absolut error with one image. Now we need to calculate this distance between the ideal 3/7 with all image in validation set in order to evaluate our model.\nThe easy method that will pop up in our mind in order to do that is to loop over all images in validation set and use the function min_abser() to calulate the difference over all of those images\nThe better way, is to use a method called Broadcasting which is a way of extending a tensor to match to others in order to do calulations\n\n\n#example of broadcasting:\ntensor([2, 3, 4])+tensor(-2)\n\ntensor([0, 1, 2])\n\n\n\npytorch execute a calculation between 2 tensors with different ranks(dimension), we will take adventage of that method in order to do same with our case\n\n\n# shape of mean3/7 and the shape of validation set tensor\nmean3.shape, valid_ten_3.shape\n\n(torch.Size([28, 28]), torch.Size([1010, 28, 28]))\n\n\n\nThere’s 1010 image and we want to compare that ideal image mean3 against\nis_3() decide whether its 3 or 7 by copmuting which output of min_abser() is smaller\n\n\ndef is_3(x): return min_abser(x,mean3) &lt; min_abser(x,mean7)\n\n\nis_3(a_3), is_3(a_3).float()\n\n(tensor(True), tensor(1.))\n\n\n\nNote that when we convert the Boolean response to a float, we get 1.0 for True and 0.0 for False. Thanks to broadcasting, we can also test it on the full validation set of 3s:\n\n\nis_3(valid_ten_3)\n\ntensor([True, True, True,  ..., True, True, True])\n\n\n\nNow we can calculate the accuracy for each of the 3s and 7s by taking the average of that function for all 3s and its inverse for all 7s:\n\n\naccuracy_3s =      is_3(valid_ten_3).float() .mean()\naccuracy_7s = (1 - is_3(valid_ten_7).float()).mean()\n\naccuracy_3s,accuracy_7s,(accuracy_3s+accuracy_7s)/2\n\n(tensor(0.9168), tensor(0.9854), tensor(0.9511))\n\n\n\nWe’re getting +90% accuracy just by doing base-line model!!\nThe base-Line model is good for understanding the problem and building the intuition, but we didn’t build a deep learning model yet.\n\nwe did not add the Learning fase to our model, which is a crucial part according to Arthur Samuel definition\n\nIn other words, this model cannot be updated and improved by learning\n\nwe can’t improve pixel similarity approach by modifying set of parameters, because we don’t have one! and that’s why we need SGD"
  },
  {
    "objectID": "posts/Fastai_ch4/Ch4.html#stochastic-gradient-descent",
    "href": "posts/Fastai_ch4/Ch4.html#stochastic-gradient-descent",
    "title": "Chapter 4: Deep learning for coders with fastai and pytorch",
    "section": "Stochastic Gradient Descent",
    "text": "Stochastic Gradient Descent\n\nInstead of trying to find similarity between an image and the “ideal image” we could add set of weights to each pixel, such as the heighest are associated with darker pixel and lowest are more likely to be white.\n\nfor example the pixel bottom right are white in 7s, so we will give them low weights\n\nThis can be represented as a function and set of weight values for each possible digit:\ndef pr_eight(x,w): return (x*w).sum()\n\nx is the image we’re predicting which will be represented as vector\nw is the weights of the image, also vector\n\nThe idea to find a method by which we update the weights, such as it can help us to make to predict better by a bit, then repeat those steps many times til we get the best prediction we can get.\n\nfind the specific values for the vector w that causes the result of our function to be high for those images that are actually 8s, and low for those images that are not.\n\nHere are the steps that we are going to require, to turn this function into a machine learning classifier:\n\n\nInitialize the weights.\n\n\nFor each image, use these weights to predict whether it appears to be a 3 or a 7.\n\n\nBased on these predictions, calculate how good the model is (its loss).\n\n\nCalculate the gradient, which measures for each weight, how changing that weight would change the loss\n\n\nStep (that is, change) all the weights based on that calculation.\n\n\nGo back to the step 2, and repeat the process.\n\n\nIterate until you decide to stop the training process (for instance, because the model is good enough or you don’t want to wait any longer). \n\n\n\n\nApllying SGD on a simple case\n\nBefore applying these steps to our image classification problem, let’s illustrate what they look like in a simpler case.\nFirst we will define a very simple function f, the quadratic—let’s pretend that this is our loss function, and x is a weight parameter of the function:\n\n\ndef f(x): return x**2\n\n\nplot_function(f, 'x', 'x**2')\n\n\n\n\n\n\n\n\nLet’s pick a rondom value for the paramter, and calculating the loss\n\nplot_function(f, 'x', 'x**2')\nplt.scatter(-1.5, f(-1.5), color='red');\n\n\n\n\n\n\n\n\n\nnow we will increase/decrease the parameter value by just a bit(0.5)and see what will happen:\n\n\nplot_function(f,'x','x**2')\nplt.scatter(-1.5, f(-1.5), color='red' );\nplt.scatter(-1,f(-1), color='blue');\n\n\n\n\n\n\n\n\n\nIt seem that our loss get better(remember, the whole objective of this process is to minimize the loss to 0), we better keep increase the paramter but this time by (0.3), then(0.3):\n\n\nplot_function(f,'x','x**2')\nplt.scatter(-1.5, f(-1.5), color='red' );\nplt.scatter(-1,f(-1), color='blue');\nplt.scatter(-0.7,f(-0.7), color='green');\nplt.scatter(-0.5, f(-0.5), color='orange');\n\n\n\n\n\n\n\n\n\nThe main idea here is to adjust the paramters in a way that causes a minimal loss \nWe can change our weight by a little in the direction of the slope, calculate our loss and adjustment again, and repeat this a few times. Eventually, we will get to the lowest point on our curve:\n\n\n\n\nScreenshot 2022-09-13 at 14-25-28 04_mnist_basics - Jupyter Notebook.png\n\n\n\n\nCalculating Gradients\n\nIt’s obvious now that in order to optimize the loss function we need to update the weights.\n\nto do that we need the help of calculus, it will allow us to update the weights in the direction that optimize the loss\n\n\n\n\nCalculating derivative on Pytorch\n\n#let's assume this variable\ndef f(x): return x**2\nxt = tensor(3.).requires_grad_()\n\n\nhere we create a tensor at value 3 the we call the method requires_grad_ which will calculate the gradients in respect to that variable at that value.\n\n\n# add the function f(x)=x**2 as a Y\nyt = f(xt)\nyt\n\ntensor(9., grad_fn=&lt;PowBackward0&gt;)\n\n\n\n# now we calculate the gradients using the backward() \nyt.backward()\n\n\n#now we can views the gradients by checking the `grad` attribute of the tensor:\nxt.grad\n\ntensor(6.)\n\n\n\n#now we will repeat the same steps but now with a vector:\nxt = tensor([3.,4.,10.]).requires_grad_()\n\n\ndef f(x): return (x**2).sum()\n\n\n#let's check our function\nf(xt)\n\ntensor(125., grad_fn=&lt;SumBackward0&gt;)\n\n\n\nyt = f(xt)\n\n\n#calculate the gradients\nyt.backward()\n\n\n#as expected 2xt\nxt.grad\n\ntensor([ 6.,  8., 20.])\n\n\n\n#let's create another example\nx= tensor(3.).requires_grad_()\nw= tensor(4.).requires_grad_()\nb= tensor(5.).requires_grad_()\ny = x * w + b\ny\n\ntensor(17., grad_fn=&lt;AddBackward0&gt;)\n\n\n\ny.backward()\n\n\nprint('d(y)/dx= ', x.grad)\nprint('d(y)/dw= ', w.grad)\nprint('d(y)/bx= ', b.grad)\n\nd(y)/dx=  tensor(4.)\nd(y)/dw=  tensor(3.)\nd(y)/bx=  tensor(1.)\n\n\n\nNow we have all the ingredients to apply what we have learned on a real problem.\n\nthe goal here is to apply these 7 steps we saw in order to optimize the weights which will effect the loss, which also effect the accuracy of the model\n\none last thing before we do that, we will talk about Learnin rate\nGradient descent allow us to correct our weights by taking steps toward the optimal value of these weights, but it didn’t tell us how big or small these steps are, thats why we have to initilize a learning rate.\nLearning rate is a value, by which our gradient calculate new weights in order to get better loss.\nIn general the learning rate is some randome value we chase between 0.1 and 0.001\nOnce we have picked a learning rate we then adjust the parameters using this simple function:\n\nw-=gradient(w)*lr\n\n\nAn End-to-End SGD Example\n\nSuppose we want to predict the speed of a Roller Coaster over a hump.\nWe want to build a model that predict how the speed change over time\n\nwe measure the speed of the 20 seconds manualy/ every second:\n\n\n\ntime = torch.arange(20).float();\ntime\n\ntensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13., 14., 15., 16., 17., 18., 19.])\n\n\n\nIt might look something like this:\n\n\n# we add some noise to the data since this is the way we usualy find data in real world\nspeed = torch.randn(20)*3 + 0.75*(time-9.5)**2 + 1\nplt.scatter(time,speed);\n\n\n\n\n\n\n\n\n\nThe goal here is to find a function that matches our observastions using SGD\nWe chose here a quadratic function!.\n\nwe need to distinguish clearly between the input of the function t (the that’s the product of our observation) and it’s parameters params\n\n\n\n#let's just assume this  quadratic function!!!\n\ndef f(t, params):\n    a, b, c= params\n    return a*(t**2)+(b*t)+c\n\n\nThe we need to set a loss function that will tell us how good or bad our prediction of the parameters a, b, c\n\n\ndef mse(preds, targets): return((preds - targets)**2).mean().sqrt()\n\n\n\nStep 1: Initialize the parameters\n\nfirst we need to initialize the parametrs by telling pytorch that we want to track its gradients\n\n\nparams= torch.randn(3).requires_grad_()\nparams\n\ntensor([-0.7658, -0.7506,  1.3525], requires_grad=True)\n\n\n\n#??\norig_params = params.clone()\n\n\n\nStep 2: Calculate the predictions\n\nNext we calculate the prediction\n\n\npreds = f(time, params)\npreds\n\ntensor([ 1.3525e+00, -1.6391e-01, -3.2121e+00, -7.7919e+00, -1.3903e+01, -2.1547e+01, -3.0721e+01, -4.1428e+01, -5.3666e+01, -6.7436e+01, -8.2738e+01, -9.9571e+01, -1.1794e+02, -1.3783e+02,\n        -1.5926e+02, -1.8222e+02, -2.0671e+02, -2.3274e+02, -2.6029e+02, -2.8938e+02], grad_fn=&lt;AddBackward0&gt;)\n\n\nThe pred here are the function we create earlier. * f(t, params): am bm c= params return a*(t**2)+(b*t)+c - where the t==time, and params are the initialized values we took in the step before, so the f will be calculated by taking those values as a part of it\n\n# plot the actual calues and our prediction \ndef show_preds(preds, ax=None):\n    if ax is None: ax=plt.subplots()[1]\n    ax.scatter(time, speed)\n    ax.scatter(time, to_np(preds), color='red')\n    ax.set_ylim(-300,100)\n\n\nshow_preds(preds)\n\n\n\n\n\n\n\n\n\nThe blue dot represent the actal value\nThe red dots represent what our model\n\npredictions are really bad, but we need to remember that these prediction are based on Random Values\n\nSo our job here is to update these values to get better predictions\n\n\n\nStep 3: Calculate the loss\n\nWe calculate now the loss of our prediction\nRemember:\n\ndef mse(preds, targets): return((preds - targets)**2).mean().sqrt()\n\nloss= mse(preds, speed)\nloss\n\ntensor(160.6979, grad_fn=&lt;SqrtBackward0&gt;)\n\n\n\nOur goal is to improve this loss function by minimizing it, to be as close as possible to the target(speed)\n\n\n\nStep 4: Calculate the gradients\n\nIn order to minimize the loss function we use the gradients to aproximate how the parameters can be changed to achieve our goal\n\n\nloss.backward()\nparams.grad\n\ntensor([-165.5151,  -10.6402,   -0.7900])\n\n\n\nparams.grad\n\ntensor([-165.5151,  -10.6402,   -0.7900])\n\n\n\nparams\n\ntensor([-0.7658, -0.7506,  1.3525], requires_grad=True)\n\n\n\n\nStep 5: Step the weights\n\nWe need to updated the weights(paramaters) we just calculated\n\nfirst we need to fix the learning rate\nthen we need to call .data on the parameters and parameters.grad, it’s like telling pytorch to not track the change in the gradients at this point.\n\n\n\nlr = 1e-5\nparams.data -= lr * params.grad.data\nparams.grad = None\n\n\nLet’s see if the loss has improved:\n\n\npreds = f(time,params)\nmse(preds, speed)\n\ntensor(160.4228, grad_fn=&lt;SqrtBackward0&gt;)\n\n\n\nwhat’s about the plot\n\n\nshow_preds(preds)\n\n\n\n\n\n\n\n\n\nNow let’s execute all steps in one function\n\n\ndef apply_step(params, prn=True):\n    preds = f(time, params)\n    loss = mse(preds, speed)\n    loss.backward()\n    params.data -= lr * params.grad.data\n    params.grad = None\n    if prn: print(loss.item())\n    return preds\n\n\nLet’s execute this steps for 100s of times\n\n\nfor i in range (1200): apply_step(params)\n\n160.42279052734375\n160.14772033691406\n159.87269592285156\n159.59768676757812\n159.3227081298828\n159.04774475097656\n158.7728271484375\n158.4979248046875\n158.22305297851562\n157.9481964111328\n157.67337036132812\n157.39857482910156\n157.12380981445312\n156.84906005859375\n156.5743408203125\n156.29966735839844\n156.02499389648438\n155.75035095214844\n155.4757537841797\n155.20118713378906\n154.92662048339844\n154.65211486816406\n154.37762451171875\n154.1031494140625\n153.82872009277344\n153.55430603027344\n153.27992248535156\n153.0055694580078\n152.73126220703125\n152.4569549560547\n152.18270874023438\n151.90847778320312\n151.63426208496094\n151.36009216308594\n151.08595275878906\n150.81185913085938\n150.5377655029297\n150.26370239257812\n149.9897003173828\n149.71571350097656\n149.44175720214844\n149.16783142089844\n148.89393615722656\n148.6200714111328\n148.3462371826172\n148.0724334716797\n147.79867553710938\n147.52493286132812\n147.25123596191406\n146.97756958007812\n146.7039337158203\n146.43032836914062\n146.15676879882812\n145.88323974609375\n145.60971069335938\n145.3362579345703\n145.06283569335938\n144.78941345214844\n144.51605224609375\n144.24273681640625\n143.96942138671875\n143.6961669921875\n143.4229278564453\n143.14974975585938\n142.87661743164062\n142.6034698486328\n142.3303985595703\n142.05734252929688\n141.78433227539062\n141.5113525390625\n141.23841857910156\n140.96554565429688\n140.69265747070312\n140.41983032226562\n140.14703369140625\n139.87429809570312\n139.60157775878906\n139.3289031982422\n139.05625915527344\n138.78367614746094\n138.51112365722656\n138.2386016845703\n137.96612548828125\n137.69369506835938\n137.42127990722656\n137.14894104003906\n136.87660217285156\n136.60433959960938\n136.33209228515625\n136.0598907470703\n135.7877197265625\n135.515625\n135.2435302734375\n134.9715118408203\n134.69952392578125\n134.42759704589844\n134.1556854248047\n133.88381958007812\n133.61199951171875\n133.3402099609375\n133.06849670410156\n132.79681396484375\n132.52517700195312\n132.25357055664062\n131.98204040527344\n131.71051025390625\n131.43905639648438\n131.16763305664062\n130.89627075195312\n130.62493896484375\n130.35366821289062\n130.08242797851562\n129.81126403808594\n129.54013061523438\n129.26902770996094\n128.99798583984375\n128.72698974609375\n128.4560546875\n128.18515014648438\n127.91431427001953\n127.64350891113281\n127.37277221679688\n127.1020736694336\n126.83142852783203\n126.56082916259766\n126.29029083251953\n126.01979064941406\n125.74934387207031\n125.47895812988281\n125.2086410522461\n124.93834686279297\n124.6681137084961\n124.39794921875\n124.12782287597656\n123.85773468017578\n123.58772277832031\n123.31776428222656\n123.04785919189453\n122.77799987792969\n122.5082015991211\n122.23847198486328\n121.96878814697266\n121.69915771484375\n121.42959594726562\n121.16007995605469\n120.89063262939453\n120.6212387084961\n120.35188293457031\n120.08260345458984\n119.81338500976562\n119.54422760009766\n119.27513122558594\n119.00609588623047\n118.73711395263672\n118.46820831298828\n118.19935607910156\n117.93054962158203\n117.66181182861328\n117.39315795898438\n117.12455749511719\n116.85600280761719\n116.5875473022461\n116.31912994384766\n116.05079650878906\n115.78250122070312\n115.51428985595703\n115.24613952636719\n114.97806549072266\n114.71004486083984\n114.44210052490234\n114.17422485351562\n113.90641784667969\n113.63868713378906\n113.37100982666016\n113.10340118408203\n112.83587646484375\n112.56842041015625\n112.30104064941406\n112.03372192382812\n111.7664794921875\n111.49931335449219\n111.23222351074219\n110.96520233154297\n110.6982421875\n110.43138122558594\n110.16458129882812\n109.89786529541016\n109.63121795654297\n109.36465454101562\n109.09815979003906\n108.83175659179688\n108.56542205810547\n108.2991714477539\n108.03300476074219\n107.76690673828125\n107.50091552734375\n107.23497772216797\n106.96913146972656\n106.70336151123047\n106.43769073486328\n106.17208862304688\n105.90658569335938\n105.64115142822266\n105.37582397460938\n105.1105728149414\n104.84541320800781\n104.58033752441406\n104.31534576416016\n104.05045318603516\n103.78563690185547\n103.52091979980469\n103.25628662109375\n102.99176025390625\n102.72731018066406\n102.46295928955078\n102.1987075805664\n101.9345474243164\n101.67047119140625\n101.40650177001953\n101.14262390136719\n100.87885284423828\n100.61516571044922\n100.35159301757812\n100.0881118774414\n99.8247299194336\n99.56144714355469\n99.29827117919922\n99.03519439697266\n98.772216796875\n98.50934600830078\n98.24658966064453\n97.98394012451172\n97.72138977050781\n97.45895385742188\n97.19661712646484\n96.93439483642578\n96.67227172851562\n96.41026306152344\n96.14837646484375\n95.88658905029297\n95.62493133544922\n95.3633804321289\n95.1019287109375\n94.84060668945312\n94.57940673828125\n94.31830596923828\n94.0573501586914\n93.79650115966797\n93.5357666015625\n93.27516174316406\n93.0146713256836\n92.75431823730469\n92.49407958984375\n92.23397827148438\n91.97398376464844\n91.7141342163086\n91.45439910888672\n91.1948013305664\n90.93533325195312\n90.67599487304688\n90.41679382324219\n90.15772247314453\n89.89878845214844\n89.63999938964844\n89.3813247680664\n89.122802734375\n88.86441802978516\n88.60618591308594\n88.34807586669922\n88.09011840820312\n87.8322982788086\n87.57463073730469\n87.31710815429688\n87.05973052978516\n86.80250549316406\n86.54542541503906\n86.28850555419922\n86.03172302246094\n85.77511596679688\n85.51864624023438\n85.26234436035156\n85.00618743896484\n84.75019836425781\n84.49436950683594\n84.23870086669922\n83.98320007324219\n83.72785949707031\n83.4726791381836\n83.21766662597656\n82.96282958984375\n82.70816802978516\n82.45367431640625\n82.19934844970703\n81.94519805908203\n81.69123077392578\n81.43744659423828\n81.18382263183594\n80.93038940429688\n80.67713928222656\n80.42406463623047\n80.17118072509766\n79.91848754882812\n79.66597747802734\n79.41366577148438\n79.16154479980469\n78.90961456298828\n78.65788269042969\n78.4063491821289\n78.15501403808594\n77.90387725830078\n77.65293884277344\n77.4022216796875\n77.15169525146484\n76.90137481689453\n76.65127563476562\n76.40138244628906\n76.15170288085938\n75.9022445678711\n75.65299224853516\n75.40396881103516\n75.15515899658203\n74.90658569335938\n74.6582260131836\n74.41009521484375\n74.16220092773438\n73.9145278930664\n73.6670913696289\n73.4198989868164\n73.17293548583984\n72.92621612548828\n72.67974853515625\n72.43351745605469\n72.18753051757812\n71.94180297851562\n71.69631958007812\n71.45108795166016\n71.20611572265625\n70.9614028930664\n70.71694946289062\n70.47276306152344\n70.22883605957031\n69.98519134521484\n69.74180603027344\n69.49870300292969\n69.25586700439453\n69.01331329345703\n68.77104187011719\n68.52906036376953\n68.28734588623047\n68.04594421386719\n67.80481719970703\n67.56399536132812\n67.3234634399414\n67.08323669433594\n66.84332275390625\n66.60370635986328\n66.36438751220703\n66.12539672851562\n65.88671875\n65.64836120605469\n65.41032409667969\n65.17259979248047\n64.93521881103516\n64.69815063476562\n64.46143341064453\n64.22505187988281\n63.98899841308594\n63.7532958984375\n63.5179328918457\n63.282928466796875\n63.04827117919922\n62.81398010253906\n62.580047607421875\n62.34648132324219\n62.11327362060547\n61.88043975830078\n61.64798355102539\n61.41590118408203\n61.184200286865234\n60.95288848876953\n60.72196960449219\n60.49143981933594\n60.26130294799805\n60.031578063964844\n59.80224609375\n59.573326110839844\n59.34482192993164\n59.116729736328125\n58.889068603515625\n58.66182327270508\n58.43500518798828\n58.2086296081543\n57.98268127441406\n57.757179260253906\n57.532127380371094\n57.307525634765625\n57.0833740234375\n56.85968780517578\n56.6364631652832\n56.413700103759766\n56.19141387939453\n55.969608306884766\n55.74828338623047\n55.52744674682617\n55.30709457397461\n55.087249755859375\n54.867897033691406\n54.649051666259766\n54.430721282958984\n54.21290969848633\n53.995609283447266\n53.77884292602539\n53.56260299682617\n53.34690475463867\n53.131744384765625\n52.91713333129883\n52.703067779541016\n52.489566802978516\n52.2766227722168\n52.06424331665039\n51.852447509765625\n51.641231536865234\n51.43058776855469\n51.220542907714844\n51.01108932495117\n50.802242279052734\n50.593997955322266\n50.38636779785156\n50.179351806640625\n49.972965240478516\n49.7672119140625\n49.56209182739258\n49.35761260986328\n49.153778076171875\n48.95060348510742\n48.74808120727539\n48.54623031616211\n48.345054626464844\n48.14455032348633\n47.944732666015625\n47.745609283447266\n47.547176361083984\n47.34945297241211\n47.152435302734375\n46.95613479614258\n46.76055908203125\n46.565704345703125\n46.3715934753418\n46.17822265625\n45.985599517822266\n45.79372787475586\n45.60261535644531\n45.41227340698242\n45.22270965576172\n45.03392028808594\n44.84592056274414\n44.65871810913086\n44.47231674194336\n44.286712646484375\n44.1019287109375\n43.91796875\n43.734832763671875\n43.552528381347656\n43.37106704711914\n43.190452575683594\n43.01069259643555\n42.83179473876953\n42.65375900268555\n42.476600646972656\n42.30031967163086\n42.12492752075195\n41.9504280090332\n41.77682876586914\n41.6041374206543\n41.43235778808594\n41.26150131225586\n41.09156799316406\n40.92256164550781\n40.75450134277344\n40.5873908996582\n40.42121887207031\n40.256011962890625\n40.091773986816406\n39.92850112915039\n39.766204833984375\n39.60489273071289\n39.4445686340332\n39.285240173339844\n39.12691116333008\n38.96958923339844\n38.81327438354492\n38.65798568725586\n38.50371551513672\n38.35047149658203\n38.19826889038086\n38.04710006713867\n37.896976470947266\n37.74790954589844\n37.59988784790039\n37.45293426513672\n37.30704116821289\n37.1622200012207\n37.01847457885742\n36.87580490112305\n36.73421859741211\n36.593719482421875\n36.454307556152344\n36.31599807739258\n36.17878341674805\n36.04267501831055\n35.90766906738281\n35.77377700805664\n35.640995025634766\n35.509334564208984\n35.378787994384766\n35.24936294555664\n35.121063232421875\n34.993892669677734\n34.86784744262695\n34.74293899536133\n34.619163513183594\n34.49652099609375\n34.37501907348633\n34.2546501159668\n34.13542556762695\n34.01734161376953\n33.90039825439453\n33.78459548950195\n33.66993713378906\n33.55642318725586\n33.44404983520508\n33.332820892333984\n33.22273635864258\n33.113792419433594\n33.00598907470703\n32.89932632446289\n32.79380416870117\n32.68942642211914\n32.58617401123047\n32.484066009521484\n32.38309097290039\n32.28324508666992\n32.18452835083008\n32.086936950683594\n31.99047088623047\n31.89512825012207\n31.800899505615234\n31.70779037475586\n31.61579132080078\n31.5248966217041\n31.435110092163086\n31.346420288085938\n31.25882911682129\n31.17232894897461\n31.086910247802734\n31.002580642700195\n30.919322967529297\n30.83713722229004\n30.756017684936523\n30.675962448120117\n30.596956253051758\n30.51900291442871\n30.442092895507812\n30.36622428894043\n30.291379928588867\n30.217559814453125\n30.14476203918457\n30.07297134399414\n30.00218963623047\n29.93239974975586\n29.863605499267578\n29.79578971862793\n29.72895050048828\n29.6630802154541\n29.598169326782227\n29.534212112426758\n29.4711971282959\n29.409116744995117\n29.347970962524414\n29.287738800048828\n29.228425979614258\n29.170013427734375\n29.11249351501465\n29.055862426757812\n29.000110626220703\n28.945226669311523\n28.891206741333008\n28.83803367614746\n28.78570556640625\n28.734214782714844\n28.683551788330078\n28.63370132446289\n28.584657669067383\n28.53641700744629\n28.488964080810547\n28.442289352416992\n28.396390914916992\n28.35125160217285\n28.306867599487305\n28.263225555419922\n28.220321655273438\n28.178142547607422\n28.136682510375977\n28.095928192138672\n28.055875778198242\n28.016508102416992\n27.977825164794922\n27.9398136138916\n27.902463912963867\n27.865768432617188\n27.829721450805664\n27.794307708740234\n27.759521484375\n27.725353240966797\n27.691795349121094\n27.65884017944336\n27.626476287841797\n27.594696044921875\n27.56348991394043\n27.532852172851562\n27.50277328491211\n27.473243713378906\n27.444255828857422\n27.415802001953125\n27.38787269592285\n27.360462188720703\n27.333559036254883\n27.30715560913086\n27.281248092651367\n27.25582504272461\n27.230878829956055\n27.206403732299805\n27.182390213012695\n27.158830642700195\n27.135719299316406\n27.113048553466797\n27.090810775756836\n27.06899642944336\n27.047603607177734\n27.02661895751953\n27.006038665771484\n26.985857009887695\n26.966068267822266\n26.946659088134766\n26.927631378173828\n26.908971786499023\n26.890676498413086\n26.872737884521484\n26.855154037475586\n26.837913513183594\n26.821012496948242\n26.804445266723633\n26.788204193115234\n26.77228546142578\n26.756681442260742\n26.74138832092285\n26.726398468017578\n26.711708068847656\n26.697311401367188\n26.683198928833008\n26.66937255859375\n26.65582275390625\n26.642541885375977\n26.629533767700195\n26.616785049438477\n26.604291915893555\n26.592052459716797\n26.580062866210938\n26.568313598632812\n26.55680274963379\n26.54552459716797\n26.53447723388672\n26.52365493774414\n26.513051986694336\n26.502666473388672\n26.492490768432617\n26.482528686523438\n26.472766876220703\n26.46320343017578\n26.453842163085938\n26.44466781616211\n26.43568229675293\n26.4268856048584\n26.41826820373535\n26.409826278686523\n26.401559829711914\n26.39346694946289\n26.38553810119629\n26.377775192260742\n26.37017250061035\n26.362730026245117\n26.355438232421875\n26.348299026489258\n26.341310501098633\n26.33446502685547\n26.327762603759766\n26.32120132446289\n26.314775466918945\n26.30848503112793\n26.302322387695312\n26.29629135131836\n26.29038429260254\n26.28460121154785\n26.27894401550293\n26.27340316772461\n26.267974853515625\n26.262662887573242\n26.257463455200195\n26.252370834350586\n26.247386932373047\n26.242507934570312\n26.23773193359375\n26.233055114746094\n26.228477478027344\n26.223997116088867\n26.219608306884766\n26.215314865112305\n26.211111068725586\n26.20699691772461\n26.20296859741211\n26.19902801513672\n26.195167541503906\n26.191389083862305\n26.18769073486328\n26.184070587158203\n26.18052864074707\n26.177061080932617\n26.173667907714844\n26.17034339904785\n26.16709327697754\n26.163909912109375\n26.16079330444336\n26.157745361328125\n26.154760360717773\n26.151840209960938\n26.14898109436035\n26.146183013916016\n26.14344596862793\n26.140766143798828\n26.13814353942871\n26.135576248168945\n26.133060455322266\n26.130603790283203\n26.128196716308594\n26.125839233398438\n26.123537063598633\n26.121280670166016\n26.11907196044922\n26.11690902709961\n26.114797592163086\n26.11272430419922\n26.110698699951172\n26.108718872070312\n26.10677719116211\n26.10487937927246\n26.103023529052734\n26.10120391845703\n26.09942626953125\n26.09768295288086\n26.095979690551758\n26.094310760498047\n26.092681884765625\n26.091081619262695\n26.089519500732422\n26.08799171447754\n26.08649253845215\n26.085031509399414\n26.083599090576172\n26.082195281982422\n26.080820083618164\n26.079477310180664\n26.07816505432129\n26.07687759399414\n26.075618743896484\n26.074386596679688\n26.073179244995117\n26.072004318237305\n26.070846557617188\n26.069719314575195\n26.068614959716797\n26.06753158569336\n26.06647300720215\n26.06543731689453\n26.064424514770508\n26.063432693481445\n26.062463760375977\n26.061511993408203\n26.060583114624023\n26.059673309326172\n26.05878257751465\n26.057912826538086\n26.05706214904785\n26.056228637695312\n26.055410385131836\n26.05461311340332\n26.0538330078125\n26.053068161010742\n26.05232048034668\n26.05158805847168\n26.050870895385742\n26.0501708984375\n26.049484252929688\n26.04881477355957\n26.04815673828125\n26.04751205444336\n26.046886444091797\n26.046268463134766\n26.04566764831543\n26.04507827758789\n26.04450035095215\n26.0439395904541\n26.043384552001953\n26.0428466796875\n26.04231834411621\n26.04180145263672\n26.04129409790039\n26.040800094604492\n26.040315628051758\n26.03984260559082\n26.039377212524414\n26.038921356201172\n26.038476943969727\n26.038042068481445\n26.037616729736328\n26.037200927734375\n26.036794662475586\n26.036394119262695\n26.0360050201416\n26.03562355041504\n26.03525161743164\n26.03488540649414\n26.034526824951172\n26.034177780151367\n26.03383445739746\n26.033498764038086\n26.033170700073242\n26.032852172851562\n26.032535552978516\n26.032228469848633\n26.03192901611328\n26.031635284423828\n26.03134536743164\n26.031064987182617\n26.03078842163086\n26.030517578125\n26.030254364013672\n26.02999496459961\n26.02974510192871\n26.029499053955078\n26.029254913330078\n26.029020309448242\n26.028785705566406\n26.0285587310791\n26.028337478637695\n26.028120040893555\n26.027908325195312\n26.027700424194336\n26.027498245239258\n26.02729606628418\n26.027101516723633\n26.02690887451172\n26.026721954345703\n26.026540756225586\n26.0263614654541\n26.026187896728516\n26.026016235351562\n26.025848388671875\n26.025684356689453\n26.025524139404297\n26.025365829467773\n26.02521324157715\n26.025062561035156\n26.02491569519043\n26.024770736694336\n26.024627685546875\n26.024494171142578\n26.024356842041016\n26.02422523498535\n26.02409553527832\n26.023969650268555\n26.023847579956055\n26.023725509643555\n26.023605346679688\n26.023488998413086\n26.023374557495117\n26.023263931274414\n26.023155212402344\n26.023048400878906\n26.0229434967041\n26.022842407226562\n26.022741317749023\n26.02264404296875\n26.022546768188477\n26.02245330810547\n26.022363662719727\n26.02227210998535\n26.022186279296875\n26.022096633911133\n26.022016525268555\n26.02193260192871\n26.021852493286133\n26.021772384643555\n26.02169418334961\n26.021617889404297\n26.02154541015625\n26.021472930908203\n26.02140235900879\n26.021331787109375\n26.021265029907227\n26.021198272705078\n26.021133422851562\n26.02107048034668\n26.021007537841797\n26.020946502685547\n26.02088737487793\n26.020828247070312\n26.020771026611328\n26.020713806152344\n26.020658493041992\n26.020605087280273\n26.020551681518555\n26.0205020904541\n26.020450592041016\n26.020402908325195\n26.020353317260742\n26.020305633544922\n26.0202579498291\n26.020214080810547\n26.02016830444336\n26.020126342773438\n26.020084381103516\n26.020042419433594\n26.020000457763672\n26.019960403442383\n26.019920349121094\n26.019882202148438\n26.019845962524414\n26.019807815551758\n26.019771575927734\n26.019737243652344\n26.01970100402832\n26.01966667175293\n26.019634246826172\n26.019601821899414\n26.019569396972656\n26.01953887939453\n26.019508361816406\n26.01947784423828\n26.019451141357422\n26.019418716430664\n26.019393920898438\n26.019365310668945\n26.019336700439453\n26.019309997558594\n26.019285202026367\n26.019258499145508\n26.019235610961914\n26.019208908081055\n26.019187927246094\n26.019163131713867\n26.019142150878906\n26.01911735534668\n26.01909637451172\n26.019075393676758\n26.019054412841797\n26.019033432006836\n26.019012451171875\n26.018991470336914\n26.018972396850586\n26.018953323364258\n26.01893424987793\n26.0189151763916\n26.018898010253906\n26.01888084411621\n26.018861770629883\n26.01884651184082\n26.018829345703125\n26.018814086914062\n26.018798828125\n26.018781661987305\n26.01876449584961\n26.018753051757812\n26.018735885620117\n26.018722534179688\n26.018707275390625\n26.018693923950195\n26.018678665161133\n26.018667221069336\n26.018651962280273\n26.018638610839844\n26.018625259399414\n26.018613815307617\n26.01860237121582\n26.018590927124023\n26.018579483032227\n26.018566131591797\n26.0185546875\n26.018545150756836\n26.01853370666504\n26.018524169921875\n26.018510818481445\n26.01850128173828\n26.018491744995117\n26.018484115600586\n26.018470764160156\n26.018461227416992\n26.018451690673828\n26.018442153930664\n26.018434524536133\n26.018423080444336\n26.018417358398438\n26.018409729003906\n26.018400192260742\n26.018390655517578\n26.018383026123047\n26.018375396728516\n26.018367767333984\n26.018360137939453\n26.018352508544922\n26.01834487915039\n26.01833724975586\n26.018329620361328\n26.018321990966797\n26.018314361572266\n26.018308639526367\n26.01830291748047\n26.01829719543457\n26.018287658691406\n26.01828384399414\n26.01827621459961\n26.01827049255371\n26.018264770507812\n26.018259048461914\n26.018251419067383\n26.018245697021484\n26.018239974975586\n26.018234252929688\n26.01822853088379\n26.01822280883789\n26.018217086791992\n26.01820945739746\n26.018207550048828\n26.018199920654297\n26.01819610595703\n26.0181884765625\n26.018184661865234\n26.0181827545166\n26.018177032470703\n26.018171310424805\n26.01816749572754\n26.01816177368164\n26.018157958984375\n26.01815414428711\n26.01814842224121\n26.018144607543945\n26.018138885498047\n26.01813507080078\n26.018131256103516\n26.01812744140625\n26.018123626708984\n26.01811981201172\n26.018115997314453\n26.018110275268555\n26.018108367919922\n26.018102645874023\n26.01810073852539\n26.018096923828125\n26.018091201782227\n26.01808738708496\n26.018085479736328\n26.018081665039062\n26.018077850341797\n26.018075942993164\n26.018070220947266\n26.01806640625\n26.018062591552734\n26.018062591552734\n26.018056869506836\n26.018054962158203\n26.018049240112305\n26.018049240112305\n26.01804542541504\n26.018041610717773\n26.018037796020508\n26.018035888671875\n26.018033981323242\n26.018030166625977\n26.01802635192871\n26.018022537231445\n26.018020629882812\n26.01801872253418\n26.018014907836914\n26.01801300048828\n26.01801109313965\n26.01800537109375\n26.018003463745117\n26.018001556396484\n26.01799774169922\n26.01799774169922\n26.017993927001953\n26.017990112304688\n26.017988204956055\n26.01798439025879\n26.017982482910156\n26.017980575561523\n26.01797866821289\n26.017974853515625\n26.017972946166992\n26.017969131469727\n26.017967224121094\n26.01796531677246\n26.017963409423828\n26.017959594726562\n26.017959594726562\n26.017955780029297\n26.017953872680664\n26.0179500579834\n26.017948150634766\n26.0179443359375\n26.0179443359375\n26.017942428588867\n26.017940521240234\n26.01793670654297\n26.01793670654297\n26.017932891845703\n26.017929077148438\n26.017929077148438\n26.017927169799805\n26.01792335510254\n26.01792335510254\n26.017919540405273\n26.01791763305664\n26.017913818359375\n26.017911911010742\n26.017911911010742\n26.017908096313477\n26.017906188964844\n26.017902374267578\n26.017902374267578\n26.017898559570312\n26.017898559570312\n26.017894744873047\n26.017892837524414\n26.017892837524414\n26.01789093017578\n26.01788902282715\n26.01788330078125\n26.01788330078125\n26.017881393432617\n26.017879486083984\n26.01787757873535\n26.01787567138672\n26.01787567138672\n26.01786994934082\n26.01786994934082\n26.017868041992188\n26.017868041992188\n26.01786231994629\n26.01786231994629\n26.017860412597656\n26.017860412597656\n26.01785659790039\n26.01785659790039\n26.017852783203125\n26.017850875854492\n26.017847061157227\n26.017847061157227\n26.017845153808594\n26.017845153808594\n26.017841339111328\n26.017837524414062\n26.017837524414062\n26.01783561706543\n26.017833709716797\n26.017831802368164\n26.017831802368164\n26.01782989501953\n26.01782989501953\n26.017826080322266\n26.017822265625\n26.017822265625\n26.017820358276367\n26.017818450927734\n26.0178165435791\n26.01781463623047\n26.017812728881836\n26.017810821533203\n26.01780891418457\n26.017807006835938\n26.017805099487305\n26.017805099487305\n26.01780128479004\n26.017799377441406\n26.017797470092773\n26.017799377441406\n26.017793655395508\n26.01779556274414\n26.01778793334961\n26.017789840698242\n26.01778793334961\n\n\n\nAfter 1200 iterations we manage to reduce the loss from 160. to 26.\nNow let’s plot the process\n\n\n_,axs = plt.subplots(1,4,figsize=(12,3))\nfor ax in axs: show_preds(apply_step(params, False), ax)\nplt.tight_layout()\n\n\n\n\n\n\n\n\n\nAfter each iteration we will have a brand new quadratic function, which will be much more close to the actual one that represent the real data\n\n\n\nStep 7: stop\n\nAfter n# of iterations we decide to stop\n\n\n\nSummarizing Gradient Descent\n\nAt the beginnig we start with the Weights\n\npick the randomly if we build the model from scartch\nget them pretrained from another model : TransferLearning\n\nBuild a Loss Function\n\nallow us to see how good or bad the outputs the model gives us\nthen we try to change/update the weights in way that makes the loss function better==lower\n\nTo find a way to do that (update the weights to optimize the loss) we use calculus to caltulate the Gradients\n\ngradients descent tells us either we decrease or increase the weights in order to minimize the loss (that simple!!)\n\nWe then iterate till we reached the lowest point\nStop"
  },
  {
    "objectID": "posts/Fastai_ch4/Ch4.html#the-mnist-loss-function",
    "href": "posts/Fastai_ch4/Ch4.html#the-mnist-loss-function",
    "title": "Chapter 4: Deep learning for coders with fastai and pytorch",
    "section": "The MNIST Loss Function",
    "text": "The MNIST Loss Function\n\nWe saw previously the function pr_eights() where we represent the input images x as vector, just like the w weight vector.\n\nhere we will do the same with our MNIST_sample\n\nWe already have our dataset for 3s and 7s as tensors == the x of the function:\n\ntraining-set: stacked_threes, stacked_sevens\nvalidation-set : valid_ten_3, valid_ten_7\n\nWe’ll concatenate them all into a single tensor, and also change them from a list of matrices (a rank-3 tensor) to a list of vectors (a rank-2 tensor)\n\nby using .view\nwhich is a Pytorh method that changes the shape of a tensor without changing its content\n-1 is a special parameter to .view that mean: make this axis as big as necessary to fit the data\n\n\n\ntrain_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n\n\ntrain_x.shape\n\ntorch.Size([12396, 784])\n\n\n\nWe need a label for each image. We’ll use 1 for 3s and 0 for 7s:\n\n\ntrain_y = tensor([1]*len(threes) + [0]*len(sevens))\ntrain_x.shape,train_y.shape\n\n(torch.Size([12396, 784]), torch.Size([12396]))\n\n\n\nThe problem here is that train_x and train_y don’t match in terms of shape.\nHere we will use unsqueeze() method to train_y which will return rank 2 tensor: \n\n\ntrain_y= train_y.unsqueeze(1)\ntrain_y.shape\n\ntorch.Size([12396, 1])\n\n\n\nHere we create dset dataset for training by ziping both dependent and independent variables.\n\n\ndset = list(zip(train_x,train_y))\nx,y = dset[0]\nx.shape,y\n\n(torch.Size([784]), tensor([1]))\n\n\n\nGo through the same steps for validation set\n\n\nvalid_x = torch.cat([valid_ten_3, valid_ten_7]).view(-1, 28*28)\nvalid_y = tensor([1]*len(valid_ten_3) + [0]*len(valid_ten_7)).unsqueeze(1)\nvalid_dset = list(zip(valid_x,valid_y))\n\nNow we begin the 7 steps we saw earlier but now for the mnist model\n### 1-INIT the parameters\n\ndef init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()\n\n\nInitialize weights\n\n\nweights = init_params((28*28, 1))\nweights.shape\n\ntorch.Size([784, 1])\n\n\n\nInitialize the bias\n\n\nbias = init_params(1)\nbias\n\ntensor([0.6863], requires_grad=True)\n\n\n\n2-Prediction calculation\n\nNow we can calculate the prediction based on those randome weights and biases for one image[0]\nIn order to multiply 2 matrix you need to make sure they have same number of inner product:\n\nnumber of columns first matrix==number of rows second matrix\n\n\n\n(train_x[0]*weights.T).sum()+bias\n\ntensor([20.2336], grad_fn=&lt;AddBackward0&gt;)\n\n\n\nIn python matrix multiplication is represented by @\nHere we create a function that return our training set as matrix multiplied @ by weights then added to the bias radome value\n\n\ndef linear1(xb): return xb@weights + bias\npreds = linear1(train_x)\npreds\n\ntensor([[20.2336],\n        [17.0644],\n        [15.2384],\n        ...,\n        [18.3804],\n        [23.8567],\n        [28.6816]], grad_fn=&lt;AddBackward0&gt;)\n\n\n\nCheck the accuracy of our modl based on random weights\n\n\n# Let's check our accuracy\ncorrects = (preds&gt;0.0).float()==train_y\ncorrects\n\ntensor([[ True],\n        [ True],\n        [ True],\n        ...,\n        [False],\n        [False],\n        [False]])\n\n\n\n# check the mean\ncorrects.float().mean().item()\n\n0.4912068545818329\n\n\n\nNow let’s see what the change in accuracy is for a small change in one of the weights (note that we have to ask PyTorch not to calculate gradients as we do this, which is what with torch.no_grad() is doing here):\n\n\nwith torch.no_grad(): weights[0] *= 1.0001\n\n\npreds = linear1(train_x)\n((preds&gt;0.0).float() == train_y).float().mean().item()\n\n0.4912068545818329\n\n\n\nAs we notice even with the change we commited in one of the weights we didn’t observe any change at all in the model accuracy! which rise a problem for our method. we need a formula that can reflexes the changes we commited to the parameters, so we update the parameters in a way that make our predictions better.\nThe problem with the thresh preds&gt;0.0 is that the gradients are allways equal to zero, because as we know the gradients are calculate as rise over run, and in this case the small change in parameters is rarely could change the prediction from 3 to 7 or vice-versa, so the gradients will allways indicate to 0.\n\nInstead we need a loss function, which when our weights results a slightly better prediction, gives us a slightly better loss function\n\n\ntrgts  = tensor([1,0,1])\nprds   = tensor([0.9, 0.4, 0.2])\n\n\nHere we assume that the trgts is the image we want to predict, 1 for 3’s and 0 for 7’s,\nSo in this case the model is confident in the first image it’s a 3 with 0.9, and not sure about the second image with 0.4, and way too incorrect in the 3d image with 0.2\nThe objective is to build a loss function that will calculate the accuracy of the model and returns some metrics that will be updated if we update our parameters\n\n\ndef mnist_loss(predictions, targets):\n    return torch.where(targets==1, 1-predictions, predictions).mean()\n\n\ntorch.where is a way of puting specific condition, in other way we can say this:\n\nif targets==1: loss = 1-predictions else: targets==0\n\ntorch.where(trgts==1, 1-prds, prds).mean()\n\ntensor(0.4333)\n\n\n\nSee if the loss will be updated if we change the weights.\n\nwe will pass this tensor [0.9, 0.4, 0.8] and see how to change the prediction from 0.2 to 0.8 will efects the loss function\n\n\n\nmnist_loss(tensor([0.9, 0.4, 0.8]), trgts)\n\ntensor(0.2333)\n\n\n\nAs we see here the loss function gets better when we minimize the distance between the prediction and the target in the third image\n\nThe problem that we still face in this method is that we assume that the predictions will allways be between 0 and 1\nTo solve this problem we need a function that return any prediction how matter bigger that 1 or smaller than 0 to the interval between those 2 numbers\nIn fact there’s a function that do the same exact thing, we call it SIGMOID FUNCTION\n\n\n\nSigmoid Function\nThe sigmoid function always outputs a number between 0 and 1. It’s defined as follows:\n\ndef sigmoid(x): return 1/(1+torch.exp(-x))\n\n\nplot_function(torch.sigmoid, title='Sigmoid', min=-4, max=4)\n\n\n\n\n\n\n\n\n\nWhatever input we give it to Sigmoid it will always return a number between 0 and 1\nNow let’s update the mnist_loss by adding sigmoid to its inputs\n\n\ndef mnist_loss(predictions, targets):\n    predictions = predictions.sigmoid()\n    return torch.where(targets==1, 1-predictions, predictions).mean()\n\n\n\nSGD and Mini-Batches\n\nNow we have our loss function for the SGD, we need to know which method we will take in order to update the gradients, we can update them after taking all the data points or after calculating each data points.\nThe first method will take a lot of time, and the second will not use much information, so we will take another track which is to use Mini-Batches and update the gradients after one mini-batch\nHow many datapoints in each batch is called batch-size. a larger batch size will produce more accurate result but it will take much time, and smaller batch-size will need many epochs to learn but it will be faster\nWe will see later how to decide the suitable batch-size for each situation\nWe will use DataLoader in order to shuffle data items before we create the mini-batches, so we vary the data items in each of the mini batches\n\n\n#for example\nc = range(15)\ndl = DataLoader(c, batch_size=5, shuffle=True)\nlist(dl)\n\n[tensor([ 3, 12,  8, 10,  2]),\n tensor([ 9,  4,  7, 14,  5]),\n tensor([ 1, 13,  0,  6, 11])]\n\n\n\nBut in training model scenarios we won’t need any pyhton collection, we want a collection containing dependent and independent variables.\n\nA tuple that contains dependents and independent variables called in Pytorch a Dataset\n\nHere is a simple dataset:\n\n\nds = L(enumerate(string.ascii_lowercase))\nds\n\n(#26) [(0, 'a'),(1, 'b'),(2, 'c'),(3, 'd'),(4, 'e'),(5, 'f'),(6, 'g'),(7, 'h'),(8, 'i'),(9, 'j')...]\n\n\n\nWhen we pass a Dataset to a DataLoader we will get back mini-batches which are themselves tuples of tensors representing batches of independent and dependent variables:\n\n\ndl = DataLoader(ds, batch_size=6, shuffle=True)\nlist(dl)\n\n[(tensor([17, 18, 10, 22,  8, 14]), ('r', 's', 'k', 'w', 'i', 'o')),\n (tensor([20, 15,  9, 13, 21, 12]), ('u', 'p', 'j', 'n', 'v', 'm')),\n (tensor([ 7, 25,  6,  5, 11, 23]), ('h', 'z', 'g', 'f', 'l', 'x')),\n (tensor([ 1,  3,  0, 24, 19, 16]), ('b', 'd', 'a', 'y', 't', 'q')),\n (tensor([2, 4]), ('c', 'e'))]\n\n\n\n\nPutting It All Together\nNow we have :\n* dset, valid_dset * linear1 * mnist_loss * sigmoid_function\nwe can create the model from scratch\nFirst we re-intialize our parameters:\n\nweights = init_params((28*28,1))\nbias = init_params(1)\n\n\nThen create the DataLoader from Dataset\n\n\ndl = DataLoader(dset, batch_size=256)\nxb,yb = first(dl)\nxb.shape,yb.shape\n\n(torch.Size([256, 784]), torch.Size([256, 1]))\n\n\n\nWe’ll do the same for the validation set:\n\n\nvalid_dl = DataLoader(valid_dset, batch_size=256)\n\n\nLet’s create a mini-batch of size 4 for testing:\n\n\nbatch = train_x[:4]\nbatch.shape\n\ntorch.Size([4, 784])\n\n\n\nCall linear1 model we created earlier on the batch:\n\n\npreds = linear1(batch)\npreds\n\ntensor([[-2.1876],\n        [-8.3973],\n        [ 2.5000],\n        [-4.9473]], grad_fn=&lt;AddBackward0&gt;)\n\n\n\nCreate the loss function:\n\n\nloss = mnist_loss(preds, train_y[:4])\nloss\n\ntensor(0.7419, grad_fn=&lt;MeanBackward0&gt;)\n\n\n\nNow we can calculate the gradients:\n\n\nloss.backward()\nweights.grad.shape,weights.grad.mean(),bias.grad\n\n(torch.Size([784, 1]), tensor(-0.0061), tensor([-0.0420]))\n\n\n\nLet’s put that all these steps in a single function:\n\n\ndef calc_grad(xb, yb, model):\n    preds = model(xb)\n    loss = mnist_loss(preds, yb)\n    loss.backward()\n\n\nAnd test it..\n\n\ncalc_grad(batch, train_y[:4], linear1)\nweights.grad.mean(), bias.grad\n\n(tensor(-0.0121), tensor([-0.0840]))\n\n\n\nBut look what happens if we call it twice:\n\n\ncalc_grad(batch, train_y[:4], linear1)\nweights.grad.mean(),bias.grad\n\n(tensor(-0.0182), tensor([-0.1260]))\n\n\n\nThe gradients have changed!\n\nin order to not calculate the gradients and add to the last one every time we call this function calc_gradwe need to use grad.zero_ which set the current gradients to zero\n\n\n\nweights.grad.zero_()\nbias.grad.zero_();\n\n\nOur only remaining step is to update the weights and biases based on the gradient and learning rate. When we do so, we have to tell PyTorch not to take the gradient of this step too—otherwise things will get very confusing when we try to compute the derivative at the next batch! If we assign to the data attribute of a tensor then PyTorch will not take the gradient of that step. Here’s our basic training loop for an epoch:\n\n\ndef train_epoch(model, lr, params):\n    for xb,yb in dl:\n        calc_grad(xb, yb, model)\n        for p in params:\n            p.data -= p.grad*lr\n            p.grad.zero_()\n\n\nLet’s build a function that calculate the batch accuracy\n\n\n# accuracy of the batch\n(preds&gt;0.0).float() == train_y[:4]\n\ntensor([[False],\n        [False],\n        [ True],\n        [False]])\n\n\n\nFunction to calculate our validation accuracy:\n\n\ndef batch_accuracy(xb, yb):\n    preds = xb.sigmoid()\n    correct = (preds&gt;0.5) == yb\n    return correct.float().mean()\n\n\n# check if it works\nbatch_accuracy(linear1(batch), train_y[:4])\n\ntensor(0.2500)\n\n\n\n# all together\ndef validate_epoch(model):\n    accs = [batch_accuracy(model(xb), yb) for xb,yb in valid_dl]\n    return round(torch.stack(accs).mean().item(), 4)\n\n\nvalidate_epoch(linear1)\n\n0.5262\n\n\n\nNow lets train for one epoch and see if the accuracy improve\n\n\nlr = 1.\nparams = weights,bias\ntrain_epoch(linear1, lr, params)\nvalidate_epoch(linear1)\n\n0.6663\n\n\n\nThats promising\n\nfrom 0.4642 to 0.6096 after one epoch\n\nThen do a few more:\n\n\nfor i in range(20):\n    train_epoch(linear1, lr, params)\n    print(validate_epoch(linear1), end=' ')\n\n0.8265 0.89 0.9183 0.9276 0.9398 0.9467 0.9506 0.9525 0.9559 0.9579 0.9599 0.9608 0.9613 0.9618 0.9633 0.9638 0.9647 0.9657 0.9672 0.9677 \n\n\n\n\nCreating an Optimizer\n\nAs we know the model we created is only for learning .\n\nin real world scenarios we do not need to implement everything from scratch, framworks like Pytorch and Fastai provide us with everything.\n\nThe linear1 model we created can be remplaced with nn.Linear which can do the same work and more\n\nnn.Linear combine the role of linear1 and weights+bias\n\n\n\nlinear_model = nn.Linear(28*28, 1)\n\n\nEvery PyTorch module knows what parameters it has that can be trained; they are available through the parameters method:\n\n\nw, b = linear_model.parameters()\nw.shape, b.shape\n\n(torch.Size([1, 784]), torch.Size([1]))\n\n\n\nWe can create optimizer class\n\n\nclass BasicOptim:\n    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n\n    def step(self, *args, **kwargs):\n        for p in self.params: p.data -= p.grad.data * self.lr\n\n    def zero_grad(self, *args, **kwargs):\n        for p in self.params: p.grad = None\n\n\n# passing the model params to the optimizer\nopt = BasicOptim(linear_model.parameters(), lr)\n\n\n# simplifying the epoch training function\ndef train_epoch(model):\n    for xb,yb in dl:\n        calc_grad(xb, yb, model)\n        opt.step()\n        opt.zero_grad()\n\n\n# validation doesn't change\nvalidate_epoch(linear_model)\n\n0.4606\n\n\n\n# simplifying the training loop:\ndef train_model(model, epochs):\n    for i in range(epochs):\n        train_epoch(model)\n        print(validate_epoch(model), end=' ')\n\n\n# same results as before\ntrain_model(linear_model, 20)\n\n0.4932 0.7686 0.8555 0.9136 0.9346 0.9482 0.957 0.9634 0.9658 0.9678 0.9697 0.9717 0.9736 0.9746 0.9761 0.9771 0.9775 0.9775 0.978 0.9785 \n\n\n\nThe good thing is all of this is provided by Fastai:\n\n\nlinear_model = nn.Linear(28*28,1)\nopt = SGD(linear_model.parameters(), lr)\ntrain_model(linear_model, 20)\n\n0.4932 0.8179 0.8496 0.9141 0.9346 0.9482 0.957 0.9619 0.9658 0.9673 0.9692 0.9712 0.9741 0.9751 0.9761 0.9775 0.9775 0.978 0.9785 0.979 \n\n\n\nFastai also provides Learner.fit, which we can use instead of train_model. To create a Learner we first need to create a DataLoaders, by passing in our training and validation DataLoaders:\n\n\ndls = DataLoaders(dl, valid_dl)\n\n\nTo create a Learner we need to pass in all the elements that we’ve created in this chapter: the DataLoaders, the model, the optimization function (which will be passed the parameters), the loss function, and optionally any metrics to print:\n\n\nlearn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n                loss_func=mnist_loss, metrics=batch_accuracy)\n\nNow we can call fit:\n\nlearn.fit(10, lr=lr)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nbatch_accuracy\ntime\n\n\n\n\n0\n0.636709\n0.503144\n0.495584\n00:00\n\n\n1\n0.429828\n0.248517\n0.777233\n00:00\n\n\n2\n0.161680\n0.155361\n0.861629\n00:00\n\n\n3\n0.072948\n0.097721\n0.917566\n00:00\n\n\n4\n0.040128\n0.073205\n0.936212\n00:00\n\n\n5\n0.027210\n0.059466\n0.950442\n00:00\n\n\n6\n0.021837\n0.050799\n0.957802\n00:00\n\n\n7\n0.019398\n0.044980\n0.964181\n00:00\n\n\n8\n0.018122\n0.040853\n0.966143\n00:00\n\n\n9\n0.017330\n0.037788\n0.968106\n00:00\n\n\n\n\n\n\n\nAdding a Nonlinearity\n\nSo far we managed to create a linear function that can predict hand written digit with high performance.\nBut still, it’s just a simple linear classifier, with very constraint abilities.\nTo make it more complex and capable handle complex tasks, we need to add something non-linear between two linear classifiers.\n\nThis is gives us a Neural network\n\nHere a basic architecture of a neural network:\n\n\ndef simple_net(xb): \n    res = xb@w1 + b1 # first linear function\n    res = res.max(tensor(0.0)) # non linear function\n    res = res@w2 + b2  # 2nd linear function\n    return res\n\n\nw1 = init_params((28*28,30))\nb1 = init_params(30)\nw2 = init_params((30,1))\nb2 = init_params(1)\n\n\nw1.shape, b1.shape\n\n(torch.Size([784, 30]), torch.Size([30]))\n\n\n\nthe lines: res = xb@w1 + b1 and res@w2 + b2 are two classifier, basic linear function similar to the nn.Linear we use previously\nWhile the line res = res.max(tensor(0.0)) is a non linear function\n\nthis function called rectified linear unit ReLu which return every negative number with 0\n\nSo if we think about this architecture we have here:\n\nfirst we have a linear function that does the matrix multiplication between dataset tensors and initialzed weights + bias and output 30 (we can chose any number) features, which represent for each a different mix of pixels\nthese outputs are taken by the ReLU and converted to 0 if they are negativem and x==y if it not, then output also 30 features to the next linear layer, which will do the sam computaion as the first and output the results\n\nIn pythorch there’s a modul that fit our neural nets here: nn.Sequential().\n\ntake results from a layer to another\n\nwe also replace the linear function we built by nn.Linear and max((0.0)) with nn.ReLU()\n\n\nsimple_net = nn.Sequential(\n    nn.Linear(28*28,30),\n    nn.ReLU(),\n    nn.Linear(30,1)\n)\n\n\n#lets try the model again but now with 2 layers\nlearn = Learner(dls, simple_net, opt_func=SGD,\n                loss_func=mnist_loss, metrics=batch_accuracy)\n\n\nlearn.fit(40, 0.1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\nbatch_accuracy\ntime\n\n\n\n\n0\n0.333021\n0.396112\n0.512267\n00:00\n\n\n1\n0.152461\n0.235238\n0.797350\n00:00\n\n\n2\n0.083573\n0.117471\n0.911678\n00:00\n\n\n3\n0.054309\n0.078720\n0.940628\n00:00\n\n\n4\n0.040829\n0.061228\n0.956330\n00:00\n\n\n5\n0.034006\n0.051490\n0.963690\n00:00\n\n\n6\n0.030123\n0.045381\n0.966634\n00:00\n\n\n7\n0.027619\n0.041218\n0.968106\n00:00\n\n\n8\n0.025825\n0.038200\n0.969087\n00:00\n\n\n9\n0.024441\n0.035901\n0.969578\n00:00\n\n\n10\n0.023321\n0.034082\n0.971541\n00:00\n\n\n11\n0.022387\n0.032598\n0.972031\n00:00\n\n\n12\n0.021592\n0.031353\n0.974485\n00:00\n\n\n13\n0.020904\n0.030284\n0.975466\n00:00\n\n\n14\n0.020300\n0.029352\n0.975466\n00:00\n\n\n15\n0.019766\n0.028526\n0.975466\n00:00\n\n\n16\n0.019288\n0.027788\n0.976448\n00:00\n\n\n17\n0.018857\n0.027124\n0.977429\n00:00\n\n\n18\n0.018465\n0.026523\n0.978410\n00:00\n\n\n19\n0.018107\n0.025977\n0.978901\n00:00\n\n\n20\n0.017777\n0.025479\n0.978901\n00:00\n\n\n21\n0.017473\n0.025022\n0.979392\n00:00\n\n\n22\n0.017191\n0.024601\n0.980373\n00:00\n\n\n23\n0.016927\n0.024213\n0.980373\n00:00\n\n\n24\n0.016680\n0.023855\n0.981354\n00:00\n\n\n25\n0.016449\n0.023521\n0.981354\n00:00\n\n\n26\n0.016230\n0.023211\n0.981354\n00:00\n\n\n27\n0.016023\n0.022922\n0.981354\n00:00\n\n\n28\n0.015827\n0.022653\n0.981845\n00:00\n\n\n29\n0.015641\n0.022401\n0.981845\n00:00\n\n\n30\n0.015463\n0.022165\n0.981845\n00:00\n\n\n31\n0.015294\n0.021944\n0.983317\n00:00\n\n\n32\n0.015132\n0.021736\n0.982826\n00:00\n\n\n33\n0.014977\n0.021541\n0.982826\n00:00\n\n\n34\n0.014828\n0.021357\n0.982336\n00:00\n\n\n35\n0.014686\n0.021184\n0.982336\n00:00\n\n\n36\n0.014549\n0.021019\n0.982336\n00:00\n\n\n37\n0.014417\n0.020864\n0.982336\n00:00\n\n\n38\n0.014290\n0.020716\n0.982336\n00:00\n\n\n39\n0.014168\n0.020576\n0.982336\n00:00\n\n\n\n\n\n\nAt this point we did everything we can to improve the model performane, and we got an accuracy of 982826, which is very solid number.\nfrom here on, all we can do is looking inside our model and understand the mechanic of it in each steps\n\n\n# we can see the architecture of the model\nm =learn.model\n\n\nAs expected the model architecture contains 2 layers and a non-linear function in-between.\n\n\nm\n\nSequential(\n  (0): Linear(in_features=784, out_features=30, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=30, out_features=1, bias=True)\n)\n\n\n\nWe could also see what did the model learn in each layer\n\n\nw, b= m[0].parameters()\n\n\nshow_image(w[22].view(28,28))"
  },
  {
    "objectID": "posts/Build a Large Language Model/Chapter-3/Chapter_3.html",
    "href": "posts/Build a Large Language Model/Chapter-3/Chapter_3.html",
    "title": "Chapter 3: Build a Large Language Model",
    "section": "",
    "text": "About This Chapter:\n\nUp to this point we learn how to:\n\nprepare the input text for training LLMs\nsplitting text into individual word and subword tokens\nencode tokens into vector representations, embeddings, for the LLM\n\nIn this chapter we will:\n\nbuild the most important part in the LLM architecture: The Self-Attention Mechanism\nimplement four different variants of attention mechanisms:\n\nSimplified self-attention\nSelf-attention\nCausal attention\nMulti-head attention\n\n\n\n\nThe problem with modeling long sequences\n\nWhat are encoder-decoder RNNs?\nAn encoder-decoder Recurrent Neural Network (RNN) is a sequence-to-sequence model often used in tasks like machine translation. how it works?: * Encoder: Processes the input sequence step-by-step and summarizes it into a single vector, called the context vector or hidden state. * Decoder: Takes this context vector and generates the output sequence step-by-step.\n\n\nThe limitation\n\nContext Compression:\n\nDuring encoding, the RNN compresses all the input information (e.g., the entire sentence) into a single context vector (hidden state) at the final step of the encoder.\nWhen the decoder starts generating the output, it relies entirely on this compressed context vector to predict the next token.\n\nLoss of Earlier Context:\n\nRNNs process sequences in a step-by-step manner, and the hidden state at each step only captures information from previous steps.\nBy the end of the input sequence, earlier hidden states (e.g., for the first few words) are “forgotten” or diluted because the RNN doesn’t store them explicitly.\n\nLong-Range Dependencies:\n\nSome tasks, like translating long sentences, require retaining and using information from far back in the input sequence.\nFor example, translating a complex sentence with long dependencies (like pronouns referring to subjects introduced many words earlier) becomes difficult because this information is not directly accessible to the decoder.\n\n\n\n\nWhy does this happen?\nRNNs process sequences in a linear manner, and their hidden states update iteratively. This means: - Each new hidden state overwrites the previous one with a combination of old and new information. - The longer the sequence, the harder it is to retain the critical details from the beginning.\n\n\nPractical example\nImagine translating the sentence: &gt; “The scientist who discovered penicillin was awarded the Nobel Prize.”\nThe decoder needs to keep track of “The scientist” while processing the information about “penicillin” and “the Nobel Prize.” In an encoder-decoder RNN: - By the time the encoder reaches “Nobel Prize,” the representation of “The scientist” might have been diluted, leading to errors in translation.\n\n\n\nCapturing data dependencies with attention mechanisms\n\nAttention Mechanism:\n\nInstead of relying solely on the final hidden state, the attention mechanism allows the decoder to look back at all the encoder’s hidden states dynamically.\nThis makes it easier to focus on specific parts of the input sequence that are relevant to the current decoding step.\n\nTransformers:\n\nTransformers, like those used in models such as BERT and GPT, completely avoid RNNs. They process sequences in parallel and allow direct access to all positions in the input sequence through self-attention.\n\n\n\n\nAttending to different parts of the input with self-attention\n\nIn self-attention, “self” refers to the idea that each element in a sequence (e.g., a word in a sentence) attends to all other elements in the same sequence, including itself. This mechanism allows the model to weigh the importance of other elements when understanding the context of a given element.\nFor example:\n\nIn the sentence “The cat sat on the mat”, the word “cat” can attend to itself (self) and to other words in the sentence to understand its role or meaning in context.\n\nThis “self” aspect ensures that every part of the input can contribute to understanding every other part, leading to a richer representation of the sequence as a whole.\n\n\n\nA simple self-attention mechanism without trainable weights\n\nFirst we need to design a system that capture the the idea of self-attention before adding complex elements like trainable weights.\nLet’s consider this illustration: \nHere we have an input vecor that consist of token embedding, each token represent a word in a sentence, and denoted with: \\(x\\) consisting \\(T\\) elements, from \\(x^{(1)}\\) to \\(x^{(T)}\\).\nSo each word in the sentence “Your journey starts with one step.” represent an \\(x^{(i)}\\) where \\(i\\) is an element of the sequence \\(x\\).\nEach input token is represented as 3-dimensionl embeddong vector.\nThe goal during the self-attention process is to calculate the Context Vector \\(z\\)\nThe context vector captures the relevant information from the entire sequence for a particular element, based on the attention mechanism. It allows the model to encode dependencies and relationships across the input sequence effectively.\nFor example, in a sentence:\nThe word “Journey” which is processed in this case \\(z^{(2)}\\) in “Your journey starts with one step” would have a context vector that emphasizes information related to all other input words helping to clarify meaning and relations among words."
  },
  {
    "objectID": "posts/Build a Large Language Model/Chapter-1/Build_A_Large_Language_Model_Chapter_1_.html",
    "href": "posts/Build a Large Language Model/Chapter-1/Build_A_Large_Language_Model_Chapter_1_.html",
    "title": "Chapter 1: Build a Large Language Model",
    "section": "",
    "text": "Introduction:\n  \n  Structure of the Book:\n  \n  What’s an LLM:\n  Stages of building and using LLMs:\n  Introducing the Transformer architecture:\n  Utilizing large datasets:\n  A closer look at the GPT architecture:\n  Building a large language model:"
  },
  {
    "objectID": "posts/Build a Large Language Model/Chapter-1/Build_A_Large_Language_Model_Chapter_1_.html#structure-of-the-book",
    "href": "posts/Build a Large Language Model/Chapter-1/Build_A_Large_Language_Model_Chapter_1_.html#structure-of-the-book",
    "title": "Chapter 1: Build a Large Language Model",
    "section": "Structure of the Book:",
    "text": "Structure of the Book:\n\n\n├── chapters  \n│   ├── chapter1_understanding_LLMs: high-level introduction to the fundamental concepts behind LLMs.  \n│   ├── chapter2_text_data: It covers the process ofpreparing text for LLM training, including splitting text into word and subword tokens.  \n│   ├── chapter3_attention_mechanisms:  It introduces a basicself-attention framework and progresses to an enhanced self-attention mechanism.  \n│   ├── chapter4_GPT_model: focuses on coding a GPT-like LLM that can be trained to generatehuman-like text.  \n│   ├── chapter5_pretraining: implements the pretraining process of LLMs.  \n│   ├── chapter6_text_classification:  introduces different LLM fine-tuning approaches.  \n│   ├── chapter7_instruction_following:  explores the instruction fine-tuning process of LLMs.  \n└──  \n\nThe aim of this chapter is to introduce the foundational concepts of large language models (LLMs) and the advancements in deep learning that made them possible\n\nthis chapter doesn’t contain any code.\n\nLarge language models (LLMs), like OpenAI’s ChatGPT, are deep neural networks that revolutionized natural language processing (NLP) in recent years.\nTraditional NLP methods excelled in tasks like spam classification and simple pattern recognition but struggled with complex tasks requiring advanced understanding and generation abilities.\nContemporary LLMs can handle sophisticated language tasks, such as writing an email from keywords, which was challenging for earlier models.\nWhen we say language models “understand,” we mean they can produce text that seems coherent and contextually appropriate, not that they have human-like awareness or true comprehension.\nThe transformer architecture and large datasets have driven the shift in NLP, enabling more advanced language understanding and interaction.\n\n\nWhat’s an LLM:\n\nLLM’s are neural network designed to understand and produce huma-like text.\nLarge in LLM refer to the size of the datasets those model trained on, but also on the size of parameters ( 100’s of billions)\n\nParameters are adjusted weights during training to predict next word in sentence.\n\nThe architecture of an LLM is called transformers which apply the attention mechanism to different parts of the input while performing the next word prediction. ### Applications of LLM’s:\nLLM’s can be used in many contexts to perform different tasks:\n\nmachine translation\nsentiments analysis\ntext generation\n..\n\n\n\n\nStages of building and using LLMs:\n\nBuilding LLM form scratch allow us to understand the mechanics and limitations of language models, and provide us with skills set required for pretraining or fine-tuning phase.\nCustom-built LLM outperform general purpose one.\n\nMany companies prefer to build their own domain-specific llm to keep their private data in-home and not share it with third party.\ndeveloping small lm open the door for deployment on devices like laptops or even mobiles rather than huge servers.\n\ncreating LLM is a process where pre-training and fine-tuning takes place.\n\npre indicates that it is the first phase, model is trained on huge chunk of data where it learns basic knowledge and broad pattern of the language.\nthe fine-tuning phase is where the model get further training but on very specific task and get its knowledge narrowed.\n\nFine-tuning can be devised in 2 category:\n\nInstruction fine-tuning: where the model get trained one pair of instruction =&gt; output dataset.\nWhere classification tuning the data consist of text and associated class label.\n\n\n\n\nIntroducing the Transformer architecture:\n\nAll modern LLM rely on Transformer architecture which was presented for the first time in this famous paper: Attention is all you need.\nTransformer consist of two submodal: 1-encoder and 2-decoder. - encoder module process the input text into some numerical representation that capture meaning.\n- decoder uses the numerical values and generate text\n\nthe key component of the transformer architecture is attention mechanism, we will talk about it later.\nTransformer Variants:\n- Models like BERT and GPT are based on the original transformer architecture but adapt it for different tasks.\n- BERT’s Training Strategy: BERT uses a masked word prediction approach, where it predicts missing words in a sentence, making it suitable for tasks like text classification and sentiment analysis.\n- GPT vs. BERT: GPT is designed for generative tasks, whereas BERT excels in tasks requiring understanding of context, like sentiment prediction and document categorization.\n- BERT’s Real-world Application: Platforms like X (formerly Twitter) use BERT for tasks such as detecting toxic content.\nGPT Focus: GPT utilizes the Decoder portion of the transformer architecture and is designed for text generation tasks.\nZero-shot and Few-shot Learning: GPT models excel in zero-shot learning, meaning they can handle tasks without specific prior examples. They also perform well in few-shot learning, where they learn from a small number of provided examples.\nVersatility: While GPT models are optimized for text completion, they exhibit broad adaptability and can tackle a wide range of tasks, showcasing their flexibility in natural language processing.\n\n\n\nUtilizing large datasets:\n\nDiverse Training Data: Large datasets used for training GPT- and BERT-like models contain billions of words, covering a broad range of topics and languages (both natural and programming).\nComprehensive Corpus: These datasets are designed to ensure comprehensive exposure to diverse linguistic and contextual patterns.\n\n\n\nA closer look at the GPT architecture:\n\nGPT Origin: GPT was introduced in the paper Improving Language Understanding by Generative Pre-Training by Radford et al. from OpenAI.\nGPT-3: A scaled-up version of the original GPT with more parameters and a larger training dataset.\nChatGPT’s Base Model: The initial ChatGPT model was derived by fine-tuning GPT-3 on a large instruction dataset, using methods from OpenAI’s InstructGPT paper.\nModel Versatility: Despite being trained on a simple next-word prediction task, GPT models excel in various tasks like text completion, spelling correction, classification, and language translation.\nSelf-Supervised Learning: The next-word prediction task is a type of self-supervised learning, where the model uses the structure of the data itself for training.\nLabel Creation: Labels are generated dynamically, with the next word in a sentence or document serving as the prediction target.\nTraining on Massive Datasets: This approach enables the use of large, unlabeled text datasets for training, as explicit labeling of data is unnecessary.\n\n\n\nBuilding a large language model:\n\nNow we understand the basic theory behind LLM and how they were introduced, its time to build them from scratch.\n\n &gt;Source: Book: Build A Large Language Model by Sebastian Raschka"
  },
  {
    "objectID": "posts/Fastai_ch6/Questionnaire.html",
    "href": "posts/Fastai_ch6/Questionnaire.html",
    "title": "Chapter 6: Questionnaire",
    "section": "",
    "text": "Q1:\nHow could multi-label classification improve the usability of the bear classifier?\nMulti-label classfication gives the models in production the ability to return 0 prediction if the user inputs an image that doesn't contains any of the classes we trained the model to predict. In the case of bear classification inference, if we upload an image that doesn't contains any bear, our model still predict  a class.\nQ2:\nHow do we encode the dependent variable in a multi-label classification problem?\nIn multi-label classification we use One-Hot encoders, which is represented as an list with zeros and ones, where one(s) represent the label of that particular image.\nQ3:\nHow do you access the rows and columns of a DataFrame as if it was a matrix?\nWe could use .iloc or loc to access any row or colum of a DataFrame\nQ4:\nHow do you get a column by name from a DataFrame?\n\nimport pandas as pd\n\n\ndic = {'col1':[1, 2, 3], 'col2':[4, 5, 6]}\n\n\ndf =  pd.DataFrame(dic)\ndf\n\n\n\n\n\n\n\n\ncol1\ncol2\n\n\n\n\n0\n1\n4\n\n\n1\n2\n5\n\n\n2\n3\n6\n\n\n\n\n\n\n\n\n# access column by name:\ndf.col1\n\n0    1\n1    2\n2    3\nName: col1, dtype: int64\n\n\n\n# or this way\ndf['col2']\n\n0    4\n1    5\n2    6\nName: col2, dtype: int64\n\n\nQ5:\nWhat is the difference between a Dataset and DataLoader?\nDataset could be any collection the return a tuple with dependent and independent variables when we index to it (DataFrame in our case)\nDataLoader is an iterator that provide the stream of mini batch, shuffling the datapoints..\nQ6:\nWhat does a Datasets object normally contain?\nDatasets objects contains Training Dataset and Validation Dataset\nQ7:\nWhat does a DataLoaders object normally contain?\nDataloaders contains training DataLoader and Validation DataLoader\nQ8:\nWhat does lambda do in Python?\nIt provides a shortcut for declaring small anonymous functions\nQ9:\nWhat are the methods to customize how the independent and dependent variables are created with the data block API?\nWe could use functions to customize how to define the independent and dependent variable, then assign these functions to get_x and get_y \nQ10:\nWhy is softmax not an appropriate output activation function when using a one hot encoded target?\nSoftmax pushes the model to pick one class among others, while when using one-hot encoding with multi-label classification we have more the one class per image.\nQ12:\nWhat is the difference between nn.BCELoss and nn.BCEWithLogitsLoss?\nnn.BCELoss has no sigmoid while nn.BCEWithLogitsLoss includes sigmoid in it.\nQ13:\nWhen is it okay to tune a hyperparameter on the validation set?\nWhen the results seems to have a smooth curve, what indicates the results change  based on changes to the hyper-parameters.\nQ14:\nHow is y_range implemented in fastai?\nfunction define the range of our targets. In fastai this function is implemented using the `sigmoid_range`\nQ16:\nWhat is a regression problem? What loss function should you use for such a problem?\nRegression problem is where we have to predict a continous value.\nUsually in this kind of problem the mean squared error is used\nQ17:\nWhat do you need to do to make sure the fastai library applies the same data augmentation to your input images and your target point coordinates?\nThe PointBlock class needs to be passed to the blocks parameter."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ismail TG",
    "section": "",
    "text": "I’m a former philosophy teacher turned machine learning engineer, learning in public and documenting my journey into deep learning, CUDA programming, and AI systems.\nCurrently focusing on: CUDA kernel engineering and low-level ML optimization."
  },
  {
    "objectID": "index.html#welcome",
    "href": "index.html#welcome",
    "title": "Ismail TG",
    "section": "",
    "text": "I’m a former philosophy teacher turned machine learning engineer, learning in public and documenting my journey into deep learning, CUDA programming, and AI systems.\nCurrently focusing on: CUDA kernel engineering and low-level ML optimization."
  },
  {
    "objectID": "index.html#featured-project",
    "href": "index.html#featured-project",
    "title": "Ismail TG",
    "section": "Featured Project",
    "text": "Featured Project\n\n🎬 Manim Code Generation with LLMs\nFine-tuned a small language model on the Manim dataset using instruction tuning to generate executable mathematical animation code from natural language prompts.\nTech: LLM Fine-tuning, Instruction Tuning, Code Generation\nView Project →"
  },
  {
    "objectID": "index.html#learning-journey",
    "href": "index.html#learning-journey",
    "title": "Ismail TG",
    "section": "Learning Journey",
    "text": "Learning Journey\nI’m documenting my learning process as I dive deep into:\n\nCUDA C++ - Writing efficient GPU kernels from scratch\nDeep Learning Fundamentals - fast.ai course and PyTorch internals\nTransformers & NLP - Hugging Face ecosystem\nBuilding LLMs - Following Sebastian Raschka’s book\n\nYou can follow along in my Blog where I share notes, experiments, and insights."
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "Ismail TG",
    "section": "Background",
    "text": "Background\n\n✅ Completed fast.ai Deep Learning course\n✅ Completed Hugging Face Transformers course\n\n✅ Read “Build a Large Language Model from Scratch” by Sebastian Raschka\n🔄 Currently learning CUDA kernel engineering\n\nI previously taught philosophy but lost my job during the pandemic. Now I’m carving out a niche in low-level ML systems programming - a less crowded space where deep understanding matters more than quick fine-tuning."
  },
  {
    "objectID": "index.html#connect",
    "href": "index.html#connect",
    "title": "Ismail TG",
    "section": "Connect",
    "text": "Connect\n\n🐦 Twitter/X\n💻 GitHub\n\n\nLearning in public. One kernel at a time."
  },
  {
    "objectID": "posts/HuggingFace_4/Hugging_Face_course_Notes_Chapter4.html",
    "href": "posts/HuggingFace_4/Hugging_Face_course_Notes_Chapter4.html",
    "title": "Hugging Face Course Notes: Chapter4",
    "section": "",
    "text": "The hugging Face Hub is the place where every Model, Dataset is deployed and stored.\nIn this chapter we will focus on how to:\n\nUse a fine-tuned model from the Hub\nShare and deploy a our model to the Hub\nBuild a model card\n\nAt its core a shared model is just a Git reposetory, which means that it can be cloned and used by others.\nWhen a new model is shared to the community a hosted inference API is deployed automatically, so anyone can test that model directly or build on top of it.\n\n\n\n\n\nAs we saw in previous chapters, using finetuned models from the Hub on our tasks is easy and can be achieved with few lines of code\n\n\nfrom transformers import pipeline\nunmasker = pipeline(\"fill-mask\", model = 'camembert-base')\nunmasker(\"This course will teach you all about &lt;mask&gt; models.\", top_k=2)\n\n/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \nThe secret `HF_TOKEN` does not exist in your Colab secrets.\nTo authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\nYou will be able to reuse this secret in all of your notebooks.\nPlease note that authentication is recommended but still optional to access public models or datasets.\n  warnings.warn(\n\n\n\n\n\n\n\n\nSome weights of the model checkpoint at camembert-base were not used when initializing CamembertForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n\n\n\n\n\n\n\n\n\n\n\n[{'score': 0.1466376781463623,\n  'token': 808,\n  'token_str': 'the',\n  'sequence': 'This course will teach you all about the models.'},\n {'score': 0.06081351637840271,\n  'token': 9098,\n  'token_str': 'this',\n  'sequence': 'This course will teach you all about this models.'}]\n\n\n\nOf course we need to pick a checkpoint that suitable for our task, otherwise we will get results that don’t male sense at all.\n\nin this case we pick camembert-base which is a good checkpoint for filling mask tasks.\n\nWe could also insentiate the checkpoint from the model calss directly:\n\n\nfrom transformers import CamembertTokenizer, CamembertForMaskedLM\nckpt = 'camembert-base'\ntokenizer = CamembertTokenizer.from_pretrained(ckpt)\nmodel = CamembertForMaskedLM.from_pretrained(ckpt)\n\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSome weights of the model checkpoint at camembert-base were not used when initializing CamembertForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n\n\n\nHowever its recommended to use the auto class to handel the insentitating of model and tokenizers:\n\n\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\ntokenizer = AutoTokenizer.from_pretrained(ckpt)\nmodel = AutoModelForMaskedLM.from_pretrained(ckpt)\n\nSome weights of the model checkpoint at camembert-base were not used when initializing CamembertForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n\n\n\nWhat’s important is to inderstand how that specific model is trained, which dataset is used, and what’s its limitations and biases.\n\nall of this informastions should be mentioned in the model card (which we will build later)\n\n\n\n\n\n\nIn general there’s 3 ways to create a new model reposetories:\n\nUsing the push_to_hub API\nUsing the huggingface_hub Python library\nUsing the web interface\n\nOne the repo is created, we can add and edit files just like any other repo on github\n\n\n\n\nThe simplest way to create a model repo is to use push_to_hub API.\n\nbut first we need to get our credentials in order to use the API:\n\n\n\nfrom huggingface_hub import notebook_login\nnotebook_login()\n\n\n\n\n\nWe used earlier the TrainingArguments class to pass hyper-parameters during the building of the training loop, the easiest way to push a model is by setting push_to_hub= True as an arguments:\n\n\nfrom transformers import Trainer, TrainingArguments\ntraining_arguments = TrainingArguments('test-train-0', save_strategy = 'epoch', push_to_hub= True)\n\n\nOnce the model is trained and the trainer.train() is called, the api will upload the model to the hub and save it in a repo with the name we pick test-train-0, but we can chose another name by passing hub_model_id=\"my_model_name\"\nOnce the training is complete we should do the final trainer_push_to_hub() to upload the last version of the model. This will also generate the model card, which contains all the metadata, hyperparameters and evaluation results.\n\n\n\n\nmodel card From Hugging Face\n\n\n\nThe push_to_hub() method can be applied on model, tokenizer, configs. It take care of both: creating the repo and pushing the model and tokenizer directly to that repository.\nNow let’s see exactly how this work:\n\n\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\nckpt = 'bert-base-uncased'\ntokenizer = AutoTokenizer.from_pretrained(ckpt)\nmodel = AutoModelForMaskedLM.from_pretrained(ckpt)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n\n\n\nNow we can take these model and build whatever we want with them, modify, add..and when we are satisfied with the results we can use push_to_hup() method:\n\n\nmodel.push_to_hub('test-ch4')\n\n\n\n\nCommitInfo(commit_url='https://huggingface.co/Smail/test-ch4/commit/2f5a775ac7e24540a43374fa820db4e225b195e2', commit_message='Upload BertForMaskedLM', commit_description='', oid='2f5a775ac7e24540a43374fa820db4e225b195e2', pr_url=None, pr_revision=None, pr_num=None)\n\n\n\nThis will create a new repo \"test-ch4\" in our profile and populate it with model files. We can do the same with tokenizer\n\n\ntokenizer.push_to_hub('test-ch4')\n\n\n\n\nCommitInfo(commit_url='https://huggingface.co/Smail/test-ch4/commit/e0b505500d75768b52d549adc8f67c3f40b015dd', commit_message='Upload tokenizer', commit_description='', oid='e0b505500d75768b52d549adc8f67c3f40b015dd', pr_url=None, pr_revision=None, pr_num=None)\n\n\n\nwe can also add the organization, tokenization key and other arguments that can be specified while pushing the model into the hub through API\n\n\n\n\n\nWe can also use the Huggingface_hub library that offer more tools that are simple and very effective to achieve various tasks such as pushing a model, adding files, deleting files, creating repos, editing, managing, getting informations etc.. *Similar to push_to_hub() method the package requires a key token to access the hub:\n\n\n!huggingface-cli login\n\n\n    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n\n    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n    Setting a new token will erase the existing one.\n    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\nToken: \nAdd token as git credential? (Y/n) n\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n\n\n\n!huggingface-cli whoami\n\nSmail\n\n\n\nThe huggingface_hub offers several methods and classes which are useful for our purpose. Firstly, there are a few methods to manage repository creation, deletion, and others:\n\n\nfrom huggingface_hub import (\n    #User Management\n    login,\n    logout,\n    whoami,\n\n    # Repo creation and management\n    create_repo,\n    delete_repo,\n    update_repo_visibility,\n\n    # And some methods to retrieve/change information about the content\n    list_models,\n    list_datasets,\n    list_metrics,\n    list_repo_files,\n    upload_file,\n    delete_file,\n\n)\n\n\nWe could for example try to create a repo like this:\n\n\ncreate_repo('dummi_repo')\n\nRepoUrl('https://huggingface.co/Smail/dummi_repo', endpoint='https://huggingface.co', repo_type='model', repo_id='Smail/dummi_repo')\n\n\n\nOther arguments which may be useful are:\n\nprivate, in order to specify if the repository should be visible from others or not.\ntoken, if you would like to override the token stored in your cache by a given token.\nrepo_type, if you would like to create a dataset or a space instead of a model. Accepted values are “dataset” and “space”.\n\n\nOnce the repository is created, we should add files to it! Jump to the next section to see the three ways this can be handled\n\n\n\n\nThe system to manage files on the Hugging Face Hub is based on git for regular files, and git-lfs (which stands for Git Large File Storage) for larger files.\nIn general there is 3 ways to upload files to the HUB:\n\n\n\n\n\nthis approach doesn’t require installing git or git-lf on our system, it uses HTTP POST requests to push the files directly to the hub.\nIt’s limitation is the size of the file shouldn’t be larger than 5 GB.\nSince I work in a google colab, I will create a folder and work with it “locally”.\n\n\n!mkdir my_folder\nfrom transformers import AutoModelForMaskedLM, AutoTokenizer\n\ncheckpoint = \"camembert-base\"\n\nmodel = AutoModelForMaskedLM.from_pretrained(checkpoint)\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n# Do whatever with the model, train it, fine-tune it...\n\nmodel.save_pretrained(\"/content/my_folder\")\ntokenizer.save_pretrained(\"/content/my_folder\")\n\nSome weights of the model checkpoint at camembert-base were not used when initializing CamembertForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n\n\n('/content/my_folder/tokenizer_config.json',\n '/content/my_folder/special_tokens_map.json',\n '/content/my_folder/sentencepiece.bpe.model',\n '/content/my_folder/added_tokens.json',\n '/content/my_folder/tokenizer.json')\n\n\n\nfrom huggingface_hub import upload_file\nupload_file(\n    path_or_fileobj=\"/content/my_folder/config.json\",\n    path_in_repo=\"config.json\",\n    repo_id=\"Smail/dummi_repo\",\n)\n\nCommitInfo(commit_url='https://huggingface.co/Smail/dummi_repo/commit/1af5f861f0e0a3398d3856c69ff83bd5f04c372a', commit_message='Upload config.json with huggingface_hub', commit_description='', oid='1af5f861f0e0a3398d3856c69ff83bd5f04c372a', pr_url=None, pr_revision=None, pr_num=None)\n\n\n\nThis will upload the config.json file exists in path_to_file to the root of the repo as config.json.\n\n\n\n\n\nThe repository class abstract a local repo and handle all the work in agit like manner, it requires having git and git-lf installed in our system.\n\n\n!pip install git-LFS\n\nCollecting git-LFS\n  Downloading git_lfs-1.6-py2.py3-none-any.whl (5.6 kB)\nInstalling collected packages: git-LFS\nSuccessfully installed git-LFS-1.6\n\n\n\n!git lfs install\n\nGit LFS initialized.\n\n\n\nfrom huggingface_hub import Repository\n\nrepo = Repository('/content', clone_from= 'Smail/dummi_repo')\n\n\nThis will create a folder in the path we decide and will import all the files in the repo from the hub.\nSince we didn’t create any files in that repo when we insantiate it, the only file we have is .gitattributes, from here we could deal with that repo as if it a git repo:\n\n\nrepo.git_pull()\nrepo.git_add()\nrepo.git_commit()\nrepo.git_push()\nrepo.git_tag()\n\n\nFirst we have to make the repo up-to-date with:\n\n\nrepo.git_pull()\n\n\nWe can now save the model and tokenizer in the directotry\n\n\nmodel.save_pretrained('my_folder')\ntokenizer.save_pretrained('my_folder')\n\n\nNow our local folder countains 2 new files and we could push them to the hub:\n\n\nrepo.git_add()\nrepo.git_commit('add model and tokenizer')\nrepo.git_push()\n\n\n\n\n\nThis method is very similar to the one before, its barbone method that in pure git and bash.\nFirst let’s install git and git-lf:\n\n\n!pip install git-LFS\n\nRequirement already satisfied: git-LFS in /usr/local/lib/python3.10/dist-packages (1.6)\n\n\n\nAnd the initialize git and lfs\n\n\n!git lfs install\n\nUpdated git hooks.\nGit LFS initialized.\n\n\n\nNow we can clone the repo from the hub the normal way:\n\n\n!git clone https://huggingface.co/Smail/test-model-2\n\nCloning into 'test-model-2'...\nremote: Enumerating objects: 4, done.\nremote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 4\nUnpacking objects:  25% (1/4)Unpacking objects:  50% (2/4)Unpacking objects:  75% (3/4)Unpacking objects: 100% (4/4)Unpacking objects: 100% (4/4), 1.12 KiB | 1.12 MiB/s, done.\n\n\n\nSince we are using bash, we could naigate the directory like this:\n\n\n!cd test-model-2 && ls\n\nREADME.md\n\n\n\nThis will chnage the directory the repo we just cloned, and print all the files in it.\nNow we can build a model like we did before and save all the files in the repo we cloned and push them to the hub:\n\n\nfrom transformers import AutoModelForMaskedLM, AutoTokenizer\n\ncheckpoint = \"camembert-base\"\n\nmodel = AutoModelForMaskedLM.from_pretrained(checkpoint)\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n# Do whatever with the model, train it, fine-tune it...\n\nmodel.save_pretrained(\"/content/test-model-2\")\ntokenizer.save_pretrained(\"/content/test-model-2\")\n\nSome weights of the model checkpoint at camembert-base were not used when initializing CamembertForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n\n\n('/content/test-model-2/tokenizer_config.json',\n '/content/test-model-2/special_tokens_map.json',\n '/content/test-model-2/sentencepiece.bpe.model',\n '/content/test-model-2/added_tokens.json',\n '/content/test-model-2/tokenizer.json')\n\n\n\n!ls\n\nmy_folder  sample_data  test-model-2\n\n\n\n!cd test-model-2 && ls\n\nadded_tokens.json  model.safetensors  sentencepiece.bpe.model  tokenizer_config.json\nconfig.json    README.md          special_tokens_map.json  tokenizer.json\n\n\n\nNow that we’ve saved some model and tokenizer artifacts, let’s take another look at the folder:\n\nIf you look at the file sizes (for example, with ls -lh), you should see that the model state dict file (pytorch_model.bin) is the only outlier, at more than 400 MB.\nWe can now go ahead and proceed like we would usually do with traditional Git repositories. We can add all the files to Git’s staging environment using the git add command:\n\n!cd test-model-2 && git add .\n\n\n!cd test-model-2 && git status\n\n\nOn branch main\n\nYour branch is up to date with 'origin/main'.\n\n\n\nChanges to be committed:\n\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n\n    new file:   added_tokens.json\n\n    new file:   config.json\n\n    new file:   model.safetensors\n\n    new file:   sentencepiece.bpe.model\n\n    new file:   special_tokens_map.json\n\n    new file:   tokenizer.json\n\n    new file:   tokenizer_config.json\n\n\n\n\n\n\n\nSimilarly, we can make sure that git-lfs is tracking the correct files by using its status command:\n\n\n!cd test-model-2 && git lfs status\n\nOn branch main\nObjects to be pushed to origin/main:\n\n\nObjects to be committed:\n\n    added_tokens.json (Git: 43734cd)\n    config.json (Git: 4b8db4b)\n    model.safetensors (LFS: 2785d2e)\n    sentencepiece.bpe.model (LFS: 988bc5a)\n    special_tokens_map.json (Git: b547935)\n    tokenizer.json (Git: 9a9362e)\n    tokenizer_config.json (Git: c49982e)\n\nObjects not staged for commit:\n\n\n\n\n\nWe can see that all files have Git as a handler, except pytorch_model.bin and sentencepiece.bpe.model, which have LFS. Great!\nLet’s proceed to the final steps, committing and pushing to the huggingface.co remote repository:\n\n\n!cd test-model-2 && git commit -m \"First model version\"\n\n[main adaa023] First model version\n 7 files changed, 128351 insertions(+)\n create mode 100644 added_tokens.json\n create mode 100644 config.json\n create mode 100644 model.safetensors\n create mode 100644 sentencepiece.bpe.model\n create mode 100644 special_tokens_map.json\n create mode 100644 tokenizer.json\n create mode 100644 tokenizer_config.json\n\n\n*Pushing can take a bit of time, depending on the speed of your internet connection and the size of your files:\n\n!cd test-model-2 && git push\n\nEnumerating objects: 10, done.\nCounting objects: 100% (10/10), done.\nDelta compression using up to 2 threads\nCompressing objects: 100% (8/8), done.\nWriting objects: 100% (9/9), 592.06 KiB | 5.10 MiB/s, done.\nTotal 9 (delta 0), reused 0 (delta 0), pack-reused 0\nTo https://huggingface.co/Smail/test-model-2\n   6266b40..adaa023  main -&gt; main\n\n\n\n\n\n\n\nModel card plays a crucial role in open source model, it allow others to build an idea about the important element of the model without spending time and effort, it ensures reusability and reproducibility of the results.\nBy documenting the training and evaluation process we hepl other understand what they expect from the model, its limitations and capabilities, also we have to provide enough iformations about the data we train the model and how it was preprocessed.\nThe model card usually starts with a very brief, high-level overview of what the model is for, followed by additional details in the following sections:\n\nModel description\nIntended uses & limitations\nHow to use\nLimitations and bias\nTraining data\nTraining procedure\nEvaluation results\n\n\n\n\n\nThe model description provides basic details about the model. This includes the architecture, version, if it was introduced in a paper, if an original implementation is available, the author, and general information about the model. Any copyright should be attributed here. General information about training procedures, parameters, and important disclaimers can also be mentioned in this section.\n\n\n\n\n\nHere you describe the use cases the model is intended for, including the languages, fields, and domains where it can be applied. This section of the model card can also document areas that are known to be out of scope for the model, or where it is likely to perform suboptimally.\n\n\n\n\n\nThis section should include some examples of how to use the model. This can showcase usage of the pipeline() function, usage of the model and tokenizer classes, and any other code you think might be helpful.\n\n\n\n\n\nThis part should indicate which dataset(s) the model was trained on. A brief description of the dataset(s) is also welcome.\n\n\n\n\n\nIn this section you should describe all the relevant aspects of training that are useful from a reproducibility perspective. This includes any preprocessing and postprocessing that were done on the data, as well as details such as the number of epochs the model was trained for, the batch size, the learning rate, and so on.\n\n\n\n\n\nHere you should describe the metrics you use for evaluation, and the different factors you are mesuring. Mentioning which metric(s) were used, on which dataset and which dataset split, makes it easy to compare you model’s performance compared to that of other models. These should be informed by the previous sections, such as the intended users and use cases.\n\n\n\n\n\nFinally, provide an indication of how well the model performs on the evaluation dataset. If the model uses a decision threshold, either provide the decision threshold used in the evaluation, or provide details on evaluation at different thresholds for the intended uses."
  },
  {
    "objectID": "posts/HuggingFace_4/Hugging_Face_course_Notes_Chapter4.html#introduction",
    "href": "posts/HuggingFace_4/Hugging_Face_course_Notes_Chapter4.html#introduction",
    "title": "Hugging Face Course Notes: Chapter4",
    "section": "",
    "text": "The hugging Face Hub is the place where every Model, Dataset is deployed and stored.\nIn this chapter we will focus on how to:\n\nUse a fine-tuned model from the Hub\nShare and deploy a our model to the Hub\nBuild a model card\n\nAt its core a shared model is just a Git reposetory, which means that it can be cloned and used by others.\nWhen a new model is shared to the community a hosted inference API is deployed automatically, so anyone can test that model directly or build on top of it."
  },
  {
    "objectID": "posts/HuggingFace_4/Hugging_Face_course_Notes_Chapter4.html#using-pretrained-models",
    "href": "posts/HuggingFace_4/Hugging_Face_course_Notes_Chapter4.html#using-pretrained-models",
    "title": "Hugging Face Course Notes: Chapter4",
    "section": "",
    "text": "As we saw in previous chapters, using finetuned models from the Hub on our tasks is easy and can be achieved with few lines of code\n\n\nfrom transformers import pipeline\nunmasker = pipeline(\"fill-mask\", model = 'camembert-base')\nunmasker(\"This course will teach you all about &lt;mask&gt; models.\", top_k=2)\n\n/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \nThe secret `HF_TOKEN` does not exist in your Colab secrets.\nTo authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\nYou will be able to reuse this secret in all of your notebooks.\nPlease note that authentication is recommended but still optional to access public models or datasets.\n  warnings.warn(\n\n\n\n\n\n\n\n\nSome weights of the model checkpoint at camembert-base were not used when initializing CamembertForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n\n\n\n\n\n\n\n\n\n\n\n[{'score': 0.1466376781463623,\n  'token': 808,\n  'token_str': 'the',\n  'sequence': 'This course will teach you all about the models.'},\n {'score': 0.06081351637840271,\n  'token': 9098,\n  'token_str': 'this',\n  'sequence': 'This course will teach you all about this models.'}]\n\n\n\nOf course we need to pick a checkpoint that suitable for our task, otherwise we will get results that don’t male sense at all.\n\nin this case we pick camembert-base which is a good checkpoint for filling mask tasks.\n\nWe could also insentiate the checkpoint from the model calss directly:\n\n\nfrom transformers import CamembertTokenizer, CamembertForMaskedLM\nckpt = 'camembert-base'\ntokenizer = CamembertTokenizer.from_pretrained(ckpt)\nmodel = CamembertForMaskedLM.from_pretrained(ckpt)\n\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSome weights of the model checkpoint at camembert-base were not used when initializing CamembertForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n\n\n\nHowever its recommended to use the auto class to handel the insentitating of model and tokenizers:\n\n\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\ntokenizer = AutoTokenizer.from_pretrained(ckpt)\nmodel = AutoModelForMaskedLM.from_pretrained(ckpt)\n\nSome weights of the model checkpoint at camembert-base were not used when initializing CamembertForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n\n\n\nWhat’s important is to inderstand how that specific model is trained, which dataset is used, and what’s its limitations and biases.\n\nall of this informastions should be mentioned in the model card (which we will build later)"
  },
  {
    "objectID": "posts/HuggingFace_4/Hugging_Face_course_Notes_Chapter4.html#sharing-a-pretrained-model",
    "href": "posts/HuggingFace_4/Hugging_Face_course_Notes_Chapter4.html#sharing-a-pretrained-model",
    "title": "Hugging Face Course Notes: Chapter4",
    "section": "",
    "text": "In general there’s 3 ways to create a new model reposetories:\n\nUsing the push_to_hub API\nUsing the huggingface_hub Python library\nUsing the web interface\n\nOne the repo is created, we can add and edit files just like any other repo on github\n\n\n\n\nThe simplest way to create a model repo is to use push_to_hub API.\n\nbut first we need to get our credentials in order to use the API:\n\n\n\nfrom huggingface_hub import notebook_login\nnotebook_login()\n\n\n\n\n\nWe used earlier the TrainingArguments class to pass hyper-parameters during the building of the training loop, the easiest way to push a model is by setting push_to_hub= True as an arguments:\n\n\nfrom transformers import Trainer, TrainingArguments\ntraining_arguments = TrainingArguments('test-train-0', save_strategy = 'epoch', push_to_hub= True)\n\n\nOnce the model is trained and the trainer.train() is called, the api will upload the model to the hub and save it in a repo with the name we pick test-train-0, but we can chose another name by passing hub_model_id=\"my_model_name\"\nOnce the training is complete we should do the final trainer_push_to_hub() to upload the last version of the model. This will also generate the model card, which contains all the metadata, hyperparameters and evaluation results.\n\n\n\n\nmodel card From Hugging Face\n\n\n\nThe push_to_hub() method can be applied on model, tokenizer, configs. It take care of both: creating the repo and pushing the model and tokenizer directly to that repository.\nNow let’s see exactly how this work:\n\n\nfrom transformers import AutoTokenizer, AutoModelForMaskedLM\nckpt = 'bert-base-uncased'\ntokenizer = AutoTokenizer.from_pretrained(ckpt)\nmodel = AutoModelForMaskedLM.from_pretrained(ckpt)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n\n\n\nNow we can take these model and build whatever we want with them, modify, add..and when we are satisfied with the results we can use push_to_hup() method:\n\n\nmodel.push_to_hub('test-ch4')\n\n\n\n\nCommitInfo(commit_url='https://huggingface.co/Smail/test-ch4/commit/2f5a775ac7e24540a43374fa820db4e225b195e2', commit_message='Upload BertForMaskedLM', commit_description='', oid='2f5a775ac7e24540a43374fa820db4e225b195e2', pr_url=None, pr_revision=None, pr_num=None)\n\n\n\nThis will create a new repo \"test-ch4\" in our profile and populate it with model files. We can do the same with tokenizer\n\n\ntokenizer.push_to_hub('test-ch4')\n\n\n\n\nCommitInfo(commit_url='https://huggingface.co/Smail/test-ch4/commit/e0b505500d75768b52d549adc8f67c3f40b015dd', commit_message='Upload tokenizer', commit_description='', oid='e0b505500d75768b52d549adc8f67c3f40b015dd', pr_url=None, pr_revision=None, pr_num=None)\n\n\n\nwe can also add the organization, tokenization key and other arguments that can be specified while pushing the model into the hub through API\n\n\n\n\n\nWe can also use the Huggingface_hub library that offer more tools that are simple and very effective to achieve various tasks such as pushing a model, adding files, deleting files, creating repos, editing, managing, getting informations etc.. *Similar to push_to_hub() method the package requires a key token to access the hub:\n\n\n!huggingface-cli login\n\n\n    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n\n    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n    Setting a new token will erase the existing one.\n    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\nToken: \nAdd token as git credential? (Y/n) n\nToken is valid (permission: write).\nYour token has been saved to /root/.cache/huggingface/token\nLogin successful\n\n\n\n!huggingface-cli whoami\n\nSmail\n\n\n\nThe huggingface_hub offers several methods and classes which are useful for our purpose. Firstly, there are a few methods to manage repository creation, deletion, and others:\n\n\nfrom huggingface_hub import (\n    #User Management\n    login,\n    logout,\n    whoami,\n\n    # Repo creation and management\n    create_repo,\n    delete_repo,\n    update_repo_visibility,\n\n    # And some methods to retrieve/change information about the content\n    list_models,\n    list_datasets,\n    list_metrics,\n    list_repo_files,\n    upload_file,\n    delete_file,\n\n)\n\n\nWe could for example try to create a repo like this:\n\n\ncreate_repo('dummi_repo')\n\nRepoUrl('https://huggingface.co/Smail/dummi_repo', endpoint='https://huggingface.co', repo_type='model', repo_id='Smail/dummi_repo')\n\n\n\nOther arguments which may be useful are:\n\nprivate, in order to specify if the repository should be visible from others or not.\ntoken, if you would like to override the token stored in your cache by a given token.\nrepo_type, if you would like to create a dataset or a space instead of a model. Accepted values are “dataset” and “space”.\n\n\nOnce the repository is created, we should add files to it! Jump to the next section to see the three ways this can be handled\n\n\n\n\nThe system to manage files on the Hugging Face Hub is based on git for regular files, and git-lfs (which stands for Git Large File Storage) for larger files.\nIn general there is 3 ways to upload files to the HUB:\n\n\n\n\n\nthis approach doesn’t require installing git or git-lf on our system, it uses HTTP POST requests to push the files directly to the hub.\nIt’s limitation is the size of the file shouldn’t be larger than 5 GB.\nSince I work in a google colab, I will create a folder and work with it “locally”.\n\n\n!mkdir my_folder\nfrom transformers import AutoModelForMaskedLM, AutoTokenizer\n\ncheckpoint = \"camembert-base\"\n\nmodel = AutoModelForMaskedLM.from_pretrained(checkpoint)\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n# Do whatever with the model, train it, fine-tune it...\n\nmodel.save_pretrained(\"/content/my_folder\")\ntokenizer.save_pretrained(\"/content/my_folder\")\n\nSome weights of the model checkpoint at camembert-base were not used when initializing CamembertForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n\n\n('/content/my_folder/tokenizer_config.json',\n '/content/my_folder/special_tokens_map.json',\n '/content/my_folder/sentencepiece.bpe.model',\n '/content/my_folder/added_tokens.json',\n '/content/my_folder/tokenizer.json')\n\n\n\nfrom huggingface_hub import upload_file\nupload_file(\n    path_or_fileobj=\"/content/my_folder/config.json\",\n    path_in_repo=\"config.json\",\n    repo_id=\"Smail/dummi_repo\",\n)\n\nCommitInfo(commit_url='https://huggingface.co/Smail/dummi_repo/commit/1af5f861f0e0a3398d3856c69ff83bd5f04c372a', commit_message='Upload config.json with huggingface_hub', commit_description='', oid='1af5f861f0e0a3398d3856c69ff83bd5f04c372a', pr_url=None, pr_revision=None, pr_num=None)\n\n\n\nThis will upload the config.json file exists in path_to_file to the root of the repo as config.json.\n\n\n\n\n\nThe repository class abstract a local repo and handle all the work in agit like manner, it requires having git and git-lf installed in our system.\n\n\n!pip install git-LFS\n\nCollecting git-LFS\n  Downloading git_lfs-1.6-py2.py3-none-any.whl (5.6 kB)\nInstalling collected packages: git-LFS\nSuccessfully installed git-LFS-1.6\n\n\n\n!git lfs install\n\nGit LFS initialized.\n\n\n\nfrom huggingface_hub import Repository\n\nrepo = Repository('/content', clone_from= 'Smail/dummi_repo')\n\n\nThis will create a folder in the path we decide and will import all the files in the repo from the hub.\nSince we didn’t create any files in that repo when we insantiate it, the only file we have is .gitattributes, from here we could deal with that repo as if it a git repo:\n\n\nrepo.git_pull()\nrepo.git_add()\nrepo.git_commit()\nrepo.git_push()\nrepo.git_tag()\n\n\nFirst we have to make the repo up-to-date with:\n\n\nrepo.git_pull()\n\n\nWe can now save the model and tokenizer in the directotry\n\n\nmodel.save_pretrained('my_folder')\ntokenizer.save_pretrained('my_folder')\n\n\nNow our local folder countains 2 new files and we could push them to the hub:\n\n\nrepo.git_add()\nrepo.git_commit('add model and tokenizer')\nrepo.git_push()\n\n\n\n\n\nThis method is very similar to the one before, its barbone method that in pure git and bash.\nFirst let’s install git and git-lf:\n\n\n!pip install git-LFS\n\nRequirement already satisfied: git-LFS in /usr/local/lib/python3.10/dist-packages (1.6)\n\n\n\nAnd the initialize git and lfs\n\n\n!git lfs install\n\nUpdated git hooks.\nGit LFS initialized.\n\n\n\nNow we can clone the repo from the hub the normal way:\n\n\n!git clone https://huggingface.co/Smail/test-model-2\n\nCloning into 'test-model-2'...\nremote: Enumerating objects: 4, done.\nremote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 4\nUnpacking objects:  25% (1/4)Unpacking objects:  50% (2/4)Unpacking objects:  75% (3/4)Unpacking objects: 100% (4/4)Unpacking objects: 100% (4/4), 1.12 KiB | 1.12 MiB/s, done.\n\n\n\nSince we are using bash, we could naigate the directory like this:\n\n\n!cd test-model-2 && ls\n\nREADME.md\n\n\n\nThis will chnage the directory the repo we just cloned, and print all the files in it.\nNow we can build a model like we did before and save all the files in the repo we cloned and push them to the hub:\n\n\nfrom transformers import AutoModelForMaskedLM, AutoTokenizer\n\ncheckpoint = \"camembert-base\"\n\nmodel = AutoModelForMaskedLM.from_pretrained(checkpoint)\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\n# Do whatever with the model, train it, fine-tune it...\n\nmodel.save_pretrained(\"/content/test-model-2\")\ntokenizer.save_pretrained(\"/content/test-model-2\")\n\nSome weights of the model checkpoint at camembert-base were not used when initializing CamembertForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n- This IS expected if you are initializing CamembertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing CamembertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n\n\n('/content/test-model-2/tokenizer_config.json',\n '/content/test-model-2/special_tokens_map.json',\n '/content/test-model-2/sentencepiece.bpe.model',\n '/content/test-model-2/added_tokens.json',\n '/content/test-model-2/tokenizer.json')\n\n\n\n!ls\n\nmy_folder  sample_data  test-model-2\n\n\n\n!cd test-model-2 && ls\n\nadded_tokens.json  model.safetensors  sentencepiece.bpe.model  tokenizer_config.json\nconfig.json    README.md          special_tokens_map.json  tokenizer.json\n\n\n\nNow that we’ve saved some model and tokenizer artifacts, let’s take another look at the folder:\n\nIf you look at the file sizes (for example, with ls -lh), you should see that the model state dict file (pytorch_model.bin) is the only outlier, at more than 400 MB.\nWe can now go ahead and proceed like we would usually do with traditional Git repositories. We can add all the files to Git’s staging environment using the git add command:\n\n!cd test-model-2 && git add .\n\n\n!cd test-model-2 && git status\n\n\nOn branch main\n\nYour branch is up to date with 'origin/main'.\n\n\n\nChanges to be committed:\n\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n\n    new file:   added_tokens.json\n\n    new file:   config.json\n\n    new file:   model.safetensors\n\n    new file:   sentencepiece.bpe.model\n\n    new file:   special_tokens_map.json\n\n    new file:   tokenizer.json\n\n    new file:   tokenizer_config.json\n\n\n\n\n\n\n\nSimilarly, we can make sure that git-lfs is tracking the correct files by using its status command:\n\n\n!cd test-model-2 && git lfs status\n\nOn branch main\nObjects to be pushed to origin/main:\n\n\nObjects to be committed:\n\n    added_tokens.json (Git: 43734cd)\n    config.json (Git: 4b8db4b)\n    model.safetensors (LFS: 2785d2e)\n    sentencepiece.bpe.model (LFS: 988bc5a)\n    special_tokens_map.json (Git: b547935)\n    tokenizer.json (Git: 9a9362e)\n    tokenizer_config.json (Git: c49982e)\n\nObjects not staged for commit:\n\n\n\n\n\nWe can see that all files have Git as a handler, except pytorch_model.bin and sentencepiece.bpe.model, which have LFS. Great!\nLet’s proceed to the final steps, committing and pushing to the huggingface.co remote repository:\n\n\n!cd test-model-2 && git commit -m \"First model version\"\n\n[main adaa023] First model version\n 7 files changed, 128351 insertions(+)\n create mode 100644 added_tokens.json\n create mode 100644 config.json\n create mode 100644 model.safetensors\n create mode 100644 sentencepiece.bpe.model\n create mode 100644 special_tokens_map.json\n create mode 100644 tokenizer.json\n create mode 100644 tokenizer_config.json\n\n\n*Pushing can take a bit of time, depending on the speed of your internet connection and the size of your files:\n\n!cd test-model-2 && git push\n\nEnumerating objects: 10, done.\nCounting objects: 100% (10/10), done.\nDelta compression using up to 2 threads\nCompressing objects: 100% (8/8), done.\nWriting objects: 100% (9/9), 592.06 KiB | 5.10 MiB/s, done.\nTotal 9 (delta 0), reused 0 (delta 0), pack-reused 0\nTo https://huggingface.co/Smail/test-model-2\n   6266b40..adaa023  main -&gt; main"
  },
  {
    "objectID": "posts/HuggingFace_4/Hugging_Face_course_Notes_Chapter4.html#building-model-card",
    "href": "posts/HuggingFace_4/Hugging_Face_course_Notes_Chapter4.html#building-model-card",
    "title": "Hugging Face Course Notes: Chapter4",
    "section": "",
    "text": "Model card plays a crucial role in open source model, it allow others to build an idea about the important element of the model without spending time and effort, it ensures reusability and reproducibility of the results.\nBy documenting the training and evaluation process we hepl other understand what they expect from the model, its limitations and capabilities, also we have to provide enough iformations about the data we train the model and how it was preprocessed.\nThe model card usually starts with a very brief, high-level overview of what the model is for, followed by additional details in the following sections:\n\nModel description\nIntended uses & limitations\nHow to use\nLimitations and bias\nTraining data\nTraining procedure\nEvaluation results\n\n\n\n\n\nThe model description provides basic details about the model. This includes the architecture, version, if it was introduced in a paper, if an original implementation is available, the author, and general information about the model. Any copyright should be attributed here. General information about training procedures, parameters, and important disclaimers can also be mentioned in this section.\n\n\n\n\n\nHere you describe the use cases the model is intended for, including the languages, fields, and domains where it can be applied. This section of the model card can also document areas that are known to be out of scope for the model, or where it is likely to perform suboptimally.\n\n\n\n\n\nThis section should include some examples of how to use the model. This can showcase usage of the pipeline() function, usage of the model and tokenizer classes, and any other code you think might be helpful.\n\n\n\n\n\nThis part should indicate which dataset(s) the model was trained on. A brief description of the dataset(s) is also welcome.\n\n\n\n\n\nIn this section you should describe all the relevant aspects of training that are useful from a reproducibility perspective. This includes any preprocessing and postprocessing that were done on the data, as well as details such as the number of epochs the model was trained for, the batch size, the learning rate, and so on.\n\n\n\n\n\nHere you should describe the metrics you use for evaluation, and the different factors you are mesuring. Mentioning which metric(s) were used, on which dataset and which dataset split, makes it easy to compare you model’s performance compared to that of other models. These should be informed by the previous sections, such as the intended users and use cases.\n\n\n\n\n\nFinally, provide an indication of how well the model performs on the evaluation dataset. If the model uses a decision threshold, either provide the decision threshold used in the evaluation, or provide details on evaluation at different thresholds for the intended uses."
  },
  {
    "objectID": "posts/Fastai_ch6/Ch6.html",
    "href": "posts/Fastai_ch6/Ch6.html",
    "title": "Chapter 6: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "In previous chapter we learned how to pick the right learning rate, and how the number of epochs may effect the accuarcy of our model.\nIn this chapter we will learn about two other types of computer vision problem:\n\nMulti-label classification: is when we want to predict one or more label per image (or even none)\nRegression: is when the label is a quantative number(s) rather than a categories\n\nIn the process will study more deeply the output activations, targets, and loss functions in deep learning models.\n\n\n! [ -e /content ] && pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\n\n     |████████████████████████████████| 719 kB 13.1 MB/s \n     |████████████████████████████████| 1.3 MB 27.4 MB/s \n     |████████████████████████████████| 5.3 MB 41.8 MB/s \n     |████████████████████████████████| 441 kB 48.6 MB/s \n     |████████████████████████████████| 1.6 MB 23.9 MB/s \n     |████████████████████████████████| 115 kB 50.9 MB/s \n     |████████████████████████████████| 163 kB 42.7 MB/s \n     |████████████████████████████████| 212 kB 18.8 MB/s \n     |████████████████████████████████| 127 kB 52.8 MB/s \n     |████████████████████████████████| 115 kB 48.9 MB/s \n     |████████████████████████████████| 7.6 MB 45.9 MB/s \nMounted at /content/gdrive\n\n\n\nfrom fastbook import *\n\n\n\n\nAs we briefly explain, multi-label classfication is when we predict more than category for one image or even zero category.\nIn fact the bear classfier we built earlier is a good example of multi-label calssification , the only exception is that our model doesn’t have the feature of returning zero class if the model isn’t confidently sure about neither of the classes\nIn practice it is more likely to see an images that match more than 1 categories or zero, but it’s rarely to see models being trained for that prorpose.\nFirst, let’s see what a multi-label dataset looks like, then we’ll explain how to get it ready for our model. we’ll see that the architecture of the model does not change from the last chapter; only the loss function does.\n\n\n\n\nFor this chapter we will work with Pascal Dataset which provide multi-label categories per image.\nFirst download the data\n\n\nfrom fastai.vision.all import *\npath = untar_data(URLs.PASCAL_2007)\n\n\n\n\n\n\n    \n      \n      100.00% [1637801984/1637796771 03:06&lt;00:00]\n    \n    \n\n\n\nThis dataset is differente from what we’ve seen till now, it’s not structured by filename or folder, instead comes with CSV(Comma-Separated Values) telling us what label is assigned to each image.\n\nwe will use pandas to see analyze the data\n\n\n\ndf = pd.read_csv(path/'train.csv')\ndf\n\n\n    \n      \n\n\n\n\n\n\nfname\nlabels\nis_valid\n\n\n\n\n0\n000005.jpg\nchair\nTrue\n\n\n1\n000007.jpg\ncar\nTrue\n\n\n2\n000009.jpg\nhorse person\nTrue\n\n\n3\n000012.jpg\ncar\nFalse\n\n\n4\n000016.jpg\nbicycle\nTrue\n\n\n...\n...\n...\n...\n\n\n5006\n009954.jpg\nhorse person\nTrue\n\n\n5007\n009955.jpg\nboat\nTrue\n\n\n5008\n009958.jpg\nperson bicycle\nTrue\n\n\n5009\n009959.jpg\ncar\nFalse\n\n\n5010\n009961.jpg\ndog\nFalse\n\n\n\n\n5011 rows × 3 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n\n\n###Constructing a DataBlock\n\nNow we will go through the steps of creating DataLoaders objects from DataFrame.\nThe easiest way is to use DataBlock API.\nBut first we need to define each of these concepts:\n\nDataset: A collection that return a tuple with dependent and independent variales when we index into it ( in this case dataframe)\nDataLoader: An iterator that provides a stream of mini-batches, where each mini-batch is a tuple of a batch of independent variables and a batch of dependent variables\n\nOn the top of these, fastai provides two classes for bringing training and validation set together:\n\nDatasets: a class that contains training dataset and validation dataset\nDataLoaders: a class that contains training DataLoader and validation DataLoader\n\nLet’s create a DataBlock with no parameters, then create Datasets object from in by passing the actual DataFrame we will use df\n\n\ndblock = DataBlock()\n\n\n# create datasets objects\ndsets = dblock.datasets(df)\n\n\nBy default the dataset is randomly splited to train and validation 80%/20%\n\n\nlen(dsets.train), len(dsets.valid)\n\n(4009, 1002)\n\n\n\nIf we call the first item from one of the Datasets it return a row of DataFrame twice, assuming that we have two things: input and target, which we will build later.\n\n\nx, y = dsets.train[0]\nx, y\n\n(fname       008663.jpg\n labels      car person\n is_valid         False\n Name: 4346, dtype: object, fname       008663.jpg\n labels      car person\n is_valid         False\n Name: 4346, dtype: object)\n\n\n\nThe dependent variable is the image name, and the independent variable is the label, so let’s grab them\n\n\nx['fname'], x['labels']\n\n('008663.jpg', 'car person')\n\n\n\nThe goal here is to tell Datablock how identify the x’s and y’s of the dataset.\nWe will use get_x and get_y functions\n\n\ndblock = DataBlock(get_x = lambda r: r['fname'], get_y = lambda r: r['labels'])\ndsets = dblock.datasets(df)\ndsets.train[0]\n\n('005620.jpg', 'aeroplane')\n\n\n\nThe problem with lambdas is cannot be saved when we create a learner, this is why it’s better to avoid them.\n\n\ndef get_x(r): return r['fname']\ndef get_y(r): return r['labels']\ndblock =  DataBlock(get_x= get_x, get_y=get_y)\ndsets= dblock.datasets(df)\ndsets.train[0]\n\n('002549.jpg', 'tvmonitor')\n\n\n\nfrom PIL import Image\n\n\nImage.open(path/'train'/'002549.jpg')\n\n\n\n\n\n\n\n\n\nIn order to open an image we need the path\nAs we know some images has more the one label, that why we need to split them by space.\nLet’s recreate the datablock by adding this 2 things (path, split)\n\n\ndef get_x(r): return path/'train'/r['fname']\ndef get_y(r): return r['labels'].split(' ')\ndblock =  DataBlock(get_x= get_x, get_y=get_y)\ndsets= dblock.datasets(df)\ndsets.train[0]\n\n(Path('/root/.fastai/data/pascal_2007/train/002844.jpg'), ['train'])\n\n\n\nNow we can open the image just by calling the [0] of the index of that item in dataset\nTo open image and do the conversion to tensors, we will use block types to provide us with set of transforms: ImageBlock and MultiCategoryBlock\n\nwe used ImageBlock before, it open the image from the path\nbefore we used CategoryBlock which cannot be used here, because it returned a single integer, but here we have multiple labels for each image, thats why we need MultiCategoryBlock\n\n\n\ndblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n                   get_x=get_x,\n                   get_y=get_y)\ndsets= dblock.datasets(df)\ndsets.train[0]\n\n(PILImage mode=RGB size=500x375,\n TensorMultiCategory([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]))\n\n\n\ndsets.train[0][1]\n\nTensorMultiCategory([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n\n\n\nAs we see the list of categories contains zeros and one 1.\nThe zeros represent all the other categories that doesn’t match the image, and obviously the 1 represent the label\nThis is known as One-Hot Encoding\nLet’s see which category represent this particular image by using toch.where\n\n\nidxs = torch.where(dsets.train[77][1]==1.)[0]\ndsets.train.vocab[idxs]\n\n(#2) ['person','sofa']\n\n\n\nTill we use the randome splitter provided by default, instead of using the is_valid which can be used as splitter\n\n\ndf.is_valid\n\n0        True\n1        True\n2        True\n3       False\n4        True\n        ...  \n5006     True\n5007     True\n5008     True\n5009    False\n5010    False\nName: is_valid, Length: 5011, dtype: bool\n\n\n\ndef splitter(df):\n    train = df.index[~df['is_valid']].tolist()\n    valid = df.index[df['is_valid']].tolist()\n    return train,valid\n\ndblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n                   splitter=splitter,\n                   get_x=get_x,\n                   get_y=get_y)\ndsets = dblock.datasets(df)\ndsets.train[0]\n\n(PILImage mode=RGB size=500x333,\n TensorMultiCategory([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))\n\n\n\nlen(dsets.train), len(dsets.valid)\n\n(2501, 2510)\n\n\n\nOne last we have to do before creating our dataloaders, is to make sure that all images are the same size by using RandomResizeCrop\n\n\ndblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n                   splitter=splitter,\n                   get_x=get_x, \n                   get_y=get_y,\n                   item_tfms = RandomResizedCrop(128, min_scale=0.35))\ndls = dblock.dataloaders(df)\n\n\ndls.show_batch(nrows=2, ncols=4)\n\n\n\n\n\n\n\n\n\n\n\n\nNow we need to create a Learner, we know that learner is defined by 4 things:\n\nmodel (resenet18)\ndataloaders, we already created it\nOptimizer (SGD)\nloss-function: we need to make sure that we create a suitable loss function for this type of model.First we create a learner and look at its activations\n\n\n\nlearn = vision_learner(dls, resnet18)\n\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n\n\n\n\n\n\nNow we bring one batch and deconstruct it with x and y, then call the model as function by passing the independent variable as parameter, which will return activations.\n\n\nx, y= to_cpu(dls.train.one_batch())\nactivs= learn.model(x)\nactivs.shape\n\ntorch.Size([64, 20])\n\n\n\nactivs[2]\n\nTensorBase([ 2.1179, -0.0294,  0.7001, -0.3637,  0.9945,  3.5996, -3.0180,  1.5298,  0.8906, -0.3150,  0.7787,  0.9151,  3.0681, -4.6584,  1.9598, -0.6030, -1.8170,  2.2310,  1.1888, -0.0595],\n           grad_fn=&lt;AliasBackward0&gt;)\n\n\n\nAs we see here the activations aren’t yet scaled between 0 and 1, so we need to use Sigmoid() to do that.\nThe loss we will use here is similar to the one we used in mnist dataset: mnist_loss, the only different is we will add log().\n\n\ndef binary_cross_entropy(inputs, targets):\n    inputs = inputs.sigmoid()\n    return -torch.where(targets==1, 1-inputs, inputs).log().mean()\n\n\nBecause we have a one-hot-encoded dependent variable, we can’t use nll_loss or softmax.\nSoftmax make all predictions sum to 1, and push one activation to be much larger that the others, due to use of exp, but in our case we may have more than one target we need to predict, so the sum of all activations to 1 will be am issue here\nIn other hand nll_loss as we saw returns the value of one activation, the that is corresponding to the single label. but we have have multiple labels!\nOne other benefit of this function binary_cross_entropy is that it uses the broadcasting technic, by apllying the logic -torch.where(targets==1, 1-inputs, inputs) to all labels.\n\nit’s like asking each image: is that a cat?, is that a chair? is that a person?.. and after each question calculating the different between the predicted value and the actual value and return it as loss.\n\nPytorch provide us with functions and modules that do exactly the same.\nF.binary_cross_entropy and nn.BCELoss calculate the cross-enropy on one-hot-encoded target, but without inculding the sigmoid()\nThe built-in sigmoid() version of these two are: F.binary_cross_entropy_with_logits and nn.BCEWithLogitsLoss.\nSo the equivalent built-in function to our binary_cross_entropy is nn.BCEWithLogitsLoss\n\n\nloss_func = nn.BCEWithLogitsLoss()\nloss = loss_func(activs, y)\nloss\n\nTensorMultiCategory(1.0342, grad_fn=&lt;AliasBackward0&gt;)\n\n\n\nAlthough we don’t need to tell fastai to use this function as a loss, because it will pick nn.BCEWithLogitsLoss() automatically since we have multiple category labels. ___\nIn this model we will use slightly different accuracy function.\nThe previous accuracy function compare our outputs with the single target, but since we have multiple targets, we need to aplly it differently.\nAfter we apply sigmoid to our activations, we need decide which are 1 and which are 0, the best way is to create some threshold, all values above it are 1’s, else == 0.\n\n\ndef accuracy_multi(inp, trg, thresh=0.5, sigmoid=True):\n    if sigmoid: inp = inp.sigmoid()\n    return ((inp&gt;thresh)==trg.bool()).float().mean()\n\n\nThis function use the default threshold value, if we want to adjust this value within the same function, we will use a function in Python called partial\nIt allows us to bind a function with some arguments or keyword arguments, making a new version of that function that, whenever it is called, always includes those arguments\n\n\n# partial function\ndef say_hello(name, say_what='hello'): return f'{say_what} {name}'\nsay_hello('Ismail'), say_hello('Ismail', 'hola')\n\n('hello Ismail', 'hola Ismail')\n\n\n\n# we can switch to another version of this function by calling partial\nf = partial(say_hello, say_what='Guten Tag')\nf('Salim'), f('Karim!')\n\n('Guten Tag Salim', 'Guten Tag Karim!')\n\n\n\nNow we can train our model as usual, we pick here 0.2 as threshold\n\n\nlearn =  vision_learner(dls, resnet50, metrics=partial(accuracy_multi, thresh=0.2))\nlearn.fine_tune(3, base_lr= 3e-3, freeze_epochs=4)\n\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy_multi\ntime\n\n\n\n\n0\n0.943426\n0.692230\n0.235896\n00:39\n\n\n1\n0.823277\n0.564228\n0.285199\n00:31\n\n\n2\n0.604020\n0.199862\n0.827908\n00:32\n\n\n3\n0.359526\n0.124002\n0.944323\n00:30\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy_multi\ntime\n\n\n\n\n0\n0.131472\n0.116906\n0.944203\n00:31\n\n\n1\n0.116399\n0.106551\n0.951096\n00:31\n\n\n2\n0.096168\n0.104706\n0.951116\n00:31\n\n\n\n\n\n\nPicking the threshold is so important, if we pick too low we’ll often be failing to select correctly labeled objects, and if we pick to high we end up selecting only the objects that the model is strongly confident about.\nWe will grab all predictions and target using get_preds, then we will try few values for the thresh and see what get us the highest value.\n\n\npreds, targs= learn.get_preds()\n\n\n\n\n\n\n\n\n\nThe we can call the metrics directly, we just need to deactivate the sigmoid since it already apllied by default by get_preds on activations.\n\n\nxs = torch.linspace(0.05, 0.95, 29)\naccs = [accuracy_multi(preds, targs, thresh=i, sigmoid=False) for i in xs]\nplt.plot(xs, accs)\n\n\n\n\n\n\n\n\n\nAccording to this plot, the accuracy reach its highest when the thresh at 0.6 ____\n\n\n\n\n\n\nWe usualy think of deep learnig as couple of fields, each has its own architecture, problems, datatype.. for example there’s NLP, Vision, Regression, Tabular.\nBut the main difference among models used in these fields are basically the difference between dependent and independent variables used in those models, along side with its loss function.That means that there’s really a far wider array of models than just the simple domain-based split.\n\nwe can use text to generate image or vice versa, we can use continous values to predict videos/images/ texts..\n\nHere we will build a Regression Image model\n\nthe dependent variables are images\nwhile the independent variables are float values\n\n\n\n\n\nWe will use the Biwi Kinect Head Pose dataset for this section. We’ll begin by downloading the dataset as usual:\n\n\npath = untar_data(URLs.BIWI_HEAD_POSE)\n\n\n\n\n\n\n    \n      \n      100.00% [452321280/452316199 00:36&lt;00:00]\n    \n    \n\n\n\nPath.BASE_PATH = path\n\n\npath.ls().sorted()\n\n(#50) [Path('01'),Path('01.obj'),Path('02'),Path('02.obj'),Path('03'),Path('03.obj'),Path('04'),Path('04.obj'),Path('05'),Path('05.obj')...]\n\n\n\nThere are 24 directories numbered from 01 to 24 (they correspond to the different people photographed), and a corresponding .obj file for each (we won’t need them here). Let’s take a look inside one of these directories:\n\n\n(path/'01').ls().sorted()\n\n(#1000) [Path('01/depth.cal'),Path('01/frame_00003_pose.txt'),Path('01/frame_00003_rgb.jpg'),Path('01/frame_00004_pose.txt'),Path('01/frame_00004_rgb.jpg'),Path('01/frame_00005_pose.txt'),Path('01/frame_00005_rgb.jpg'),Path('01/frame_00006_pose.txt'),Path('01/frame_00006_rgb.jpg'),Path('01/frame_00007_pose.txt')...]\n\n\n\nInside the subdirectories, we have different frames, each of them come with an image (_rgb.jpg) and a pose file (_pose.txt). We can easily get all the image files recursively with get_image_files, then write a function that converts an image filename to its associated pose file:\n\n\nimg_files = get_image_files(path)\ndef img2pose(x): return Path(f'{str(x)[:-7]}pose.txt')\nimg2pose(img_files[0])\n\nPath('20/frame_00388_pose.txt')\n\n\n\nim = PILImage.create(img_files[0])\nim.shape\n\n(480, 640)\n\n\n\nim.to_thumb(250)\n\n\n\n\n\n\n\n\n\nThe Biwi dataset website used to explain the format of the pose text file associated with each image, which shows the location of the center of the head. The details of this aren’t important for our purposes, so we’ll just show the function we use to extract the head center point:\n\n\ncal = np.genfromtxt(path/'01'/'rgb.cal', skip_footer=6)\ndef get_ctr(f):\n    ctr = np.genfromtxt(img2pose(f), skip_header=3)\n    c1 = ctr[0] * cal[0][0]/ctr[2] + cal[0][2]\n    c2 = ctr[1] * cal[1][1]/ctr[2] + cal[1][2]\n    return tensor([c1,c2])\n\n\nThis function return the coordinate of the center of the head of each image, so we can pass it as the get_y to DataBlock since it represent the independent variable for each image\n\n\nget_ctr(img_files[0])\n\ntensor([343.6303, 276.7759])\n\n\n\nThis dataset contains images of many person, each one has multiple images, so we can’t just randomly split the dataset, because we need the model to generelize on new people/images, and training the model on image of a person, and validate the results on a training set that contains images of the same person, will definitively cause Overfitting\nInstead what we do in this case, is to take all images that belong to one person, and define them as validation set.\n\n\nbiwi = DataBlock(\n    blocks=(ImageBlock, PointBlock),\n    get_items=get_image_files,\n    get_y=get_ctr,\n    splitter=FuncSplitter(lambda o: o.parent.name=='13'),\n    batch_tfms=aug_transforms(size=(240,320)))\n\n\nAs we see here we use PointBlock, this is what fastai use to coordinate data (tensor with 2 values)\nFor the splitting as we said before we took one person’s images 13 and put the all into validation dataset.\nWe use aug_transforms as transformers\nBefore doing any modeling, we should look at our data to confirm it seems okay:\n\n\ndls = biwi.dataloaders(path)\ndls.show_batch(max_n=9, figsize=(8,6))\n\n\n\n\n\n\n\n\n\nxb, yb= dls.one_batch()\nxb.shape, yb.shape\n\n(torch.Size([64, 3, 240, 320]), torch.Size([64, 1, 2]))\n\n\n\nxb shape is [64,3,240,320]:\n\n64 is the number of items in each mini-batch\n3 represent number of channels, which in this case colors\n240*320 are the pixels of the image\n\n\n\n\n\n\nHere we create learner with help of vision_learner we pass to it:\n\ndls\nresnet18\ny_range(): this function define the range of our targets. In fastai this function is implemented using the sigmoid_range\n\n\n\ndef sigmoid_range(x, lo, hi): return torch.sigmoid(x) * (hi-lo) + lo\n\n\nlearn = vision_learner(dls, resnet18, y_range=(-1,1))\n\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\nThis is set as the final layer of the model\nNote that we didn’t define the loss function, but we already know that fastai will pick the right loss function for us depend on the type of data/model\n\n\ndls.loss_func\n\nFlattenedLoss of MSELoss()\n\n\n\nFastai picked MSELoss which stands for mean square error, which make sense since we have a regression problem.\nBut in case we want different loss we can pass it to vision_learner by using loss_func parameter.\nIn this type of model, we could pick the loss as metric we just need to take the square root of it)\nNow we need to pick a learning rate\n\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0020892962347716093)\n\n\n\n\n\n\n\n\n\n\nThen we will try 0.002 as learning rate\n\n\nlr = 0.002\nlearn.fine_tune(3, lr)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.137417\n0.008638\n02:04\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.009691\n0.000932\n02:10\n\n\n1\n0.003397\n0.000595\n02:10\n\n\n2\n0.002397\n0.000345\n02:10\n\n\n\n\n\n\nloss = (0.005764+0.001309+0.000556+0.000316)/4\nloss\n\n0.00198625\n\n\n\nmetric_err_rate = round(math.sqrt(0.002), 4)\nmetric_err_rate\n\n0.0447\n\n\n\nThe accuracy of the model 96% which is good. So by using a computer vision model and with transfer learning technics we manage to solve a regression problem with accuracy of 96%.\n\n\nlearn.show_results(ds_idx=1, nrows=3, figsize=(6,8))"
  },
  {
    "objectID": "posts/Fastai_ch6/Ch6.html#multi-label-classification",
    "href": "posts/Fastai_ch6/Ch6.html#multi-label-classification",
    "title": "Chapter 6: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "As we briefly explain, multi-label classfication is when we predict more than category for one image or even zero category.\nIn fact the bear classfier we built earlier is a good example of multi-label calssification , the only exception is that our model doesn’t have the feature of returning zero class if the model isn’t confidently sure about neither of the classes\nIn practice it is more likely to see an images that match more than 1 categories or zero, but it’s rarely to see models being trained for that prorpose.\nFirst, let’s see what a multi-label dataset looks like, then we’ll explain how to get it ready for our model. we’ll see that the architecture of the model does not change from the last chapter; only the loss function does.\n\n\n\n\nFor this chapter we will work with Pascal Dataset which provide multi-label categories per image.\nFirst download the data\n\n\nfrom fastai.vision.all import *\npath = untar_data(URLs.PASCAL_2007)\n\n\n\n\n\n\n    \n      \n      100.00% [1637801984/1637796771 03:06&lt;00:00]\n    \n    \n\n\n\nThis dataset is differente from what we’ve seen till now, it’s not structured by filename or folder, instead comes with CSV(Comma-Separated Values) telling us what label is assigned to each image.\n\nwe will use pandas to see analyze the data\n\n\n\ndf = pd.read_csv(path/'train.csv')\ndf\n\n\n    \n      \n\n\n\n\n\n\nfname\nlabels\nis_valid\n\n\n\n\n0\n000005.jpg\nchair\nTrue\n\n\n1\n000007.jpg\ncar\nTrue\n\n\n2\n000009.jpg\nhorse person\nTrue\n\n\n3\n000012.jpg\ncar\nFalse\n\n\n4\n000016.jpg\nbicycle\nTrue\n\n\n...\n...\n...\n...\n\n\n5006\n009954.jpg\nhorse person\nTrue\n\n\n5007\n009955.jpg\nboat\nTrue\n\n\n5008\n009958.jpg\nperson bicycle\nTrue\n\n\n5009\n009959.jpg\ncar\nFalse\n\n\n5010\n009961.jpg\ndog\nFalse\n\n\n\n\n5011 rows × 3 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n\n\n###Constructing a DataBlock\n\nNow we will go through the steps of creating DataLoaders objects from DataFrame.\nThe easiest way is to use DataBlock API.\nBut first we need to define each of these concepts:\n\nDataset: A collection that return a tuple with dependent and independent variales when we index into it ( in this case dataframe)\nDataLoader: An iterator that provides a stream of mini-batches, where each mini-batch is a tuple of a batch of independent variables and a batch of dependent variables\n\nOn the top of these, fastai provides two classes for bringing training and validation set together:\n\nDatasets: a class that contains training dataset and validation dataset\nDataLoaders: a class that contains training DataLoader and validation DataLoader\n\nLet’s create a DataBlock with no parameters, then create Datasets object from in by passing the actual DataFrame we will use df\n\n\ndblock = DataBlock()\n\n\n# create datasets objects\ndsets = dblock.datasets(df)\n\n\nBy default the dataset is randomly splited to train and validation 80%/20%\n\n\nlen(dsets.train), len(dsets.valid)\n\n(4009, 1002)\n\n\n\nIf we call the first item from one of the Datasets it return a row of DataFrame twice, assuming that we have two things: input and target, which we will build later.\n\n\nx, y = dsets.train[0]\nx, y\n\n(fname       008663.jpg\n labels      car person\n is_valid         False\n Name: 4346, dtype: object, fname       008663.jpg\n labels      car person\n is_valid         False\n Name: 4346, dtype: object)\n\n\n\nThe dependent variable is the image name, and the independent variable is the label, so let’s grab them\n\n\nx['fname'], x['labels']\n\n('008663.jpg', 'car person')\n\n\n\nThe goal here is to tell Datablock how identify the x’s and y’s of the dataset.\nWe will use get_x and get_y functions\n\n\ndblock = DataBlock(get_x = lambda r: r['fname'], get_y = lambda r: r['labels'])\ndsets = dblock.datasets(df)\ndsets.train[0]\n\n('005620.jpg', 'aeroplane')\n\n\n\nThe problem with lambdas is cannot be saved when we create a learner, this is why it’s better to avoid them.\n\n\ndef get_x(r): return r['fname']\ndef get_y(r): return r['labels']\ndblock =  DataBlock(get_x= get_x, get_y=get_y)\ndsets= dblock.datasets(df)\ndsets.train[0]\n\n('002549.jpg', 'tvmonitor')\n\n\n\nfrom PIL import Image\n\n\nImage.open(path/'train'/'002549.jpg')\n\n\n\n\n\n\n\n\n\nIn order to open an image we need the path\nAs we know some images has more the one label, that why we need to split them by space.\nLet’s recreate the datablock by adding this 2 things (path, split)\n\n\ndef get_x(r): return path/'train'/r['fname']\ndef get_y(r): return r['labels'].split(' ')\ndblock =  DataBlock(get_x= get_x, get_y=get_y)\ndsets= dblock.datasets(df)\ndsets.train[0]\n\n(Path('/root/.fastai/data/pascal_2007/train/002844.jpg'), ['train'])\n\n\n\nNow we can open the image just by calling the [0] of the index of that item in dataset\nTo open image and do the conversion to tensors, we will use block types to provide us with set of transforms: ImageBlock and MultiCategoryBlock\n\nwe used ImageBlock before, it open the image from the path\nbefore we used CategoryBlock which cannot be used here, because it returned a single integer, but here we have multiple labels for each image, thats why we need MultiCategoryBlock\n\n\n\ndblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n                   get_x=get_x,\n                   get_y=get_y)\ndsets= dblock.datasets(df)\ndsets.train[0]\n\n(PILImage mode=RGB size=500x375,\n TensorMultiCategory([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]))\n\n\n\ndsets.train[0][1]\n\nTensorMultiCategory([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])\n\n\n\nAs we see the list of categories contains zeros and one 1.\nThe zeros represent all the other categories that doesn’t match the image, and obviously the 1 represent the label\nThis is known as One-Hot Encoding\nLet’s see which category represent this particular image by using toch.where\n\n\nidxs = torch.where(dsets.train[77][1]==1.)[0]\ndsets.train.vocab[idxs]\n\n(#2) ['person','sofa']\n\n\n\nTill we use the randome splitter provided by default, instead of using the is_valid which can be used as splitter\n\n\ndf.is_valid\n\n0        True\n1        True\n2        True\n3       False\n4        True\n        ...  \n5006     True\n5007     True\n5008     True\n5009    False\n5010    False\nName: is_valid, Length: 5011, dtype: bool\n\n\n\ndef splitter(df):\n    train = df.index[~df['is_valid']].tolist()\n    valid = df.index[df['is_valid']].tolist()\n    return train,valid\n\ndblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n                   splitter=splitter,\n                   get_x=get_x,\n                   get_y=get_y)\ndsets = dblock.datasets(df)\ndsets.train[0]\n\n(PILImage mode=RGB size=500x333,\n TensorMultiCategory([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))\n\n\n\nlen(dsets.train), len(dsets.valid)\n\n(2501, 2510)\n\n\n\nOne last we have to do before creating our dataloaders, is to make sure that all images are the same size by using RandomResizeCrop\n\n\ndblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n                   splitter=splitter,\n                   get_x=get_x, \n                   get_y=get_y,\n                   item_tfms = RandomResizedCrop(128, min_scale=0.35))\ndls = dblock.dataloaders(df)\n\n\ndls.show_batch(nrows=2, ncols=4)\n\n\n\n\n\n\n\n\n\n\n\n\nNow we need to create a Learner, we know that learner is defined by 4 things:\n\nmodel (resenet18)\ndataloaders, we already created it\nOptimizer (SGD)\nloss-function: we need to make sure that we create a suitable loss function for this type of model.First we create a learner and look at its activations\n\n\n\nlearn = vision_learner(dls, resnet18)\n\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n\n\n\n\n\n\nNow we bring one batch and deconstruct it with x and y, then call the model as function by passing the independent variable as parameter, which will return activations.\n\n\nx, y= to_cpu(dls.train.one_batch())\nactivs= learn.model(x)\nactivs.shape\n\ntorch.Size([64, 20])\n\n\n\nactivs[2]\n\nTensorBase([ 2.1179, -0.0294,  0.7001, -0.3637,  0.9945,  3.5996, -3.0180,  1.5298,  0.8906, -0.3150,  0.7787,  0.9151,  3.0681, -4.6584,  1.9598, -0.6030, -1.8170,  2.2310,  1.1888, -0.0595],\n           grad_fn=&lt;AliasBackward0&gt;)\n\n\n\nAs we see here the activations aren’t yet scaled between 0 and 1, so we need to use Sigmoid() to do that.\nThe loss we will use here is similar to the one we used in mnist dataset: mnist_loss, the only different is we will add log().\n\n\ndef binary_cross_entropy(inputs, targets):\n    inputs = inputs.sigmoid()\n    return -torch.where(targets==1, 1-inputs, inputs).log().mean()\n\n\nBecause we have a one-hot-encoded dependent variable, we can’t use nll_loss or softmax.\nSoftmax make all predictions sum to 1, and push one activation to be much larger that the others, due to use of exp, but in our case we may have more than one target we need to predict, so the sum of all activations to 1 will be am issue here\nIn other hand nll_loss as we saw returns the value of one activation, the that is corresponding to the single label. but we have have multiple labels!\nOne other benefit of this function binary_cross_entropy is that it uses the broadcasting technic, by apllying the logic -torch.where(targets==1, 1-inputs, inputs) to all labels.\n\nit’s like asking each image: is that a cat?, is that a chair? is that a person?.. and after each question calculating the different between the predicted value and the actual value and return it as loss.\n\nPytorch provide us with functions and modules that do exactly the same.\nF.binary_cross_entropy and nn.BCELoss calculate the cross-enropy on one-hot-encoded target, but without inculding the sigmoid()\nThe built-in sigmoid() version of these two are: F.binary_cross_entropy_with_logits and nn.BCEWithLogitsLoss.\nSo the equivalent built-in function to our binary_cross_entropy is nn.BCEWithLogitsLoss\n\n\nloss_func = nn.BCEWithLogitsLoss()\nloss = loss_func(activs, y)\nloss\n\nTensorMultiCategory(1.0342, grad_fn=&lt;AliasBackward0&gt;)\n\n\n\nAlthough we don’t need to tell fastai to use this function as a loss, because it will pick nn.BCEWithLogitsLoss() automatically since we have multiple category labels. ___\nIn this model we will use slightly different accuracy function.\nThe previous accuracy function compare our outputs with the single target, but since we have multiple targets, we need to aplly it differently.\nAfter we apply sigmoid to our activations, we need decide which are 1 and which are 0, the best way is to create some threshold, all values above it are 1’s, else == 0.\n\n\ndef accuracy_multi(inp, trg, thresh=0.5, sigmoid=True):\n    if sigmoid: inp = inp.sigmoid()\n    return ((inp&gt;thresh)==trg.bool()).float().mean()\n\n\nThis function use the default threshold value, if we want to adjust this value within the same function, we will use a function in Python called partial\nIt allows us to bind a function with some arguments or keyword arguments, making a new version of that function that, whenever it is called, always includes those arguments\n\n\n# partial function\ndef say_hello(name, say_what='hello'): return f'{say_what} {name}'\nsay_hello('Ismail'), say_hello('Ismail', 'hola')\n\n('hello Ismail', 'hola Ismail')\n\n\n\n# we can switch to another version of this function by calling partial\nf = partial(say_hello, say_what='Guten Tag')\nf('Salim'), f('Karim!')\n\n('Guten Tag Salim', 'Guten Tag Karim!')\n\n\n\nNow we can train our model as usual, we pick here 0.2 as threshold\n\n\nlearn =  vision_learner(dls, resnet50, metrics=partial(accuracy_multi, thresh=0.2))\nlearn.fine_tune(3, base_lr= 3e-3, freeze_epochs=4)\n\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy_multi\ntime\n\n\n\n\n0\n0.943426\n0.692230\n0.235896\n00:39\n\n\n1\n0.823277\n0.564228\n0.285199\n00:31\n\n\n2\n0.604020\n0.199862\n0.827908\n00:32\n\n\n3\n0.359526\n0.124002\n0.944323\n00:30\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy_multi\ntime\n\n\n\n\n0\n0.131472\n0.116906\n0.944203\n00:31\n\n\n1\n0.116399\n0.106551\n0.951096\n00:31\n\n\n2\n0.096168\n0.104706\n0.951116\n00:31\n\n\n\n\n\n\nPicking the threshold is so important, if we pick too low we’ll often be failing to select correctly labeled objects, and if we pick to high we end up selecting only the objects that the model is strongly confident about.\nWe will grab all predictions and target using get_preds, then we will try few values for the thresh and see what get us the highest value.\n\n\npreds, targs= learn.get_preds()\n\n\n\n\n\n\n\n\n\nThe we can call the metrics directly, we just need to deactivate the sigmoid since it already apllied by default by get_preds on activations.\n\n\nxs = torch.linspace(0.05, 0.95, 29)\naccs = [accuracy_multi(preds, targs, thresh=i, sigmoid=False) for i in xs]\nplt.plot(xs, accs)\n\n\n\n\n\n\n\n\n\nAccording to this plot, the accuracy reach its highest when the thresh at 0.6 ____"
  },
  {
    "objectID": "posts/Fastai_ch6/Ch6.html#regression",
    "href": "posts/Fastai_ch6/Ch6.html#regression",
    "title": "Chapter 6: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "We usualy think of deep learnig as couple of fields, each has its own architecture, problems, datatype.. for example there’s NLP, Vision, Regression, Tabular.\nBut the main difference among models used in these fields are basically the difference between dependent and independent variables used in those models, along side with its loss function.That means that there’s really a far wider array of models than just the simple domain-based split.\n\nwe can use text to generate image or vice versa, we can use continous values to predict videos/images/ texts..\n\nHere we will build a Regression Image model\n\nthe dependent variables are images\nwhile the independent variables are float values\n\n\n\n\n\nWe will use the Biwi Kinect Head Pose dataset for this section. We’ll begin by downloading the dataset as usual:\n\n\npath = untar_data(URLs.BIWI_HEAD_POSE)\n\n\n\n\n\n\n    \n      \n      100.00% [452321280/452316199 00:36&lt;00:00]\n    \n    \n\n\n\nPath.BASE_PATH = path\n\n\npath.ls().sorted()\n\n(#50) [Path('01'),Path('01.obj'),Path('02'),Path('02.obj'),Path('03'),Path('03.obj'),Path('04'),Path('04.obj'),Path('05'),Path('05.obj')...]\n\n\n\nThere are 24 directories numbered from 01 to 24 (they correspond to the different people photographed), and a corresponding .obj file for each (we won’t need them here). Let’s take a look inside one of these directories:\n\n\n(path/'01').ls().sorted()\n\n(#1000) [Path('01/depth.cal'),Path('01/frame_00003_pose.txt'),Path('01/frame_00003_rgb.jpg'),Path('01/frame_00004_pose.txt'),Path('01/frame_00004_rgb.jpg'),Path('01/frame_00005_pose.txt'),Path('01/frame_00005_rgb.jpg'),Path('01/frame_00006_pose.txt'),Path('01/frame_00006_rgb.jpg'),Path('01/frame_00007_pose.txt')...]\n\n\n\nInside the subdirectories, we have different frames, each of them come with an image (_rgb.jpg) and a pose file (_pose.txt). We can easily get all the image files recursively with get_image_files, then write a function that converts an image filename to its associated pose file:\n\n\nimg_files = get_image_files(path)\ndef img2pose(x): return Path(f'{str(x)[:-7]}pose.txt')\nimg2pose(img_files[0])\n\nPath('20/frame_00388_pose.txt')\n\n\n\nim = PILImage.create(img_files[0])\nim.shape\n\n(480, 640)\n\n\n\nim.to_thumb(250)\n\n\n\n\n\n\n\n\n\nThe Biwi dataset website used to explain the format of the pose text file associated with each image, which shows the location of the center of the head. The details of this aren’t important for our purposes, so we’ll just show the function we use to extract the head center point:\n\n\ncal = np.genfromtxt(path/'01'/'rgb.cal', skip_footer=6)\ndef get_ctr(f):\n    ctr = np.genfromtxt(img2pose(f), skip_header=3)\n    c1 = ctr[0] * cal[0][0]/ctr[2] + cal[0][2]\n    c2 = ctr[1] * cal[1][1]/ctr[2] + cal[1][2]\n    return tensor([c1,c2])\n\n\nThis function return the coordinate of the center of the head of each image, so we can pass it as the get_y to DataBlock since it represent the independent variable for each image\n\n\nget_ctr(img_files[0])\n\ntensor([343.6303, 276.7759])\n\n\n\nThis dataset contains images of many person, each one has multiple images, so we can’t just randomly split the dataset, because we need the model to generelize on new people/images, and training the model on image of a person, and validate the results on a training set that contains images of the same person, will definitively cause Overfitting\nInstead what we do in this case, is to take all images that belong to one person, and define them as validation set.\n\n\nbiwi = DataBlock(\n    blocks=(ImageBlock, PointBlock),\n    get_items=get_image_files,\n    get_y=get_ctr,\n    splitter=FuncSplitter(lambda o: o.parent.name=='13'),\n    batch_tfms=aug_transforms(size=(240,320)))\n\n\nAs we see here we use PointBlock, this is what fastai use to coordinate data (tensor with 2 values)\nFor the splitting as we said before we took one person’s images 13 and put the all into validation dataset.\nWe use aug_transforms as transformers\nBefore doing any modeling, we should look at our data to confirm it seems okay:\n\n\ndls = biwi.dataloaders(path)\ndls.show_batch(max_n=9, figsize=(8,6))\n\n\n\n\n\n\n\n\n\nxb, yb= dls.one_batch()\nxb.shape, yb.shape\n\n(torch.Size([64, 3, 240, 320]), torch.Size([64, 1, 2]))\n\n\n\nxb shape is [64,3,240,320]:\n\n64 is the number of items in each mini-batch\n3 represent number of channels, which in this case colors\n240*320 are the pixels of the image\n\n\n\n\n\n\nHere we create learner with help of vision_learner we pass to it:\n\ndls\nresnet18\ny_range(): this function define the range of our targets. In fastai this function is implemented using the sigmoid_range\n\n\n\ndef sigmoid_range(x, lo, hi): return torch.sigmoid(x) * (hi-lo) + lo\n\n\nlearn = vision_learner(dls, resnet18, y_range=(-1,1))\n\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n\n\n\nThis is set as the final layer of the model\nNote that we didn’t define the loss function, but we already know that fastai will pick the right loss function for us depend on the type of data/model\n\n\ndls.loss_func\n\nFlattenedLoss of MSELoss()\n\n\n\nFastai picked MSELoss which stands for mean square error, which make sense since we have a regression problem.\nBut in case we want different loss we can pass it to vision_learner by using loss_func parameter.\nIn this type of model, we could pick the loss as metric we just need to take the square root of it)\nNow we need to pick a learning rate\n\n\nlearn.lr_find()\n\n\n\n\n\n\n\n\nSuggestedLRs(valley=0.0020892962347716093)\n\n\n\n\n\n\n\n\n\n\nThen we will try 0.002 as learning rate\n\n\nlr = 0.002\nlearn.fine_tune(3, lr)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.137417\n0.008638\n02:04\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\ntime\n\n\n\n\n0\n0.009691\n0.000932\n02:10\n\n\n1\n0.003397\n0.000595\n02:10\n\n\n2\n0.002397\n0.000345\n02:10\n\n\n\n\n\n\nloss = (0.005764+0.001309+0.000556+0.000316)/4\nloss\n\n0.00198625\n\n\n\nmetric_err_rate = round(math.sqrt(0.002), 4)\nmetric_err_rate\n\n0.0447\n\n\n\nThe accuracy of the model 96% which is good. So by using a computer vision model and with transfer learning technics we manage to solve a regression problem with accuracy of 96%.\n\n\nlearn.show_results(ds_idx=1, nrows=3, figsize=(6,8))"
  },
  {
    "objectID": "posts/Build a Large Language Model/Chapter-2/Untitled.html",
    "href": "posts/Build a Large Language Model/Chapter-2/Untitled.html",
    "title": "Chapter 2: Build a Large Language Model",
    "section": "",
    "text": "About this Chapter:\n  \n  Understanding word embeddings:\n  Tokenizing text:\n  Converting tokens into token IDs:\n  Adding special context tokens:\n  Byte pair Encoding:\n  Data sampling with a sliding window:\n  Creating token embeddings:\n  Encoding word positions:\n  \n  Key Takeaways from Chapter 2:"
  },
  {
    "objectID": "posts/Build a Large Language Model/Chapter-2/Untitled.html#about-this-chapter",
    "href": "posts/Build a Large Language Model/Chapter-2/Untitled.html#about-this-chapter",
    "title": "Chapter 2: Build a Large Language Model",
    "section": "About this Chapter:",
    "text": "About this Chapter:\n\nIn order to build an LLM we need to provide a very large chunk of text.\nIn this chapter we will discuss how to prepare the text-dataset and feed it to LLM, and various technics and methods used in data preparation context.\n\n\nUnderstanding word embeddings:\n\nLLM cannot perform any kind of computation on raw text, it can only work with numbers.\nTherefor we need to apply some kind of numerical transformation to all input text.\nThis transformation called Embedding and the numerical representation of each word is Vector.\nThe embedding process work also on other data format like Audio Video .. but each type has its own embedding model. \nMany algorithms have been developed to produce embeddings for words.\nThe famous one was World2Vec.\n\nIts approach was to train Neural Network on predicting embedding of a given word based on its context, and Vice-Versa.\nThe main idea here is that words that have appear in similar context atend to have similar meaning which also efect their embedding.\nSo if these words are projected in two dimensional embedding they will be appeared in clusters. \n\nIn current LLM embeddings are way more larger and have higher dimensionality.\n\nFor example GPT-2 (117 Millions Parameters) used embeddings of 768 dimensions, where the largest GPT-3 (117 Billions Parameters) uses 12.288.\nEach word will be projected to 12.288 dimensions.\n\n\n\n\nTokenizing text:\n\nBreaking Text into Units: Tokenization splits text into smaller pieces called tokens (words, subwords, or characters), which are the building blocks the model uses to process and understand language.\nMapping Tokens to Numbers: Each token is assigned a unique numerical identifier, allowing the LLM to work with numbers instead of raw text during computations.\nEfficient Representation: The way text is tokenized affects how efficiently the LLM processes input and generates output, balancing between accuracy (preserving meaning) and memory usage (fewer tokens).\nHere we will work with raw text called The Veredict and apply some kind of tokenization on it:\n\n\nimport urllib.request\n\nurl =  (\"https://raw.githubusercontent.com/rasbt/\"\n \"LLMs-from-scratch/main/ch02/01_main-chapter-code/\"\n \"the-verdict.txt\")\nfile_path = \"the-veredict.txt\"\nurllib.request.urlretrieve(url, file_path)\n\n('the-veredict.txt', &lt;http.client.HTTPMessage at 0x705fec0466c0&gt;)\n\n\n\nOpen the data and check its length (how many chars):\n\nthe text contains 20479 charaters:\n\n\n\nwith open (\"the-veredict.txt\", \"r\", encoding= \"utf-8\") as f:\n    raw_text = f.read()\nprint(f\"total number of characters: {len(raw_text)}\")\n\ntotal number of characters: 20479\n\n\n\nTake a look on first 100 character:\n\n\nraw_text[:99]\n\n'I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no '\n\n\n\nThe goal is to tokenize the 20479 charaters in order to turn them into embeddings.\nWe will use Regular Expression as a tool to tokenize the text, just to understand the idea of tokenization since it is not the right tool for this but for our context is great.\nlets take this simple text:\n\n\nsimple_text = 'Hi there! how was your day?'\n\n\nNow lets split it to small pieces (words) with spaces \" \":\n\n\nimport re\ntokenz = re.split(r\"\\s\", simple_text)\ntokenz\n\n['Hi', 'there!', 'how', 'was', 'your', 'day?']\n\n\n\nWe need to make sure to seperate ponctuations from words:\n\n\ntokenz = re.split(r'([!?]|\\s)', simple_text)\ntokenz\n\n['Hi',\n ' ',\n 'there',\n '!',\n '',\n ' ',\n 'how',\n ' ',\n 'was',\n ' ',\n 'your',\n ' ',\n 'day',\n '?',\n '']\n\n\n\nRemove whitespaces:\n\n\nwords = [word for word in tokenz if word.strip()]\nwords\n\n['Hi', 'there', '!', 'how', 'was', 'your', 'day', '?']\n\n\n\nNow lets add more special charatcters and ponctuations such as question marks, quotation marks, and the double-dashes :\n\n\ntokenz = re.split(r'([,.:!?_;\"()\\']|--|\\s)',simple_text)\n\n\nNow lets apply this simple tokenizer on our raw_text:\n\n\ntokenz = re.split(r'([.,:;()_!?\"\\']|--|\\s)', raw_text)\ntokenz = [word.strip() for word in tokenz if word.strip()]\nlen(tokenz)\n\n4690\n\n\n\n\nConverting tokens into token IDs:\n\nSince we now have tokenz we could transform all str words into int ID.\nFirst we need to build vocabulary for all words we have in our tokenz before converting token ID into embeddings. Image\n\n\nvocabulary = sorted(set(tokenz))\nlen(vocabulary)\n\n1130\n\n\n\nAfter sorting the vocabulary and getting rid of all repeated words we have 1130 unique token in our vovabulary.\nHere we assign an int for each vocabulary element:\n\n\nvocab = {tok: integer for integer, tok in enumerate(vocabulary)}\n\n\nfor v, i in vocab.items():\n    if i &lt; 50:\n        print(f\"{i}:{v}\")\n\n0:!\n1:\"\n2:'\n3:(\n4:)\n5:,\n6:--\n7:.\n8::\n9:;\n10:?\n11:A\n12:Ah\n13:Among\n14:And\n15:Are\n16:Arrt\n17:As\n18:At\n19:Be\n20:Begin\n21:Burlington\n22:But\n23:By\n24:Carlo\n25:Chicago\n26:Claude\n27:Come\n28:Croft\n29:Destroyed\n30:Devonshire\n31:Don\n32:Dubarry\n33:Emperors\n34:Florence\n35:For\n36:Gallery\n37:Gideon\n38:Gisburn\n39:Gisburns\n40:Grafton\n41:Greek\n42:Grindle\n43:Grindles\n44:HAD\n45:Had\n46:Hang\n47:Has\n48:He\n49:Her\n\n\n\nNow we have create a simple tokenizer class that handles encoding and decoding of text based on a given vocabulary:\n\nTakes a vocab dictionary as a class attribute\nself.str_to_int: Stores the vocabulary mapping from string to integer.\nself.int_to_str: Creates a reverse dictionary that maps integers back to strings.\n\nencode Method:\n\nConverts text into a list of integer IDs based on the vocabulary.\nSplits the text into words and punctuation while preserving punctuation as separate items.\nRemoves leading/trailing spaces from each item and filters out empty strings.\nConverts the processed words/punctuation into a list of corresponding integer IDs using the str_to_int dictionary.\nReturns the list of IDs.\n\ndecode Method:\n\nConverts a list of integer IDs back into text.\nConverts the list of integer IDs into corresponding words/punctuation using the int_to_str dictionary and joins them into a single string with spaces between words.\nCleans up the text by removing spaces before punctuation marks using a regular expression.\nReturns the decoded text with properly placed punctuation.\n\n\n\nclass SimpleTokenizerV1:\n    def __init__(self, vocab):\n        self.str_to_int = vocab\n        self.int_to_str = {i:s for s,i in vocab.items()}\n\n    def encode(self, text):\n        preprocessed = re.split(r'([,.?_!\"()\\']|--|\\s)', text)\n        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n        ids = [self.str_to_int[s] for s in preprocessed]\n        return ids\n\n    def decode(self, ids):\n        text = \" \".join([self.int_to_str[i] for i in ids])\n\n        text = re.sub(r'\\s+([,.?!\"()\\'])', r'\\1', text)\n        return text\n\n\nNow we could instentiate a tokenizer object from the class SimpleTokenizerV1 and tokenize a passage from our raw text:\n\n\ntokenizer = SimpleTokenizerV1(vocab)\ntext = \"\"\"\"It's the last he painted, you know,\"\n Mrs. Gisburn said with pardonable pride.\"\"\"\n\n\nids = tokenizer.encode(text)\nids\n\n[1,\n 56,\n 2,\n 850,\n 988,\n 602,\n 533,\n 746,\n 5,\n 1126,\n 596,\n 5,\n 1,\n 67,\n 7,\n 38,\n 851,\n 1108,\n 754,\n 793,\n 7]\n\n\n\nwe can also get pass this ids into decode() method and get back the original text:\n\n\ntext = tokenizer.decode(ids)\ntext\n\n'\" It\\' s the last he painted, you know,\" Mrs. Gisburn said with pardonable pride.'\n\n\n\n\n\ndecoder_encode.png\n\n\n\n\nAdding special context tokens:\n\nWe need to modeify the tokenizer to\n\naccept Uknown words.*\nuse special tokens to handel markers of thes unkown words abd document boundaries.\n\nIf the tokenizer encounter words that doesn’t belong to the vocabulary will use &lt;|Unk|&gt; as marker for it.\nWe can also specify bondaries between documents that help the model during training to understand where the document ends and where begins.\n\n\n\n\nend_of_text.png\n\n\n\nLets modify the vocabulary to incorporate the unkown and endoftext markers:\n\n\n# create vocabulry with unique words\nall_tokenz = sorted(set(tokenz))\n# add EOT and UK to the vocabulary\nall_tokenz.extend([\"&lt;|EOT|&gt;\", \"&lt;|UK|&gt;\"])\n# give each unique vocabulary an ID\nvocab = {tokens: integers for integers, tokens in enumerate(all_tokenz)}\n\n\nCheck the last to items we just added:\n\n\nfor i, item in enumerate(list(vocab.items())[-2:]):\n    print(item)\n\n('&lt;|EOT|&gt;', 1130)\n('&lt;|UK|&gt;', 1131)\n\n\n\nLets now re-build the tokenizer class adding this two features:\n\n\nclass SimpleTokenizerV2:\n    def __init__(self, vocab):\n        self.str_to_int = vocab\n        self.int_to_str = {i: v for v, i in vocab.items()}\n\n    def encode(self, text):\n        # split each word from [,.\"'?!();]\n        preprocessed = re.split(r'([,.\"!()?;\\']|--|\\s)', text)\n        # cut white spaces from each item in preprocessed\n        preprocessed = [item.strip() for item in preprocessed if item.strip()]\n        # if the token isn't in the vocab mark it as uknown\n        preprocessed = [item if item in self.str_to_int else \"&lt;|UK|&gt;\" for item in preprocessed]\n        ids = [self.str_to_int[s] for s in preprocessed]\n        return ids\n    def decode(self, ids):\n        # add space after each element in int_to_str\n        text = \" \".join([self.int_to_str[i] for i in ids])\n        # apply some regulare expression magic \n        text =  text = re.sub(r'\\s+([,.:;?!\"()\\'])', r'\\1', text)\n        return text\n        \n\n\nLets apply the new version of the tokenizer on some text:\n\n\ntxt1 = \"Hello, my name is Ismail!\"\ntxt2 = \"I like to drink Tea.\"\ntxts = \" &lt;|EOT|&gt; \".join((txt1, txt2))\ntxts\n\n'Hello, my name is Ismail! &lt;|EOT|&gt; I like to drink Tea.'\n\n\n\nNow we tokenize this example:\n\n\ntokenizer = SimpleTokenizerV2(vocab)\ntokenizer.encode(txts)\n\n[1131, 5, 697, 1131, 584, 1131, 0, 1130, 53, 628, 1016, 1131, 1131, 7]\n\n\n\nAs we see the &lt;|EOT|&gt; token’s ID is 1130 as axpected.\nThe list of ids also contains 1131 which represent unkown words.\nWe can detokenize the sentences and see them:\n\n\ntokenized = tokenizer.encode(txts)\ndetokenized = tokenizer.decode(tokenized)\ndetokenized\n\n'&lt;|UK|&gt;, my &lt;|UK|&gt; is &lt;|UK|&gt;! &lt;|EOT|&gt; I like to &lt;|UK|&gt; &lt;|UK|&gt;.'\n\n\n\nthere is more special tokenz we could add to our raw text dataset:\n\nEOS End-of-Sentence similar to EOT it indicate where the sentence begin which allo the llm to learn more the sturcture of the dataset.\nBOS Begin-Of-Sentence works along with EOS to containerize each sentence and force llm to learn boundaries between sentences.\nPAD Padding is added to short sentences in odrer to make sure all sentences has the same size length.\n\nThe origional GPT model doesn’t use any of these special tokens except EOT including the UN toekn for out-of-vocabulary marker since it uses bytes-pair-encoding.\n\n\n\nByte pair Encoding:\n\nThe Byte-pair-encoding BPE is a technique used in the tokenization schema for training most GPT models.\nWe will use a library called Tiktoken to tokenize our input text in much efficient way that our TokenizeV2 class.\n\n\nfrom importlib.metadata import version\nimport tiktoken\nprint(\"tiktoken version:\", version(\"tiktoken\"))\n\ntiktoken version: 0.8.0\n\n\n\nInstantiate the tokenizer using the schema of GPT:\n\n\ntokenizer = tiktoken.get_encoding('gpt2')\n\n\ntext = \"hi my name is Ismail &lt;|endoftext|&gt; I like the rainy weather someweirdsyntax!\"\ntokenz = tokenizer.encode(text, allowed_special={\"&lt;|endoftext|&gt;\"})\ntokenz\n\n[5303,\n 616,\n 1438,\n 318,\n 1148,\n 4529,\n 220,\n 50256,\n 314,\n 588,\n 262,\n 37259,\n 6193,\n 4209,\n 68,\n 1447,\n 1837,\n 41641,\n 0]\n\n\n\nNow decode the tokenz into words again\n\n\nwords = tokenizer.decode(tokenz)\nwords\n\n'hi my name is Ismail &lt;|endoftext|&gt; I like the rainy weather someweirdsyntax!'\n\n\n\nThe &lt;|endoftext|&gt; is assigned to a large id: 50256.\n\nGPT2 vocabulary has 5027 so basically &lt;|endoftext|&gt; is assinged to the largest id.\n\nThe tiktoken handels someweirdsyntax just like any other word.\nThe tiktoken library handles larger or unknown words by breaking them down into subwords or smaller tokens. This process is based on the Byte Pair Encoding (BPE) algorithm, which tiktoken uses.\n\nFor large words: The word is split into smaller, frequently occurring subword units (e.g., “transformation” might become “transform” and “ation”). These subword units are part of the tokenizer’s vocabulary.\nFor unknown words: If a word or sequence is not in the vocabulary, the tokenizer falls back to encoding it as a sequence of smaller tokens, often down to individual characters or byte-level tokens if necessary.\n\nThis approach ensures that any input can be tokenized, even if the word is rare or entirely unseen\n\n\nweird_words = ['wakapondiom', 'jumanymasoodi', 'kumarytifor']\nint_list = [tokenizer.encode(word) for word in words]\nword1 = tokenizer.encode(weird_words[0])\nword2 = tokenizer.encode(weird_words[1])\nword3 = tokenizer.encode(weird_words[2])\n\n\nword1, word2, word3\n\n([86, 461, 499, 623, 29005],\n [73, 388, 1092, 5356, 702, 72],\n [74, 388, 560, 49929, 273])\n\n\n\n\nData sampling with a sliding window:\n\nFor Language Modeling (Causal or Autoregressive Models)\n\nInput: A sequence of tokens (e.g., a sentence or text passage).\nTarget: The next token(s) in the sequence.\n\nExample:\n\nInput: “The cat sat on the”\nTarget: “mat”\nThe model learns to predict the next word or token based on the given input.\n\nLets implement dataloader that fetches the input-target pairs from the dataset using the sliding window approch:\n\nfirst tokenize the dataset using BPE:\n\n\n\nencode_text = tokenizer.encode(raw_text)\n\n\n# slice out the first 50 data points\nsmpl_text = encode_text[50:]\n\n\nHere we create the input-target window by assigning x to the current/input token and y to the next/target token:\n\n\n# First creat context window:\ncontext_window = 4\n# Create the input tokens:\nx = smpl_text[:context_window]\n# Create the next token to predict:\ny = smpl_text[1: context_window+1]\nprint(x)\nprint(f\"     {y}\")\n\n[290, 4920, 2241, 287]\n     [4920, 2241, 287, 257]\n\n\n\nAfter processing the current token the llm will shift to the next token untill the last one:\n\n\nfor i in range(1,context_window + 1):\n    current = smpl_text[:i]\n    desired = smpl_text[i]\n    print(current, '---&gt;', desired)\n\n[290] ---&gt; 4920\n[290, 4920] ---&gt; 2241\n[290, 4920, 2241] ---&gt; 287\n[290, 4920, 2241, 287] ---&gt; 257\n\n\n\nConvert the same tokens into words again using the same method:\n\n\nfor i in range(1, context_window+1):\n    current = smpl_text[:i]\n    desired = smpl_text[i]\n    print(f\"{tokenizer.decode(current)} ----&gt; {tokenizer.decode([desired])}\")\n\n and ----&gt;  established\n and established ----&gt;  himself\n and established himself ----&gt;  in\n and established himself in ----&gt;  a\n\n\n\nNow we need to implement efficient data loader that iterate over dataset and returns pairs of Input --&gt; Target pairs tokens as Tensors. \nWe will built-in Pytorch Dataset & DataLoader classes:\n\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\n\nclass GPTDatasetV1(Dataset):\n    def __init__(self, txt, tokenizer, max_length, stride):\n        self.input_ids = []\n        self.target_ids = []\n        token_ids = tokenizer.encode(txt)\n        \n        for i in range(0, len(token_ids)-max_length, stride):\n            input_chunk = token_ids[i:i + max_length]\n            target_chunk = token_ids[i+1: i+max_length+1]\n            self.input_ids.append(torch.tensor(input_chunk))\n            self.target_ids.append(torch.tensor(target_chunk))\n    \n    def __len__(self):\n        return len(self.input_ids)\n\n    def __getitem__(self, idx):\n        return self.input_ids[idx], self.target_ids[idx]\n                \n\n\nParameters:\n\ntxt: A large text sequence to process (e.g., the dataset for training).\ntokenizer: A tokenizer object that encodes text into token IDs (e.g., Hugging Face tokenizer).\nmax_length: The maximum length of each input sequence for the model.\nstride: The step size for creating overlapping sequences.\n\nAttributes:\n\nself.input_ids: Stores the input token sequences for the model.\nself.target_ids: Stores the corresponding target sequences (shifted version of input for next-token prediction).\n\nTokenization:\n\ntokenizer.encode(txt) converts the input text into a list of token IDs (token_ids).\n\nSliding Window with Stride:\n\nrange(0, len(token_ids) - max_length, stride) iterates through the tokenized text in steps of stride.\nAt each step:\n\nInput Chunk: token_ids[i:i + max_length] selects max_length tokens starting from index i.\nTarget Chunk: token_ids[i + 1: i + max_length + 1] selects the next max_length tokens (input shifted by 1 token for next-token prediction).\n\n\nAppending Chunks:\n\nThe input and target chunks are converted into PyTorch tensors and appended to self.input_ids and self.target_ids, respectively.\n\nReturns the number of input-target pairs in the dataset.\nTakes an index idx and returns the corresponding input_ids and target_ids as a tuple.\nThis allows the dataset to be indexed like a list.\nThis dataset would create input-target pairs for training a GPT model, ensuring that the model can learn from overlapping sequences in the text.\n\n\ndef DataLoaderGPTV1(txt, batch_size=4, max_length=256, \n                    stride=128, shuffle= True, drop_last= True, num_workers= 0):\n    tokenizer = tiktoken.get_encoding('gpt2')\n    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n    dataloader = DataLoader(\n        dataset,\n        batch_size = batch_size,\n        shuffle= shuffle,\n        drop_last=drop_last,\n        num_workers=num_workers)\n    return dataloader\n        \n\n\nHere we test our dataloader for one batch, with context window of size 4:\n\n\nwith open(\"the-veredict.txt\", 'r', encoding='utf-8') as f:\n    raw_txt = f.read()\n    \n\n\ndataloader = DataLoaderGPTV1(raw_txt, batch_size=1, max_length=4, stride=1, shuffle=False)\ndata_iter = iter(dataloader)\n\n\nnext(data_iter)\n\n[tensor([[  40,  367, 2885, 1464]]), tensor([[ 367, 2885, 1464, 1807]])]\n\n\n\nThe first batch returns 2 tensors:\n\nthe first tensor stores the input token IDs.\nand the second tensor stores the target token IDs.\n\nSince we fixed the max_length in 4 we get tensors of size 4.\nThe stride decides of the slide from batch to batch. here since we pick1 the target input will shift by one only.\nHere we use batch of 8 and stride=4\n\n\ndataloader = DataLoaderGPTV1(raw_txt, batch_size= 8, max_length= 4, stride= 4, shuffle= False)\ndata_iter = iter(dataloader)\n\n\nnext(data_iter)\n\n[tensor([[   40,   367,  2885,  1464],\n         [ 1807,  3619,   402,   271],\n         [10899,  2138,   257,  7026],\n         [15632,   438,  2016,   257],\n         [  922,  5891,  1576,   438],\n         [  568,   340,   373,   645],\n         [ 1049,  5975,   284,   502],\n         [  284,  3285,   326,    11]]),\n tensor([[  367,  2885,  1464,  1807],\n         [ 3619,   402,   271, 10899],\n         [ 2138,   257,  7026, 15632],\n         [  438,  2016,   257,   922],\n         [ 5891,  1576,   438,   568],\n         [  340,   373,   645,  1049],\n         [ 5975,   284,   502,   284],\n         [ 3285,   326,    11,   287]])]\n\n\n\n\nCreating token embeddings:\n\nNext step is to create Embeddings from token ID’s.\nEmbeddings are trainable weights that help the model to Learn meanings from words.\nTo fully understand how embedding works we will create simple embedding layer:\n\n\nvocab_size = 6\noutput_dim = 3\n\n\nJust in order to grasp the idea of embedding we imagine that we have a vocabulary of size 6 and each vocab is projected to 3 dimensions.\nHere we use Pytorch to create an embedding layer:\n\n\ntorch.manual_seed(123)\nembedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n\n\n\nThe embedding layer dimensions as created:\n\n\nembedding_layer\n\nEmbedding(6, 3)\n\n\n\nAnd those are the weights that are randomely set:\n\n\nembedding_layer.weight\n\nParameter containing:\ntensor([[ 0.3374, -0.1778, -0.1690],\n        [ 0.9178,  1.5810,  1.3010],\n        [ 1.2753, -0.2010, -0.1606],\n        [-0.4015,  0.9666, -1.1481],\n        [-1.1589,  0.3255, -0.6315],\n        [-2.8400, -0.7849, -1.4096]], requires_grad=True)\n\n\n\nThe weigth matrix contains small values that will be optimized during the training of the LLM.\nEach of the six rows represent a token.\nEach of the three columns represents on dimension of that token.\n\n\nembedding_layer(torch.tensor([3]))\n\ntensor([[-0.4015,  0.9666, -1.1481]], grad_fn=&lt;EmbeddingBackward0&gt;)\n\n\n\n\nEncoding word positions:\n\nSince transformers lack inherent sequence-awareness (they process tokens in parallel), position encoding adds this information to the input embeddings.\nToken position encoding incorporate information about the order of tokens in a sequence.\nThere are two common methods for position encoding:\n\nAbsolute Position Encoding: Assigns a unique position value (e.g., using sinusoidal functions or learned embeddings) to each token’s position in the sequence.\nRelative Position Encoding: Encodes the positional relationship between tokens, focusing on their relative distance rather than their absolute positions.\n\nNow lets build a larger version of the embedding layer with 256 dimensions instead of 3, still this number is way smaller than the original gpt3 with 12288.\nAssuming we have a vocab_size of 50257:\n\n\nvocab_size = 50257\noutput_dim = 256\n\n\ntoken_embedding_layer = torch.nn.Embedding(vocab_size, output_dim)\n\n\nIf we use the our dataloader with this embedding layer, for exmaple with a batch size of 8, for tokens each, we will have tensor of size: 8*4*256\n\n\nmax_length = 4\ndataloader = DataLoaderGPTV1(raw_txt, batch_size=8, max_length=max_length, stride=4, shuffle=False)\n\n\ndata_iter = iter(dataloader)\n\n\ninputs, targets= next(data_iter)\n\n\nprint('Token IDs:\\n', inputs)\nprint('\\nInput shape:\\n', inputs.shape)\n\nToken IDs:\n tensor([[   40,   367,  2885,  1464],\n        [ 1807,  3619,   402,   271],\n        [10899,  2138,   257,  7026],\n        [15632,   438,  2016,   257],\n        [  922,  5891,  1576,   438],\n        [  568,   340,   373,   645],\n        [ 1049,  5975,   284,   502],\n        [  284,  3285,   326,    11]])\n\nInput shape:\n torch.Size([8, 4])\n\n\n\nPass it through the embedding layer we created:\n\n\ntoken_embedding= token_embedding_layer(inputs)\n\n\ntoken_embedding.shape\n\ntorch.Size([8, 4, 256])\n\n\n\nTo create position encoding layer the gpt3 way, we just need to create another embedding layer that has the same dimension as token_embedding_layer:\n\n\ncontext_length = 4\npos_embedding_layer = torch.nn.Embedding(context_length, output_dim)\npos_embedding = pos_embedding_layer(torch.arange(context_length))\npos_embedding.shape\n\ntorch.Size([4, 256])\n\n\n\nThe input to the pos_embeddings is usually a placeholder vector torch.arange(context_length), which contains a sequence of numbers 0, 1, …, up to the maximum input length –1.\n\n\ninput_embedding = token_embedding + pos_embedding\ninput_embedding.shape\n\ntorch.Size([8, 4, 256])"
  },
  {
    "objectID": "posts/Build a Large Language Model/Chapter-2/Untitled.html#key-takeaways-from-chapter-2",
    "href": "posts/Build a Large Language Model/Chapter-2/Untitled.html#key-takeaways-from-chapter-2",
    "title": "Chapter 2: Build a Large Language Model",
    "section": "Key Takeaways from Chapter 2:",
    "text": "Key Takeaways from Chapter 2:\n\nLearned how to tokenize raw text and convert it into a structured format for model input.\nExplored Byte Pair Encoding (BPE) as a way to handle subword units efficiently.\nUnderstood how to convert tokens into token IDs using a vocabulary.\nAdded special context tokens (like BOS and EOS) to guide the model during training.\nUsed a sliding window approach for efficient data sampling from long texts.\nBuilt token embeddings to map token IDs into dense vector representations.\nEncoded positional information so the model can understand word order."
  },
  {
    "objectID": "posts/Fastai_ch4/Questionnaire.html",
    "href": "posts/Fastai_ch4/Questionnaire.html",
    "title": "Chapter 4: Questionnaire",
    "section": "",
    "text": "Q1:\nHow is a grayscale image represented on a computer? How about a color image? ___ * Grayscale image is way of turning an array/tensor to grayscale value on each pixel of that image, the values went from 0 to 256, the darker the pixel the closer to 256.\nQ2:\nHow are the files and folders in the MNIST_SAMPLE dataset structured? Why?\n___\n* MNIST_SAMPLE contains two folders Train and Valid.\n* This method of structuring dataset help the community to compare the results between models by setting the same framework.\nQ3:\nExplain how the “pixel similarity” approach to classifying digits works.\n___\n* First we turn images in tensor, then we stack them together. * we take the mean value of each pixel for all images, this will give us an image that each pixel of it represent the mean of all datset. * Then we classify images by comparing the mean absolute error between that image and the ideal3/ideal7 and see which return low distance.\nQ4:\nWhat is a list comprehension? Create one now that selects odd numbers from a list and doubles them.\n___\n\n# list with odd and even numbers\nlisst =  [1, 2, 3, 4, 5, 31, 17, 70]\n# using list-comprehension to select only odd numbers\ndouble_odd = [2*i for i in lisst if i%2==1]\ndouble_odd\n\n[2, 6, 10, 62, 34]\n\n\nQ5:\nWhat is a “rank-3 tensor”?\n___ * It’s a tensor with 3 dimensions, each can be represented as an array (array of array of array), it’s basically a cube.\nQ6:\nWhat is the difference between tensor rank and shape? How do you get the rank from the shape?\n____\n* Rank represent the dimesion of the tensorm while shape tells how many elemen there’s in each dimension.\nQ7:\nWhat are RMSE and L1 norm?\n___\n* RMSE also called L2 stands dor Root Mean Square Error, while L1 is Least Absolute Error. * This functions are basically the same, we used them to measure distance.\nQ9:\nCreate a 3x3 tensor or array containing the numbers from 1 to 9. Double it. Select the bottom right 4 numbers.\n___\n\nimport torch\n\n\nr3_tens = torch.Tensor(list(range(1,10))).view(3,3)\nr3_tens\n\ntensor([[1., 2., 3.],\n        [4., 5., 6.],\n        [7., 8., 9.]])\n\n\n\ndouble_tens= 2*r3_tens\ndouble_tens\n\ntensor([[ 2.,  4.,  6.],\n        [ 8., 10., 12.],\n        [14., 16., 18.]])\n\n\n\ndouble_tens[1:, 1:]\n\ntensor([[10., 12.],\n        [16., 18.]])\n\n\nQ10:\nWhat is broadcasting?\n___\n* It refers to mathematical operation between different dimensions arrays and tensors.\nQ11:\nAre metrics generally calculated using the training set, or the validation set? Why?\n_____ * Metrics are calculated on validation set, so we have good measure of the model performance.\nQ12&13:\nWhat is SGD?\nWhy does SGD use mini-batches?\n____ * SGD or Stochastic Gradient Descent is an optimization function that help us to update weights and minimize the loss. * SGD updates gradients after each mini batch, otherwise it will take a lot of time if we decide to update the gradients after going through all the dataset, or the model won’t learn much if we decide to updates the gradients after each data point.\nQ14:\nWhat are the seven steps in SGD for machine learning?\n___\n* Initialize the parameters * Calculate the predictions * Calculate the loss * Calculate the gradients * Step the weights * Redo the whole process from step 2 * Stop\nQ15:\nHow do we initialize the weights in a model?\n___\n* Usually we initialize weights by picking random values\nQ16:\nWhat is “loss”?\n___\n* The loss is function that uses the model in order to optimizes it’s predictions\nQ17:\nWhat’s the gradients?\n___\n* The gradients are values that dictate how much should we change the weights in order to minimize the loss\nQ18:\nWhy can’t we always use a high learning rate?\n___\n* Picking a large learning rate will get the loss worse.\nQ19:\nDo you need to know how to calculate gradients yourself? ___\n* It’s important to understand the math behind each concept in Deep Learning, but we don’t need to do everything by ourself, we could use frameworks like pytorch and fastai.\nQ20:\nWhy can’t we use accuracy as a loss function?\n___\n* Loss function changes as the weights changes, but the accuracy only changes when the predictions change.\nQ21:\nDraw the sigmoid function. What is special about its shape?\n___\n* Sigmoid takes an input and return a number always between 0 and 1.\n\ndef sigmoid(x): return 1/(1+torch.exp(-x))\n\n\nfrom fastbook import *\nfrom fastai.vision.widgets import *\n\n\nplot_function(torch.sigmoid, title='Sigmoid', min=-4, max=4)\n\n\n\n\n\n\n\n\nQ22:\nWhat is the difference between a loss function and a metric?\n___\n* Loss is what model uses to optimize the predidictions, while metrics is what we (the ML practitioner) use to understand the performance of the model.\nQ23:\nWhat is the function to calculate new weights using a learning rate?\n___\n* The optimizer function\nQ24:\nWhat does the DataLoader class do?\n___ * Can be used to iterate through data, create batches, transform data..\nQ25:\nWrite pseudocode showing the basic steps taken in each epoch for SGD.\n____\n\npredictions = linear_model(x)\nloss = mnist_loss(predictions, y)\nloss.backward()\nfor parameter in parameters:\n    parameter.data -= parameter.grad.data * learning_rate\n    parameter.grad = None\nQ26:\nCreate a function which, if passed two arguments [1,2,3,4] and ‘abcd’ , returns [(1, ‘a’), (2, ‘b’), (3, ‘c’), (4, ‘d’)] . What is special about that output data structure?\n___\n\nThis kind of datascructure is convinient for machine learning where we need to iterate through dataset.\n\n\ninputs = [1, 2, 3, 4]\nlabels = ['a', 'b', 'c', 'd']\ndef data_func(xb, yb):\n    return list(zip(xb, yb))\ndata_func(inputs, labels)\n\n[(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')]\n\n\nQ27:\nWhat does view in Pytorch do? ____\n* It changes the shape of the tensor without changing it content.\nQ28:\nWhat are the “bias” parameters in a neural network? Why do we need them?\n___\n* Bias allow us to all kind of multiplications without thinking if the inputs are zero in some cases.\nQ29:\nWhat does the @ operator do in Python?\n___\n* In python @ is used to do matrix multiplication.\nQ30:\nWhat does the backward method do?\n___ * Backward tells pytorch to calculate the change in the gradients at that point\nQ31:\nWhy do we have to zero the gradients?\n___ * zero gradients tell pytorch to not track the changes in gradients while we updates the weights.\nQ32:\nWhat information do we have to pass to Learner?\n___ * things we pass to Learner : - DataLoaders - architecture - loss_func - metrics\nQ33:\nShow Python or pseudocode for the basic steps of a training loop.\n____\n\n\n    def train_epoch(model, lr, params):\n        for xb,yb in dl:\n            calc_grad(xb, yb, model)\n            for p in params:\n                p.data -= p.grad*lr\n                p.grad.zero_()\n    for i in range(5):\n        train_epoch(model, lr, params)\n\n\nQ34:\nWhat is “ReLU”? Draw a plot of it for values from -2 to +2.\n___ * ReLU stands from Rectified Linear Unit. This non-linear finction return any negative activations into zero. \nQ35:\nWhat is an “activation function”?\n___ * An activation function is a non-linear function that takes the outputs activations fron one layer of the neural network as inputs and output it after some kind of computation to another layer o NN."
  },
  {
    "objectID": "posts/Fastai_ch4/Questionnaire.html#questionnaire",
    "href": "posts/Fastai_ch4/Questionnaire.html#questionnaire",
    "title": "Chapter 4: Questionnaire",
    "section": "",
    "text": "Q1:\nHow is a grayscale image represented on a computer? How about a color image? ___ * Grayscale image is way of turning an array/tensor to grayscale value on each pixel of that image, the values went from 0 to 256, the darker the pixel the closer to 256.\nQ2:\nHow are the files and folders in the MNIST_SAMPLE dataset structured? Why?\n___\n* MNIST_SAMPLE contains two folders Train and Valid.\n* This method of structuring dataset help the community to compare the results between models by setting the same framework.\nQ3:\nExplain how the “pixel similarity” approach to classifying digits works.\n___\n* First we turn images in tensor, then we stack them together. * we take the mean value of each pixel for all images, this will give us an image that each pixel of it represent the mean of all datset. * Then we classify images by comparing the mean absolute error between that image and the ideal3/ideal7 and see which return low distance.\nQ4:\nWhat is a list comprehension? Create one now that selects odd numbers from a list and doubles them.\n___\n\n# list with odd and even numbers\nlisst =  [1, 2, 3, 4, 5, 31, 17, 70]\n# using list-comprehension to select only odd numbers\ndouble_odd = [2*i for i in lisst if i%2==1]\ndouble_odd\n\n[2, 6, 10, 62, 34]\n\n\nQ5:\nWhat is a “rank-3 tensor”?\n___ * It’s a tensor with 3 dimensions, each can be represented as an array (array of array of array), it’s basically a cube.\nQ6:\nWhat is the difference between tensor rank and shape? How do you get the rank from the shape?\n____\n* Rank represent the dimesion of the tensorm while shape tells how many elemen there’s in each dimension.\nQ7:\nWhat are RMSE and L1 norm?\n___\n* RMSE also called L2 stands dor Root Mean Square Error, while L1 is Least Absolute Error. * This functions are basically the same, we used them to measure distance.\nQ9:\nCreate a 3x3 tensor or array containing the numbers from 1 to 9. Double it. Select the bottom right 4 numbers.\n___\n\nimport torch\n\n\nr3_tens = torch.Tensor(list(range(1,10))).view(3,3)\nr3_tens\n\ntensor([[1., 2., 3.],\n        [4., 5., 6.],\n        [7., 8., 9.]])\n\n\n\ndouble_tens= 2*r3_tens\ndouble_tens\n\ntensor([[ 2.,  4.,  6.],\n        [ 8., 10., 12.],\n        [14., 16., 18.]])\n\n\n\ndouble_tens[1:, 1:]\n\ntensor([[10., 12.],\n        [16., 18.]])\n\n\nQ10:\nWhat is broadcasting?\n___\n* It refers to mathematical operation between different dimensions arrays and tensors.\nQ11:\nAre metrics generally calculated using the training set, or the validation set? Why?\n_____ * Metrics are calculated on validation set, so we have good measure of the model performance.\nQ12&13:\nWhat is SGD?\nWhy does SGD use mini-batches?\n____ * SGD or Stochastic Gradient Descent is an optimization function that help us to update weights and minimize the loss. * SGD updates gradients after each mini batch, otherwise it will take a lot of time if we decide to update the gradients after going through all the dataset, or the model won’t learn much if we decide to updates the gradients after each data point.\nQ14:\nWhat are the seven steps in SGD for machine learning?\n___\n* Initialize the parameters * Calculate the predictions * Calculate the loss * Calculate the gradients * Step the weights * Redo the whole process from step 2 * Stop\nQ15:\nHow do we initialize the weights in a model?\n___\n* Usually we initialize weights by picking random values\nQ16:\nWhat is “loss”?\n___\n* The loss is function that uses the model in order to optimizes it’s predictions\nQ17:\nWhat’s the gradients?\n___\n* The gradients are values that dictate how much should we change the weights in order to minimize the loss\nQ18:\nWhy can’t we always use a high learning rate?\n___\n* Picking a large learning rate will get the loss worse.\nQ19:\nDo you need to know how to calculate gradients yourself? ___\n* It’s important to understand the math behind each concept in Deep Learning, but we don’t need to do everything by ourself, we could use frameworks like pytorch and fastai.\nQ20:\nWhy can’t we use accuracy as a loss function?\n___\n* Loss function changes as the weights changes, but the accuracy only changes when the predictions change.\nQ21:\nDraw the sigmoid function. What is special about its shape?\n___\n* Sigmoid takes an input and return a number always between 0 and 1.\n\ndef sigmoid(x): return 1/(1+torch.exp(-x))\n\n\nfrom fastbook import *\nfrom fastai.vision.widgets import *\n\n\nplot_function(torch.sigmoid, title='Sigmoid', min=-4, max=4)\n\n\n\n\n\n\n\n\nQ22:\nWhat is the difference between a loss function and a metric?\n___\n* Loss is what model uses to optimize the predidictions, while metrics is what we (the ML practitioner) use to understand the performance of the model.\nQ23:\nWhat is the function to calculate new weights using a learning rate?\n___\n* The optimizer function\nQ24:\nWhat does the DataLoader class do?\n___ * Can be used to iterate through data, create batches, transform data..\nQ25:\nWrite pseudocode showing the basic steps taken in each epoch for SGD.\n____\n\npredictions = linear_model(x)\nloss = mnist_loss(predictions, y)\nloss.backward()\nfor parameter in parameters:\n    parameter.data -= parameter.grad.data * learning_rate\n    parameter.grad = None\nQ26:\nCreate a function which, if passed two arguments [1,2,3,4] and ‘abcd’ , returns [(1, ‘a’), (2, ‘b’), (3, ‘c’), (4, ‘d’)] . What is special about that output data structure?\n___\n\nThis kind of datascructure is convinient for machine learning where we need to iterate through dataset.\n\n\ninputs = [1, 2, 3, 4]\nlabels = ['a', 'b', 'c', 'd']\ndef data_func(xb, yb):\n    return list(zip(xb, yb))\ndata_func(inputs, labels)\n\n[(1, 'a'), (2, 'b'), (3, 'c'), (4, 'd')]\n\n\nQ27:\nWhat does view in Pytorch do? ____\n* It changes the shape of the tensor without changing it content.\nQ28:\nWhat are the “bias” parameters in a neural network? Why do we need them?\n___\n* Bias allow us to all kind of multiplications without thinking if the inputs are zero in some cases.\nQ29:\nWhat does the @ operator do in Python?\n___\n* In python @ is used to do matrix multiplication.\nQ30:\nWhat does the backward method do?\n___ * Backward tells pytorch to calculate the change in the gradients at that point\nQ31:\nWhy do we have to zero the gradients?\n___ * zero gradients tell pytorch to not track the changes in gradients while we updates the weights.\nQ32:\nWhat information do we have to pass to Learner?\n___ * things we pass to Learner : - DataLoaders - architecture - loss_func - metrics\nQ33:\nShow Python or pseudocode for the basic steps of a training loop.\n____\n\n\n    def train_epoch(model, lr, params):\n        for xb,yb in dl:\n            calc_grad(xb, yb, model)\n            for p in params:\n                p.data -= p.grad*lr\n                p.grad.zero_()\n    for i in range(5):\n        train_epoch(model, lr, params)\n\n\nQ34:\nWhat is “ReLU”? Draw a plot of it for values from -2 to +2.\n___ * ReLU stands from Rectified Linear Unit. This non-linear finction return any negative activations into zero. \nQ35:\nWhat is an “activation function”?\n___ * An activation function is a non-linear function that takes the outputs activations fron one layer of the neural network as inputs and output it after some kind of computation to another layer o NN."
  },
  {
    "objectID": "posts/Manim-Project/Blog_0.html",
    "href": "posts/Manim-Project/Blog_0.html",
    "title": "Manim Project Part 1: Prepare The Dataset",
    "section": "",
    "text": "The Idea of the project:\n  Exploring the Dataset\n  Filtering Clean Examples\n  Designing Prompt-Format:\n  Mapping Instruction → Output Pairs\n  Train-Validation Split and Saving\n  What’s next?"
  },
  {
    "objectID": "posts/Manim-Project/Blog_0.html#the-idea-of-the-project",
    "href": "posts/Manim-Project/Blog_0.html#the-idea-of-the-project",
    "title": "Manim Project Part 1: Prepare The Dataset",
    "section": "The Idea of the project:",
    "text": "The Idea of the project:\nAs part of my exploration into building a prototype that generates Manim animations from natural language descriptions, I came across the bespoke-manim dataset on Hugging Face. It looked like a perfect starting point — each example includes narration, visual structure, and the Python code used to generate an animation video using ManimCE.\nBut to actually use this dataset for fine-tuning an instruction-following model, I had to reshape it significantly. In this post, I’ll walk through how I approached this process: inspecting the raw dataset, deciding what to keep (and what to filter), and ultimately turning it into a set of instruction → output pairs that a model can learn from."
  },
  {
    "objectID": "posts/Manim-Project/Blog_0.html#exploring-the-dataset",
    "href": "posts/Manim-Project/Blog_0.html#exploring-the-dataset",
    "title": "Manim Project Part 1: Prepare The Dataset",
    "section": "Exploring the Dataset",
    "text": "Exploring the Dataset\nWhen I loaded the dataset, it looked like this:\nDatasetDict({\n    train: Dataset({\n        features: [\n            'subject', 'topic', 'question', 'title', 'narration',\n            'visual_elements', 'equations', 'key_timestamps', 'visual_style',\n            'concept_id', 'python_code', 'scene_class_name', 'generation_time',\n            'filename', 'message', 'error', 'stdout', 'stderr', 'video',\n            'instruction', 'output'\n        ],\n        num_rows: 1000\n    })\n})\nAt first glance, I noticed that not all of the 1000 entries were usable. Some had Python code that failed to execute (captured in the error field), and others were missing videos entirely — which probably meant the code never produced a usable animation.\nAlso I noticed that many fields are created in order to store some meta data.\nAfter analyzing each field’s potential value for fine-tuning I think not all fields are necessary:\n\nEssential Fields:\n\nquestion : Core input that defines what the animation should explain\npython_code - The target output the model needs to generate\ntitle - Provides concise focus for the animation\nnarration - Detailed explanation that significantly shapes the animation’s content\nvisual_elements- Critical for understanding what should be visually represented in the code\nequations - Mathematical formulas that need to be rendered in the animation\n\nPotentially Useful Fields:\n\nsubject and topic - Provide context that might help the model generate more appropriate code\nvisual_style - Contains styling information that influences the visual appearance\nkey_timestamps - Provides structure for the animation sequence\n\nUnnecessary Fields:\n\nscene_class_name - Typically derived from the code itself\ngeneration_time - Metadata unlikely to influence code generation\nfilename, message - More metadata\nstdout, stderr - Execution logs not needed for generation\nerror - sould be already filtered for successful examples\nvideo - The rendered output, not needed for training\nconcept_id - not needed"
  },
  {
    "objectID": "posts/Manim-Project/Blog_0.html#filtering-clean-examples",
    "href": "posts/Manim-Project/Blog_0.html#filtering-clean-examples",
    "title": "Manim Project Part 1: Prepare The Dataset",
    "section": "Filtering Clean Examples",
    "text": "Filtering Clean Examples\nTo keep the training signal clean, I applied a simple filter to remove any examples where:\n\nThe errorfield was not None\nThe video field was None\n\nThis will reduce the size of the dataset but we will have only data-points where the code is executable.\n\ndataset = dataset.filter(\n    lambda example: example['error'] is None and example['video'] is not None\n)\n\n\ndataset\n\nAs expected now we only have 252 which is not bad, since we are now sure that the dataset is high quality."
  },
  {
    "objectID": "posts/Manim-Project/Blog_0.html#designing-prompt-format",
    "href": "posts/Manim-Project/Blog_0.html#designing-prompt-format",
    "title": "Manim Project Part 1: Prepare The Dataset",
    "section": "Designing Prompt-Format:",
    "text": "Designing Prompt-Format:\nAt this point we need to create training examples by combining the essential fields into well-structured prompts paired with the working code. This will give our model the most relevant information while removing noise from the training data.\nLet’s implement this data transformation using the Hugging Face datasets library.\n\ndef create_prompt(example):\n    prompt = f\"Subject: {example['subject']}\\n\"\n    prompt += f\"Topic: {example['topic']}\\n\\n\"\n    prompt += f\"Question: {example['question']}\\n\\n\"\n    prompt += f\"Title: {example['title']}\\n\\n\"\n    prompt += f\"Narration:\\n{example['narration']}\\n\\n\"\n\n    if example['visual_elements'] and len(example['visual_elements']) &gt; 0:\n        prompt += \"Visual Elements:\\n\"\n        for i, elem in enumerate(example['visual_elements']):\n            prompt += f\"- {elem['description']} (Timestamp: {elem['timestamp']})\\n\"\n        prompt += \"\\n\"\n\n    if example['equations'] and len(example['equations']) &gt; 0:\n        prompt += \"Equations:\\n\"\n        for i, eq in enumerate(example['equations']):\n            prompt += f\"- {eq}\\n\"\n        prompt += \"\\n\"\n\n    if example['visual_style']:\n        prompt += f\"Visual Style:\\n{example['visual_style']}\\n\\n\"\n\n    prompt += \"Generate manim code to create this animation:\"\n\n    return prompt\n\n# Create the training dataset with input-output pairs\ndef process_example(example):\n    return {\n        \"instruction\": create_prompt(example),\n        \"output\": example['python_code']\n    }\n\nThis resulted in a rich, semantically meaningful prompt — not just a raw dump of metadata, but something that reads like a real instruction."
  },
  {
    "objectID": "posts/Manim-Project/Blog_0.html#mapping-instruction-output-pairs",
    "href": "posts/Manim-Project/Blog_0.html#mapping-instruction-output-pairs",
    "title": "Manim Project Part 1: Prepare The Dataset",
    "section": "Mapping Instruction → Output Pairs",
    "text": "Mapping Instruction → Output Pairs\nOnce I had a clear structure for the prompt, I turned each example into an input-output pair for fine-tuning:\n\n# Map the function over the filtered dataset\n\ntraining_dataset = dataset.map(process_example)\n\n\n# Select only the columns we need for fine-tuning\n\ntraining_dataset = training_dataset.select_columns([\"instruction\", \"output\"])\n\nNow I had exactly what I needed: a list of instructions describing an animation, and the Manim Python code that generates it."
  },
  {
    "objectID": "posts/Manim-Project/Blog_0.html#train-validation-split-and-saving",
    "href": "posts/Manim-Project/Blog_0.html#train-validation-split-and-saving",
    "title": "Manim Project Part 1: Prepare The Dataset",
    "section": "Train-Validation Split and Saving",
    "text": "Train-Validation Split and Saving\nTo prepare for fine-tuning, I split the dataset into a training and validation set:\n\nfrom datasets import Dataset\ndataset_split = training_dataset['train'].train_test_split(test_size=0.1)\ntrain_dataset = dataset_split['train']\nvalidation_dataset = dataset_split['test']\n\nI also saved each split to disk and pushed the final version to the Hugging Face Hub:\n\ntrain_dataset.save_to_disk(\"manim_train_dataset\")\nvalidation_dataset.save_to_disk(\"manim_validation_dataset\")"
  },
  {
    "objectID": "posts/Manim-Project/Blog_0.html#whats-next",
    "href": "posts/Manim-Project/Blog_0.html#whats-next",
    "title": "Manim Project Part 1: Prepare The Dataset",
    "section": "What’s next?",
    "text": "What’s next?\nThis preprocessing pipeline is just the first step in my journey to build a system that can generate Manim animations from natural language prompts. Now that I have a clean dataset of instruction → output pairs, I can move on to experimenting with fine-tuning small instruction-following models like Mistral or Phi.\nThe end goal is to create a workflow where you can go from:\nA structured prompt →  Valid Manim code →  A rendered animation\nThere’s still a lot to explore — from prompt engineering and model evaluation, to automated testing of generated code and scalable video rendering. But having this dataset ready brings me much closer to building a working prototype."
  },
  {
    "objectID": "posts/Fastai_ch7/Questionnaire.html",
    "href": "posts/Fastai_ch7/Questionnaire.html",
    "title": "Chapter 7: Questionnaire",
    "section": "",
    "text": "Q1:\nWhat is the difference between ImageNet and Imagenette? When is it better to experiment on one versus the other?\n* ImageNet is dataset with 1.3 million images and 1000 gategories, while Imagenette is a dataset that represent a small portion of ImageNet with 10 classes. * For studying/devloping ideas/ prototyping we better use a small dataset.\nQ2:\nWhat is normalization?\n* Normalization is a method that get the mean close to 0, and the standar diviation clos to 1 (ideally mean==0, std==1)\nQ3:\nWhy didn’t we have to care about normalization when using a pretrained model?\n* Using pretrained models through vision_learner set the Normalization method automatically.\nQ4:\nWhat is progressive resizing?\n* Progressive resizing is the idea of using small images in the earlier epochs of training phase, then changing the size of the images by a bit and fine tune the model for more epochs, repeat this process till we reach the original size of the image from the dataset.\nQ5:\nWhat is test time augmentation? How do you use it in fastai?\n* Validation set by default uses centre crop for images, which will leads to information lost, TTA addresses this problem by cropping from multiple areas of the image and calculate the predictions of all this crops, then take the average(or the max). preds,targs = learn.tta()\naccuracy(preds, targs).item()\nQ6:\nIs using TTA at inference slower or faster than regular inference? Why?\n* It will take more time than regular inference, because the model calculate the prediction of an image more than once.\nQ7:\nWhat is Mixup? How do you use it in fastai?\n* It’s a data augmenatation method that takes 2 images and mix them together. In fastai mixup used as callback : cbs=Mixup()\nQ10:\nWhat is the idea behind label smoothing?\n* It’s a technique that change the one-hot-encodings value from 0 and 1 to float values, this reduce the overfitting and produce better performance.\nQ11:\nWhen using label smoothing with five categories, what is the target associated with the index 1?\n\nlabels = [0, 1, 0, 0, 0]\nparam = 0.1\n\ndef label_smoothing(labels, param):\n    new_labels = []\n    for label in labels:\n        if label == 1:\n            new_label = 1 - param + param / len(labels)\n            new_labels.append(new_label)\n        else:\n            new_label = param / len(labels)\n            new_labels.append(new_label)\n    return new_labels\n\nlabel_smoothing(labels, param)\n\n[0.02, 0.92, 0.02, 0.02, 0.02]\n\n\nQ12:\nWhat is the first step to take when you want to prototype quick experiments on a new dataset?\n* First do the protoype and experiments, if it takes more than couple of minutes, then we need to consider new subset of that dataset."
  },
  {
    "objectID": "posts/HuggingFace_1/HuggingFace_NLP_course_Notes.html",
    "href": "posts/HuggingFace_1/HuggingFace_NLP_course_Notes.html",
    "title": "Hugging Face Course Notes: Chapter1",
    "section": "",
    "text": "In this series I wiil cover notes I took from the Hugging Face NLP course with code snippets and examples.\n\n\n\nIn this course we will have 9 Chapters\nFrom chapter 1 to 4 we will cover the main conceptsof **Transformers** library:\n\nHow transformer models works\nHow to use a model from Hugging Face Hub\nHow to fine-tune it on your dataset and share the result\n\nChapter 5 to 8 covers the basics of HF Datasets and Tokenizer"
  },
  {
    "objectID": "posts/HuggingFace_1/HuggingFace_NLP_course_Notes.html#course-overview",
    "href": "posts/HuggingFace_1/HuggingFace_NLP_course_Notes.html#course-overview",
    "title": "Hugging Face Course Notes: Chapter1",
    "section": "",
    "text": "In this course we will have 9 Chapters\nFrom chapter 1 to 4 we will cover the main conceptsof **Transformers** library:\n\nHow transformer models works\nHow to use a model from Hugging Face Hub\nHow to fine-tune it on your dataset and share the result\n\nChapter 5 to 8 covers the basics of HF Datasets and Tokenizer"
  },
  {
    "objectID": "posts/Fastai_ch5/Questionnaire.html",
    "href": "posts/Fastai_ch5/Questionnaire.html",
    "title": "Chapter 5: Questionnaire",
    "section": "",
    "text": "Q1:\nWhy do we first resize to a large size on the CPU, and then to a smaller size on the GPU?\n\nReisizing images is done image per image on cpu, while transformation is done one gpu. This method is called presizing:\n\ncrop the image and resize it to 460 by 460 first, this operation is done on CPU.\nthen we do the data augmentation in batches, by cropping a rotated random part of that 460^2 image, and taking the cropped image then resize again to a 224 by 224 image, all this operation are done on batch level, which mean on GPU\n\n\nQ2:\nIf you are not familiar with regular expressions, find a regular expression tutorial, and some problem sets, and complete them. Have a look on the book’s website for suggestions.\n\nWill write serie of blog posts about Regular Expression\n\nQ3:\nWhat are the two ways in which data is most commonly provided, for most deep learning datasets?\n\nData is usually provided as :\n\nIndividual files like images of text\nComma separted Values csv.\n\n\nQ4:\nLook up the documentation for L and try using a few of the new methods that it adds.\n\nLater\n\nQ5:\nLook up the documentation for the Python pathlib module and try using a few methods of the Path class.\n\nLater\n\nQ6:\nGive two examples of ways that image transformations can degrade the quality of the data\n\nInterpolations lead to an image with pixel values that are estimated using estimated pixel values which loses quality each time.\nRotating an image 45 degrees creates empty space in the corners.\n\nQ7:\nWhat method does fastai provide to view the data in a DataLoaders?\nDataLoader.show_batch\nQ8:\nWhat method does fastai provide to help you debug a DataBlock?\nDataBlock.summary\nQ9:\nShould you hold off on training a model until you have thoroughly cleaned your data?\n\nNo. It’s better to start using the building a model as soon as possible, we could even use it as data cleaning tool.**\n\nQ10:\nWhat method does fastai provide to help you debug a DataBlock?\n\nPlot_Confusion_Matrix: for displaying where the model make bad predictions the most.\nPlot_Top_Losses: A method that displays the images with the highest loss value.\n\nQ11:\nWhat are the two pieces that are combined into cross-entropy loss in PyTorch?\n\nSoftmax function and Negative Log Likelihood Loss.\n\nQ12:\nWhat are the two properties of activations that softmax ensures? Why is this important?\n\nIt make sure all activations add uo to 1\nIt help the model to pick one class\n\nQ13:\nWhen might you want your activations to not have these two properties?\n\nWhen we have multi-label classification, more than one label for one image.\n\nQ14:\nCalculate the exp and softmax columns of bear_softmax yourself (i.e., in a spreadsheet, with a calculator, or in a notebook).\nLater\nQ15:\nWhy can’t we use torch.where to create a loss function for datasets where our label can have more than two categories?\n\nWhen we have more than 2 classes to class torch.where it’s not ideal, because it build only to select 1 between 2 categories.\n\nQ16:\nWhat is the value of log(-2)? Why?\n\nThe logarithm is the inverse of the exponential function, which mean logarithm of a value is the result of that value after applying the exponential, and there’s no number that can result a nigative number after the exponential, so log(-2) = not defined\n\nQ17:\nWhat are two good rules of thumb for picking a learning rate from the learning rate finder?\n\nPick Learning rate smaller 10x than the minimum value of loss\nUse the learning rate at the last point that the loss value was decreasing.\n\nQ18:\nWhat two steps does the fine_tune method do?\n\nTrain the added layer using random weights for one epoch\nUnfreeze all the layers and train them all together as normal model for number of epochs\n\nQ19:\nIn Jupyter notebook, how do you get the source code for a method or function?\n\nBy using ?? after the function.\n\nQ20:\nWhat are discriminative learning rates?\n\nIt’s a method that allow us to use different learning rate for each part of the neural network. Using a pretrained model means that the earlier layers are trained for many epochs which mean that the parameters don’t need to be updated by much, in other hand the last layers needs to be matched with task we have. That’s why it’s good to pick slightly smaller value for learning rate for the earlier layers, and bigger one for the last ones.\n\nQ21:\nHow is a Python slice object interpreted when passed as a learning rate to fastai?\n\nThe first value in the slice object sets the lowest learning rate.\nThe second value in the slice object sets the highest learning rate."
  },
  {
    "objectID": "posts/Learning_CPP/basicsLesson2.html",
    "href": "posts/Learning_CPP/basicsLesson2.html",
    "title": "Learning CPP As Pythonista: Day-2",
    "section": "",
    "text": "% gives the remainder of division, perfect for checking parity.\nA boolean variable like iseven stores true/false logic.\nif/else chooses which message to display.\n\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\n\nint main()\n{\n  int number;\n  cout &lt;&lt; \"Please enter a Number: \" &lt;&lt; endl;\n  cin &gt;&gt; number;\n\n  bool iseven = number % 2 == 0;\n  if(iseven)\n  {\n    cout &lt;&lt; number &lt;&lt; \" is an even number\" &lt;&lt; endl;\n  }\n  else\n  {\n    cout &lt;&lt; number &lt;&lt; \" is an odd number\" &lt;&lt; endl;\n  }\n\n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/basicsLesson2.html#even-odd",
    "href": "posts/Learning_CPP/basicsLesson2.html#even-odd",
    "title": "Learning CPP As Pythonista: Day-2",
    "section": "",
    "text": "% gives the remainder of division, perfect for checking parity.\nA boolean variable like iseven stores true/false logic.\nif/else chooses which message to display.\n\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\n\nint main()\n{\n  int number;\n  cout &lt;&lt; \"Please enter a Number: \" &lt;&lt; endl;\n  cin &gt;&gt; number;\n\n  bool iseven = number % 2 == 0;\n  if(iseven)\n  {\n    cout &lt;&lt; number &lt;&lt; \" is an even number\" &lt;&lt; endl;\n  }\n  else\n  {\n    cout &lt;&lt; number &lt;&lt; \" is an odd number\" &lt;&lt; endl;\n  }\n\n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/basicsLesson2.html#weekly-payout",
    "href": "posts/Learning_CPP/basicsLesson2.html#weekly-payout",
    "title": "Learning CPP As Pythonista: Day-2",
    "section": "Weekly Payout:",
    "text": "Weekly Payout:\n\nSimple payroll logic with overtime calculation.\nHours above 40 are paid at 1.5x the regular rate.\nRead multiple inputs from the user and compute the result.\n\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\nint main()\n{\n  float hourPerWeek;\n  float payPerHour;\n  string name;\n  float weekPayout;\n\n  cout &lt;&lt; \"How many Hours did you work last week: \" &lt;&lt; endl;\n  cin &gt;&gt; hourPerWeek;\n  cout &lt;&lt; \"How much you earn per hour: \" &lt;&lt; endl;\n  cin &gt;&gt; payPerHour;\n  cout &lt;&lt; \"What's your name: \" &lt;&lt; endl;\n  cin &gt;&gt; name;\n\n  if(hourPerWeek &lt;= 40.0)\n  {\n    weekPayout = hourPerWeek * payPerHour;\n    cout &lt;&lt; name &lt;&lt; \" earned \" &lt;&lt; weekPayout &lt;&lt; \"$$.\" &lt;&lt; endl;\n  }\n  else:\n  {\n    weekPayout = ((payPerHour * 40.0) + ((hourPerWeek - 40) * (payPerHour * 1.5)));\n    cout &lt;&lt; name &lt;&lt; \"  earned \" &lt;&lt; weekPayout &lt;&lt; \"$$.\" &lt;&lt; endl;\n  }\n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/basicsLesson2.html#water-temperature",
    "href": "posts/Learning_CPP/basicsLesson2.html#water-temperature",
    "title": "Learning CPP As Pythonista: Day-2",
    "section": "Water Temperature:",
    "text": "Water Temperature:\n\nNested if statements help handle several rules inside one category.\nLogical OR || checks if the scale is either C or F.\nDifferent boiling/freezing points for Celsius vs Fahrenheit.\nProvide feedback for invalid input.\n\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\nint main()\n{\n  float temp;\n  char tempScale;\n  cout &lt;&lt; \"Enter in the temperature: \" &lt;&lt; endl;\n  cin &gt;&gt; temp;\n  cout &lt;&lt; \"Enter temperature scale ( C or F ): \" &lt;&lt; endl;\n  cin &gt;&gt; tempScale;\n\n  if( tempScale == 'C' || tempScale == 'F')\n  {\n    if(tempScale == 'F')\n    {\n      if(temp &lt;= 32.0)\n      {\n        cout &lt;&lt; \"Water will turn to ice at \"&lt;&lt;temp&lt;&lt; \" F degrees.\" &lt;&lt; endl;\n        \n      }\n      else if(temp &gt;= 212.0)\n      {\n        cout &lt;&lt; \"Water will turn to steam at \" &lt;&lt;temp&lt;&lt; \" F degrees.\" &lt;&lt; endl;\n\n      }\n      else\n      {\n        cout &lt;&lt; \"Water will stay liquid at \" &lt;&lt; temp&lt;&lt; \" F degrees.\" &lt;&lt; endl;\n      }\n    \n    }\n    else\n    {\n      if(temp &lt;= 0.0)\n      {\n        cout &lt;&lt; \"Water will turn to ice at \" &lt;&lt; temp &lt;&lt; \" C degrees.\" &lt;&lt; endl;\n      }\n      else if(temp &gt;= 100.0)\n      {\n        cout &lt;&lt; \"Water will turn to steam at \" &lt;&lt; temp &lt;&lt; \"C degrees.\" &lt;&lt; endl;\n      }\n      else\n      {\n        cout &lt;&lt; \"water will stay liquid at \" &lt;&lt; temp &lt;&lt; \"C degrees.\" &lt;&lt; endl;\n      }\n    }\n  }\n  else \n  {\n    cout &lt;&lt; \"You entered an invalid temperature scale. Please run the program again.\" &lt;&lt;endl;\n  }\n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/basicsLesson2.html#number-of-the-day-if-else-if",
    "href": "posts/Learning_CPP/basicsLesson2.html#number-of-the-day-if-else-if",
    "title": "Learning CPP As Pythonista: Day-2",
    "section": "Number of the Day (If / else if):",
    "text": "Number of the Day (If / else if):\n\nChain of else if to match a specific number with its weekday.\nDemonstrates grouping conditions like weekend vs weekday.\nA good example where many comparisons might get messy.\n\n\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\n// slightly different version of switch.cpp\n// using || and && and adding weekend \n\n\nint main()\n{\n  int dayNum;\n  cout &lt;&lt; \"Enter a number day (1 Sunday, 2 Monday, 3 Tuesday .. etc\" &lt;&lt; endl;\n  cin &gt;&gt; dayNum;\n  cout &lt;&lt; \"You selected \";\n  \n  if(dayNum == 1)\n  {\n    cout &lt;&lt; \"Sunday. \";\n\n  }\n  else if(dayNum == 2)\n  {\n    cout &lt;&lt; \"Monday. \";\n  }\n  else if(dayNum == 3)\n  {\n    cout &lt;&lt; \"Tuesday. \";\n  }\n  else if(dayNum == 4)\n  {\n    cout &lt;&lt; \"Wednesday. \";\n  }\n  else if(dayNum == 5)\n  {\n    cout &lt;&lt; \"Thursday. \";\n  }\n  else if(dayNum == 6)\n  {\n    cout &lt;&lt; \"Friday. \";\n  }\n  else if(dayNum == 6)\n  {\n    cout &lt;&lt; \"Saturday. \";\n  }\n  else\n    cout &lt;&lt; \"Please enter a valid day. \";\n\n\n  if(dayNum == 1 || dayNum == 7)\n  {\n    cout &lt;&lt; \"It's a weekend.\";\n  }\n  else if(dayNum &gt;=2 && dayNum &lt;= 6)\n  {\n    cout &lt;&lt; \"It's a weekday.\" &lt;&lt; endl;\n  }\n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/basicsLesson2.html#number-of-the-day-switch",
    "href": "posts/Learning_CPP/basicsLesson2.html#number-of-the-day-switch",
    "title": "Learning CPP As Pythonista: Day-2",
    "section": "Number of the Day (switch):",
    "text": "Number of the Day (switch):\n\nswitch is a cleaner choice for fixed numeric options.\nEach case handles one specific value.\nbreak prevents “falling through” to the next case.\ndefault is like the else of switch statements.\n\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n// same as what I did in switch.cpp but now I will use swith instead of if statements.\n\nint main()\n{\n  int dayNumber;\n  cout &lt;&lt; \"Enter a number day ( 1 for Sunday, 2 Monday, 3 Tuesday ...etc)\" &lt;&lt; endl;\n  cin &gt;&gt; dayNumber;\n  \n\n  switch(dayNumber)\n  {\n    case 1:\n      cout &lt;&lt; \"Sunday. \" &lt;&lt; endl;\n      break;\n    case 2:\n      cout &lt;&lt; \"Monday. \" &lt;&lt; endl;\n      break;\n    case 3:\n      cout &lt;&lt; \"Tuesday. \" &lt;&lt; endl;\n      break;\n    case 4:\n      cout &lt;&lt; \"Wednesday. \" &lt;&lt; endl;\n      break;\n    case 5:\n      cout &lt;&lt; \"Thursday. \" &lt;&lt; endl;\n      break;\n    case 6:\n      cout &lt;&lt; \"Friday. \" &lt;&lt; endl;\n      break;\n    case 7:\n      cout &lt;&lt; \"Saturday. \" &lt;&lt; endl;\n      break;\n    default:\n      cout &lt;&lt; \"an invalid day. \" &lt;&lt; endl;\n  }\n  return 0;\n\n}"
  },
  {
    "objectID": "posts/Learning_CPP/basicsLesson2.html#day-2-summarization",
    "href": "posts/Learning_CPP/basicsLesson2.html#day-2-summarization",
    "title": "Learning CPP As Pythonista: Day-2",
    "section": "Day 2 Summarization :",
    "text": "Day 2 Summarization :\nHere is what I achieved:\n\nI learned the if statement, the first building block of logical decision-making.\nI used comparison operators like ==, &lt;=, and &gt;= to evaluate conditions.\nI combined conditions using logical operators such as || and &&.\nI controlled program behavior with if / else / else if chains for multiple outcomes.\nI explored switch as a cleaner option for specific numeric cases.\nI wrote several mini programs with real-world logic:\n\nEven or odd number checker\nWeekly pay calculator with overtime\nWater state detector (ice, liquid, steam)\nDay-of-the-week selector (two versions)"
  },
  {
    "objectID": "posts/Learning_CPP/basics_Lesson1.html",
    "href": "posts/Learning_CPP/basics_Lesson1.html",
    "title": "Learning CPP As Pythonista: Day-1",
    "section": "",
    "text": "In this series of lessons, I will track my learning through the universe of C++ as someone who mainly program in Python.\nThe motivation behind learning C++ in 2025 can be resumed into one word: Cuda.\nCUDA kernels are still C++ first, Python second. Learning the bare-metal steps so I can stop guessing and start writing fast GPU code. One small page a day until the compiler feels normal.\nThis idea of learning C++ for CUDA make it less intimidating, since C++ isn’t the goal here rather just a tool for something else.\nBut still I need to learn some basics of C++ in order to navigate its world that already after one studying session looks very strange and outlandish for a Python programmer."
  },
  {
    "objectID": "posts/Learning_CPP/basics_Lesson1.html#motivation",
    "href": "posts/Learning_CPP/basics_Lesson1.html#motivation",
    "title": "Learning CPP As Pythonista: Day-1",
    "section": "",
    "text": "In this series of lessons, I will track my learning through the universe of C++ as someone who mainly program in Python.\nThe motivation behind learning C++ in 2025 can be resumed into one word: Cuda.\nCUDA kernels are still C++ first, Python second. Learning the bare-metal steps so I can stop guessing and start writing fast GPU code. One small page a day until the compiler feels normal.\nThis idea of learning C++ for CUDA make it less intimidating, since C++ isn’t the goal here rather just a tool for something else.\nBut still I need to learn some basics of C++ in order to navigate its world that already after one studying session looks very strange and outlandish for a Python programmer."
  },
  {
    "objectID": "posts/Learning_CPP/basics_Lesson1.html#c-world",
    "href": "posts/Learning_CPP/basics_Lesson1.html#c-world",
    "title": "Learning CPP As Pythonista: Day-1",
    "section": "C++ World:",
    "text": "C++ World:\n\nC++ is a Compiled language, which means the code goes through a transformation process before it can run.\nIn C++, we write code then a special program called Compiler translates our Human-readable code into machine code (1s & 0s) that computer can executes.\nThis process of compiling works in 4 stages:\n\nStage1: Pre-processing before the compiler even looks at our code, it’s a text manipulation step where the preprocessor check code that starts with # and copy-past, find-replace it automatically, so the next step include only pure C++ code.\nStage2: The compiler reads the C++ code and converts it to Assembly Language, which is a human readable instructions that are very close to machine code.\nStage3: An Assembler converts assembly into actual 1s & 0s that the CPU understands.\nStage4: A Linker connects everything together (code, libraries, other file..) and creates the final executable file that can run.\n\n\n\n\nCode\n#include &lt;iostream&gt;\nint main()\n{\n    // print my name in three lines\n    std::cout &lt;&lt; \"Hi, My\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"name is\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Ismail.\" &lt;&lt; std::endl;\n    // in one line with three string\n    std::cout &lt;&lt; \"Hi, my \" &lt;&lt; \"name is \" &lt;&lt; \"Ismail.\" &lt;&lt;std::endl;\n    // print the whole expression in one string\n    std::cout &lt;&lt; \"Hi, my name is Ismail.\";\n    \n    return 0;\n}\n\n\n\n\nCode\nmain()\n\n\nHi, My\nname is\nIsmail.\nHi, my name is Ismail.\nHi, my name is Ismail.\n\n\n0\n\n\n\nImporting in CPP:\n\nIn order to use libraries and tools in C++ we use the keyword #include, it’s equivalent to import in Python.\nLibrary we used here is iostream which allows us to print in the screen and many more things.\n\n\n\nMain() function:\n\nAll C++ programs has one main() function, it’s the starting point of every program, The main function is called automatically when a C++ program begins.\n\n\nPrinting:\n\nBy using cout we can print text on the screen.\nMore than one piece of data can be printed at a time.\nendl is used after cout to end the line, so the next cout could starts printing next line.\nWe can print multiple pieces of data if we seperate them with &lt;&lt;.\n\n\n\nStatements:\n\nThe lines of code inside main function are called statements.\nAll statements in C++ must end with semi-colon ;.\nThe compiler reads our code and turns it into instructions that a computer can understand (machine instructions).\nThen the compiler will generate an executable program which is just a file filled with machine instructions.\n\nThe compiler uses the semi-colons to know where each statement ends. If you do not include a semi-colon at the end of every statement then you will get a syntax error. A program with syntax errors will not compile and run. #### String:\n\nThe thing printed to the screen is called string, which refers to a groupr of characters inside \"\". #### Comments:\nAs in python comments are non executable code that we put beside the code in order to explain for us or others ideas or concepts in the code.\nIn C++ the comment starts with //.\nThere are two types of comments:\n- single line comments and multi-line comments. All code in between a /* and a */ are called multi-line comments. They will also be ignored by the compiler. When you have a lot to say in a comment you will use these\n\n\n\n\nVariables:\n\nWe will write a program that will find the distance between two points on a graph. It will need variables to hold the points (an X and a Y value for each point) and a variable to hold the length of the line that connects the points.\nSince C++ is a static typing language, we need to declare the type of the variable while creating it, and this variable will only accept the type is assigned to.\nHere we declare a variable var with type int which refers to integer or whole number.\n\n\n\nCode\nint var = 5;\nstd::cout &lt;&lt; \"variable of type integer: \" &lt;&lt; var &lt;&lt; std::endl;\n\n\nvariable of type integer: 5\n\n\n\nA variable is place where we store data in the memory that can be read or written to in a program.\nWe think of variables as boxes that hold data, and each box is distinct in the memory. So every variable lives in a location in memory, and we can retrieve it by name without carrying about it’s location in memory.\n\n\n\nCode\nvoid func()\n{\n    // declare variables\n    int var0;\n    int var1;\n\n    int var2;\n    int var3;\n\n    // assign values to each variable\n    var0 = 1;\n    var1 = 1;\n    var2 = 2;\n    var3 = 2;\n\n    // print the variables value with a message on the screen\n    std::cout &lt;&lt;\"variable 1: \" &lt;&lt;var0&lt;&lt; std::endl;\n    std::cout &lt;&lt;\"variable 2: \" &lt;&lt;var1&lt;&lt; std::endl;\n    std::cout &lt;&lt;\"variable 3: \" &lt;&lt;var2&lt;&lt; std::endl;\n    std::cout &lt;&lt;\"variable 4: \" &lt;&lt;var3&lt;&lt; std::endl;\n}\nfunc();\n\n\nvariable 1: 1\nvariable 2: 1\nvariable 3: 2\nvariable 4: 2\n\n\n\nHere I declared 4 variables of type int, at this point the program requires a box in the memory for each variable.\nThen when I assign each variable to a value, the program will put those values in their correspondent box.\nNow we have what represents the points in a graph: var0 and var1 for point 1 & var2 and var3 for point 2, now we need variable that will hold the value of the distance. The type of that variable must be float number, since it can be decimal.\n\n\n\nCode\nvoid func2()\n{\n    int var0;\n    int var1;\n    int var2;\n    int var3;\n    var0 = 1;\n    var1 = 1;\n    var2 = 2;\n    var3 = 2;\n\n    // declare a float type variable\n\n    float lengthOfline;\n}\n\n\n\nthe variable lengthOfline doesn’t have value yet, so need to calculate the distance: \\(d = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}\\)\nSo we need power and square root. we could multiply the number by itself to obtain the power but the square root need to be hard coded, but luckily we can just import it from math module in C++, which we need to import in order to use the built in function sqrt.\n\n\n\nCode\n#include &lt;cmath&gt;\nvoid func3()\n{ \n    //declare the variables to hold points \n    int x1; \n    int y1; \n \n    int x2; \n    int y2; \n \n    //fill the point variables with data \n    x1 = 2; \n    y1 = 2; \n \n    x2 = 2; \n    y2 = 4; \n \n    //declare a variable to hold the length of a line between two points \n    float lengthOfLine; \n \n    //use the distance formula to find the distance \n    lengthOfLine = sqrt(((x2 - x1) * (x2 - x1)) + ((y2 - y1) * (y2 - y1))); \n \n    //print the length of the line \n    std::cout&lt;&lt;\"The length of the line is: \"&lt;&lt;lengthOfLine&lt;&lt;std::endl; \n  \n}\nfunc3();\n\n\nThe length of the line is: 2\n\n\n\n\nData types:\n\nIn C++ data types are defined once and cannot be changed. If a variable is declared with a specific data type, it can only hold values that suits that data type.\nWe already used int which is a whole number, float a decimal. There are many other types:\n\n\n\nCode\n#include &lt;string&gt;\nusing namespace std;\n\n\n\n\nCode\nvoid basicdtypes()\n{\n    int num = 5;\n    float dec = 5.22;\n    char oneChar = 'K';\n    string name = \"Ismail\";\n\n    cout &lt;&lt;\"this is a whole number: \" &lt;&lt; num &lt;&lt; endl;\n    cout &lt;&lt;\"this is a decimal number: \" &lt;&lt;dec&lt;&lt; endl;\n    cout &lt;&lt; \"this is single character: \" &lt;&lt;oneChar&lt;&lt; endl;\n    cout &lt;&lt; \"This is a string of charaters: \" &lt;&lt;name&lt;&lt; endl;\n}\nbasicdtypes();\n\n\nthis is a whole number: 5\nthis is a decimal number: 5.22\nthis is single character: K\nThis is a string of charaters: Ismail\n\n\n\nchar is a single character between single quotes.\nstring is couple of characters between double quotes, and it’s not primitive type, it must be imported #include &lt;string&gt;\n\n\n\nNumbers types:\n\nTill now we saw 2 numerical data types: int and float.\nA data type defines a few things:\n\nthe operations that can be performed on variables of that type\nthe values that can be stored inside a variable of that type (there is usually a range of acceptable values)\nthe amount of space a variable takes up in memory\n\nThe operations performed on int are: - + / *, the division is the only operation that requires some explanation.\nHere is a division between to integers:\n\n\n\nCode\nvoid divint()\n{\n    int a = 10;\n    int b = 5;\n    int res = a / b;\n    cout &lt;&lt;\"result a / b =&gt; \" &lt;&lt;res&lt;&lt; endl;\n}    \ndivint();\n\n\nresult a / b =&gt; 2\n\n\n\nWhat if we want to divide 2 integers that will causes not a whole number:\n\n\n\nCode\nvoid dvd()\n{\n    int num = 12;\n    int num1 = 2;\n    int res = num / num1;\n    cout &lt;&lt;\"result as num = 12: \" &lt;&lt;res&lt;&lt; endl;\n    num = 13;\n    res = num / num1;\n    cout &lt;&lt;\"result as num = 13: \" &lt;&lt;res&lt;&lt; endl;\n}\ndvd();\n\n\nresult as num = 12: 6\nresult as num = 13: 6\n\n\n\nAt first, the result was 6 which is the obvious answer, but when we predicted 6.5 we still get 6?\nThe reason is that integer division returns the quotient which is always an integer. This is true of all integer divides using the / operator\nThere is another integer division operator called the modulus operator that returns the remainder. The mod operator is the % symbol.\n\n\n\nCode\nvoid divmod()\n{\n     \n    int num1 = 12; \n    int num2 = 2; \n    int result; \n \n    result = num1 / num2; \n    cout &lt;&lt; \"result with / operator: \" &lt;&lt; result &lt;&lt; endl;     \n \n    result = num1 % num2; \n    cout &lt;&lt; \" result with % operator: \" &lt;&lt; result &lt;&lt; endl;\n    \n}\n\ndivmod();\n\n\nresult with / operator: 6\n result with % operator: 0\n\n\n\nA data type also specifies an acceptable range of values.\nAn int variable cannot hold an infinite sized number, there is a limit.\nThere is a built in constant called INT_MAX that holds the largest value that can be stored in any int variable (there is an INT_MIN too).\n\n\n\nCode\n#include &lt;climits&gt;\n\n\n\n\nCode\nint largeNumber;\nlargeNumber = INT_MAX;\ncout&lt;&lt;\"largest number can be stored: \" &lt;&lt;largeNumber&lt;&lt; endl;\n\n\nlargest number can be stored: 2147483647\n\n\n\nAdding one number to that value will causes an out of range error\nThe arithmetic operators for floats are the same as ints except there is no mod operator. float division results in numbers with fractional parts.\nIn case we want to declare a float data type but the value is a whole number we need to explicitly tell the compiler it’s a float number by adding .0:\n\n\n\nCode\n#include &lt;typeinfo&gt;\nvoid wholeFloat()\n{\n    int num1 = 15;\n    float num2 = 15.0;\n    cout &lt;&lt; \"the type of num1 = 15 :  \" &lt;&lt; typeid(num1).name() &lt;&lt; endl;\n    cout &lt;&lt; \"the type of num2 = 15.0 :  \" &lt;&lt; typeid(num2).name() &lt;&lt; endl;\n    \n    \n}\n\nwholeFloat();\n\n\nthe type of num1 = 15 :  i\nthe type of num2 = 15.0 :  f\n\n\n\nWe get i for integer for 15 and f float for 15.0.\n\n\n\nCharacters and strings\n\nstring is very strong type which allows us to make many different things and manipulates data in many ways.\nWhile **char* is a bit hard to work with, since it’s limited and not as versatile as string.\n\n\n\nCode\nvoid chars()\n{\n    \n    char first = 'c';\n    char second = 'h';\n    char third = 'a';\n    char fourth = 'r';\n\n    string word = \"String\";\n    \n    cout &lt;&lt; first &lt;&lt; second &lt;&lt; third &lt;&lt; fourth &lt;&lt; endl;\n    cout &lt;&lt; word &lt;&lt; endl;\n\n}\n\n\n\n\nCode\nchars();\n\n\nchar\nString\n\n\n\nString Operations:\n\nString tyoe has many operation that we could use to manipulate data, like length() which as the name suggests tells us the length of string:\n\n\n\nCode\nstring name = \"Ismail\";\ncout &lt;&lt; \"Number of characters in Ismail is: \" &lt;&lt; name.length() &lt;&lt; endl;\n\n\nNumber of characters in Ismail is: 6\n\n\n\nThe square brackets is another operator that will return an individual character in the string:\n\n\n\nCode\nstring word = \"word\";\nchar letter  = word[0];\ncout &lt;&lt; \"this is a string: \" &lt;&lt; word &lt;&lt; endl;\n// the index is 0 based\ncout &lt;&lt; \"this is the first character of that word: \" &lt;&lt; letter &lt;&lt; endl;\n\n\nthis is a string: word\nthis is the first character of that word: w\n\n\n\nThe + operator concatenates strings together.\n\n\n\nCode\nstring sentence = \"word1\";\nsentence = sentence + \" word2\" + \" word3\" + \" ...\";\ncout &lt;&lt; sentence &lt;&lt; endl;\n\n\nword1 word2 word3 ...\n\n\n\nsubstr is a string function that will create a new string from the innards of another.\nThis function takes a starting position and the number of character to use after that position and copies the characters into a new string.\n\n\n\nCode\nstring sentence = \"find the third word\";\nstring aWord = sentence.substr(9, 5);\ncout &lt;&lt; aWord &lt;&lt; endl;\n\n\nthird\n\n\n\nfind will return the position where the first occurrence of a word is found (and -1 if it is not found).\n\n\n\nCode\nstring sentence = \"where is Aldo ?\";\nint findAldo = sentence.find(\"Aldo\");\ncout &lt;&lt; \"Aldo can be found at this position: \" &lt;&lt; findAldo &lt;&lt; endl;\n\n\nAldo can be found at this position: 9\n\n\n\nerase will remove characters from a string. It takes the starting position of where I want to start removing characters and he total number of characters to get rid of.\n\n\n\nCode\nvoid func()\n{\n    string sentence = \"In this sentence sentence, it must be no repeated word!\";\n    int repeatedWord = sentence.find(\"sentence\");\n    sentence.erase(repeatedWord, 9);\n    cout &lt;&lt; sentence &lt;&lt; endl;\n}\n\n\n\n\nCode\nfunc();\n\n\nIn this sentence, it must be no repeated word!\n\n\n\ninsert adds a new string after the position specified in the string.\n\n\n\nCode\nstring sentence = \", my name is Ismail.\";\nstring greeting = \"Hi\";\nsentence = sentence.insert(0, greeting);\ncout &lt;&lt; sentence &lt;&lt; endl;\n\n\nHi, my name is Ismail.\n\n\n\n\n\nWeekly pay calculator\n\nIn this small program we will use the cin which takes input from users and use it in the program, displays it or further process it.\nIn this program we will calculate the weekly pay from employers by taking inputs from them and use as arguments in a formula in order to calculate.\ncin is part of &lt;iostream&gt; just like cout.\n\n\n\nCode\n#include &lt;iostream&gt;\nusing namespace std;\n\n\n\n\nCode\nvoid calculatePay()\n{\n    float numHoursWorked;\n    float hourlyPayRate;\n    string employeeName;\n    float weeklyPay;\n    \n}\n\n\n\nThe rpoblem with this approach is that we need to add the numbers manually for each employee or ask them the modify the code for themselves, which is inconvenient.\nThe idea is write code that asks them for their informations, stores it and calculates the weekly pay.\n\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\nusing namespace std;\n\nint main()\n{\n  float hoursPerWeek;\n  float hourlyPayRate;\n  string employeeName;\n  float weeklyPay;\n  cout &lt;&lt; \"Enter hours worked per week: \"&lt;&lt; endl;\n  cin &gt;&gt; hoursPerWeek;\n  cout &lt;&lt; \"Enter hourly pay rate: \" &lt;&lt; endl;\n  cin &gt;&gt; hourlyPayRate;\n  cout &lt;&lt; \"Enter your Name: \" &lt;&lt; endl;\n  cin &gt;&gt; employeeName;\n\n  weeklyPay = hoursPerWeek * hourlyPayRate;\n\n  cout &lt;&lt; employeeName &lt;&lt; \" Earned \" &lt;&lt; weeklyPay &lt;&lt; \"$ this week.\" &lt;&lt; endl;\n\n  return 0;\n  }\n\n\n\nI could revisit the distance formula I program earlier and apply the idea of cin values instead of hard coding them like in the first version.\n\n\n\nCode\n// old version\nint main()\n{\n  int x0;\n  int y0;\n  int x1;\n  int y1;\n\n  x0 = 2;\n  y0 = 3;\n  x1 = 3;\n  y1 = 4;\n\n  float distanceFormula;\n\n  distanceFormula = sqrt(((x1 - x0) * (x1 - x0)) - ((y1 - y0) * (y1 - y0))\n\n  return 0;\n  \n}\n\n\n\nIn the new version the values x0, x1, y0, y1 will be decided by the user through cin.\n\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\nint main()\n{\n    float x0, x1, y0, y1;  // Changed to float for better precision\n\n    cout &lt;&lt; \"Please enter the values of the first point: \" &lt;&lt; endl;\n    cout &lt;&lt; \"X: \";\n    cin &gt;&gt; x0;\n    cout &lt;&lt; \"Y: \";\n    cin &gt;&gt; y0;\n\n    cout &lt;&lt; \"Please enter the values of the second point: \" &lt;&lt; endl;\n    cout &lt;&lt; \"X: \";\n    cin &gt;&gt; x1;\n    cout &lt;&lt; \"Y: \";\n    cin &gt;&gt; y1;\n    \n    // distance formula: sqrt((x1-x0)² + (y1-y0)²)\n    float distanceFormula = sqrt(pow(x1 - x0, 2) + pow(y1 - y0, 2));\n    \n    cout &lt;&lt; \"The length of the line is: \" &lt;&lt; distanceFormula &lt;&lt; endl;\n\n    return 0;\n}\n\n\n\nFurther using cin &gt;&gt; in a function where I have to calculate many values and manipulate them:\n\n\n\nCode\n%%writefile gasMileage.cpp\n\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\n\nint main()\n{\n  float distance;\n  string carBrand;\n  string carModel;\n  float carCapacity;\n  float mpg;\n\n  cout &lt;&lt; \"Enter the Distance of the Trip: \" &lt;&lt; endl;\n  cin &gt;&gt; distance;\n\n  cout &lt;&lt; \"Enter the rand of the car: \" &lt;&lt; endl;\n  cin &gt;&gt; carBrand;\n\n  cout  &lt;&lt; \"Enter the car Model: \" &lt;&lt; endl;\n  cin &gt;&gt; carModel;\n\n  cout &lt;&lt; \"Enter the fuel Tank Capacity: \" &lt;&lt; endl;\n  cin &gt;&gt; carCapacity;\n  \n  cout &lt;&lt; \"Enter the MPG of the car: \" &lt;&lt; endl;\n  cin &gt;&gt; mpg;\n\n\n  float mileageOnFullTank;\n  mileageOnFullTank = mpg * carCapacity;\n  float numOfStops = int(distance / mileageOnFullTank);\n  float gasRequired = distance / mpg;\n  float galonsLeft = ((numOfStops+1) * carCapacity) - gasRequired;\n  \n  \n  cout &lt;&lt; \"For a trip of \" &lt;&lt; distance &lt;&lt; \" miles\" &lt;&lt; endl;\n  cout &lt;&lt; \" a \" &lt;&lt; carBrand &lt;&lt; \" model \" &lt;&lt; carModel &lt;&lt; \" requires \" &lt;&lt; gasRequired &lt;&lt; \" Gallons Of Gas \" &lt;&lt; endl;\n  cout &lt;&lt; \" will require \" &lt;&lt; numOfStops &lt;&lt; \" stop for gas \" &lt;&lt; endl;\n  cout &lt;&lt; \" and will have \" &lt;&lt; galonsLeft &lt;&lt; \" gallons of gas left in the tank\" &lt;&lt; endl;\n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/basics_Lesson1.html#day-1-recap",
    "href": "posts/Learning_CPP/basics_Lesson1.html#day-1-recap",
    "title": "Learning CPP As Pythonista: Day-1",
    "section": "Day 1 Recap:",
    "text": "Day 1 Recap:\n\nToday I started exploring C++ as a Python programmer, motivated by my goal of writing CUDA kernels. I covered the following fundamentals:\nThe compilation process (pre-processor → compiler → assembler → linker) and how C++ differs from interpreted languages.\nHow to include libraries using #include, and the special role of the main() function.\nBasic printing with std::cout, ending lines with &lt;&lt; std::endl, and formatting simple output.\nVariables: declaring types explicitly (e.g., int, float), how static typing enforces constraints, and understanding variables as named boxes in memory.\nFundamental data types: integers, floats, characters, strings; string operations like length, indexing, concatenation, substrings.\nA simple user-input example: using std::cin to build a basic “weekly pay” calculator."
  },
  {
    "objectID": "posts/Learning_CPP/basicsLesson1.html",
    "href": "posts/Learning_CPP/basicsLesson1.html",
    "title": "Learning CPP As Pythonista: Day-1",
    "section": "",
    "text": "In this series of lessons, I will track my learning through the universe of C++ as someone who mainly program in Python.\nThe motivation behind learning C++ in 2025 can be resumed into one word: Cuda.\nCUDA kernels are still C++ first, Python second. Learning the bare-metal steps so I can stop guessing and start writing fast GPU code. One small page a day until the compiler feels normal.\nThis idea of learning C++ for CUDA make it less intimidating, since C++ isn’t the goal here rather just a tool for something else.\nBut still I need to learn some basics of C++ in order to navigate its world that already after one studying session looks very strange and outlandish for a Python programmer."
  },
  {
    "objectID": "posts/Learning_CPP/basicsLesson1.html#motivation",
    "href": "posts/Learning_CPP/basicsLesson1.html#motivation",
    "title": "Learning CPP As Pythonista: Day-1",
    "section": "",
    "text": "In this series of lessons, I will track my learning through the universe of C++ as someone who mainly program in Python.\nThe motivation behind learning C++ in 2025 can be resumed into one word: Cuda.\nCUDA kernels are still C++ first, Python second. Learning the bare-metal steps so I can stop guessing and start writing fast GPU code. One small page a day until the compiler feels normal.\nThis idea of learning C++ for CUDA make it less intimidating, since C++ isn’t the goal here rather just a tool for something else.\nBut still I need to learn some basics of C++ in order to navigate its world that already after one studying session looks very strange and outlandish for a Python programmer."
  },
  {
    "objectID": "posts/Learning_CPP/basicsLesson1.html#c-world",
    "href": "posts/Learning_CPP/basicsLesson1.html#c-world",
    "title": "Learning CPP As Pythonista: Day-1",
    "section": "C++ World:",
    "text": "C++ World:\n\nC++ is a Compiled language, which means the code goes through a transformation process before it can run.\nIn C++, we write code then a special program called Compiler translates our Human-readable code into machine code (1s & 0s) that computer can executes.\nThis process of compiling works in 4 stages:\n\nStage1: Pre-processing before the compiler even looks at our code, it’s a text manipulation step where the preprocessor check code that starts with # and copy-past, find-replace it automatically, so the next step include only pure C++ code.\nStage2: The compiler reads the C++ code and converts it to Assembly Language, which is a human readable instructions that are very close to machine code.\nStage3: An Assembler converts assembly into actual 1s & 0s that the CPU understands.\nStage4: A Linker connects everything together (code, libraries, other file..) and creates the final executable file that can run.\n\n\n#include &lt;iostream&gt;\nint main()\n{\n    // print my name in three lines\n    std::cout &lt;&lt; \"Hi, My\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"name is\" &lt;&lt; std::endl;\n    std::cout &lt;&lt; \"Ismail.\" &lt;&lt; std::endl;\n    // in one line with three string\n    std::cout &lt;&lt; \"Hi, my \" &lt;&lt; \"name is \" &lt;&lt; \"Ismail.\" &lt;&lt;std::endl;\n    // print the whole expression in one string\n    std::cout &lt;&lt; \"Hi, my name is Ismail.\";\n    \n    return 0;\n}\nmain()\nHi, My\nname is\nIsmail.\nHi, my name is Ismail.\nHi, my name is Ismail.\n\n\n\n\n0\n\nImporting in CPP:\n\nIn order to use libraries and tools in C++ we use the keyword #include, it’s equivalent to import in Python.\nLibrary we used here is iostream which allows us to print in the screen and many more things.\n\n\n\nMain() function:\n\nAll C++ programs has one main() function, it’s the starting point of every program, The main function is called automatically when a C++ program begins.\n\n\nPrinting:\n\nBy using cout we can print text on the screen.\nMore than one piece of data can be printed at a time.\nendl is used after cout to end the line, so the next cout could starts printing next line.\nWe can print multiple pieces of data if we seperate them with &lt;&lt;.\n\n\n\nStatements:\n\nThe lines of code inside main function are called statements.\nAll statements in C++ must end with semi-colon ;.\nThe compiler reads our code and turns it into instructions that a computer can understand (machine instructions).\nThen the compiler will generate an executable program which is just a file filled with machine instructions.\n\nThe compiler uses the semi-colons to know where each statement ends. If you do not include a semi-colon at the end of every statement then you will get a syntax error. A program with syntax errors will not compile and run. #### String:\n\nThe thing printed to the screen is called string, which refers to a groupr of characters inside \"\". #### Comments:\nAs in python comments are non executable code that we put beside the code in order to explain for us or others ideas or concepts in the code.\nIn C++ the comment starts with //.\nThere are two types of comments:\n- single line comments and multi-line comments. All code in between a /* and a */ are called multi-line comments. They will also be ignored by the compiler. When you have a lot to say in a comment you will use these\n\n\n\n\nVariables:\n\nWe will write a program that will find the distance between two points on a graph. It will need variables to hold the points (an X and a Y value for each point) and a variable to hold the length of the line that connects the points.\nSince C++ is a static typing language, we need to declare the type of the variable while creating it, and this variable will only accept the type is assigned to.\nHere we declare a variable var with type int which refers to integer or whole number.\n\nint var = 5;\nstd::cout &lt;&lt; \"variable of type integer: \" &lt;&lt; var &lt;&lt; std::endl;\nvariable of type integer: 5\n\nA variable is place where we store data in the memory that can be read or written to in a program.\nWe think of variables as boxes that hold data, and each box is distinct in the memory. So every variable lives in a location in memory, and we can retrieve it by name without carrying about it’s location in memory.\n\nvoid func()\n{\n    // declare variables\n    int var0;\n    int var1;\n\n    int var2;\n    int var3;\n\n    // assign values to each variable\n    var0 = 1;\n    var1 = 1;\n    var2 = 2;\n    var3 = 2;\n\n    // print the variables value with a message on the screen\n    std::cout &lt;&lt;\"variable 1: \" &lt;&lt;var0&lt;&lt; std::endl;\n    std::cout &lt;&lt;\"variable 2: \" &lt;&lt;var1&lt;&lt; std::endl;\n    std::cout &lt;&lt;\"variable 3: \" &lt;&lt;var2&lt;&lt; std::endl;\n    std::cout &lt;&lt;\"variable 4: \" &lt;&lt;var3&lt;&lt; std::endl;\n}\nfunc();\nvariable 1: 1\nvariable 2: 1\nvariable 3: 2\nvariable 4: 2\n\nHere I declared 4 variables of type int, at this point the program requires a box in the memory for each variable.\nThen when I assign each variable to a value, the program will put those values in their correspondent box.\nNow we have what represents the points in a graph: var0 and var1 for point 1 & var2 and var3 for point 2, now we need variable that will hold the value of the distance. The type of that variable must be float number, since it can be decimal.\n\nvoid func2()\n{\n    int var0;\n    int var1;\n    int var2;\n    int var3;\n    var0 = 1;\n    var1 = 1;\n    var2 = 2;\n    var3 = 2;\n\n    // declare a float type variable\n\n    float lengthOfline;\n}\n\nthe variable lengthOfline doesn’t have value yet, so need to calculate the distance: \\(d = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}\\)\nSo we need power and square root. we could multiply the number by itself to obtain the power but the square root need to be hard coded, but luckily we can just import it from math module in C++, which we need to import in order to use the built in function sqrt.\n\n#include &lt;cmath&gt;\nvoid func3()\n{ \n    //declare the variables to hold points \n    int x1; \n    int y1; \n \n    int x2; \n    int y2; \n \n    //fill the point variables with data \n    x1 = 2; \n    y1 = 2; \n \n    x2 = 2; \n    y2 = 4; \n \n    //declare a variable to hold the length of a line between two points \n    float lengthOfLine; \n \n    //use the distance formula to find the distance \n    lengthOfLine = sqrt(((x2 - x1) * (x2 - x1)) + ((y2 - y1) * (y2 - y1))); \n \n    //print the length of the line \n    std::cout&lt;&lt;\"The length of the line is: \"&lt;&lt;lengthOfLine&lt;&lt;std::endl; \n  \n}\nfunc3();\nThe length of the line is: 2\n\n\nData types:\n\nIn C++ data types are defined once and cannot be changed. If a variable is declared with a specific data type, it can only hold values that suits that data type.\nWe already used int which is a whole number, float a decimal. There are many other types:\n\n#include &lt;string&gt;\nusing namespace std;\nvoid basicdtypes()\n{\n    int num = 5;\n    float dec = 5.22;\n    char oneChar = 'K';\n    string name = \"Ismail\";\n\n    cout &lt;&lt;\"this is a whole number: \" &lt;&lt; num &lt;&lt; endl;\n    cout &lt;&lt;\"this is a decimal number: \" &lt;&lt;dec&lt;&lt; endl;\n    cout &lt;&lt; \"this is single character: \" &lt;&lt;oneChar&lt;&lt; endl;\n    cout &lt;&lt; \"This is a string of charaters: \" &lt;&lt;name&lt;&lt; endl;\n}\nbasicdtypes();\nthis is a whole number: 5\nthis is a decimal number: 5.22\nthis is single character: K\nThis is a string of charaters: Ismail\n\nchar is a single character between single quotes.\nstring is couple of characters between double quotes, and it’s not primitive type, it must be imported #include &lt;string&gt;\n\n\n\nNumbers types:\n\nTill now we saw 2 numerical data types: int and float.\nA data type defines a few things:\n\nthe operations that can be performed on variables of that type\nthe values that can be stored inside a variable of that type (there is usually a range of acceptable values)\nthe amount of space a variable takes up in memory\n\nThe operations performed on int are: - + / *, the division is the only operation that requires some explanation.\nHere is a division between to integers:\n\nvoid divint()\n{\n    int a = 10;\n    int b = 5;\n    int res = a / b;\n    cout &lt;&lt;\"result a / b =&gt; \" &lt;&lt;res&lt;&lt; endl;\n}    \ndivint();\nresult a / b =&gt; 2\n\nWhat if we want to divide 2 integers that will causes not a whole number:\n\nvoid dvd()\n{\n    int num = 12;\n    int num1 = 2;\n    int res = num / num1;\n    cout &lt;&lt;\"result as num = 12: \" &lt;&lt;res&lt;&lt; endl;\n    num = 13;\n    res = num / num1;\n    cout &lt;&lt;\"result as num = 13: \" &lt;&lt;res&lt;&lt; endl;\n}\ndvd();\nresult as num = 12: 6\nresult as num = 13: 6\n\nAt first, the result was 6 which is the obvious answer, but when we predicted 6.5 we still get 6?\nThe reason is that integer division returns the quotient which is always an integer. This is true of all integer divides using the / operator\nThere is another integer division operator called the modulus operator that returns the remainder. The mod operator is the % symbol.\n\nvoid divmod()\n{\n     \n    int num1 = 12; \n    int num2 = 2; \n    int result; \n \n    result = num1 / num2; \n    cout &lt;&lt; \"result with / operator: \" &lt;&lt; result &lt;&lt; endl;     \n \n    result = num1 % num2; \n    cout &lt;&lt; \" result with % operator: \" &lt;&lt; result &lt;&lt; endl;\n    \n}\n\ndivmod();\nresult with / operator: 6\n result with % operator: 0\n\nA data type also specifies an acceptable range of values.\nAn int variable cannot hold an infinite sized number, there is a limit.\nThere is a built in constant called INT_MAX that holds the largest value that can be stored in any int variable (there is an INT_MIN too).\n\n#include &lt;climits&gt;\nint largeNumber;\nlargeNumber = INT_MAX;\ncout&lt;&lt;\"largest number can be stored: \" &lt;&lt;largeNumber&lt;&lt; endl;\nlargest number can be stored: 2147483647\n\nAdding one number to that value will causes an out of range error\nThe arithmetic operators for floats are the same as ints except there is no mod operator. float division results in numbers with fractional parts.\nIn case we want to declare a float data type but the value is a whole number we need to explicitly tell the compiler it’s a float number by adding .0:\n\n#include &lt;typeinfo&gt;\nvoid wholeFloat()\n{\n    int num1 = 15;\n    float num2 = 15.0;\n    cout &lt;&lt; \"the type of num1 = 15 :  \" &lt;&lt; typeid(num1).name() &lt;&lt; endl;\n    cout &lt;&lt; \"the type of num2 = 15.0 :  \" &lt;&lt; typeid(num2).name() &lt;&lt; endl;\n    \n    \n}\n\nwholeFloat();\nthe type of num1 = 15 :  i\nthe type of num2 = 15.0 :  f\n\nWe get i for integer for 15 and f float for 15.0.\n\n\n\nCharacters and strings\n\nstring is very strong type which allows us to make many different things and manipulates data in many ways.\nWhile **char* is a bit hard to work with, since it’s limited and not as versatile as string.\n\nvoid chars()\n{\n    \n    char first = 'c';\n    char second = 'h';\n    char third = 'a';\n    char fourth = 'r';\n\n    string word = \"String\";\n    \n    cout &lt;&lt; first &lt;&lt; second &lt;&lt; third &lt;&lt; fourth &lt;&lt; endl;\n    cout &lt;&lt; word &lt;&lt; endl;\n\n}\nchars();\nchar\nString\n\nString Operations:\n\nString tyoe has many operation that we could use to manipulate data, like length() which as the name suggests tells us the length of string:\n\nstring name = \"Ismail\";\ncout &lt;&lt; \"Number of characters in Ismail is: \" &lt;&lt; name.length() &lt;&lt; endl;\nNumber of characters in Ismail is: 6\n\nThe square brackets is another operator that will return an individual character in the string:\n\nstring word = \"word\";\nchar letter  = word[0];\ncout &lt;&lt; \"this is a string: \" &lt;&lt; word &lt;&lt; endl;\n// the index is 0 based\ncout &lt;&lt; \"this is the first character of that word: \" &lt;&lt; letter &lt;&lt; endl;\nthis is a string: word\nthis is the first character of that word: w\n\nThe + operator concatenates strings together.\n\nstring sentence = \"word1\";\nsentence = sentence + \" word2\" + \" word3\" + \" ...\";\ncout &lt;&lt; sentence &lt;&lt; endl;\nword1 word2 word3 ...\n\nsubstr is a string function that will create a new string from the innards of another.\nThis function takes a starting position and the number of character to use after that position and copies the characters into a new string.\n\nstring sentence = \"find the third word\";\nstring aWord = sentence.substr(9, 5);\ncout &lt;&lt; aWord &lt;&lt; endl;\nthird\n\nfind will return the position where the first occurrence of a word is found (and -1 if it is not found).\n\nstring sentence = \"where is Aldo ?\";\nint findAldo = sentence.find(\"Aldo\");\ncout &lt;&lt; \"Aldo can be found at this position: \" &lt;&lt; findAldo &lt;&lt; endl;\nAldo can be found at this position: 9\n\nerase will remove characters from a string. It takes the starting position of where I want to start removing characters and he total number of characters to get rid of.\n\nvoid func()\n{\n    string sentence = \"In this sentence sentence, it must be no repeated word!\";\n    int repeatedWord = sentence.find(\"sentence\");\n    sentence.erase(repeatedWord, 9);\n    cout &lt;&lt; sentence &lt;&lt; endl;\n}\nfunc();\nIn this sentence, it must be no repeated word!\n\ninsert adds a new string after the position specified in the string.\n\nstring sentence = \", my name is Ismail.\";\nstring greeting = \"Hi\";\nsentence = sentence.insert(0, greeting);\ncout &lt;&lt; sentence &lt;&lt; endl;\nHi, my name is Ismail.\n\n\n\nWeekly pay calculator\n\nIn this small program we will use the cin which takes input from users and use it in the program, displays it or further process it.\nIn this program we will calculate the weekly pay from employers by taking inputs from them and use as arguments in a formula in order to calculate.\ncin is part of &lt;iostream&gt; just like cout.\n\n#include &lt;iostream&gt;\nusing namespace std;\nvoid calculatePay()\n{\n    float numHoursWorked;\n    float hourlyPayRate;\n    string employeeName;\n    float weeklyPay;\n    \n}\n\nThe rpoblem with this approach is that we need to add the numbers manually for each employee or ask them the modify the code for themselves, which is inconvenient.\nThe idea is write code that asks them for their informations, stores it and calculates the weekly pay.\n\n#include &lt;iostream&gt;\n#include &lt;string&gt;\nusing namespace std;\n\nint main()\n{\n  float hoursPerWeek;\n  float hourlyPayRate;\n  string employeeName;\n  float weeklyPay;\n  cout &lt;&lt; \"Enter hours worked per week: \"&lt;&lt; endl;\n  cin &gt;&gt; hoursPerWeek;\n  cout &lt;&lt; \"Enter hourly pay rate: \" &lt;&lt; endl;\n  cin &gt;&gt; hourlyPayRate;\n  cout &lt;&lt; \"Enter your Name: \" &lt;&lt; endl;\n  cin &gt;&gt; employeeName;\n\n  weeklyPay = hoursPerWeek * hourlyPayRate;\n\n  cout &lt;&lt; employeeName &lt;&lt; \" Earned \" &lt;&lt; weeklyPay &lt;&lt; \"$ this week.\" &lt;&lt; endl;\n\n  return 0;\n  }\n\nI could revisit the distance formula I program earlier and apply the idea of cin values instead of hard coding them like in the first version.\n\n// old version\nint main()\n{\n  int x0;\n  int y0;\n  int x1;\n  int y1;\n\n  x0 = 2;\n  y0 = 3;\n  x1 = 3;\n  y1 = 4;\n\n  float distanceFormula;\n\n  distanceFormula = sqrt(((x1 - x0) * (x1 - x0)) - ((y1 - y0) * (y1 - y0))\n\n  return 0;\n  \n}\n\nIn the new version the values x0, x1, y0, y1 will be decided by the user through cin.\n\n#include &lt;iostream&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\nint main()\n{\n    float x0, x1, y0, y1;  // Changed to float for better precision\n\n    cout &lt;&lt; \"Please enter the values of the first point: \" &lt;&lt; endl;\n    cout &lt;&lt; \"X: \";\n    cin &gt;&gt; x0;\n    cout &lt;&lt; \"Y: \";\n    cin &gt;&gt; y0;\n\n    cout &lt;&lt; \"Please enter the values of the second point: \" &lt;&lt; endl;\n    cout &lt;&lt; \"X: \";\n    cin &gt;&gt; x1;\n    cout &lt;&lt; \"Y: \";\n    cin &gt;&gt; y1;\n    \n    // distance formula: sqrt((x1-x0)² + (y1-y0)²)\n    float distanceFormula = sqrt(pow(x1 - x0, 2) + pow(y1 - y0, 2));\n    \n    cout &lt;&lt; \"The length of the line is: \" &lt;&lt; distanceFormula &lt;&lt; endl;\n\n    return 0;\n}\n\nFurther using cin &gt;&gt; in a function where I have to calculate many values and manipulate them:\n\n%%writefile gasMileage.cpp\n\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\n\nint main()\n{\n  float distance;\n  string carBrand;\n  string carModel;\n  float carCapacity;\n  float mpg;\n\n  cout &lt;&lt; \"Enter the Distance of the Trip: \" &lt;&lt; endl;\n  cin &gt;&gt; distance;\n\n  cout &lt;&lt; \"Enter the rand of the car: \" &lt;&lt; endl;\n  cin &gt;&gt; carBrand;\n\n  cout  &lt;&lt; \"Enter the car Model: \" &lt;&lt; endl;\n  cin &gt;&gt; carModel;\n\n  cout &lt;&lt; \"Enter the fuel Tank Capacity: \" &lt;&lt; endl;\n  cin &gt;&gt; carCapacity;\n  \n  cout &lt;&lt; \"Enter the MPG of the car: \" &lt;&lt; endl;\n  cin &gt;&gt; mpg;\n\n\n  float mileageOnFullTank;\n  mileageOnFullTank = mpg * carCapacity;\n  float numOfStops = int(distance / mileageOnFullTank);\n  float gasRequired = distance / mpg;\n  float galonsLeft = ((numOfStops+1) * carCapacity) - gasRequired;\n  \n  \n  cout &lt;&lt; \"For a trip of \" &lt;&lt; distance &lt;&lt; \" miles\" &lt;&lt; endl;\n  cout &lt;&lt; \" a \" &lt;&lt; carBrand &lt;&lt; \" model \" &lt;&lt; carModel &lt;&lt; \" requires \" &lt;&lt; gasRequired &lt;&lt; \" Gallons Of Gas \" &lt;&lt; endl;\n  cout &lt;&lt; \" will require \" &lt;&lt; numOfStops &lt;&lt; \" stop for gas \" &lt;&lt; endl;\n  cout &lt;&lt; \" and will have \" &lt;&lt; galonsLeft &lt;&lt; \" gallons of gas left in the tank\" &lt;&lt; endl;\n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/basicsLesson1.html#day-1-recap",
    "href": "posts/Learning_CPP/basicsLesson1.html#day-1-recap",
    "title": "Learning CPP As Pythonista: Day-1",
    "section": "Day 1 Recap:",
    "text": "Day 1 Recap:\n\nToday I started exploring C++ as a Python programmer, motivated by my goal of writing CUDA kernels. I covered the following fundamentals:\nThe compilation process (pre-processor → compiler → assembler → linker) and how C++ differs from interpreted languages.\nHow to include libraries using #include, and the special role of the main() function.\nBasic printing with std::cout, ending lines with &lt;&lt; std::endl, and formatting simple output.\nVariables: declaring types explicitly (e.g., int, float), how static typing enforces constraints, and understanding variables as named boxes in memory.\nFundamental data types: integers, floats, characters, strings; string operations like length, indexing, concatenation, substrings.\nA simple user-input example: using std::cin to build a basic “weekly pay” calculator."
  },
  {
    "objectID": "posts/Learning_CPP/loopsLesson.html",
    "href": "posts/Learning_CPP/loopsLesson.html",
    "title": "Learning CPP As Pythonista: Day-3",
    "section": "",
    "text": "Today I learned how to repeat actions in C++ using while and for loops. I practiced printing values multiple times, validating input, summing ranges of numbers, using nested loops for a multiplication table, and even modifying characters inside a string. I also learned how break and continue can control the flow inside a loop.\n\n\nConcept: Counter-controlled loop\nWhat it does: Asks the user how many times to print their name, then uses a while loop to repeat the output.\nKey learning: Loop structure, incrementing counters.\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\nint main()\n{\n  int numberOfIterations;\n  string name;\n\n  cout &lt;&lt; \"Enter number of times your name will be printed: \" &lt;&lt; endl;\n  cin &gt;&gt; numberOfIterations;\n  cout &lt;&lt; \"Enter your name: \" &lt;&lt; endl;\n  cin &gt;&gt; name;\n\n  int count = 1;\n  while( count &lt;= numberOfIterations)\n  {\n    cout &lt;&lt; name &lt;&lt; endl;\n    count++;\n  }    \n  return 0;\n}  \n\n\n\nConcept: Boolean condition control (bool + while)\nWhat it does: Keeps asking the user a Yes/No question until the correct answer is given.\nKey learning: Using a flag (doneYet) to control loop exit, if/else inside a loop.\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\nint main()\n{\n  bool doneYet = false;\n  char answer;\n\n  while(!doneYet)\n  {\n    cout &lt;&lt; \"Are you Ismail Taghouchti?:(Y or N)  \" &lt;&lt; endl;\n    cin &gt;&gt; answer;\n    \n    if(answer == 'Y')\n    {\n      doneYet = true;\n      cout &lt;&lt; \"access granted ..\" &lt;&lt; endl;\n    }\n    else \n    {\n      cout &lt;&lt; \"Only Ismail Taghouchti could access.\" &lt;&lt; endl;\n    }\n    \n  }    \n  return 0;\n}  \n\n\n\nConcepts: Input validation + running total\nWhat it does: Ensures the ending value is larger than the starting value, then calculates the sum step by step.\nKey learning: Nested logic using validation loop followed by a counting accumulation loop.\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\nint main()\n{\n  int startingV;\n  int endingV;\n\n  cout &lt;&lt; \"Enter in a starting value: \";\n  cin &gt;&gt; startingV;\n\n  cout &lt;&lt; \"Enter in an ending value:  \";\n  cin &gt;&gt; endingV;\n\n\n  while( endingV &lt;= startingV)\n  {\n    cout &lt;&lt; \"Please enter starting value larger then ending value. Try again.\" &lt;&lt; endl;\n    cout &lt;&lt; \"Enter in a starting value: \";\n    cin  &gt;&gt; startingV;\n    cout &lt;&lt; \"Enter in a ending value: \" &lt;&lt; endl;\n    cin &gt;&gt; endingV;\n  }\n   \n  int count = startingV + 1;\n  int totalSum = startingV;\n  while(count &lt;= endingV)\n  {\n      cout &lt;&lt; totalSum &lt;&lt; \" + \" &lt;&lt; count &lt;&lt; \" = \";\n      totalSum = totalSum + count;\n      cout &lt;&lt; totalSum &lt;&lt; endl;\n      count ++;\n  }\n    \n  cout &lt;&lt; \"The Sum of the numbers from \" &lt;&lt; startingV &lt;&lt; \" to \" &lt;&lt; endingV &lt;&lt; \" is \";\n  cout &lt;&lt; totalSum &lt;&lt; endl;\n     \n  return 0;\n}\n\n\n\nConcept: Nested while loops\nWhat it does: Prints a full 9×9 multiplication table by looping rows and columns.\nKey learning: Inner loop runs completely for each iteration of the outer loop.\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\n\nint main()\n{\n  int left;\n  int right;\n  int product;\n  \n\n  left = 1;\n  while(left &lt; 10)\n  {\n    right = 1;\n    while(right &lt; 10)\n    {\n      product = left * right;\n      cout &lt;&lt; left &lt;&lt; \"X\" &lt;&lt; right &lt;&lt; \"=\" &lt;&lt; product &lt;&lt; \" \";\n      right++;\n    }\n    left++;\n    cout &lt;&lt; endl;\n  }\n\n  return 0;\n}\n\n\n\nConcept: Comparison between for and while for counting\nWhat it does: Same task as Program 3, but uses a for loop for cleaner counting logic.\nKey learning: When iteration count is known → for loop is simpler and more readable.\n#include &lt;iostream&gt;\n#include &lt;string&gt;\nusing namespace std;\n\nint main()\n{\n  int startingV;\n  int endingV;\n  int sum;\n  \n  cout &lt;&lt; \"Enter in starting value: \" &lt;&lt; endl;\n  cin &gt;&gt; startingV;\n\n  cout &lt;&lt; \"Enter in endingV: \" &lt;&lt; endl;\n  cin &gt;&gt; endingV;\n\n  while(endingV &lt; startingV)\n  {\n    cout &lt;&lt; \"The ending value must be greater than or equal to starting value \" &lt;&lt; startingV &lt;&lt; \"Please enter again: \"&lt;&lt; endl;\n    cin &gt;&gt; startingV;\n\n    cout &lt;&lt; \"Enter in ending value: \" &lt;&lt; endl;\n    cin  &gt;&gt; endingV;\n\n  }    \n  sum = startingV;\n  for(int count = startingV + 1; count &lt;= endingV; count++)\n  {\n    cout &lt;&lt; sum &lt;&lt; \" + \" &lt;&lt; count &lt;&lt; \" = \";\n    sum = sum + count;\n    cout &lt;&lt; sum &lt;&lt; endl;\n  \n  }\n  cout &lt;&lt; \"the summation of numbers from \" &lt;&lt; startingV &lt;&lt; \" to \" &lt;&lt; endingV &lt;&lt; \" is: \" &lt;&lt; sum &lt;&lt; endl;\n  return 0;\n}\n\n\n\nConcept: Looping through strings using indexes\nWhat it does: Detects spaces and capitalizes the next character.\nKey learning: Boolean flag (isCap) + character processing using toupper().\n#include &lt;iostream&gt;\n#include &lt;string&gt;\nusing namespace std;\n\nint main()\n{\n  string sentence = \"Today was a bit sunny.\";\n  cout &lt;&lt; sentence &lt;&lt; endl;\n  cout &lt;&lt; \"After Capitalization: \" &lt;&lt; endl;\n  bool isCap = false;\n  for(int i=0; i &lt; sentence.length(); i++)\n  {\n    if(isCap)\n    {\n      char capL = toupper(sentence[i]);\n      cout &lt;&lt; capL;\n      isCap = false;\n    }\n    else \n    {\n      cout &lt;&lt; sentence[i];\n    }\n    if(sentence[i] == ' ')\n    {\n      isCap = true;\n    }\n      \n  }\n  cout &lt;&lt; endl;\n  return 0;\n}\n\n\n\nConcept: Loop flow control\nWhat it does: Loops from 0 to 49 but:\ncontinue skips printing even numbers\nbreak stops when i == 21\nKey learning: Adjusting loop behavior without changing loop condition.\n#include &lt;iostream&gt;\n#include &lt;string&gt;\nusing namespace std;\n\n\nint main()\n{\n  for(int i = 0; i &lt; 50; i++)\n  {\n    if(i == 21)\n    {\n      break;\n    }  \n\n    if(i % 2 == 0)\n    {\n      continue;\n    }  \n    cout &lt;&lt; i &lt;&lt; endl;\n  }  \n  return 0;  \n}"
  },
  {
    "objectID": "posts/Learning_CPP/loopsLesson.html#repeating-output-with-a-while-loop",
    "href": "posts/Learning_CPP/loopsLesson.html#repeating-output-with-a-while-loop",
    "title": "Learning CPP As Pythonista: Day-3",
    "section": "",
    "text": "Concept: Counter-controlled loop\nWhat it does: Asks the user how many times to print their name, then uses a while loop to repeat the output.\nKey learning: Loop structure, incrementing counters.\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\nint main()\n{\n  int numberOfIterations;\n  string name;\n\n  cout &lt;&lt; \"Enter number of times your name will be printed: \" &lt;&lt; endl;\n  cin &gt;&gt; numberOfIterations;\n  cout &lt;&lt; \"Enter your name: \" &lt;&lt; endl;\n  cin &gt;&gt; name;\n\n  int count = 1;\n  while( count &lt;= numberOfIterations)\n  {\n    cout &lt;&lt; name &lt;&lt; endl;\n    count++;\n  }    \n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/loopsLesson.html#validating-user-input-in-a-loop",
    "href": "posts/Learning_CPP/loopsLesson.html#validating-user-input-in-a-loop",
    "title": "Learning CPP As Pythonista: Day-3",
    "section": "",
    "text": "Concept: Boolean condition control (bool + while)\nWhat it does: Keeps asking the user a Yes/No question until the correct answer is given.\nKey learning: Using a flag (doneYet) to control loop exit, if/else inside a loop.\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\nint main()\n{\n  bool doneYet = false;\n  char answer;\n\n  while(!doneYet)\n  {\n    cout &lt;&lt; \"Are you Ismail Taghouchti?:(Y or N)  \" &lt;&lt; endl;\n    cin &gt;&gt; answer;\n    \n    if(answer == 'Y')\n    {\n      doneYet = true;\n      cout &lt;&lt; \"access granted ..\" &lt;&lt; endl;\n    }\n    else \n    {\n      cout &lt;&lt; \"Only Ismail Taghouchti could access.\" &lt;&lt; endl;\n    }\n    \n  }    \n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/loopsLesson.html#summing-a-range-of-numbers-using-while",
    "href": "posts/Learning_CPP/loopsLesson.html#summing-a-range-of-numbers-using-while",
    "title": "Learning CPP As Pythonista: Day-3",
    "section": "",
    "text": "Concepts: Input validation + running total\nWhat it does: Ensures the ending value is larger than the starting value, then calculates the sum step by step.\nKey learning: Nested logic using validation loop followed by a counting accumulation loop.\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\nint main()\n{\n  int startingV;\n  int endingV;\n\n  cout &lt;&lt; \"Enter in a starting value: \";\n  cin &gt;&gt; startingV;\n\n  cout &lt;&lt; \"Enter in an ending value:  \";\n  cin &gt;&gt; endingV;\n\n\n  while( endingV &lt;= startingV)\n  {\n    cout &lt;&lt; \"Please enter starting value larger then ending value. Try again.\" &lt;&lt; endl;\n    cout &lt;&lt; \"Enter in a starting value: \";\n    cin  &gt;&gt; startingV;\n    cout &lt;&lt; \"Enter in a ending value: \" &lt;&lt; endl;\n    cin &gt;&gt; endingV;\n  }\n   \n  int count = startingV + 1;\n  int totalSum = startingV;\n  while(count &lt;= endingV)\n  {\n      cout &lt;&lt; totalSum &lt;&lt; \" + \" &lt;&lt; count &lt;&lt; \" = \";\n      totalSum = totalSum + count;\n      cout &lt;&lt; totalSum &lt;&lt; endl;\n      count ++;\n  }\n    \n  cout &lt;&lt; \"The Sum of the numbers from \" &lt;&lt; startingV &lt;&lt; \" to \" &lt;&lt; endingV &lt;&lt; \" is \";\n  cout &lt;&lt; totalSum &lt;&lt; endl;\n     \n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/loopsLesson.html#multiplication-table-nested-loops",
    "href": "posts/Learning_CPP/loopsLesson.html#multiplication-table-nested-loops",
    "title": "Learning CPP As Pythonista: Day-3",
    "section": "",
    "text": "Concept: Nested while loops\nWhat it does: Prints a full 9×9 multiplication table by looping rows and columns.\nKey learning: Inner loop runs completely for each iteration of the outer loop.\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\n\nint main()\n{\n  int left;\n  int right;\n  int product;\n  \n\n  left = 1;\n  while(left &lt; 10)\n  {\n    right = 1;\n    while(right &lt; 10)\n    {\n      product = left * right;\n      cout &lt;&lt; left &lt;&lt; \"X\" &lt;&lt; right &lt;&lt; \"=\" &lt;&lt; product &lt;&lt; \" \";\n      right++;\n    }\n    left++;\n    cout &lt;&lt; endl;\n  }\n\n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/loopsLesson.html#summing-a-range-of-numbers-using-for",
    "href": "posts/Learning_CPP/loopsLesson.html#summing-a-range-of-numbers-using-for",
    "title": "Learning CPP As Pythonista: Day-3",
    "section": "",
    "text": "Concept: Comparison between for and while for counting\nWhat it does: Same task as Program 3, but uses a for loop for cleaner counting logic.\nKey learning: When iteration count is known → for loop is simpler and more readable.\n#include &lt;iostream&gt;\n#include &lt;string&gt;\nusing namespace std;\n\nint main()\n{\n  int startingV;\n  int endingV;\n  int sum;\n  \n  cout &lt;&lt; \"Enter in starting value: \" &lt;&lt; endl;\n  cin &gt;&gt; startingV;\n\n  cout &lt;&lt; \"Enter in endingV: \" &lt;&lt; endl;\n  cin &gt;&gt; endingV;\n\n  while(endingV &lt; startingV)\n  {\n    cout &lt;&lt; \"The ending value must be greater than or equal to starting value \" &lt;&lt; startingV &lt;&lt; \"Please enter again: \"&lt;&lt; endl;\n    cin &gt;&gt; startingV;\n\n    cout &lt;&lt; \"Enter in ending value: \" &lt;&lt; endl;\n    cin  &gt;&gt; endingV;\n\n  }    \n  sum = startingV;\n  for(int count = startingV + 1; count &lt;= endingV; count++)\n  {\n    cout &lt;&lt; sum &lt;&lt; \" + \" &lt;&lt; count &lt;&lt; \" = \";\n    sum = sum + count;\n    cout &lt;&lt; sum &lt;&lt; endl;\n  \n  }\n  cout &lt;&lt; \"the summation of numbers from \" &lt;&lt; startingV &lt;&lt; \" to \" &lt;&lt; endingV &lt;&lt; \" is: \" &lt;&lt; sum &lt;&lt; endl;\n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/loopsLesson.html#capitalizing-letters-after-spaces",
    "href": "posts/Learning_CPP/loopsLesson.html#capitalizing-letters-after-spaces",
    "title": "Learning CPP As Pythonista: Day-3",
    "section": "",
    "text": "Concept: Looping through strings using indexes\nWhat it does: Detects spaces and capitalizes the next character.\nKey learning: Boolean flag (isCap) + character processing using toupper().\n#include &lt;iostream&gt;\n#include &lt;string&gt;\nusing namespace std;\n\nint main()\n{\n  string sentence = \"Today was a bit sunny.\";\n  cout &lt;&lt; sentence &lt;&lt; endl;\n  cout &lt;&lt; \"After Capitalization: \" &lt;&lt; endl;\n  bool isCap = false;\n  for(int i=0; i &lt; sentence.length(); i++)\n  {\n    if(isCap)\n    {\n      char capL = toupper(sentence[i]);\n      cout &lt;&lt; capL;\n      isCap = false;\n    }\n    else \n    {\n      cout &lt;&lt; sentence[i];\n    }\n    if(sentence[i] == ' ')\n    {\n      isCap = true;\n    }\n      \n  }\n  cout &lt;&lt; endl;\n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/loopsLesson.html#using-break-and-continue",
    "href": "posts/Learning_CPP/loopsLesson.html#using-break-and-continue",
    "title": "Learning CPP As Pythonista: Day-3",
    "section": "",
    "text": "Concept: Loop flow control\nWhat it does: Loops from 0 to 49 but:\ncontinue skips printing even numbers\nbreak stops when i == 21\nKey learning: Adjusting loop behavior without changing loop condition.\n#include &lt;iostream&gt;\n#include &lt;string&gt;\nusing namespace std;\n\n\nint main()\n{\n  for(int i = 0; i &lt; 50; i++)\n  {\n    if(i == 21)\n    {\n      break;\n    }  \n\n    if(i % 2 == 0)\n    {\n      continue;\n    }  \n    cout &lt;&lt; i &lt;&lt; endl;\n  }  \n  return 0;  \n}"
  },
  {
    "objectID": "posts/Learning_CPP/basics_Lesson2.html",
    "href": "posts/Learning_CPP/basics_Lesson2.html",
    "title": "Learning CPP As Pythonista: Day-2",
    "section": "",
    "text": "% gives the remainder of division, perfect for checking parity.\nA boolean variable like iseven stores true/false logic.\nif/else chooses which message to display.\n\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\n\nint main()\n{\n  int number;\n  cout &lt;&lt; \"Please enter a Number: \" &lt;&lt; endl;\n  cin &gt;&gt; number;\n\n  bool iseven = number % 2 == 0;\n  if(iseven)\n  {\n    cout &lt;&lt; number &lt;&lt; \" is an even number\" &lt;&lt; endl;\n  }\n  else\n  {\n    cout &lt;&lt; number &lt;&lt; \" is an odd number\" &lt;&lt; endl;\n  }\n\n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/basics_Lesson2.html#even-odd",
    "href": "posts/Learning_CPP/basics_Lesson2.html#even-odd",
    "title": "Learning CPP As Pythonista: Day-2",
    "section": "",
    "text": "% gives the remainder of division, perfect for checking parity.\nA boolean variable like iseven stores true/false logic.\nif/else chooses which message to display.\n\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\n\nint main()\n{\n  int number;\n  cout &lt;&lt; \"Please enter a Number: \" &lt;&lt; endl;\n  cin &gt;&gt; number;\n\n  bool iseven = number % 2 == 0;\n  if(iseven)\n  {\n    cout &lt;&lt; number &lt;&lt; \" is an even number\" &lt;&lt; endl;\n  }\n  else\n  {\n    cout &lt;&lt; number &lt;&lt; \" is an odd number\" &lt;&lt; endl;\n  }\n\n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/basics_Lesson2.html#weekly-payout",
    "href": "posts/Learning_CPP/basics_Lesson2.html#weekly-payout",
    "title": "Learning CPP As Pythonista: Day-2",
    "section": "Weekly Payout:",
    "text": "Weekly Payout:\n\nSimple payroll logic with overtime calculation.\nHours above 40 are paid at 1.5x the regular rate.\nRead multiple inputs from the user and compute the result.\n\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\nint main()\n{\n  float hourPerWeek;\n  float payPerHour;\n  string name;\n  float weekPayout;\n\n  cout &lt;&lt; \"How many Hours did you work last week: \" &lt;&lt; endl;\n  cin &gt;&gt; hourPerWeek;\n  cout &lt;&lt; \"How much you earn per hour: \" &lt;&lt; endl;\n  cin &gt;&gt; payPerHour;\n  cout &lt;&lt; \"What's your name: \" &lt;&lt; endl;\n  cin &gt;&gt; name;\n\n  if(hourPerWeek &lt;= 40.0)\n  {\n    weekPayout = hourPerWeek * payPerHour;\n    cout &lt;&lt; name &lt;&lt; \" earned \" &lt;&lt; weekPayout &lt;&lt; \"$$.\" &lt;&lt; endl;\n  }\n  else:\n  {\n    weekPayout = ((payPerHour * 40.0) + ((hourPerWeek - 40) * (payPerHour * 1.5)));\n    cout &lt;&lt; name &lt;&lt; \"  earned \" &lt;&lt; weekPayout &lt;&lt; \"$$.\" &lt;&lt; endl;\n  }\n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/basics_Lesson2.html#water-temperature",
    "href": "posts/Learning_CPP/basics_Lesson2.html#water-temperature",
    "title": "Learning CPP As Pythonista: Day-2",
    "section": "Water Temperature:",
    "text": "Water Temperature:\n\nNested if statements help handle several rules inside one category.\nLogical OR || checks if the scale is either C or F.\nDifferent boiling/freezing points for Celsius vs Fahrenheit.\nProvide feedback for invalid input.\n\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\nint main()\n{\n  float temp;\n  char tempScale;\n  cout &lt;&lt; \"Enter in the temperature: \" &lt;&lt; endl;\n  cin &gt;&gt; temp;\n  cout &lt;&lt; \"Enter temperature scale ( C or F ): \" &lt;&lt; endl;\n  cin &gt;&gt; tempScale;\n\n  if( tempScale == 'C' || tempScale == 'F')\n  {\n    if(tempScale == 'F')\n    {\n      if(temp &lt;= 32.0)\n      {\n        cout &lt;&lt; \"Water will turn to ice at \"&lt;&lt;temp&lt;&lt; \" F degrees.\" &lt;&lt; endl;\n        \n      }\n      else if(temp &gt;= 212.0)\n      {\n        cout &lt;&lt; \"Water will turn to steam at \" &lt;&lt;temp&lt;&lt; \" F degrees.\" &lt;&lt; endl;\n\n      }\n      else\n      {\n        cout &lt;&lt; \"Water will stay liquid at \" &lt;&lt; temp&lt;&lt; \" F degrees.\" &lt;&lt; endl;\n      }\n    \n    }\n    else\n    {\n      if(temp &lt;= 0.0)\n      {\n        cout &lt;&lt; \"Water will turn to ice at \" &lt;&lt; temp &lt;&lt; \" C degrees.\" &lt;&lt; endl;\n      }\n      else if(temp &gt;= 100.0)\n      {\n        cout &lt;&lt; \"Water will turn to steam at \" &lt;&lt; temp &lt;&lt; \"C degrees.\" &lt;&lt; endl;\n      }\n      else\n      {\n        cout &lt;&lt; \"water will stay liquid at \" &lt;&lt; temp &lt;&lt; \"C degrees.\" &lt;&lt; endl;\n      }\n    }\n  }\n  else \n  {\n    cout &lt;&lt; \"You entered an invalid temperature scale. Please run the program again.\" &lt;&lt;endl;\n  }\n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/basics_Lesson2.html#number-of-the-day-if-else-if",
    "href": "posts/Learning_CPP/basics_Lesson2.html#number-of-the-day-if-else-if",
    "title": "Learning CPP As Pythonista: Day-2",
    "section": "Number of the Day (If / else if):",
    "text": "Number of the Day (If / else if):\n\nChain of else if to match a specific number with its weekday.\nDemonstrates grouping conditions like weekend vs weekday.\nA good example where many comparisons might get messy.\n\n\n\nCode\n\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n\n// slightly different version of switch.cpp\n// using || and && and adding weekend \n\n\nint main()\n{\n  int dayNum;\n  cout &lt;&lt; \"Enter a number day (1 Sunday, 2 Monday, 3 Tuesday .. etc\" &lt;&lt; endl;\n  cin &gt;&gt; dayNum;\n  cout &lt;&lt; \"You selected \";\n  \n  if(dayNum == 1)\n  {\n    cout &lt;&lt; \"Sunday. \";\n\n  }\n  else if(dayNum == 2)\n  {\n    cout &lt;&lt; \"Monday. \";\n  }\n  else if(dayNum == 3)\n  {\n    cout &lt;&lt; \"Tuesday. \";\n  }\n  else if(dayNum == 4)\n  {\n    cout &lt;&lt; \"Wednesday. \";\n  }\n  else if(dayNum == 5)\n  {\n    cout &lt;&lt; \"Thursday. \";\n  }\n  else if(dayNum == 6)\n  {\n    cout &lt;&lt; \"Friday. \";\n  }\n  else if(dayNum == 6)\n  {\n    cout &lt;&lt; \"Saturday. \";\n  }\n  else\n    cout &lt;&lt; \"Please enter a valid day. \";\n\n\n  if(dayNum == 1 || dayNum == 7)\n  {\n    cout &lt;&lt; \"It's a weekend.\";\n  }\n  else if(dayNum &gt;=2 && dayNum &lt;= 6)\n  {\n    cout &lt;&lt; \"It's a weekday.\" &lt;&lt; endl;\n  }\n  return 0;\n}"
  },
  {
    "objectID": "posts/Learning_CPP/basics_Lesson2.html#number-of-the-day-switch",
    "href": "posts/Learning_CPP/basics_Lesson2.html#number-of-the-day-switch",
    "title": "Learning CPP As Pythonista: Day-2",
    "section": "Number of the Day (switch):",
    "text": "Number of the Day (switch):\n\nswitch is a cleaner choice for fixed numeric options.\nEach case handles one specific value.\nbreak prevents “falling through” to the next case.\ndefault is like the else of switch statements.\n\n\n\nCode\n#include &lt;iostream&gt;\n#include &lt;string&gt;\n#include &lt;cmath&gt;\nusing namespace std;\n// same as what I did in switch.cpp but now I will use swith instead of if statements.\n\nint main()\n{\n  int dayNumber;\n  cout &lt;&lt; \"Enter a number day ( 1 for Sunday, 2 Monday, 3 Tuesday ...etc)\" &lt;&lt; endl;\n  cin &gt;&gt; dayNumber;\n  \n\n  switch(dayNumber)\n  {\n    case 1:\n      cout &lt;&lt; \"Sunday. \" &lt;&lt; endl;\n      break;\n    case 2:\n      cout &lt;&lt; \"Monday. \" &lt;&lt; endl;\n      break;\n    case 3:\n      cout &lt;&lt; \"Tuesday. \" &lt;&lt; endl;\n      break;\n    case 4:\n      cout &lt;&lt; \"Wednesday. \" &lt;&lt; endl;\n      break;\n    case 5:\n      cout &lt;&lt; \"Thursday. \" &lt;&lt; endl;\n      break;\n    case 6:\n      cout &lt;&lt; \"Friday. \" &lt;&lt; endl;\n      break;\n    case 7:\n      cout &lt;&lt; \"Saturday. \" &lt;&lt; endl;\n      break;\n    default:\n      cout &lt;&lt; \"an invalid day. \" &lt;&lt; endl;\n  }\n  return 0;\n\n}"
  },
  {
    "objectID": "posts/Learning_CPP/basics_Lesson2.html#day-2-summarization",
    "href": "posts/Learning_CPP/basics_Lesson2.html#day-2-summarization",
    "title": "Learning CPP As Pythonista: Day-2",
    "section": "Day 2 Summarization :",
    "text": "Day 2 Summarization :\nHere is what I achieved:\n\nI learned the if statement, the first building block of logical decision-making.\nI used comparison operators like ==, &lt;=, and &gt;= to evaluate conditions.\nI combined conditions using logical operators such as || and &&.\nI controlled program behavior with if / else / else if chains for multiple outcomes.\nI explored switch as a cleaner option for specific numeric cases.\nI wrote several mini programs with real-world logic:\n\nEven or odd number checker\nWeekly pay calculator with overtime\nWater state detector (ice, liquid, steam)\nDay-of-the-week selector (two versions)"
  },
  {
    "objectID": "posts/Fastai_ch1/Ch1_Questionnaire.html",
    "href": "posts/Fastai_ch1/Ch1_Questionnaire.html",
    "title": "Chapter 1: Questionnaire and Further Research",
    "section": "",
    "text": "Do you need these for deep learning?\n\nLots of math\n\nFalse\n\nLots of data\n\nFalse\n\nLots of expensive computers\n\nFalse\n\nA PhD\n\nFalse\n\n\n\n\n\nName five areas where deep learning is now the best in the world.\n\nMedical research\nRobotics\nAssurance\nLinguistics/ Natural Lunguage Processing\nBiology\n\n\n\n\nWhat was the name of the first device that was based on the principle of the artificial neuron?\n\nPercepton\n\n\n\n\nBased on the book of the same name, what are the requirements for parallel distributed processing (PDP)?\n\nSet of processing units\n\nA state of activation\n\nAn output function for each unit\n\nPattern of connectivity among units\n\nPropagation rule for propagating patterns of activities through the network of connectivities\n\nAn activation rule for combining the inputs impinging on a unit with the current state of that unit to produce an output for the unit\n\nLearning rule whereby patterns of connectivity are modified by experience\n\nAn environment within which the system must operate\n\n\n\n\nWhat were the two theoretical misunderstandings that held back the field of neural networks?\nMinsky in his book Perceptons shows the limitation of the device “perceptons” and how it cannot solve any comlex problem, the ai community did agreed with Minsky, but the did not pay attention to the solution he suggested, which is a 2 layer model.\nIn 80’s the 2 layer models were usual in ai labs. In theory a 2 layer model can solve any problem, but in practice the layers were too big and consum a lot of computation power, the solution to this is to add more layers, but this insight was not acknowledged, what leat to the 2 winter of NN.\n\n\n\nWhat is a GPU?\nIt’s a Graphic Prossessing Unit, which is used to do many computation tasks in parallel, which help to accelerate to compution of big tasks by cutting them into small tasks and compute them in parallel\n\n\n\nWhy is it hard to use a traditional computer program to recognize images in a photo?\nto write a programm that recognize images in a photo we need to write a long set of rules that resume any possible photo and image, tell the computer exactly how to deal with any of them, which is way more complicated that what we can do. That’s way we use machine learning to solve those kinfd of problems, just by showing the model data and help it to learn from it.\n\n\n\nWhat did Samuel mean by “Weight Assignment”?\nWhat term do we normally use in deep learning for what Samuel called “Weights”?\nDraw a picture that summarizes Arthur Samuel’s view of a machine learning model\nweight Assignment is refer to the parameters of the model, these are what we call today weights and bias. they are set of value we assign to each data point, what make the optimization of the loss possible.\n\n\n\nWhy is it hard to understand why a deep learning model makes a particular prediction?\nThis is a highly-researched topic known as interpretability of deep learning models. the natur of deep learning “deep” make it hard to really understand the way the model solve each problem, specially if the model has many layers, what makes it even hard to know exactly which layer is responsable of the procces of learning which part.\n\n\n\nWhat is the name of the theorem that shows that a neural network can solve any mathematical problem to any level of accuracy?\nUniversal approximation theorem\n\n\n\nWhat do you need in order to train a model?\nIn order to train a model, we need architecture for the given problem, we first need data(+labels), then we need set of values (paramaters), then we need some kind of metric to know if our model did good or bad (loss function), and we need a way to updates these parameters in order to optimize the loss function.\n\n\n\nHow could a feedback loop impact the rollout of a predictive policing model?\nIn a predictive policing model, we might end up with a positive feedback loop, leading to a highly biased model with little predictive power. For example, we may want a model that would predict crimes, but we use information on arrests as a proxy . However, this data itself is slightly biased due to the biases in existing policing processes. Training with this data leads to a biased model. Law enforcement might use the model to determine where to focus police activity, increasing arrests in those areas. These additional arrests would be used in training future iterations of models, leading to an even more biased model. This cycle continues as a positive feedback loop\n\n\n\nDo we always have to use 224x224 pixel images with the cat recognition model?\nNo.\n\n\n\nWhat is the difference between classification and regression?\nClassification problem is when we need to decide between 2(or more) classes, the prediction in this problem isn’t quantity, where regression problem is focused on predecting numeric quantity.\n\n\n\nWhat is a validation set? What is a test set? Why do we need them?\nValidation set is small portion of the data set that we preserve from the training fase in order to prevent the model from memorizing the data instead of learning from it. The validation set allow us to measure the performance of the model on data that the model didn’t see before. Same we can say about test set, which is another preserved protion of data that we use in the final fase of the training in order to have a real idea of model performance.\n\n\n\nWhat will fastai do if you don’t provide a validation set?\nit will automatically create a validation set of 20% of our dataset.\nvalid_pct=0.2\n\n\n\nWhat is overfitting?\nis when the model is memorizing answears instead of learning from data.\n\n\n\nWhat is a metric? How does it differ to “loss”?\nMetric is what tells us how the model perform, in other way the loss is what we should minimize in order to optimize the model perfromance.as we will see later, sometimes, we could use the metric as loss.\n\n\n\nHow can pretrained models help?\npertrained model can be used again, we just need to fin it in our probem.\na pretrained model is a model that learned many lesson from the prior problem, and already has good set of paramters, these parameters(weights+biases) are what we seek in the proccess of using a pretrained model. this procces is called fine-tunning, which mean less money and time consuming.\n\n\n\nWhat is the “head” of a model?\nWhen using a pretrained model, the later layers of the model, which were useful for the task that the model was originally trained on, are replaced with one or more new layers with randomized weights, of an appropriate size for the dataset you are working with. These new layers are called the “head” of the model.\n\n\n\nWhat is an “architecture”?\nThe architecture is the template or structure of the model we are trying to fit. It defines the mathematical model we are trying to fit.\n\n\n\nWhat are “hyperparameters”?\nTraining models requires various other parameters that define how the model is trained. For example, we need to define how long we train for, or what learning rate (how fast the model parameters are allowed to change) is used. These sorts of parameters are hyperparameters."
  },
  {
    "objectID": "posts/Fastai_ch1/Ch1_Questionnaire.html#questionnaire",
    "href": "posts/Fastai_ch1/Ch1_Questionnaire.html#questionnaire",
    "title": "Chapter 1: Questionnaire and Further Research",
    "section": "",
    "text": "Do you need these for deep learning?\n\nLots of math\n\nFalse\n\nLots of data\n\nFalse\n\nLots of expensive computers\n\nFalse\n\nA PhD\n\nFalse\n\n\n\n\n\nName five areas where deep learning is now the best in the world.\n\nMedical research\nRobotics\nAssurance\nLinguistics/ Natural Lunguage Processing\nBiology\n\n\n\n\nWhat was the name of the first device that was based on the principle of the artificial neuron?\n\nPercepton\n\n\n\n\nBased on the book of the same name, what are the requirements for parallel distributed processing (PDP)?\n\nSet of processing units\n\nA state of activation\n\nAn output function for each unit\n\nPattern of connectivity among units\n\nPropagation rule for propagating patterns of activities through the network of connectivities\n\nAn activation rule for combining the inputs impinging on a unit with the current state of that unit to produce an output for the unit\n\nLearning rule whereby patterns of connectivity are modified by experience\n\nAn environment within which the system must operate\n\n\n\n\nWhat were the two theoretical misunderstandings that held back the field of neural networks?\nMinsky in his book Perceptons shows the limitation of the device “perceptons” and how it cannot solve any comlex problem, the ai community did agreed with Minsky, but the did not pay attention to the solution he suggested, which is a 2 layer model.\nIn 80’s the 2 layer models were usual in ai labs. In theory a 2 layer model can solve any problem, but in practice the layers were too big and consum a lot of computation power, the solution to this is to add more layers, but this insight was not acknowledged, what leat to the 2 winter of NN.\n\n\n\nWhat is a GPU?\nIt’s a Graphic Prossessing Unit, which is used to do many computation tasks in parallel, which help to accelerate to compution of big tasks by cutting them into small tasks and compute them in parallel\n\n\n\nWhy is it hard to use a traditional computer program to recognize images in a photo?\nto write a programm that recognize images in a photo we need to write a long set of rules that resume any possible photo and image, tell the computer exactly how to deal with any of them, which is way more complicated that what we can do. That’s way we use machine learning to solve those kinfd of problems, just by showing the model data and help it to learn from it.\n\n\n\nWhat did Samuel mean by “Weight Assignment”?\nWhat term do we normally use in deep learning for what Samuel called “Weights”?\nDraw a picture that summarizes Arthur Samuel’s view of a machine learning model\nweight Assignment is refer to the parameters of the model, these are what we call today weights and bias. they are set of value we assign to each data point, what make the optimization of the loss possible.\n\n\n\nWhy is it hard to understand why a deep learning model makes a particular prediction?\nThis is a highly-researched topic known as interpretability of deep learning models. the natur of deep learning “deep” make it hard to really understand the way the model solve each problem, specially if the model has many layers, what makes it even hard to know exactly which layer is responsable of the procces of learning which part.\n\n\n\nWhat is the name of the theorem that shows that a neural network can solve any mathematical problem to any level of accuracy?\nUniversal approximation theorem\n\n\n\nWhat do you need in order to train a model?\nIn order to train a model, we need architecture for the given problem, we first need data(+labels), then we need set of values (paramaters), then we need some kind of metric to know if our model did good or bad (loss function), and we need a way to updates these parameters in order to optimize the loss function.\n\n\n\nHow could a feedback loop impact the rollout of a predictive policing model?\nIn a predictive policing model, we might end up with a positive feedback loop, leading to a highly biased model with little predictive power. For example, we may want a model that would predict crimes, but we use information on arrests as a proxy . However, this data itself is slightly biased due to the biases in existing policing processes. Training with this data leads to a biased model. Law enforcement might use the model to determine where to focus police activity, increasing arrests in those areas. These additional arrests would be used in training future iterations of models, leading to an even more biased model. This cycle continues as a positive feedback loop\n\n\n\nDo we always have to use 224x224 pixel images with the cat recognition model?\nNo.\n\n\n\nWhat is the difference between classification and regression?\nClassification problem is when we need to decide between 2(or more) classes, the prediction in this problem isn’t quantity, where regression problem is focused on predecting numeric quantity.\n\n\n\nWhat is a validation set? What is a test set? Why do we need them?\nValidation set is small portion of the data set that we preserve from the training fase in order to prevent the model from memorizing the data instead of learning from it. The validation set allow us to measure the performance of the model on data that the model didn’t see before. Same we can say about test set, which is another preserved protion of data that we use in the final fase of the training in order to have a real idea of model performance.\n\n\n\nWhat will fastai do if you don’t provide a validation set?\nit will automatically create a validation set of 20% of our dataset.\nvalid_pct=0.2\n\n\n\nWhat is overfitting?\nis when the model is memorizing answears instead of learning from data.\n\n\n\nWhat is a metric? How does it differ to “loss”?\nMetric is what tells us how the model perform, in other way the loss is what we should minimize in order to optimize the model perfromance.as we will see later, sometimes, we could use the metric as loss.\n\n\n\nHow can pretrained models help?\npertrained model can be used again, we just need to fin it in our probem.\na pretrained model is a model that learned many lesson from the prior problem, and already has good set of paramters, these parameters(weights+biases) are what we seek in the proccess of using a pretrained model. this procces is called fine-tunning, which mean less money and time consuming.\n\n\n\nWhat is the “head” of a model?\nWhen using a pretrained model, the later layers of the model, which were useful for the task that the model was originally trained on, are replaced with one or more new layers with randomized weights, of an appropriate size for the dataset you are working with. These new layers are called the “head” of the model.\n\n\n\nWhat is an “architecture”?\nThe architecture is the template or structure of the model we are trying to fit. It defines the mathematical model we are trying to fit.\n\n\n\nWhat are “hyperparameters”?\nTraining models requires various other parameters that define how the model is trained. For example, we need to define how long we train for, or what learning rate (how fast the model parameters are allowed to change) is used. These sorts of parameters are hyperparameters."
  },
  {
    "objectID": "posts/Fastai_ch1/Ch1_Questionnaire.html#further-research",
    "href": "posts/Fastai_ch1/Ch1_Questionnaire.html#further-research",
    "title": "Chapter 1: Questionnaire and Further Research",
    "section": "Further Research",
    "text": "Further Research\n\nWhy is a GPU useful for deep learning? How is a CPU different, and why is it less effective for deep learning?"
  },
  {
    "objectID": "posts/Fastai_ch1/Ch1_Questionnaire.html#what-is-a-gpu-what-make-it-different-from-cpu-and-why-do-we-need-it-to-do-deep-learning-tasks",
    "href": "posts/Fastai_ch1/Ch1_Questionnaire.html#what-is-a-gpu-what-make-it-different-from-cpu-and-why-do-we-need-it-to-do-deep-learning-tasks",
    "title": "Chapter 1: Questionnaire and Further Research",
    "section": "What is a GPU? What make it different from CPU? and Why do we need it to do Deep Learning tasks:",
    "text": "What is a GPU? What make it different from CPU? and Why do we need it to do Deep Learning tasks:\n\nGPU stands for Graphic Processing Unit, is a specialized processor with dedicated memory that conventionally perform floating point operations required for rendering graphics.\nIn other words, it’s a single-chip processor used for extensive graphical and mathematical computations which help the CPU to achieve other tasks.\nWhile CPU is designed to handel the complex logic in code once at a time, GPU can do many small operations at the same time, which make it very convenient to deep learning where we need to do many milions of calculations in order to train a model\n\n\nWhy do Deep Learning needs GPU?\n\nGPUs are optimized for training neural networks models as they can process multiple computations simultaneously.\nFor example the model we’ve fine-tuned in chapter one resnet18 which the smaller version of resnet models with only 18 hidden layers,though it has more than 11 millions parameters, in order to do one epoch and calculate all these parameter (wights + biases) and multiply them by the input variables (images) then do the Back-probagation and update them after calculating the loss … all this multiplications will take a large amount of time if we did it on CPU."
  },
  {
    "objectID": "posts/Understanding Pytorch/pytorch-1.html",
    "href": "posts/Understanding Pytorch/pytorch-1.html",
    "title": "Deep Dive into PyTorch Internals: Autograd and torch.fx",
    "section": "",
    "text": "As I continue to deepen my understanding of machine learning systems, I’ve realized that knowing how models run is just as important as knowing how to build them. This post kicks off a series where I explore PyTorch internals, starting with two powerful components: Autograd and torch.fx.\n\n\n\n\n\nPyTorch’s autograd is a dynamic automatic differentiation engine. It records operations on tensors to build a computation graph during the forward pass, and then traverses that graph in reverse to compute gradients during the backward pass.\n\n\n\nWhen you perform operations on torch.Tensor objects with requires_grad=True, PyTorch:\n\nCreates a computation graph on the fly.\nEach operation produces a Function object (e.g., AddBackward, MulBackward).\nWhen .backward() is called, the engine performs reverse-mode automatic differentiation.\n\n\n\n\n\nimport torch\nx = torch.tensor(2.0, requires_grad=True)\ny = x * x + 3 * x\nz = y.mean()\nz.backward()\nprint(x.grad)  # 7.0 = d(x^2 + 3x)/dx at x=2\n\ntensor(7.)\n\n\n\n\n\n\nTensor.grad_fn: Points to the function that created the tensor.\nTensor.grad: Stores the computed gradient.\ntorch.autograd.Function: Base class for custom differentiable operations.\n\n\n\n\n\n\n\ntorch.fx allows you to capture and transform PyTorch programs as Python-level graphs. This is useful for: - Programmatic model transformations - Debugging and visualization - Building custom compiler backends\n\n\n\n\nGraphModule: A traced model with a modifiable structure.\nTracer: Walks through the model and builds a Graph.\nGraph: Contains Node objects that represent operations.\n\n\n\nimport torch\nimport torch.nn as nn\nimport torch.fx as fx\n\nclass MyModel(nn.Module):\n    def forward(self, x):\n        return x * 2 + 3\n\nmodel = MyModel()\ntraced = fx.symbolic_trace(model)\nprint(traced.graph)\n\ngraph():\n    %x : [num_users=1] = placeholder[target=x]\n    %mul : [num_users=1] = call_function[target=operator.mul](args = (%x, 2), kwargs = {})\n    %add : [num_users=1] = call_function[target=operator.add](args = (%mul, 3), kwargs = {})\n    return add\n\n\n\n\n\n\nTorchDynamo and TorchInductor use FX graphs as part of the compilation pipeline.\nFX enables quantization and pruning workflows by allowing insertion or transformation of operations.\n\n\n\n\n\nBoth Autograd and torch.fx are essential for understanding what happens under the hood in PyTorch. Whether you’re debugging models, optimizing inference, or building custom backends, mastering these tools opens the door to deeper systems-level work in AI.\nIn future posts, I plan to explore: - Implementing custom autograd functions - Writing your own FX passes for transformations - Diving into TorchDynamo and TorchInductor"
  },
  {
    "objectID": "posts/Understanding Pytorch/pytorch-1.html#introduction",
    "href": "posts/Understanding Pytorch/pytorch-1.html#introduction",
    "title": "Deep Dive into PyTorch Internals: Autograd and torch.fx",
    "section": "",
    "text": "As I continue to deepen my understanding of machine learning systems, I’ve realized that knowing how models run is just as important as knowing how to build them. This post kicks off a series where I explore PyTorch internals, starting with two powerful components: Autograd and torch.fx."
  },
  {
    "objectID": "posts/Understanding Pytorch/pytorch-1.html#pytorch-autograd-the-engine-behind-gradient-descent",
    "href": "posts/Understanding Pytorch/pytorch-1.html#pytorch-autograd-the-engine-behind-gradient-descent",
    "title": "Deep Dive into PyTorch Internals: Autograd and torch.fx",
    "section": "",
    "text": "PyTorch’s autograd is a dynamic automatic differentiation engine. It records operations on tensors to build a computation graph during the forward pass, and then traverses that graph in reverse to compute gradients during the backward pass.\n\n\n\nWhen you perform operations on torch.Tensor objects with requires_grad=True, PyTorch:\n\nCreates a computation graph on the fly.\nEach operation produces a Function object (e.g., AddBackward, MulBackward).\nWhen .backward() is called, the engine performs reverse-mode automatic differentiation.\n\n\n\n\n\nimport torch\nx = torch.tensor(2.0, requires_grad=True)\ny = x * x + 3 * x\nz = y.mean()\nz.backward()\nprint(x.grad)  # 7.0 = d(x^2 + 3x)/dx at x=2\n\ntensor(7.)\n\n\n\n\n\n\nTensor.grad_fn: Points to the function that created the tensor.\nTensor.grad: Stores the computed gradient.\ntorch.autograd.Function: Base class for custom differentiable operations."
  },
  {
    "objectID": "posts/Understanding Pytorch/pytorch-1.html#torch.fx-pytorchs-intermediate-representation",
    "href": "posts/Understanding Pytorch/pytorch-1.html#torch.fx-pytorchs-intermediate-representation",
    "title": "Deep Dive into PyTorch Internals: Autograd and torch.fx",
    "section": "",
    "text": "torch.fx allows you to capture and transform PyTorch programs as Python-level graphs. This is useful for: - Programmatic model transformations - Debugging and visualization - Building custom compiler backends\n\n\n\n\nGraphModule: A traced model with a modifiable structure.\nTracer: Walks through the model and builds a Graph.\nGraph: Contains Node objects that represent operations.\n\n\n\nimport torch\nimport torch.nn as nn\nimport torch.fx as fx\n\nclass MyModel(nn.Module):\n    def forward(self, x):\n        return x * 2 + 3\n\nmodel = MyModel()\ntraced = fx.symbolic_trace(model)\nprint(traced.graph)\n\ngraph():\n    %x : [num_users=1] = placeholder[target=x]\n    %mul : [num_users=1] = call_function[target=operator.mul](args = (%x, 2), kwargs = {})\n    %add : [num_users=1] = call_function[target=operator.add](args = (%mul, 3), kwargs = {})\n    return add\n\n\n\n\n\n\nTorchDynamo and TorchInductor use FX graphs as part of the compilation pipeline.\nFX enables quantization and pruning workflows by allowing insertion or transformation of operations."
  },
  {
    "objectID": "posts/Understanding Pytorch/pytorch-1.html#conclusion",
    "href": "posts/Understanding Pytorch/pytorch-1.html#conclusion",
    "title": "Deep Dive into PyTorch Internals: Autograd and torch.fx",
    "section": "",
    "text": "Both Autograd and torch.fx are essential for understanding what happens under the hood in PyTorch. Whether you’re debugging models, optimizing inference, or building custom backends, mastering these tools opens the door to deeper systems-level work in AI.\nIn future posts, I plan to explore: - Implementing custom autograd functions - Writing your own FX passes for transformations - Diving into TorchDynamo and TorchInductor"
  },
  {
    "objectID": "posts/Fastai_ch2/Questionnaire.html",
    "href": "posts/Fastai_ch2/Questionnaire.html",
    "title": "Chapter 2: Questionnaire",
    "section": "",
    "text": "Q1:\nProvide an example of where the bear classification model might work poorly in production, due to structural or style differences in the training data.\n___ * There is many cases where the bear_classifaction model could produce low results because of low quality of training data: - imbalance dataset: where we have much datapoint of one class way more than other classes, what causes the model to be biased toward one class. - the image used in training are low quality, low resolution.\nQ2: Where do text models currently have a major deficiency? ___ * The current transformers models shows oustanding results in generating texts and essais, understanding (in a way!) human language and can participate in a full conversation on different topics and give understandable and admirable responses. * However the way models learn from text is way different than the human do. Models needs a huge amount of text data: \n\nIn this paper,Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data Emily Bender and Alexander Koller consider whether LMs such as GPT-3 or BERT can ever learn to “understand” language? the researchers insists on deffirentiate between form (which LMs are good at understanding) and meaning( which obviously LMs can’t understand).\n\nQ3:\nWhat are the possible negative societal implications of text generation models?\n___ * If someone uses these LMs to generate highly-compeling responds on social media in order to spred misinformation or encourage conflits.\nQ4:\nIn situations where a model might make mistakes, and those mistakes could be harmful, what is a good alternative to automating a process?\n___\n* In this case we need to set a system where there’s a human intervention.\nQ5:\nWhat are the steps of the Drivetrain approach?\n___ - Define your Objective\n- Levers\n- Data\n- Models\nQ6:\nWhat is DataLoaders?\n___ * DataLoaders is a Fastai thin class that coutains dataloader for training and validation.\nQ7:\nWhat four things do we need to tell fastai to create DataLoaders?\n___ * Data we have * How to get items * How to label them * How to create train/validation\nQ8:\nWhat does the splitter parameter to DataBlock do? ___ * Splitter provide the way we want our data set to be splited.\nQ9:\nHow do we ensure a random split always gives the same validation set?\n___ * By fixing the seed value.\nQ10:\nWhat letters are often used to signify the independent and dependent variables?\n____ * x for independent variables, y for dependent.\nQ11:\nWhat’s the difference between crop, pad, and squish Resize() approaches? When might you choose one over the other?\n___\n\nCrop is the default Resize() method, which crop the image and take desired dimension, this may cause losing important information.\nPad is an alternative Resize() method, which pads the matrix of the image’s pixels with zeros (which shows as black when viewing the images), this may results in a lower effective resolution for the part of the image we actually use.\nSquish is another alternative Resize() method, which can either squish or stretch the image. This can cause the image to take on an unrealistic shape, leading to a model that learns that things look different to how they actually are, which we would expect to result in lower accuracy.\nThe better method is something depends on the problem we have, type of data we will use..\nWe will see later different methods, like RandomResizeCrop and many more.\n\nQ12:\nWhat is data augmentation? Why is it needed?\n___\n* Data augmentation refer to the process of generating more datapoints from the actaual data we have, and representing it within the dataset. * For example we could take an image and do some type of transformation to it, like flipping it or ratating it the resize the crop it, which will give us many images with different views and sizes. * This method other than making our dataset larger, it make it rich and diverse which will without doubt influence the generalization of the model.\nQ13:\nWhat is the difference between item_tfms and batch_tfms?\n___ * item_tfms is done on cpu, batch_tfms on gpu.\nQ14:\nWhat is a confusion matrix?\n___ * confusion_matrix return where the model get wrong prediction and what was the actual label.\nQ15:\nWhat does export save do?\n____ * It saves 3 things: - the architecture - the updated parameters(weihts+biases) - the way we built dataloaders\nQ15:\nWhat is it called when we use a model for getting predictions, instead of training?\n____ * Inference"
  },
  {
    "objectID": "posts/Fastai_ch2/Questionnaire.html#questionnaire",
    "href": "posts/Fastai_ch2/Questionnaire.html#questionnaire",
    "title": "Chapter 2: Questionnaire",
    "section": "",
    "text": "Q1:\nProvide an example of where the bear classification model might work poorly in production, due to structural or style differences in the training data.\n___ * There is many cases where the bear_classifaction model could produce low results because of low quality of training data: - imbalance dataset: where we have much datapoint of one class way more than other classes, what causes the model to be biased toward one class. - the image used in training are low quality, low resolution.\nQ2: Where do text models currently have a major deficiency? ___ * The current transformers models shows oustanding results in generating texts and essais, understanding (in a way!) human language and can participate in a full conversation on different topics and give understandable and admirable responses. * However the way models learn from text is way different than the human do. Models needs a huge amount of text data: \n\nIn this paper,Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data Emily Bender and Alexander Koller consider whether LMs such as GPT-3 or BERT can ever learn to “understand” language? the researchers insists on deffirentiate between form (which LMs are good at understanding) and meaning( which obviously LMs can’t understand).\n\nQ3:\nWhat are the possible negative societal implications of text generation models?\n___ * If someone uses these LMs to generate highly-compeling responds on social media in order to spred misinformation or encourage conflits.\nQ4:\nIn situations where a model might make mistakes, and those mistakes could be harmful, what is a good alternative to automating a process?\n___\n* In this case we need to set a system where there’s a human intervention.\nQ5:\nWhat are the steps of the Drivetrain approach?\n___ - Define your Objective\n- Levers\n- Data\n- Models\nQ6:\nWhat is DataLoaders?\n___ * DataLoaders is a Fastai thin class that coutains dataloader for training and validation.\nQ7:\nWhat four things do we need to tell fastai to create DataLoaders?\n___ * Data we have * How to get items * How to label them * How to create train/validation\nQ8:\nWhat does the splitter parameter to DataBlock do? ___ * Splitter provide the way we want our data set to be splited.\nQ9:\nHow do we ensure a random split always gives the same validation set?\n___ * By fixing the seed value.\nQ10:\nWhat letters are often used to signify the independent and dependent variables?\n____ * x for independent variables, y for dependent.\nQ11:\nWhat’s the difference between crop, pad, and squish Resize() approaches? When might you choose one over the other?\n___\n\nCrop is the default Resize() method, which crop the image and take desired dimension, this may cause losing important information.\nPad is an alternative Resize() method, which pads the matrix of the image’s pixels with zeros (which shows as black when viewing the images), this may results in a lower effective resolution for the part of the image we actually use.\nSquish is another alternative Resize() method, which can either squish or stretch the image. This can cause the image to take on an unrealistic shape, leading to a model that learns that things look different to how they actually are, which we would expect to result in lower accuracy.\nThe better method is something depends on the problem we have, type of data we will use..\nWe will see later different methods, like RandomResizeCrop and many more.\n\nQ12:\nWhat is data augmentation? Why is it needed?\n___\n* Data augmentation refer to the process of generating more datapoints from the actaual data we have, and representing it within the dataset. * For example we could take an image and do some type of transformation to it, like flipping it or ratating it the resize the crop it, which will give us many images with different views and sizes. * This method other than making our dataset larger, it make it rich and diverse which will without doubt influence the generalization of the model.\nQ13:\nWhat is the difference between item_tfms and batch_tfms?\n___ * item_tfms is done on cpu, batch_tfms on gpu.\nQ14:\nWhat is a confusion matrix?\n___ * confusion_matrix return where the model get wrong prediction and what was the actual label.\nQ15:\nWhat does export save do?\n____ * It saves 3 things: - the architecture - the updated parameters(weihts+biases) - the way we built dataloaders\nQ15:\nWhat is it called when we use a model for getting predictions, instead of training?\n____ * Inference"
  },
  {
    "objectID": "posts/HuggingFace_3/HuggungFace_NLP_course_Notes_3.html",
    "href": "posts/HuggingFace_3/HuggungFace_NLP_course_Notes_3.html",
    "title": "Hugging Face Course Notes: Chapter3",
    "section": "",
    "text": "In the previous chapter we learned how to use tokenizers and pretrained models to make predictions.\nIn this chapter we will see how to Fine-tune a model on our Dataset by learning:\n\nHow to prepare a large dataset for the finetuning process\nHow to use the high level API trainer to finetune a model\nHow to leverage the HuggingFace Accelerate library to easily run that custom training loop on any distributed setup\n\nBut first let’s do the usuall by picking an architecture/model/tokenizer, and then train it some sample data:\n\n\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n\n\nmdl_ckp = 'bert-base-uncased'\ntokenizer = AutoTokenizer.from_pretrained(mdl_ckp)\nmodel = AutoModelForSequenceClassification.from_pretrained(mdl_ckp)\nsequences = [\"I've been waiting for a HuggingFace course my whole life.\", \"This course is amazing!\"]\nbatch = tokenizer(sequences, truncation=True, padding=True, return_tensors='pt')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n\n# will be axplained later\nbatch['labels'] = torch.tensor([1, 1])\n\n\n# training\noptimizer = torch.optim.AdamW(model.parameters())\nloss = model(**batch).loss\nloss.backward()\noptimizer.step()\n\n\nOf course training a model on 2 sentences will not yield a good results\nSo we need to introduce it to a larger dataset\nIn this chapter we will work with: example the MRPC (Microsoft Research Paraphrase Corpus) dataset.\n\nThe dataset consists of 5,801 pairs of sentences, with a label indicating if they are paraphrases or not (i.e., if both sentences mean the same thing)\nThis is one of the 10 datasets composing the GLUE benchmark, which is an academic benchmark that is used to measure the performance of ML models across 10 different text classification tasks\n\n\n\n\n\nWe can easily download a dataset from the Hub just like we did with models before:\n\n\n# load dataset\nfrom datasets import load_dataset\nraw_ds = load_dataset('glue', 'mrpc')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nraw_ds\n\nDatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 3668\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 408\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 1725\n    })\n})\n\n\n\nDatasets are presented as DatasetDict which is an object dictionary that our datset is organized by.\n\nHere we have our training-set, validation-set and test-set.\nEach set 2 keys: features and num_rows.\nFeatures has: sentence1, sentence2, label, idx\nsentence1&2 represent the pair we need to train our model on and predict whether its paraphrased or not.\n\nWe can access each pair of sentences in our raw_datasets object by indexing, like with a dictionary:\n\n\n# training set\ntrain_ds = raw_ds['train']\ntrain_ds[22]\n\n{'sentence1': 'A BMI of 25 or above is considered overweight ; 30 or above is considered obese .',\n 'sentence2': 'A BMI between 18.5 and 24.9 is considered normal , over 25 is considered overweight and 30 or greater is defined as obese .',\n 'label': 0,\n 'idx': 24}\n\n\n\nHere we see the pair of sentences, the label and the index of that pair.\nLabels are already int value so we won’t need to preprocess them.\nWhat means label: 0?\n\n\n# what means each label\ntrain_ds.features\n\n{'sentence1': Value(dtype='string', id=None),\n 'sentence2': Value(dtype='string', id=None),\n 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n 'idx': Value(dtype='int32', id=None)}\n\n\n\n0 for not_equivalent and 1 for equivalent\n\n\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(mdl_ckp)\ntrain_seq1 = tokenizer(train_ds['sentence1'])\ntrain_seq2 = tokenizer(train_ds['sentence2'])\n\n\n\n\n\nWe can’t just pass two sequences to the model and expect to get proper prediction about whether these sequences are paraphrased or not.\nWe need to apply a proper preparation of the data in order feed the model pairs of sequences instead 2 sentences separtly.\nThis can be done first whith the tokenizer, we create pairs of tokens and compute them the way BERT expect:\n\n\n#example\ninput = tokenizer('this is the first sentence', 'this is number 2')\ninput\n\n{'input_ids': [101, 2023, 2003, 1996, 2034, 6251, 102, 2023, 2003, 2193, 1016, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n\n\n\nThe tokenizer output: input_ids, attention_mask, but also token_type_ids.\nThis feature tells us that the tokenizer is aware that we are dealing with the two sentences, each is represented by either 0 or 1\n\n\ninput.token_type_ids\n\n[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n\n\n\nIf we convert each input_ids back to token we can have and idea of what happend:\n\n\ntokenizer.convert_ids_to_tokens(input['input_ids'])\n\n['[CLS]',\n 'this',\n 'is',\n 'the',\n 'first',\n 'sentence',\n '[SEP]',\n 'this',\n 'is',\n 'number',\n '2',\n '[SEP]']\n\n\n\nSo we see the model expects the inputs to be of the form [CLS] sentence1 [SEP] sentence2 [SEP]\nNote that not all model’s tokenizer can perform this because the way each model is trained, here BERT have seen pairs and knows how to deal with them.\nWe can then pass pairs of sentences to the tokenizer like this:\n\n\ntokenized_dataset = tokenizer(train_ds['sentence1'], train_ds['sentence2'], truncation=True, padding=True)\n\n\nThis way of tokenizing the whole dataset is not ideal since it requires huge RAM to store the dataset while we process it.\nIt will also return dictionary keys: attention_mask, input_ids, token_type_ids and its values.\nTo work around this problem we will use map() method which will keep data as dataset, and also it will give us more flexibility if we need more preprocessing more than just tokenizing.\nmap() works by applying a function to each element of the dataset, let’s create a function that tokenize pairs of sentences so the map method use it over the whole dataset:\n\n\ndef func_tokenize(example):\n  return tokenizer(example['sentence1'], example['sentence2'], truncation=True)\n\n\nThis function takes a dictionary (like the items of our dataset) and returns a new dictionary with the keys input_ids, attention_mask, and token_type_ids.\nWe didn’t include the padding here, because it’s not sufficient to pad the whole dataset based on the longest sentence, when we can do it on the batch level\nWe can pass the batching as argument in the map() method\n\n\ntokenized_datasets = raw_ds.map(func_tokenize, batched=True)\n\n\n\n\n\n\n\n\n\n\n\nLet’s take a look on pair exmaple from the training dataset:\nWe get what we expected, the 3 keys representing tokenization process, plus the dictionary key we already have: label, idx and sentence1&2:\n\n\ntokenized_datasets['train'][55].keys()\n\ndict_keys(['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'])\n\n\n\nNow we have to deal with the padding since we decided to apply it o the batch-level, so each batch will have its own longest sequence to pad on.\nSo we need to do a process called: Dynamic Padding.\n\n\n\n\nPutting the samples together in a single batch is done throught a function called: Collate function.\nCollate function convert our samples to Pytorch tensors and concatenate them.\nBut this can’t be done without padding, otherwise we will get different shapes for tensors.\nAs we said before the padding process should be done on batch level, which means each batch will have its samples padded according to the longest sequence otherwise we will get samples a with lot of paddings.\nIn practice we have to define a collate-function that apply the correct amount of padding to the items of the dataset we want to batch together.\n\n\nfrom transformers import DataCollatorWithPadding\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n\nHere we test this collate function on some samples from training set.\nWe need first to remove columns idx, sentence1, sentence2 since we don’t need them.\nLet’s have a look at the length of each entry in the batch:\n\n\nsamples = tokenized_datasets['train'][:8]\nsamples = {k: v for k, v in samples.items() if k not in ['idx', 'sentence1', 'sentence2']}\n[len(x) for x in samples['input_ids']]\n\n\n[50, 59, 47, 67, 59, 50, 62, 32]\n\n\n\nsamples.keys()\n\ndict_keys(['label', 'input_ids', 'token_type_ids', 'attention_mask'])\n\n\n\nThese samples are varying between 32 and 67, so our job here is to pad all the other sequence in this particular in respect to the treshold.\n\n\nsample_batch = data_collator(samples)\n{k:v.shape for k, v in sample_batch.items()}\n\nYou're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n\n\n{'input_ids': torch.Size([8, 67]),\n 'token_type_ids': torch.Size([8, 67]),\n 'attention_mask': torch.Size([8, 67]),\n 'labels': torch.Size([8])}\n\n\n\nLet’s check again if our input_ids have the same length:\n\n\n[len(i) for i in sample_batch['input_ids']]\n\n[67, 67, 67, 67, 67, 67, 67, 67]"
  },
  {
    "objectID": "posts/HuggingFace_3/HuggungFace_NLP_course_Notes_3.html#loading-datasets-from-the-hub",
    "href": "posts/HuggingFace_3/HuggungFace_NLP_course_Notes_3.html#loading-datasets-from-the-hub",
    "title": "Hugging Face Course Notes: Chapter3",
    "section": "",
    "text": "We can easily download a dataset from the Hub just like we did with models before:\n\n\n# load dataset\nfrom datasets import load_dataset\nraw_ds = load_dataset('glue', 'mrpc')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nraw_ds\n\nDatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 3668\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 408\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 1725\n    })\n})\n\n\n\nDatasets are presented as DatasetDict which is an object dictionary that our datset is organized by.\n\nHere we have our training-set, validation-set and test-set.\nEach set 2 keys: features and num_rows.\nFeatures has: sentence1, sentence2, label, idx\nsentence1&2 represent the pair we need to train our model on and predict whether its paraphrased or not.\n\nWe can access each pair of sentences in our raw_datasets object by indexing, like with a dictionary:\n\n\n# training set\ntrain_ds = raw_ds['train']\ntrain_ds[22]\n\n{'sentence1': 'A BMI of 25 or above is considered overweight ; 30 or above is considered obese .',\n 'sentence2': 'A BMI between 18.5 and 24.9 is considered normal , over 25 is considered overweight and 30 or greater is defined as obese .',\n 'label': 0,\n 'idx': 24}\n\n\n\nHere we see the pair of sentences, the label and the index of that pair.\nLabels are already int value so we won’t need to preprocess them.\nWhat means label: 0?\n\n\n# what means each label\ntrain_ds.features\n\n{'sentence1': Value(dtype='string', id=None),\n 'sentence2': Value(dtype='string', id=None),\n 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n 'idx': Value(dtype='int32', id=None)}\n\n\n\n0 for not_equivalent and 1 for equivalent\n\n\nfrom transformers import AutoTokenizer\ntokenizer = AutoTokenizer.from_pretrained(mdl_ckp)\ntrain_seq1 = tokenizer(train_ds['sentence1'])\ntrain_seq2 = tokenizer(train_ds['sentence2'])"
  },
  {
    "objectID": "posts/HuggingFace_3/HuggungFace_NLP_course_Notes_3.html#preprocessing-the-dataset",
    "href": "posts/HuggingFace_3/HuggungFace_NLP_course_Notes_3.html#preprocessing-the-dataset",
    "title": "Hugging Face Course Notes: Chapter3",
    "section": "",
    "text": "We can’t just pass two sequences to the model and expect to get proper prediction about whether these sequences are paraphrased or not.\nWe need to apply a proper preparation of the data in order feed the model pairs of sequences instead 2 sentences separtly.\nThis can be done first whith the tokenizer, we create pairs of tokens and compute them the way BERT expect:\n\n\n#example\ninput = tokenizer('this is the first sentence', 'this is number 2')\ninput\n\n{'input_ids': [101, 2023, 2003, 1996, 2034, 6251, 102, 2023, 2003, 2193, 1016, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n\n\n\nThe tokenizer output: input_ids, attention_mask, but also token_type_ids.\nThis feature tells us that the tokenizer is aware that we are dealing with the two sentences, each is represented by either 0 or 1\n\n\ninput.token_type_ids\n\n[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n\n\n\nIf we convert each input_ids back to token we can have and idea of what happend:\n\n\ntokenizer.convert_ids_to_tokens(input['input_ids'])\n\n['[CLS]',\n 'this',\n 'is',\n 'the',\n 'first',\n 'sentence',\n '[SEP]',\n 'this',\n 'is',\n 'number',\n '2',\n '[SEP]']\n\n\n\nSo we see the model expects the inputs to be of the form [CLS] sentence1 [SEP] sentence2 [SEP]\nNote that not all model’s tokenizer can perform this because the way each model is trained, here BERT have seen pairs and knows how to deal with them.\nWe can then pass pairs of sentences to the tokenizer like this:\n\n\ntokenized_dataset = tokenizer(train_ds['sentence1'], train_ds['sentence2'], truncation=True, padding=True)\n\n\nThis way of tokenizing the whole dataset is not ideal since it requires huge RAM to store the dataset while we process it.\nIt will also return dictionary keys: attention_mask, input_ids, token_type_ids and its values.\nTo work around this problem we will use map() method which will keep data as dataset, and also it will give us more flexibility if we need more preprocessing more than just tokenizing.\nmap() works by applying a function to each element of the dataset, let’s create a function that tokenize pairs of sentences so the map method use it over the whole dataset:\n\n\ndef func_tokenize(example):\n  return tokenizer(example['sentence1'], example['sentence2'], truncation=True)\n\n\nThis function takes a dictionary (like the items of our dataset) and returns a new dictionary with the keys input_ids, attention_mask, and token_type_ids.\nWe didn’t include the padding here, because it’s not sufficient to pad the whole dataset based on the longest sentence, when we can do it on the batch level\nWe can pass the batching as argument in the map() method\n\n\ntokenized_datasets = raw_ds.map(func_tokenize, batched=True)\n\n\n\n\n\n\n\n\n\n\n\nLet’s take a look on pair exmaple from the training dataset:\nWe get what we expected, the 3 keys representing tokenization process, plus the dictionary key we already have: label, idx and sentence1&2:\n\n\ntokenized_datasets['train'][55].keys()\n\ndict_keys(['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'])\n\n\n\nNow we have to deal with the padding since we decided to apply it o the batch-level, so each batch will have its own longest sequence to pad on.\nSo we need to do a process called: Dynamic Padding.\n\n\n\n\nPutting the samples together in a single batch is done throught a function called: Collate function.\nCollate function convert our samples to Pytorch tensors and concatenate them.\nBut this can’t be done without padding, otherwise we will get different shapes for tensors.\nAs we said before the padding process should be done on batch level, which means each batch will have its samples padded according to the longest sequence otherwise we will get samples a with lot of paddings.\nIn practice we have to define a collate-function that apply the correct amount of padding to the items of the dataset we want to batch together.\n\n\nfrom transformers import DataCollatorWithPadding\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\n\nHere we test this collate function on some samples from training set.\nWe need first to remove columns idx, sentence1, sentence2 since we don’t need them.\nLet’s have a look at the length of each entry in the batch:\n\n\nsamples = tokenized_datasets['train'][:8]\nsamples = {k: v for k, v in samples.items() if k not in ['idx', 'sentence1', 'sentence2']}\n[len(x) for x in samples['input_ids']]\n\n\n[50, 59, 47, 67, 59, 50, 62, 32]\n\n\n\nsamples.keys()\n\ndict_keys(['label', 'input_ids', 'token_type_ids', 'attention_mask'])\n\n\n\nThese samples are varying between 32 and 67, so our job here is to pad all the other sequence in this particular in respect to the treshold.\n\n\nsample_batch = data_collator(samples)\n{k:v.shape for k, v in sample_batch.items()}\n\nYou're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n\n\n{'input_ids': torch.Size([8, 67]),\n 'token_type_ids': torch.Size([8, 67]),\n 'attention_mask': torch.Size([8, 67]),\n 'labels': torch.Size([8])}\n\n\n\nLet’s check again if our input_ids have the same length:\n\n\n[len(i) for i in sample_batch['input_ids']]\n\n[67, 67, 67, 67, 67, 67, 67, 67]"
  },
  {
    "objectID": "posts/HuggingFace_3/HuggungFace_NLP_course_Notes_3.html#evaluation",
    "href": "posts/HuggingFace_3/HuggungFace_NLP_course_Notes_3.html#evaluation",
    "title": "Hugging Face Course Notes: Chapter3",
    "section": "Evaluation:",
    "text": "Evaluation:\n\nFirst we need to build a compute_metrics() function in order to use it in the next training.\nThe function takes a EvalPrediction object as argument, which is basically a named tuple with:\n\npredictions field\nlabel_ids field\n\nHere we get some predictions from our model:\n\n\npredictions = trainer.predict(tokenized_datasets[\"validation\"])\nprint(predictions.predictions.shape, predictions.label_ids.shape)\n\n\n\n\n(408, 2) (408,)\n\n\n\nThe output of the predict() method is another named tuple with three fields: predictions, label_ids, and metrics.\nMetrics represent the loss on the dataset, as well as the time metrics, how much it takes the predictions on total average.\nAs we see here, predictions is a two-dimensional array with shape 408 x 2 (408 being the number of elements in the dataset we used).\nIt represent the logits for each element of the dataset we passed to predict() .\nTo transform them into predictions that we can compare to our labels, we need to take the index with the maximum value on the second axis:\n\n\nimport numpy as np\n\npreds = np.argmax(predictions.predictions, axis=-1)\n\n\nNow we have ot build our compute_metrics() function in order to compare the predictions of the model with the actual labels.\nWe will use the metrics from the huggingFace library **’evaluate**, we just need to loa the meetrics associated with the dataset we usedmrpc`:\n\n\nimport evaluate\nmetric = evaluate.load('glue', 'mrpc')\nmetric.compute(predictions= preds, references= predictions.label_ids)\n\n\n\n\n{'accuracy': 0.8529411764705882, 'f1': 0.8993288590604027}\n\n\n\nNow let’s wrap everething in a single function:\n\n\ndef compute_metrics(eval_preds):\n  metric = evaluate.load('glue', 'mrpc')\n  logits, labels = eval_preds\n  predictions = np.argmax(logits, axis= -1)\n  return metric.compute(predictions= predictions, references= labels)\n\n\nNow let’s use it the training loop so it report all the metrics at the end of each epoch:\n\n\ntraining_args = TrainingArguments('test-train', evaluation_strategy= 'epoch')\ntrainer= Trainer(\n    model,\n    training_args,\n    train_dataset= tokenized_datasets['train'],\n    eval_dataset= tokenized_datasets['validation'],\n    data_collator= data_collator,\n    tokenizer= tokenizer,\n    compute_metrics= compute_metrics\n)\n\n\ntrainer.train()\n\n\n      \n      \n      [1377/1377 03:39, Epoch 3/3]\n    \n    \n\n\n\nEpoch\nTraining Loss\nValidation Loss\nAccuracy\nF1\n\n\n\n\n1\nNo log\n0.681234\n0.843137\n0.893333\n\n\n2\n0.162700\n0.998050\n0.840686\n0.892562\n\n\n3\n0.051500\n1.032399\n0.852941\n0.898305\n\n\n\n\n\n\nTrainOutput(global_step=1377, training_loss=0.08403856129254997, metrics={'train_runtime': 219.6964, 'train_samples_per_second': 50.087, 'train_steps_per_second': 6.268, 'total_flos': 405626802939840.0, 'train_loss': 0.08403856129254997, 'epoch': 3.0})\n\n\n\nIn this section we fine-tuned a model on a dataset by using the Trainer API, which minimize the work we have to since it works out of the box.\nTrainer can be used in most NLP tasks, but what if we need to do everything manualy by using pure Pytorch?\nIn next section we will build the same Trainer by hand.\n\n# A full training\n\nIn this section we will try to achieve the same results we had with Trainer API.\nSince we already done with the preprocessing of the dataset, we just have to to some tweaks regarding some columns of the dataset we won’t use:\n\n\ntokenized_ds = tokenized_datasets.remove_columns(['sentence1', 'sentence2', 'idx'])\ntokenized_ds = tokenized_ds.rename_column('label', 'labels')\ntokenized_ds.set_format('torch')\ntokenized_ds['train'].column_names\n\n['labels', 'input_ids', 'token_type_ids', 'attention_mask']\n\n\n\nNow we need to define the DataLoader that will help us to feed the model the dataset in batches:\n\n\nimport torch\nfrom torch.utils.data import DataLoader\n\n\ntrain_dataloader = DataLoader(tokenized_ds['train'], shuffle= True, batch_size= 8, collate_fn= data_collator)\neval_dataloader = DataLoader(tokenized_ds['validation'], batch_size= 8, collate_fn= data_collator)\n\n\nCheck the training data loader:\n\n\nfor batch in train_dataloader:\n  break\n{k:v.shape for k,v in batch.items()}\n\n{'labels': torch.Size([8]),\n 'input_ids': torch.Size([8, 70]),\n 'token_type_ids': torch.Size([8, 70]),\n 'attention_mask': torch.Size([8, 70])}\n\n\n\nMake sure that everything will go smoothly during the training , we pass a batch to the model:\n\n\nmodel = AutoModelForSequenceClassification.from_pretrained(mdl_ckp, num_labels= 2)\noutput= model(**batch)\noutput.loss, output.logits.shape\n\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n(tensor(0.5792, grad_fn=&lt;NllLossBackward0&gt;), torch.Size([8, 2]))\n\n\n\nEverything looks fine, before we build the training loop we just need 2 things:\n\noptimizer\nlearning-rate scheduler\n\nSonce we want to replicate the Trainer and its defaults parameters, the optimizer used by Trainer is Adam, we will use a slightly different optimizer AdamW:\n\n\noptimizer = AdamW(model.parameters(), lr= 5e-5)\n\n/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\n\n\nFinally the learning-rate scheduler used by the Trainer is just a simple linear decay from the highest learning-rate 5e-5 to 0.\nIn order to define it we just need to know the number of training steps.\n\n\nfrom transformers import get_scheduler\n\nnum_epochs = 3\nnum_training_steps = num_epochs * len(train_dataloader)\nlr_scheduler= get_scheduler(\n    'linear',\n    optimizer= optimizer,\n    num_warmup_steps = 0,\n    num_training_steps = num_training_steps\n)\n\n\nAs we mension before, Trainer works out of the box with any set of hardware we have, but now we have to set the GPU as device during the training:\n\n\ndevice = torch.device('cuda') if torch.cuda.is_available else torch.device('cpu')\nmodel.to(device)\n\nBertForSequenceClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): BertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=2, bias=True)\n)\n\n\n\nTraining Loop:\n\nNow we have all the ingredients to start out training loop:\n\n\nfrom tqdm.auto import tqdm\nprogress_bar = tqdm(range(num_training_steps))\n\nmodel.train()\nfor epoch in range(num_epochs):\n  for batch in train_dataloader:\n    batch = {k:v.to(device) for k, v in batch.items()}\n    outputs = model(**batch)\n    loss = outputs.loss\n    loss.backward()\n\n    optimizer.steps()\n    lr_scheduler.steps()\n    optimizer.zero_grad()\n    progress_bar.update(1)\n\n\n\nEvaluating Loop:\n\nEvaluation loop is basically the same as compute_metrics() function we built before:\n\n\nmetric = evaluate.load('glue', 'mrpc')\nmodel.eval()\nfor batch in eval_dataloader:\n  batch = {k:v.to(device) for k, v in batch.itmes()}\n  with torch.no_grad():\n    outputs = model(**batch)\n\n  logits = outputs.logits\n  predictions = torch.argmax(logits, axis= -1)\n  metric.add_batch(predictions=predictions, references= batch['labels'] )\nmetric.compute()\n\nTo recap, in this chapter we :\n- Learned about datasets in the Hub\n- Learned how to load and preprocess datasets, including using dynamic padding and collators\n- Implemented your own fine-tuning and evaluation of a model\n- Implemented a lower-level training loop"
  },
  {
    "objectID": "posts/GPU engineering/Tensors.html",
    "href": "posts/GPU engineering/Tensors.html",
    "title": "Learning Basics of Tensors",
    "section": "",
    "text": "import torch\nimport numpy as np\na = torch.tensor(range(6))\na = a.reshape(2, 3)\na.shape, a.stride()\n\n(torch.Size([2, 3]), (3, 1))"
  },
  {
    "objectID": "posts/GPU engineering/Tensors.html#data-blobs",
    "href": "posts/GPU engineering/Tensors.html#data-blobs",
    "title": "Learning Basics of Tensors",
    "section": "Data BLOBs:",
    "text": "Data BLOBs:\n\nThe last tensor we’ve created has a very interesting proprety, first we created the number of elements we want 12 then we reshape it by repspecting 2 rules:\n\nthe total number of elements should be 12 exactly\nthese 12 elements should be distributed on 3 dimensions in order to call it tensor\nwe decided to ge with (2, 3, 2) but we could go with any distribution as long as we respect the 2 rules.\n\nThe 12 represent the data BLOB while the distribution represent the metadata that tells us how the data is shaped.\nData Blob is a large, row chunk of numerical data with no assumed structure untill interpreted, it’s shapeless untill we attach metadata to it.\nIn the context of Kernel engineering we are not working with well defined tensors shapes, but with:\n\npointers to data blobs in memory\nsome metadata (shape, strides, dtype)\na set of indexing rules to access the correct slice\n\nSo if we write a tensor:\n\n\nx = torch.tensor((3, 4, 5))\n\n\nUnder the hood the data is stored in a single flat buffer 60 floats\nThe shape tells us: This is 3 blocks of 4 rows of 5 elements.\n\n\nStride:\n\nIn the context of Kernel engineering the Stride is the most important key. Since data is stored in the memory as blobs, stride tells us how many elements to skip in memory to move to the next element along a specific dimension. Think of it as the “memory jump” for each axis.\n\n\nz = torch.tensor(range(6))\nz = z.reshape(3, 2)\nz.shape, z.stride()\n\n(torch.Size([3, 2]), (2, 1))\n\n\n\nThe stride says:\n\nto move one row: jump 3 elements stride[0]\nto move one column: jumpt one element stride[1]\n\nSo in our case the tensor z has a stride of (2, 1):\n\n2 is the number of jumps in order to get to the next row\nwhile 1 is the number of jump to get to the next column\n\n\n\n\nTransposed Stride:\n\nWhat if we transposed the tensor z? will the stride remain the same?\n\n\ny = z.t()\nz.stride(), y.stride()\n\n((2, 1), (1, 2))\n\n\n\nThe transpose changed the stride but the data blob remain the same:\n\n\nz.data_ptr() == y.data_ptr()\n\nTrue\n\n\n\n\nStride exercises:\n\nLearn how stride works with some simple Pytorch examples: #### Exercise 1: Basic 2D Tensor Create a 2D tensor and inspect its stride.\n\n\n# x is a 2D tensor\nx =  torch.tensor(range(6)).reshape(2, 3)\n# its shape:\nx.shape\n\ntorch.Size([2, 3])\n\n\n\nHow to think about its stride?:\n\nIn order to move to the next row how many element should we pass? ==&gt; 3\nIn order to get to the next column how many elements we need to jump? ==&gt; 1\n\nSo the stride is (3, 1)\n\n\nx, x.stride()\n\n(tensor([[0, 1, 2],\n         [3, 4, 5]]),\n (3, 1))\n\n\n\nExercise 2: Transposed Tensor\n\nTranspose the tensor and observe how the stride changes.\n\n\ny = x.t()\ny, y.shape\n\n(tensor([[0, 3],\n         [1, 4],\n         [2, 5]]),\n torch.Size([3, 2]))\n\n\n\nIn this case and since we reversed the shape, its obvious that the stride also will be reversed: (1, 3)\nWhat’s important is that Pytorch doesn’t create new copy of x when trasnposed, it only redefine the way the new tensor is viewed with creating new shape and new stride.\n\n\ny.stride()\n\n(1, 3)\n\n\n\n\nExercise 3: Unsqueezed Tensor\n\nAdd a new dimension and understand how stride adjusts.\n\n\nz = x.unsqueeze(0)\nx.shape, z.shape\n\n(torch.Size([2, 3]), torch.Size([1, 2, 3]))\n\n\n\nWhat happend here is that Pytorch pretend there’s a new outer dim, so the shape is changed from [2, 3] to [1, 2, 3].\nthe new dim dim[0] should have stride of 6, because in order to get to a new element in that dim (even that there’s only one element in that dim) we need to pass all other elements in both dimensions [1] and [2], which both contain 2*3 = 6.\nRULE: the stride of the new dim is always the product of the inner strides\n\nso the stride should be: (6, 3, 1)\n\n\n\nz.stride()\n\n(6, 3, 1)\n\n\n\nd = torch.tensor(range(8)).reshape(2, 4)\nd, d.shape\n\n(tensor([[0, 1, 2, 3],\n         [4, 5, 6, 7]]),\n torch.Size([2, 4]))\n\n\n\nd.stride()\n\n(4, 1)\n\n\n\nd1 = d.unsqueeze(1)\nd1\n\ntensor([[[0, 1, 2, 3]],\n\n        [[4, 5, 6, 7]]])\n\n\n\nd1.shape, d1.stride()\n\n(torch.Size([2, 1, 4]), (4, 4, 1))\n\n\n\n\nExercise 4: Expanded Tensor\n\nBroadcast a tensor without copying memory.\n\n\na = torch.ones(1, 3)\nb = a.expand(2, 3)\n\n\na.shape, b.shape\n\n(torch.Size([1, 3]), torch.Size([2, 3]))\n\n\n\na.stride()\n\n(3, 1)\n\n\n\nHere we have a tensor a of shape [1, 3] then we use expand to make tensor b with shape of [2, 3].\nthe method expand doesn’t create a new copy of the original tensor rather then virtually expanding a dimension by repeating it without chnaging the memory.\nIn this case the dim[0] will be virtually repeated 2 times.\nIn the original tensor a we have a stride of (3, 1):\n\nIn order to get to the next element along dim=0(rows) we have to move 3 steps in memory\nTo move to the next element along dim=1 (columns), step by 1 in memory.\n\nNow with tensor b, as we say expand add a virtuall element to the dim=0, it add a new row, but in memory we don’t change anything. So to move to the next row we don’t have to step at all, so the stride at that dimension will be 0.\nThe other dim=1 remain the same 1\n\n\nb.stride()\n\n(0, 1)\n\n\n\n\nExercise 5: Permuted Tensor\nChange dimension order and inspect stride layout.\n\nx3 = torch.randn(2, 3, 4)\ny3 = x3.permute(2, 0, 1)\n\n\nx3, x3.shape\n\n(tensor([[[-4.9521e-01, -1.5715e+00,  9.7796e-01, -2.6375e-01],\n          [ 1.0992e+00,  4.2912e-01,  7.5855e-02,  1.6052e+00],\n          [-7.1012e-01,  7.3460e-01, -3.9331e-01,  1.0008e+00]],\n \n         [[ 5.4850e-01, -1.6360e+00,  1.8978e-01, -1.3920e-01],\n          [ 1.4362e-01,  4.4029e-01, -2.0576e-01, -2.7227e-01],\n          [-1.2247e-03,  1.3967e+00, -5.3473e-01, -7.4465e-01]]]),\n torch.Size([2, 3, 4]))\n\n\n\nx3.stride()\n\n(12, 4, 1)\n\n\n\ny3, y3.shape\n\n(tensor([[[-4.9521e-01,  1.0992e+00, -7.1012e-01],\n          [ 5.4850e-01,  1.4362e-01, -1.2247e-03]],\n \n         [[-1.5715e+00,  4.2912e-01,  7.3460e-01],\n          [-1.6360e+00,  4.4029e-01,  1.3967e+00]],\n \n         [[ 9.7796e-01,  7.5855e-02, -3.9331e-01],\n          [ 1.8978e-01, -2.0576e-01, -5.3473e-01]],\n \n         [[-2.6375e-01,  1.6052e+00,  1.0008e+00],\n          [-1.3920e-01, -2.7227e-01, -7.4465e-01]]]),\n torch.Size([4, 2, 3]))\n\n\n\nTo move along the new dimension 0 (size 4, originally dim 2), you step by 1 in memory (same as original dim 2).\nTo move along the new dimension 1 (size 2, originally dim 0), you step by 12 in memory (same as original dim 0).\nTo move along the new dimension 2 (size 3, originally dim 1), you step by 4 in memory (same as original dim 1).\nThis shows that permutation changes the order of strides but not their values. The new strides correspond to the original strides in the permuted order."
  },
  {
    "objectID": "posts/GPU engineering/Tensors.html#view",
    "href": "posts/GPU engineering/Tensors.html#view",
    "title": "Learning Basics of Tensors",
    "section": "View:",
    "text": "View:\n\nIn PyTorch, viewing a tensor refers to creating a new tensor that shares the same underlying data storage as the original tensor but with a different shape, stride, or metadata. This means the viewed tensor does not copy the data; instead, it provides an alternative way to interpret the existing data in memory. 1- Memory:\nView allow tensors to share memory.\nModifying the viewed tensor will modifies the original tensor. 2- Shape and Stride adjustement:\nAs we saw earlier view can reinterpret a tensor shape end stride without copying it or changing the memory. 3- Zero-Cost Operation:\nViewing is efficient because it does not allocate new memory or copy data.\nOperations like view(), transpose(), permute(), expand(), and slicing often return views."
  },
  {
    "objectID": "posts/GPU engineering/Tensors.html#broadcasting",
    "href": "posts/GPU engineering/Tensors.html#broadcasting",
    "title": "Learning Basics of Tensors",
    "section": "Broadcasting:",
    "text": "Broadcasting:\n\nBroadcasting automatically expands smaller tensors to match the shape of larger tensors for element-wise operations by following specific rules:\n\nTensors are aligned from rights to left\nif sizes are equal then they are compatible\nIf one tensor size is 1, it’s streched to match the other\nIf one tensor is missing a dimension, it’s treated like size 1 dimension (then streched to match)\n\n\n\n# adding vector to scalar\nvec = torch.tensor([1, 2, 3])\nscal = torch.tensor(5)\nout =  vec + scal\n\n\nprint(vec, vec.shape)\nprint(scal, scal.shape)\nprint(out, out.shape)\n\ntensor([1, 2, 3]) torch.Size([3])\ntensor(5) torch.Size([])\ntensor([6, 7, 8]) torch.Size([3])\n\n\n\n# tensor size 1\nA = torch.tensor([[1, 2], [3, 4]])  # Shape (2, 2)\nB = torch.tensor([[10, 20]])         # Shape (1, 2)\nC = A + B\n\n\nprint(A, A.shape)\nprint(B, B.shape)\nprint(C, C.shape)\n\ntensor([[1, 2],\n        [3, 4]]) torch.Size([2, 2])\ntensor([[10, 20]]) torch.Size([1, 2])\ntensor([[11, 22],\n        [13, 24]]) torch.Size([2, 2])\n\n\n\n# tensor missing a dimension:\nD = torch.tensor([[1, 2], [3, 4]])  # Shape (2, 2)\nR = torch.tensor([10, 20])          # Shape (2,)\nS = D + R\n\n\nprint(D, D.shape)\nprint(R, R.shape)\nprint(S, S.shape)\n\ntensor([[1, 2],\n        [3, 4]]) torch.Size([2, 2])\ntensor([10, 20]) torch.Size([2])\ntensor([[11, 22],\n        [13, 24]]) torch.Size([2, 2])"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Deep dive into PyTorch’s autograd system and torch.fx - understanding how automatic differentiation works under the hood.\nTopics: Autograd, torch.fx, PyTorch internals\nRead More →\n\n\n\n\nExploring tensors from a systems perspective: blobs, views, broadcasting, and how to think about tensor operations efficiently.\nTopics: Tensors, GPU Programming, Vectorization, Broadcasting\nRead More →\n\n\n\n\nUnderstanding Preference Optimization and its applications in aligning language models.\nStatus: Work in Progress 🔄\nRead Draft →"
  },
  {
    "objectID": "blog.html#featured-posts",
    "href": "blog.html#featured-posts",
    "title": "Blog",
    "section": "",
    "text": "Deep dive into PyTorch’s autograd system and torch.fx - understanding how automatic differentiation works under the hood.\nTopics: Autograd, torch.fx, PyTorch internals\nRead More →\n\n\n\n\nExploring tensors from a systems perspective: blobs, views, broadcasting, and how to think about tensor operations efficiently.\nTopics: Tensors, GPU Programming, Vectorization, Broadcasting\nRead More →\n\n\n\n\nUnderstanding Preference Optimization and its applications in aligning language models.\nStatus: Work in Progress 🔄\nRead Draft →"
  },
  {
    "objectID": "blog.html#all-posts",
    "href": "blog.html#all-posts",
    "title": "Blog",
    "section": "All Posts",
    "text": "All Posts\nThe posts below include learning notes, experiments, and technical write-ups from my journey."
  },
  {
    "objectID": "courses.html",
    "href": "courses.html",
    "title": "Courses & Learning Notes",
    "section": "",
    "text": "This section contains my notes, exercises, and insights from various courses and books I’ve worked through. These are organized sequentially to follow the learning path."
  },
  {
    "objectID": "courses.html#fast.ai-deep-learning-course",
    "href": "courses.html#fast.ai-deep-learning-course",
    "title": "Courses & Learning Notes",
    "section": "🎓 fast.ai Deep Learning Course",
    "text": "🎓 fast.ai Deep Learning Course\nPractical deep learning course by Jeremy Howard. Focused on top-down learning approach.\n\nChapter 1 - Getting Started | Questionnaire\nChapter 2 - Production Models | Questionnaire\nChapter 4 - Under the Hood | Questionnaire\nChapter 5 - Image Classification | Questionnaire\nChapter 6 - Other Computer Vision Problems | Questionnaire\nChapter 7 - Training a State-of-the-Art Model | Questionnaire\n\nStatus: Completed ✅"
  },
  {
    "objectID": "courses.html#hugging-face-transformers-course",
    "href": "courses.html#hugging-face-transformers-course",
    "title": "Courses & Learning Notes",
    "section": "🤗 Hugging Face Transformers Course",
    "text": "🤗 Hugging Face Transformers Course\nDeep dive into the Transformers library and modern NLP architectures.\n\nCourse 1 - Introduction\nCourse 2 - Using Transformers\nCourse 3 - Fine-tuning Models\nCourse 4 - Sharing Models and Tokenizers\nCourse 5 - Advanced Topics\n\nStatus: Completed ✅"
  },
  {
    "objectID": "courses.html#build-a-large-language-model-from-scratch",
    "href": "courses.html#build-a-large-language-model-from-scratch",
    "title": "Courses & Learning Notes",
    "section": "📚 Build a Large Language Model from Scratch",
    "text": "📚 Build a Large Language Model from Scratch\nFollowing Sebastian Raschka’s book on building LLMs from first principles.\n\nChapter 1 - Understanding Large Language Models\nChapter 2 - Working with Text Data\nChapter 3 - Coding Attention Mechanisms\n\nStatus: In Progress 🔄"
  },
  {
    "objectID": "courses.html#learning-c-and-cuda",
    "href": "courses.html#learning-c-and-cuda",
    "title": "Courses & Learning Notes",
    "section": "⚡ Learning C++ and CUDA",
    "text": "⚡ Learning C++ and CUDA\nLearning C++ fundamentals and CUDA programming for GPU kernel development.\n\nView Learning Notes -Lesson - 1 : Understanding the Compiler system of C++ and basic Synatax.\nView Learning Notes -Lesson - 2 : Learning about if statements, evaluating statements, comparison operators.\nView Learning Notes -Lesson - 3 : Learning about Lopps, their syntax, and how to use them properly.\nView Learning Notes\n\nStatus: Currently Learning 🔄"
  },
  {
    "objectID": "courses.html#whats-next",
    "href": "courses.html#whats-next",
    "title": "Courses & Learning Notes",
    "section": "What’s Next?",
    "text": "What’s Next?\nAfter completing the CUDA fundamentals, I plan to dive deeper into: - cuBLAS and cuDNN internals - Custom CUDA kernels for ML operations - PyTorch autograd and operator implementation\n\nThese notes represent my learning journey. They may contain errors or incomplete understanding as I progress. Feel free to point out mistakes or suggest improvements!"
  }
]