[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "In this Blog I share my learning journey through machine learning and datascience."
  },
  {
    "objectID": "posts/Fastai_ch1/Chapter1.html",
    "href": "posts/Fastai_ch1/Chapter1.html",
    "title": "Chapter 1: Deep learning for coders with fastai and pytorch",
    "section": "",
    "text": "! [ -e /content ] && pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()\n\n     |████████████████████████████████| 719 kB 34.6 MB/s \n     |████████████████████████████████| 1.3 MB 53.8 MB/s \n     |████████████████████████████████| 5.3 MB 53.3 MB/s \n     |████████████████████████████████| 441 kB 65.8 MB/s \n     |████████████████████████████████| 1.6 MB 46.3 MB/s \n     |████████████████████████████████| 212 kB 71.6 MB/s \n     |████████████████████████████████| 115 kB 71.6 MB/s \n     |████████████████████████████████| 163 kB 73.8 MB/s \n     |████████████████████████████████| 127 kB 72.7 MB/s \n     |████████████████████████████████| 115 kB 73.2 MB/s \n     |████████████████████████████████| 7.6 MB 48.1 MB/s \nMounted at /content/gdrive"
  },
  {
    "objectID": "posts/Fastai_ch1/Chapter1.html#brief-history-of-neural-network",
    "href": "posts/Fastai_ch1/Chapter1.html#brief-history-of-neural-network",
    "title": "Chapter 1: Deep learning for coders with fastai and pytorch",
    "section": "Brief History of Neural Network",
    "text": "Brief History of Neural Network\n\nIn 1943 Warren McCulloch, a neurophysiologist, and Walter Pitts, a logician, both devoloped a concept called Artificial Neuron which is seen today as the first theorotical demonstration of a machine that’s “..capable of perceiving, recognizing and identifying its surrondings”\n\nIn the 50’s Frank Rossenblatt devoloped a device based on the principiles of Artificial Neuron\n\nRosenblatt invented The Perceptron which was capable of recognizing simple shapes and patterns\n\n\nIn 1969 Marvin minsky write a book called Perceptrons where he showed that Perceptron limits of solving critical math problem\n\n\nParallel Distributed Processing (PDP)\n\nAfter a long winter of Deep Learning, a group of researchers at MIT released a papper in 1986 released the most influencial papper in history of Neural Network\n\nAuthors claimed that PDP approach was closer to how human brain works\n\nPDP require some enviroments elements:\n\nSet of processing units\n\nA state of activation\n\nAn output function for each unit\n\nPattern of connectivity among units\n\nPropagation rule for propagating patterns of activities through the network of connectivities\n\nAn activation rule for combining the inputs impinging on a unit with the current state of that unit to produce an output for the unit\n\nLearning rule whereby patterns of connectivity are modified by experience\n\nAn environment within which the system must operate\n\n\n\n\n1980’s and 90’s\n\nDuring this epoch researcher started to build models with 2 layers of neurons\n\nWe saw real world application of Deep Learning"
  },
  {
    "objectID": "posts/Fastai_ch1/Chapter1.html#top-to-bottom-learning-approach",
    "href": "posts/Fastai_ch1/Chapter1.html#top-to-bottom-learning-approach",
    "title": "Chapter 1: Deep learning for coders with fastai and pytorch",
    "section": "Top to bottom learning approach",
    "text": "Top to bottom learning approach\n\nStart with the end point\n\nBuild a foundation of intuition through application then build on it with theory\nShow students how individuals pieces of theory are combined in a real-world application\n\nTeach through examples\n\nProvide a context and a purpose for abstract concepts\n\n\n\nWhat is Machine Learning?\nTraditional Programming:\n- It’s hard to explicitly code hard tasks specialy when you don’t know the exact steps\n\n\n\na-traditional-program.png\n\n\nMachine Learning\n- A program that need to be showed examples of the desired tasks so it can Learn from them\n- Demand sufficient amount of examples(Data)\n- In 1949 Arthur Samuel manage to build a machine that can play checker - This work introduced multiple concepts to the world of machine learning: - The idea of a weight assignment\n- The fact that every weight assignment has some actual performance\n- The requirement that there be an automatic means of testing that performance\n- The need for a mechanism (i.e., another automatic process) for improving the performance by changing the weight assignments\n- Update the weight values based on the performance with the current values\n\n\n\nprogram-using-weight-assignments.png\n\n\n\nA system that used Weight Assignment\n\n >Training Machine Learning model with help of weights updating\n >Using the trained model as program\nNow Let’s Build Our First Model!"
  },
  {
    "objectID": "posts/Fastai_ch1/Chapter1.html#first-deep-learning-model-its-a-bird",
    "href": "posts/Fastai_ch1/Chapter1.html#first-deep-learning-model-its-a-bird",
    "title": "Chapter 1: Deep learning for coders with fastai and pytorch",
    "section": "First Deep Learning Model: It’s a Bird!",
    "text": "First Deep Learning Model: It’s a Bird!\n\nImport Dependencies\n\n#Import fastai library\n#Import fastai computer vision library \nfrom fastbook import *\nfrom fastai.vision.all import *\n\n\n\nStart working with Data\n\n# Here we use search_images_ddg in order to download an url from ddg\n# search engine accornding to the keyword we choose: birds photo\nurls = search_images_ddg('birds photo', max_images=1)\nlen(urls), urls[0]\n\n(1,\n 'https://www.wallpapergeeks.com/wp-content/uploads/2014/02/Colorful-Bird-Perched-Wallpaper.jpg')\n\n\n\n# download the photo from the url\ndest = 'bird.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nPath('bird.jpg')\n\n\n\n# then show it\nim = Image.open(dest)\nim.to_thumb(256,256)\n\n\n\n\nNow we will do the same etapes we did with bird.jpg image but with forest picture\n\n# Download the url, download the image then open it\ndownload_url(search_images_ddg('forest photos', max_images=1)[0], 'forest.jpg', show_progress=False)\nImage.open('forest.jpg').to_thumb(256,256)\n\n\n\n\nThe idea here is to build a model that can classify pictures of birds and forests accuratly, but first we need to build the Dataset\n\n# create 2 directories, one for birds and other for forest, then do the same etapes we did earlier,\n# download the urls then the images\nsearches = 'forest','bird'\npath = Path('bird_or_not')\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images_ddg(f'{o} photo'))\n    resize_images(path/o, max_size=400, dest=path/o)\n\nSince we are dowlnloading images from the web, there is a chance that some of them are corrupted, so we need to clean the dataset from them\n\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n1\n\n\n\nNow we have two directories :\n\nbirds\nforests\n\nAs we saw before, machine learning model needs to be feed many examples in order to learn from them.\nThese examples are the images of birds and forests in our case\nWe need to tell the model bunch of informations about our data before the training process, this will be done with help of DataBlock\n\n\n\nCreating DataBlock and DataLoaders\nNow we need to build DataBlock in order to feed the dataset to the model for the training.it’s basically set of rules of how to organize the dataset for the model.\nI will write a BlogPost about this concept later\nThere’s also the concept of DataLoaders which is an iterator class that load data to the model according to the set of rules that we set earlier while creating DataBlock\n\n# create the dataBlock\n# tell the model what kind of data we'r dealing with\n# how to get the data\n# how to create validation and training set\n# how to get the labels\n# how to set tranformers(items in this case)\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path)\n\ndls.show_batch(max_n=6)\n\n\n\n\n\n\nTraining the Model\nNow we are ready to train our model and see if we could classify photo of birds and forests\nThe model we will use here is resenet18 which is a famous model that’s used widely among computer vision classification problem, 18 stands for how many layers does the model have.\nfastai comes with fine_tune() which uses the best practices of fine tuning process.\n\nlearn =  vision_learner(dls, resnet18, metrics= error_rate)\nlearn.fine_tune(3)\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.550929\n      2.057105\n      0.447368\n      00:02\n    \n  \n\n\n\n\n\n\n\n\n\n  \n    \n      epoch\n      train_loss\n      valid_loss\n      error_rate\n      time\n    \n  \n  \n    \n      0\n      0.084728\n      0.225560\n      0.092105\n      00:02\n    \n    \n      1\n      0.045721\n      0.024148\n      0.000000\n      00:02\n    \n    \n      2\n      0.031065\n      0.012299\n      0.000000\n      00:02\n    \n  \n\n\n\n\nWith help of fastai library, and less than 20 lines of code we managed to build a model that can predict images of birds and forests with accuracy of 100%!\n\n\n\nFine Tuning\nis a process where we start with a model that has already be trained and we use it on our problem and on our dataset, this operation needs to adapt the pre-trained model by a bit so it fit our system\nThis approach can save us money and time, all we need to do is adapt the pre-trained model and take advantage of set of weights and use them in our problem\n\n\n\nLearner\nIn Fastai we have the Learner which takes 2 things(For now!): firsly the Dataset, and secondly the Model.\nBecause Deep Learning is more mature now,there’s a small group of Architecture that can be used in nearly any problem, that’s why the actual work of deep learning practionaire is to work on data preparation, and model deploying, more than anything else.\nThis is why Fastai integrated a famous library Timm which collect all SOTA (State Of The Art) computer vision models.\n\n\nVisualizing layers of a trained neural network\n\nIt is possible to inspect deep learning models and get insights from them\n\ncan still be challenging to fully understand\n\nVisualizing and Understanding Convolutional Networks paper\n\npublished by PhD student Matt Zeiler and his supervisor Rob Fergus in 2013\nshowed how to visualize the neural network weights learned in each layer of a model\ndiscovered the early layers in a convolutional neural network recognize edges and simple patterns which are combined in later layers to detect more complex shapes\n\nWe will see this paper in details later, but for now we could show the model architecture.\n\n\n# show the model architecture\nm = learn.model\nm\n\nSequential(\n  (0): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): ReLU(inplace=True)\n    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (5): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (6): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (7): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (1): Sequential(\n    (0): AdaptiveConcatPool2d(\n      (ap): AdaptiveAvgPool2d(output_size=1)\n      (mp): AdaptiveMaxPool2d(output_size=1)\n    )\n    (1): fastai.layers.Flatten(full=False)\n    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (3): Dropout(p=0.25, inplace=False)\n    (4): Linear(in_features=1024, out_features=512, bias=False)\n    (5): ReLU(inplace=True)\n    (6): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): Dropout(p=0.5, inplace=False)\n    (8): Linear(in_features=512, out_features=2, bias=False)\n  )\n)\n\n\n\n\nOther Deep Learning Applications\n\nImage Segmentation\n\ntraining a model to recognize the content of every single pixel in an image\n\n\n\n\n\noutput_47_2.png\n\n\n\nNatural Language Processing (NLP)\n\ngenerate text\ntranslate from one language to another\nanalyze comments\nlabel words in sentences\n\nTabular Data\n\ndata that in in the form of a table\n\nspreedsheets\ndatabases\nComma-separated Values (CSV) files\n\nmodel tries to predict the value of one column based on information in other columns\n\nRecommendation Systems\n\nmodel tries to predict the rating a user would give for something"
  },
  {
    "objectID": "posts/Fastai_ch1/Ch1_Questionnaire.html",
    "href": "posts/Fastai_ch1/Ch1_Questionnaire.html",
    "title": "Chapter 1: Questionnaire and Further Research",
    "section": "",
    "text": "Do you need these for deep learning?\n\nLots of math\n\nFalse\n\nLots of data\n\nFalse\n\nLots of expensive computers\n\nFalse\n\nA PhD\n\nFalse\n\n\n\n\n\nName five areas where deep learning is now the best in the world.\n\nMedical research\nRobotics\nAssurance\nLinguistics/ Natural Lunguage Processing\nBiology\n\n\n\n\nWhat was the name of the first device that was based on the principle of the artificial neuron?\n\nPercepton\n\n\n\n\nBased on the book of the same name, what are the requirements for parallel distributed processing (PDP)?\n\nSet of processing units\n\nA state of activation\n\nAn output function for each unit\n\nPattern of connectivity among units\n\nPropagation rule for propagating patterns of activities through the network of connectivities\n\nAn activation rule for combining the inputs impinging on a unit with the current state of that unit to produce an output for the unit\n\nLearning rule whereby patterns of connectivity are modified by experience\n\nAn environment within which the system must operate\n\n\n\n\nWhat were the two theoretical misunderstandings that held back the field of neural networks?\nMinsky in his book Perceptons shows the limitation of the device “perceptons” and how it cannot solve any comlex problem, the ai community did agreed with Minsky, but the did not pay attention to the solution he suggested, which is a 2 layer model.\nIn 80’s the 2 layer models were usual in ai labs. In theory a 2 layer model can solve any problem, but in practice the layers were too big and consum a lot of computation power, the solution to this is to add more layers, but this insight was not acknowledged, what leat to the 2 winter of NN.\n\n\n\nWhat is a GPU?\nIt’s a Graphic Prossessing Unit, which is used to do many computation tasks in parallel, which help to accelerate to compution of big tasks by cutting them into small tasks and compute them in parallel\n\n\n\nWhy is it hard to use a traditional computer program to recognize images in a photo?\nto write a programm that recognize images in a photo we need to write a long set of rules that resume any possible photo and image, tell the computer exactly how to deal with any of them, which is way more complicated that what we can do. That’s way we use machine learning to solve those kinfd of problems, just by showing the model data and help it to learn from it.\n\n\n\nWhat did Samuel mean by “Weight Assignment”?\nWhat term do we normally use in deep learning for what Samuel called “Weights”?\nDraw a picture that summarizes Arthur Samuel’s view of a machine learning model\nweight Assignment is refer to the parameters of the model, these are what we call today weights and bias. they are set of value we assign to each data point, what make the optimization of the loss possible.\n\n\n\nWhy is it hard to understand why a deep learning model makes a particular prediction?\nThis is a highly-researched topic known as interpretability of deep learning models. the natur of deep learning “deep” make it hard to really understand the way the model solve each problem, specially if the model has many layers, what makes it even hard to know exactly which layer is responsable of the procces of learning which part.\n\n\n\nWhat is the name of the theorem that shows that a neural network can solve any mathematical problem to any level of accuracy?\nUniversal approximation theorem\n\n\n\nWhat do you need in order to train a model?\nIn order to train a model, we need architecture for the given problem, we first need data(+labels), then we need set of values (paramaters), then we need some kind of metric to know if our model did good or bad (loss function), and we need a way to updates these parameters in order to optimize the loss function.\n\n\n\nHow could a feedback loop impact the rollout of a predictive policing model?\nIn a predictive policing model, we might end up with a positive feedback loop, leading to a highly biased model with little predictive power. For example, we may want a model that would predict crimes, but we use information on arrests as a proxy . However, this data itself is slightly biased due to the biases in existing policing processes. Training with this data leads to a biased model. Law enforcement might use the model to determine where to focus police activity, increasing arrests in those areas. These additional arrests would be used in training future iterations of models, leading to an even more biased model. This cycle continues as a positive feedback loop\n\n\n\nDo we always have to use 224x224 pixel images with the cat recognition model?\nNo.\n\n\n\nWhat is the difference between classification and regression?\nClassification problem is when we need to decide between 2(or more) classes, the prediction in this problem isn’t quantity, where regression problem is focused on predecting numeric quantity.\n\n\n\nWhat is a validation set? What is a test set? Why do we need them?\nValidation set is small portion of the data set that we preserve from the training fase in order to prevent the model from memorizing the data instead of learning from it. The validation set allow us to measure the performance of the model on data that the model didn’t see before. Same we can say about test set, which is another preserved protion of data that we use in the final fase of the training in order to have a real idea of model performance.\n\n\n\nWhat will fastai do if you don’t provide a validation set?\nit will automatically create a validation set of 20% of our dataset.\nvalid_pct=0.2\n\n\n\nWhat is overfitting?\nis when the model is memorizing answears instead of learning from data.\n\n\n\nWhat is a metric? How does it differ to “loss”?\nMetric is what tells us how the model perform, in other way the loss is what we should minimize in order to optimize the model perfromance.as we will see later, sometimes, we could use the metric as loss.\n\n\n\nHow can pretrained models help?\npertrained model can be used again, we just need to fin it in our probem.\na pretrained model is a model that learned many lesson from the prior problem, and already has good set of paramters, these parameters(weights+biases) are what we seek in the proccess of using a pretrained model. this procces is called fine-tunning, which mean less money and time consuming.\n\n\n\nWhat is the “head” of a model?\nWhen using a pretrained model, the later layers of the model, which were useful for the task that the model was originally trained on, are replaced with one or more new layers with randomized weights, of an appropriate size for the dataset you are working with. These new layers are called the “head” of the model.\n\n\n\nWhat is an “architecture”?\nThe architecture is the template or structure of the model we are trying to fit. It defines the mathematical model we are trying to fit.\n\n\n\nWhat are “hyperparameters”?\nTraining models requires various other parameters that define how the model is trained. For example, we need to define how long we train for, or what learning rate (how fast the model parameters are allowed to change) is used. These sorts of parameters are hyperparameters."
  },
  {
    "objectID": "posts/Fastai_ch1/Ch1_Questionnaire.html#further-research",
    "href": "posts/Fastai_ch1/Ch1_Questionnaire.html#further-research",
    "title": "Chapter 1: Questionnaire and Further Research",
    "section": "Further Research",
    "text": "Further Research\n\nWhy is a GPU useful for deep learning? How is a CPU different, and why is it less effective for deep learning?"
  },
  {
    "objectID": "posts/Fastai_ch1/Ch1_Questionnaire.html#what-is-a-gpu-what-make-it-different-from-cpu-and-why-do-we-need-it-to-do-deep-learning-tasks",
    "href": "posts/Fastai_ch1/Ch1_Questionnaire.html#what-is-a-gpu-what-make-it-different-from-cpu-and-why-do-we-need-it-to-do-deep-learning-tasks",
    "title": "Chapter 1: Questionnaire and Further Research",
    "section": "What is a GPU? What make it different from CPU? and Why do we need it to do Deep Learning tasks:",
    "text": "What is a GPU? What make it different from CPU? and Why do we need it to do Deep Learning tasks:\n\nGPU stands for Graphic Processing Unit, is a specialized processor with dedicated memory that conventionally perform floating point operations required for rendering graphics.\nIn other words, it’s a single-chip processor used for extensive graphical and mathematical computations which help the CPU to achieve other tasks.\nWhile CPU is designed to handel the complex logic in code once at a time, GPU can do many small operations at the same time, which make it very convenient to deep learning where we need to do many milions of calculations in order to train a model\n\n\nWhy do Deep Learning needs GPU?\n\nGPUs are optimized for training neural networks models as they can process multiple computations simultaneously.\nFor example the model we’ve fine-tuned in chapter one resnet18 which the smaller version of resnet models with only 18 hidden layers,though it has more than 11 millions parameters, in order to do one epoch and calculate all these parameter (wights + biases) and multiply them by the input variables (images) then do the Back-probagation and update them after calculating the loss … all this multiplications will take a large amount of time if we did it on CPU."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lifelong-Learner.github.io",
    "section": "",
    "text": "Fastai\n\n\nPytorch\n\n\nDeep Learning\n\n\n\n\n\n\n\n\n\n\n\nOct 25, 2022\n\n\nIsmail TG\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nFastai\n\n\nPytorch\n\n\nDeep Learning\n\n\n\n\n\n\n\n\n\n\n\nOct 25, 2022\n\n\nIsmail TG\n\n\n\n\n\n\nNo matching items"
  }
]