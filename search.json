[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/2022-22-10-Chapter-One.html",
    "href": "posts/2022-22-10-Chapter-One.html",
    "title": "Fastai Series: Chapter One",
    "section": "",
    "text": "Brief History of Neural Network\n\nIn 1943 Warren McCulloch, a neurophysiologist, and Walter Pitts, a logician, both devoloped a concept called Artificial Neuron which is seen today as the first theorotical demonstration of a machine that’s “..capable of perceiving, recognizing and identifying its surrondings”\n\nIn the 50’s Frank Rossenblatt devoloped a device based on the principiles of Artificial Neuron\n\nRosenblatt invented The Perceptron which was capable of recognizing simple shapes and patterns\n\n\nIn 1969 Marvin minsky write a book called Perceptrons where he showed that Perceptron limits of solving critical math problem\n\n\nParallel Distributed Processing (PDP)\n\nAfter a long winter of Deep Learning, a group of researchers at MIT released a papper in 1986 released the most influencial papper in history of Neural Network\n\nAuthors claimed that PDP approach was closer to how human brain works\n\nPDP require some enviroments elements:\n\nSet of processing units\n\nA state of activation\n\nAn output function for each unit\n\nPattern of connectivity among units\n\nPropagation rule for propagating patterns of activities through the network of connectivities\n\nAn activation rule for combining the inputs impinging on a unit with the current state of that unit to produce an output for the unit\n\nLearning rule whereby patterns of connectivity are modified by experience\n\nAn environment within which the system must operate\n\n\n1980’s and 90’s\n- During this epoch researcher started to build models with 2 layers of neurons\n- We saw real world application of Deep Learning\n\n\n\nTop to bottom learning approach\n\nStart with the end point\n\nBuild a foundation of intuition through application then build on it with theory\nShow students how individuals pieces of theory are combined in a real-world application\n\nTeach through examples\n\nProvide a context and a purpose for abstract concepts\n\n\n\n\nWhat is Machine Learning?\nTraditional Programming:\n- It’s hard to explicitly code hard tasks specialy when you don’t know the exact steps\n\n\n\na-traditional-program.png\n\n\nMachine Learning\n- Need to be showed examples of the desire tasks so it can Learn from them\n- Demand sufficient amount of examples(Data)\n- In 1949 Arthur Samuel manage to build a machine that can play checker - This work introduced multiple concepts to the world of machine learning: - The idea of a weight assignment\n- The fact that every weight assignment has some actual performance\n- The requirement that there be an automatic means of testing that performance\n- The need for a mechanism (i.e., another automatic process) for improving the performance by changing the weight assignments\n- Update the weight values based on the performance with the current values\n\n\n\nprogram-using-weight-assignments.png\n\n\n\nA system that used Weight Assignment\n\n >Training Machine Learning model with help of weights updating\n >Using the trained model as program\nNow Let’s Build Our First Model!\n\n\nFirst Deep Learning Model: It’s a Bird!\n\nImport Dependencies\n\n#Import fastai library\n#Import fastai computer vision library \nfrom fastbook import *\nfrom fastai.vision.all import *\n\nStart working with Data\n\n# Here we use search_images_ddg in order to download an url from ddg\n# search engine accornding to the keyword we choose: birds photo\nurls = search_images_ddg('birds photo', max_images=1)\nlen(urls), urls[0]\n\n(100,\n 'http://www.saga.co.uk/contentlibrary/saga/publishing/verticals/home-and-garden/gardening/garden-wildlife/galleries/exotic-birds/hoopoe.jpg')\n\n\n\n# download the photo from the url\ndest = 'bird.jpg'\ndownload_url(urls[0], dest, show_progress=False)\n\nPath('bird.jpg')\n\n\n\n# then show it\nim = Image.open(dest)\nim.to_thumb(256,256)\n\n\n\n\nNow we will do the same etapes we did with bird.jpg image but with forest picture\n\n# Download the url, download the image then open it\ndownload_url(search_images_ddg('forest photos', max_images=1)[0], 'forest.jpg', show_progress=False)\nImage.open('forest.jpg').to_thumb(256,256)\n\n\n\n\nThe idea here is to build a model that can classify pictures of birds and forests accuratly, but first we need to build the Dataset\n\n# create 2 directories, one for birds and other for forest, then do the same etapes we did earlier, download the urls then the images\nsearches = 'forest','bird'\npath = Path('bird_or_not')\n\nfor o in searches:\n    dest = (path/o)\n    dest.mkdir(exist_ok=True, parents=True)\n    download_images(dest, urls=search_images_ddg(f'{o} photo'))\n    resize_images(path/o, max_size=400, dest=path/o)\n\nSince we are dowlnloading images from the web, there is a chance that some of them are corrupted, so we need to clean the dataset from them\n\nfailed = verify_images(get_image_files(path))\nfailed.map(Path.unlink)\nlen(failed)\n\n1\n\n\n\n\nCreating DataBlock and DataLoaders\nNow we need to build DataBlock in order to feed the dataset to the model for the training.it’s basically set of rules of how to organize the dataset for the model.\nI will write a BlogPost about this concept later\nThere’s also the concept of DataLoaders which is an iterator class that load data to the model according to the set of rules that we set earlier while creating DataBlock\n\n# create the dataBlock\n# tell the model what kind of data we'r dealing with\n# how to get the data\n# how to create validation and training set\n# how to get the labels\n# how to set tranformers(items in this case)\ndls = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=[Resize(192, method='squish')]\n).dataloaders(path)\n\ndls.show_batch(max_n=6)\n\n\n\n\n\n\n\nTraining the Model\nNow we are ready to train our model and see if we could classify photo of birds and forests\nThe model we will use here is resenet18 which is a famous model that’s used widely among computer vision classification problem, 18 stands for how many layers does the model have.\nfastai comes with fine_tune() which uses the best practices of fine tuning process.\nbecause I can’t train this model on a old pc without gpu I did it on kaggle and this was the output of the training phase\nlearn = vision_learner(dls, resnet18, metrics=error_rate) learn.fine_tune(3)\n\n\n\nScreenshot%202022-07-27%20at%2002-47-01%20Fastai-CH1%20Kaggle.png\n\n\nFine Tuning\nis a process where we start with a model that has already be trained and we use it on our problem and on our dataset, this operation needs to adapt the pre-trained model by a bit so it fit our system\nThis approach can save us money and time, all we need to do is adapt the pre-trained model and take advantage of set of weights and use them in our problem\n\nLearner\nIn Fastai we have the Learner which takes 2 things: firsly the Dataset, and secondly the Model.\nBecause Deep Learning is more mature now,there’s a small group of Architecture that can be used in nearly any problem, that’s why the actual work of deep learning practionaire is to work on data preparation, and model deploying, more than anything else.\nThis is why Fastai integrated a famous library Timm which collect all SOTA (State Of The Art) computer vision models.\n\n\nVisualizing layers of a trained neural network\n\nIt is possible to inspect deep learning models and get insights from them\n\ncan still be challenging to fully understand\n\nVisualizing and Understanding Convolutional Networks\n\npublished by PhD student Matt Zeiler and his supervisor Rob Fergus in 2013\nshowed how to visualize the neural network weights learned in each layer of a model\ndiscovered the early layers in a convolutional neural network recognize edges and simple patterns which are combined in later layers to detect more complex shapes\n\n\n\n\nOther Deep Learning Applications\n\nImage Segmentation\n\ntraining a model to recognize the content of every single pixel in an image\n\n\n\n\n\noutput_47_2.png\n\n\n\nNatural Language Processing (NLP)\n\ngenerate text\ntranslate from one language to another\nanalyze comments\nlabel words in sentences\n\nTabular Data\n\ndata that in in the form of a table\n\nspreedsheets\ndatabases\nComma-separated Values (CSV) files\n\nmodel tries to predict the value of one column based on information in other columns\n\nRecommendation Systems\n\nmodel tries to predict the rating a user would give for something"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/Hallo-World-2022-22-10.html",
    "href": "posts/Hallo-World-2022-22-10.html",
    "title": "Hello World",
    "section": "",
    "text": "22+2\n\n24"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lifelong-Learner.github.io",
    "section": "",
    "text": "Fastai\n\n\nDeep Learning\n\n\n\n\n\n\n\n\n\n\n\nOct 22, 2022\n\n\n@ismailTG3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOct 22, 2022\n\n\nYour Name\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nOct 22, 2022\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  }
]