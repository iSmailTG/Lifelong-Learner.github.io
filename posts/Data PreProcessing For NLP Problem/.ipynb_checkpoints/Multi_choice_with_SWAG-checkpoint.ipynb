{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Multi Choice with Swag Dataset \"\n",
    "author: \"Ismail TG\"\n",
    "date: \"11/28/2023\"\n",
    "categories: [HuggingFace, Pytorch, NLP, Datasets]\n",
    "image: \"datasets.png\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leLWIjHwmM7n"
   },
   "source": [
    "# Introduction:\n",
    "\n",
    "* In this notebook I will try to investigate the **`SWAG`** datasets.\n",
    "* The idea is to understand how to deal with multiple choice datasets and how to prepare them for the next step.\n",
    "* Multiple choice is frequent problem in the filed of LLMs and NLP in general\n",
    "* So the preprocessing of data will have a huge effect on the success of any proposed solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "MAi3oFQroQ2q"
   },
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset('swag', 'regular')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "frevJ4E2onpX",
    "outputId": "77217f90-a443-47cd-aeda-db885317e33a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'video-id': 'anetv_jkn6uvmqwh4',\n",
       " 'fold-ind': '3416',\n",
       " 'startphrase': 'Members of the procession walk down the street holding small horn brass instruments. A drum line',\n",
       " 'sent1': 'Members of the procession walk down the street holding small horn brass instruments.',\n",
       " 'sent2': 'A drum line',\n",
       " 'gold-source': 'gold',\n",
       " 'ending0': 'passes by walking down the street playing their instruments.',\n",
       " 'ending1': 'has heard approaching them.',\n",
       " 'ending2': \"arrives and they're outside dancing and asleep.\",\n",
       " 'ending3': 'turns the lead singer watches the performance.',\n",
       " 'label': 0}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's grab a sample\n",
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SGWa8W6PrATB"
   },
   "source": [
    "* These fields represent the idea begind this dataset\n",
    "   - a situation where we have to predict the right ending\n",
    "   - `sent1` and `sent2` represent the given situation and they added up to `startphrase`\n",
    "   - `endings 0 to 3` represent the the endings for that situation, only one is the right\n",
    "   - `label` index the right answer   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUZ7r9evQA-U"
   },
   "source": [
    "* Now let's initialized `BERT` and load its `tokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "DcgqKQybtVA4"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pHFPNIXsQUCL"
   },
   "source": [
    "* The idea here is to tokenize a start sentence with each one of the 4 choices,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "DH8Zl0ZWov4G"
   },
   "outputs": [],
   "source": [
    "ending_names = [\"ending0\", \"ending1\", \"ending2\", \"ending3\"]\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    first_sentences = [[context] * 4 for context in examples[\"sent1\"]]\n",
    "    question_headers = examples[\"sent2\"]\n",
    "    second_sentences = [\n",
    "        [f\"{header} {examples[end][i]}\" for end in ending_names]\n",
    "        for i, header in enumerate(question_headers)\n",
    "    ]\n",
    "\n",
    "    first_sentences = sum(first_sentences, [])\n",
    "    second_sentences = sum(second_sentences, [])\n",
    "\n",
    "    tokenized_examples = tokenizer(first_sentences, second_sentences, truncation=True)\n",
    "    return {k: [v[i : i + 4] for i in range(0, len(v), 4)] for k, v in tokenized_examples.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdMiFTee8TwW"
   },
   "source": [
    "* To understand each operation of that function we will do it step-by-step:\n",
    "\n",
    "  - First let's create a sub-set of the training set\n",
    "  - Create a `endings` list that we will use later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "UK8S8wXUvYf4"
   },
   "outputs": [],
   "source": [
    "endings = [\"ending0\", \"ending1\", \"ending2\", \"ending3\"]\n",
    "train_ds = dataset['train']\n",
    "smp = train_ds[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5Z8UjpP9EPS"
   },
   "source": [
    "* Multiply each `sent1` by 4 and stack them all in a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "L1OtRJD39TT7"
   },
   "outputs": [],
   "source": [
    "sent_1 = [[sent] * 4 for sent in smp['sent1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "onqh7m0W9n5m"
   },
   "source": [
    "* Let's retrieve the length of that list and see what's inside one element of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bU96Asn-9mo-",
    "outputId": "51416942-b830-4a47-e26f-c6453d2f0c1c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['A group of members in green uniforms walks waving flags.',\n",
       "  'A group of members in green uniforms walks waving flags.',\n",
       "  'A group of members in green uniforms walks waving flags.',\n",
       "  'A group of members in green uniforms walks waving flags.'],\n",
       " 20)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_1[2], len(sent_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3RvfvmK-Z7V"
   },
   "source": [
    "* So basically we have 4 copies of each first-sentence of the dataset.\n",
    "* Now we will create a list of the second-sentence or the header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "kABBaBBT_qyq"
   },
   "outputs": [],
   "source": [
    "headers = smp['sent2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ywfx7ZS5_4Lu"
   },
   "source": [
    "* At this point we have:\n",
    "  - `sent_1` which each element is multiplied by 4\n",
    "  - `headers` that complete `sent_1`\n",
    "* The idea here is to create pairs of each `header` +`sent_2` for each `sent_1`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "Bw3vRZjUIjHZ"
   },
   "outputs": [],
   "source": [
    "sent_2 = [[f'{head}{smp[end][i]}' for end in endings] for i, head in enumerate(headers)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Pre-processing](Preprocessing_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUwAc_lgJ4ex"
   },
   "source": [
    "* Now we need to **flatten** the pair of sentences, so we could tokenize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "7znDtBorJ2e5"
   },
   "outputs": [],
   "source": [
    "frst_sent = sum(sent_1, [])\n",
    "scnd_sent = sum(sent_2, [])\n",
    "tok_smp = tokenizer(frst_sent, scnd_sent, truncation=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPb4dJCOpHO1"
   },
   "source": [
    "* We tokenize the pair of list sentences which will return a dictionary with 3 keys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bfuL--GpBHo",
    "outputId": "a580136c-b58f-42d7-f71c-4a059c5e69a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_smp.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCAqoXaHpwMf"
   },
   "source": [
    "* But since we already flattend the pairs before the tokenization step, we need to get them unflatten again so we can pass it through the `map()` function in order to be computed by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "eLUTIRvGqVfk"
   },
   "outputs": [],
   "source": [
    "outputs = {k: [v[i: i + 4] for i in range(0, len(v), 4)] for k, v in tok_smp.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lwZ9IcrirgOy"
   },
   "source": [
    "* Lets check if we get the unflatten step right, we just need to make sure that the `input_ids` of the first sentence has the same values in both: `tok_smp` and `outputs`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "d7iR4tEEsGIL"
   },
   "outputs": [],
   "source": [
    "flatten_smp = tok_smp['input_ids']\n",
    "unflatten_smp = outputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ll4hRVSsmGZ",
    "outputId": "21ff1639-09f6-4aec-bfd3-4a866a21f985"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_smp[0:4] == unflatten_smp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ajEsMHJs5Lw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
