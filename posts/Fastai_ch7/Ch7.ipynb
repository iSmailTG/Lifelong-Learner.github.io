{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Chapter 7: Deep learning for coders with fastai and pytorch \"\n",
    "author: \"Ismail TG\"\n",
    "date: \"10/30/2022\"\n",
    "categories: [Fastai, Pytorch, Deep Learning]\n",
    "image: \"fastbook.jpg\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URgm-iewfgFK"
   },
   "source": [
    "# Training a State-of-the-Art Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpqWeGjSfhtp"
   },
   "source": [
    "* In this chapter we will discuss more advanced technics for training image classifier models and getting better results.\n",
    "* In this chapter we will see: \n",
    "    - What is **Normalization**?\n",
    "    - Data augmentation with **Mixup**\n",
    "    - **Progressive Risizing**\n",
    "    - **Test Time Augmentation**\n",
    "* To implement all those technics, we will build model from scartch an train it on a subset of **ImageNet** called [Imagenette](https://github.com/fastai/imagenette)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UPkP3MQVsrdD"
   },
   "source": [
    "## Imagenette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlERMj7Usvu1"
   },
   "source": [
    "* This dataset is created by Fastai community, the goal of it is to have a dataset that can train models that generelize well on the larger version (ImageNet), which will help Machine learning practitioners to build and experiment many ideas and projects with less computation power.\n",
    "* Imagenette has 10 classes, which are very different from one another.\n",
    "* Let's download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wFemVpUHfLnL",
    "outputId": "083a9d7b-5e03-474d-f6c8-67af5824513f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 719 kB 5.1 MB/s \n",
      "\u001b[K     |████████████████████████████████| 5.3 MB 26.5 MB/s \n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 49.1 MB/s \n",
      "\u001b[K     |████████████████████████████████| 441 kB 16.3 MB/s \n",
      "\u001b[K     |████████████████████████████████| 163 kB 50.3 MB/s \n",
      "\u001b[K     |████████████████████████████████| 212 kB 56.5 MB/s \n",
      "\u001b[K     |████████████████████████████████| 115 kB 39.6 MB/s \n",
      "\u001b[K     |████████████████████████████████| 127 kB 50.6 MB/s \n",
      "\u001b[K     |████████████████████████████████| 7.6 MB 72.8 MB/s \n",
      "\u001b[?25hMounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "! [ -e /content ] && pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MW0MstiJfXcC"
   },
   "outputs": [],
   "source": [
    "from fastbook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "-gbvSEhrfgyH",
    "outputId": "2fd0ea83-ed5c-41ae-dc26-f3e3307dda19"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='1557168128' class='' max='1557161267' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [1557168128/1557161267 00:38&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "path = untar_data(URLs.IMAGENETTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t87t0u9Ouk6_"
   },
   "source": [
    "* Here we create `DataLoaders` using the `Resize` technic we saw in CH5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oURPbWp1uLUO"
   },
   "outputs": [],
   "source": [
    "dblock = DataBlock(blocks=(ImageBlock(), CategoryBlock()),\n",
    "                   get_items=get_image_files,\n",
    "                   get_y=parent_label,\n",
    "                   item_tfms=Resize(460),\n",
    "                   batch_tfms=aug_transforms(size=224, min_scale=0.75))\n",
    "dls = dblock.dataloaders(path, bs=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6Oeqij0u6Fl"
   },
   "source": [
    "* Now we do the training just to have something to begin with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "FTg7mJCCuPbN",
    "outputId": "b4e28afe-a0bd-4527-cf13-7e0ac1d9653d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.615762</td>\n",
       "      <td>1.960073</td>\n",
       "      <td>0.446229</td>\n",
       "      <td>02:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.231709</td>\n",
       "      <td>1.436732</td>\n",
       "      <td>0.542943</td>\n",
       "      <td>03:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.946307</td>\n",
       "      <td>0.957584</td>\n",
       "      <td>0.703883</td>\n",
       "      <td>03:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.710163</td>\n",
       "      <td>0.686722</td>\n",
       "      <td>0.788648</td>\n",
       "      <td>02:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.581876</td>\n",
       "      <td>0.551411</td>\n",
       "      <td>0.833831</td>\n",
       "      <td>02:57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = xresnet50(n_out=dls.c)\n",
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n",
    "learn.fit_one_cycle(5, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pag8FJarvNGe"
   },
   "source": [
    "* Not bad result considering that we didn't use a pretrained model.\n",
    "* The aim of this chapter is to increase the peformance of this base-line model by implementing different technics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxUeSdsjxZXK"
   },
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lGJPxbXrxjdd"
   },
   "source": [
    "* Normalization means having a dataset with mean of 0 and standard diviation of 1.\n",
    "* Most images and computer vision libraries use values between 0 and 255 for pixels, or between 0 and 1; in either case, your data is not going to have a mean of 0 and a standard deviation of 1.\n",
    "* Let's grab a batch of data and take the average of each axis except the channels axis (indx==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZWc87RfHxi9L",
    "outputId": "71ccc725-e59b-45e5-95ba-568420522712"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorImage([0.4573, 0.4509, 0.4188], device='cuda:0'),\n",
       " TensorImage([0.2730, 0.2652, 0.2803], device='cuda:0'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = dls.one_batch()\n",
    "x.mean(dim=[0,2,3]),x.std(dim=[0,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpSpMpeizMNx"
   },
   "source": [
    "* As expected, the `mean` and `std` is different than what we desire.\n",
    "* Fastai provide the method `Normalize` which can be applied on the whole batch, so we could add it to `batch_tfms` section of the datablock, we just need to tell fastai which are the mean and the standard deviation we want to use (in this case we will use ImageNet stats) but even without giving these stats fastai will calculate them from one batch and use them.\n",
    "* Notice here we build the datablock withing a function that take `batch_size` and `size` as parameters, we will see way later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4K63b2ozLop"
   },
   "outputs": [],
   "source": [
    "def get_dls(bs, size):\n",
    "    dblock = DataBlock(blocks=(ImageBlock, CategoryBlock),\n",
    "                   get_items=get_image_files,\n",
    "                   get_y=parent_label,\n",
    "                   item_tfms=Resize(460),\n",
    "                   batch_tfms=[*aug_transforms(size=size, min_scale=0.75),\n",
    "                               Normalize.from_stats(*imagenet_stats)])\n",
    "    return dblock.dataloaders(path, bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mjuAFuwaviFT"
   },
   "outputs": [],
   "source": [
    "dls = get_dls(64, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pP6k_UZf2TCn",
    "outputId": "3b6401f9-4438-4937-a1f6-c1156d87713d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorImage([-0.0920, -0.0490,  0.0548], device='cuda:0'),\n",
       " TensorImage([1.1969, 1.1888, 1.2855], device='cuda:0'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = dls.one_batch()\n",
    "x.mean(dim=[0,2,3]),x.std(dim=[0,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQcwYPDW2aPS"
   },
   "source": [
    "* This `Normalize` method help us to get close to the desired values for `mean` and `std`\n",
    "* Let's how this effect the performance of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ZJ3QGCdC2YWK",
    "outputId": "4131da38-1d8e-4bcb-ef54-c5541e9a92c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.617465</td>\n",
       "      <td>1.945767</td>\n",
       "      <td>0.462285</td>\n",
       "      <td>02:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.272744</td>\n",
       "      <td>2.252786</td>\n",
       "      <td>0.462659</td>\n",
       "      <td>02:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.947452</td>\n",
       "      <td>1.084139</td>\n",
       "      <td>0.643017</td>\n",
       "      <td>02:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.722699</td>\n",
       "      <td>0.795408</td>\n",
       "      <td>0.765123</td>\n",
       "      <td>03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.610676</td>\n",
       "      <td>0.577560</td>\n",
       "      <td>0.819642</td>\n",
       "      <td>02:58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = xresnet50(n_out=dls.c)\n",
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), metrics=accuracy)\n",
    "learn.fit_one_cycle(5, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bw4KNicv6dR_"
   },
   "source": [
    "* Implementing the normalization didn't help the model get better results, because this technic works better when using a pretrained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkKWRVdFsGov"
   },
   "source": [
    "## Progressive Resizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pHYMD5IsJhj"
   },
   "source": [
    "* The idea behind Progressive Resizing is to start training the model with small images, and end the training fase with large images.\n",
    "* As we have seen, the image size doesn't play a role in the learning process.\n",
    "* Although changing the image size in the middel of training will effect how the model behave in a way or another.\n",
    "* The best way is to deal with the transition from small image to larger images as if we do transfer learning. After changing the images size we should `fine_tune` method.\n",
    "* We can look to Progressive Resizing as a form of data augmentation, which mean the model will generalize well.\n",
    "* To implement progressive resizing it is most convenient if you first create a `get_dls` function which takes an image size and a batch size as we did in the section before, and returns your `DataLoaders`:\n",
    "\n",
    "* Now you can create your `DataLoaders` with a small size and use `fit_one_cycle` in the usual way, training for a few less epochs than you might otherwise do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a9C_HgUf2xok"
   },
   "outputs": [],
   "source": [
    "dls = get_dls(128, 128)\n",
    "learn = Learner(dls, xresnet50(n_out=dls.c), loss_func=CrossEntropyLossFlat(), \n",
    "                metrics=accuracy)\n",
    "learn.fit_one_cycle(4, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bfy7nBFMwxXC"
   },
   "source": [
    "* Then you can replace the `DataLoaders` inside the `Learner`, and fine-tune:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mI2ZUOr4w1q8"
   },
   "outputs": [],
   "source": [
    "learn.dls = get_dls(64, 224)\n",
    "learn.fine_tune(5, 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MNelU3TTw4gi"
   },
   "source": [
    "* We can increase the image size by a bit, untill we reach the normal size of the actual image in dataset.\n",
    "* Progressive resizing can be good or bad depending many factors:\n",
    "     - For transfer learning, if the model is already trained on similar task we will use it for, and on similar size of images, normally re-training it on smaller images will damage the performance.\n",
    "     - In other hand if the model is trained on dataset with different size of images, and on dfferent task, using progressive resizing may help the model performance.\n",
    "- There's no right answear for every situation, we just need to try and experiment different things.          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SkcucQMy7Ex0"
   },
   "source": [
    "## Test Time Augmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D5fLhfVOTsSC"
   },
   "source": [
    "* Till now all kind of data augmentations we implement are done on training set, while the validation set is taking the same images.\n",
    "* The idea behind Test Time Augmentation `tta` is to use some augmented images for the validation set to get predictions (for the same image) and average (or take the maximun) them.\n",
    "* Usually fastai do center cropping for validation.\n",
    "* This method may cause the model to miss valuable lessons from edges of the cropped images.\n",
    "* We could avoid center cropping but instead to select a number of areas to crop from the original rectangular image, pass each of them through our model, then take the average of predictions or the maximum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBsgge4r3EGt"
   },
   "source": [
    "* By default, fastai will use the unaugmented center crop image plus four randomly augmented images.\n",
    "\n",
    "* You can pass any `DataLoader` to fastai's `tta` method; by default, it will use your validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HYsyaS545rmp"
   },
   "outputs": [],
   "source": [
    "preds,targs = learn.tta()\n",
    "accuracy(preds, targs).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9z4Srx7b3I9S"
   },
   "source": [
    "## Mixup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vr5inDhpIyYx"
   },
   "source": [
    "* The idea of mixup is to take two data points (images) and mix them together with some percentage, then do the ine-hot encodings  where the new image represented with the new values (percentages) instead of `0` or `1`. The model here have to predict not only the right label, but also the percentage by which the label is represented in that image.\n",
    "* We can express this idea with code as:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B5-M2Du-uHQD"
   },
   "outputs": [],
   "source": [
    "church = PILImage.create(get_image_files_sorted(path/'train'/'n03028079')[0])\n",
    "gas = PILImage.create(get_image_files_sorted(path/'train'/'n03425413')[0])\n",
    "church = church.resize((256,256))\n",
    "gas = gas.resize((256,256))\n",
    "tchurch = tensor(church).float() / 255.\n",
    "tgas = tensor(gas).float() / 255.\n",
    "\n",
    "_,axs = plt.subplots(1, 3, figsize=(12,4))\n",
    "show_image(tchurch, ax=axs[0]);\n",
    "show_image(tgas, ax=axs[1]);\n",
    "show_image((0.3*tchurch + 0.7*tgas), ax=axs[2]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16zzlGqwMbOV"
   },
   "outputs": [],
   "source": [
    "model = xresnet50(n_out=dls.c)\n",
    "learn = Learner(dls, model, loss_func=CrossEntropyLossFlat(), \n",
    "                metrics=accuracy, cbs=MixUp())\n",
    "learn.fit_one_cycle(5, 3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99FwL2HrMyJ3"
   },
   "source": [
    "* Training a model with mixup techninx make it way hareder for the model to learn, because the model need to predict 2 labels for each image instead of one, plus predicting the righ percentage of each label.\n",
    "* Overfitting seems less likely to be a problem when mixup is used.\n",
    "* Mixup tend to produce good results with 80 epochs of training or more.\n",
    "* One other benefit of using Mixup is when we have labels == 0, 1, because of using `softmax` and `sigmoid` the output can never be 0 or 1, thus our loss can never be perfect. With mixup labels cannot be 0 or 1 unless we mix 2 images with the same label, the rest of the time our labels will be linear combinations like 0.4, 0.6 .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4smWuGOabx3r"
   },
   "source": [
    "## Label Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6Kx66L-cGWF"
   },
   "source": [
    "* In classfication problems we usually have labels like `0` and `1`, so the model job is to return them accuaratly, even 0.999 is not good enough where the label is 1!. this cuase the model to update the weights in order to get closer and closer to the right and unique answear, what will lead to overfitting.\n",
    "* The solution to this problem is to smooth the labels, by replacing 1 with a bit smaller number, and 0 with a bit bigger number. this will encourage the model to be less confident, which will help to better generalization.\n",
    "* **Label Smoothing** can be expressed mathematically:\n",
    "   - `0`: $\\frac{\\epsilon}{N}$  where N is number of classes we have and epsilon represent a parameter usually 0.1(it's like saying we're 10% less confident about the label)\n",
    "\n",
    "   - `1`: $1-\\epsilon + \\frac{\\epsilon}{N}$\n",
    "* In our Imagenette example where we have 10 classes, the targets become something like (here for a target that corresponds to the index 3):\n",
    "```\n",
    "[0.01, 0.01, 0.01, 0.91, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01]\n",
    "```   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8gZML_l1f5WP"
   },
   "source": [
    "* To use this in practice, we just have to change the loss function in our call to `Learner`:\n",
    "\n",
    "```python\n",
    "model = xresnet50(n_out=dls.c)\n",
    "learn = Learner(dls, model, loss_func=LabelSmoothingCrossEntropy(), \n",
    "                metrics=accuracy)\n",
    "learn.fit_one_cycle(5, 3e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S6eYo_aBbxHQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_RvUrRNuVoLf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
