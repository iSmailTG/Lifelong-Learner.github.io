{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Hugging Face Course Notes: Chapter2 \"\n",
    "author: \"Ismail TG\"\n",
    "date: \"10/19/2023\"\n",
    "categories: [Hugging-Face, NLP, LLMs, Pytorch]\n",
    "image: \"nlp-course.png\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OlBVuXXbyRWv"
   },
   "source": [
    "# Introduction:\n",
    "\n",
    "* Transformer models are very large with Ms to 10s of Billions of parameters, which make the process of training and fine-tuning and deploying them very hard.\n",
    "* Here comes the **Hugging Face** library which adress that problem, the goal is to provide a single `API` through which any transformer model can be loaded, trained and saved.\n",
    "* With **`Transformer`** library we can:\n",
    "      - Download, load and use models for inference or fine-tuning with just couple lines of code\n",
    "      - all models in the library are stored like any other model, at their core they are just a simple pytorch `nn.Module` class.\n",
    "      - All components of the models are stored in one file, so no abstarctions or shared modules across files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wCjbXZ0I1IZT"
   },
   "source": [
    "# Behind the PipeLine:\n",
    "\n",
    "* To understand what's happenening behind the scene we must first start with what already know: **Pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AHCVWrsn0Get",
    "outputId": "8c5bb09b-9b67-4e95-a58f-b3c9d95e77da"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9996117949485779}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "classifier(['My birthday is today!'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nMVAamS3H7n"
   },
   "source": [
    "* As we saw in the previous chapter the `pipeline` goups 3 steps in order to perform such a task:  \n",
    "\n",
    "![pipeline](pic1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxOsm19u3kI9"
   },
   "source": [
    "## Preprocessing with a Tokenizer:\n",
    "\n",
    "* In order to convert raw text to its numerical form before we feed it to the model, we use **Tokenizer**.\n",
    "* Here is how we tokenize any input words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SLXTlCFB2zT8",
    "outputId": "938f7399-0dd3-433b-e4c4-ba6a83ff2ec3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 2026, 5798, 2003, 2651,  999,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "mdl_ckpt = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(mdl_ckpt)\n",
    "inputs = 'My birthday is today!'\n",
    "outputs = tokenizer(inputs, padding=True, truncation=True, return_tensors='pt')\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Vzq-0WG5QxV"
   },
   "source": [
    "* First we pick a model `distilbert-base-uncased-finetuned-sst-2-english` which is basically the same model our pipeline used to classify the sentence.\n",
    "* We use `AutoTokenizer` to get to tokenization method according to that model, because each model has its own method of tokenizing words.\n",
    "* Then we feed the text to the tokenizer, and we pick which type of tensors we want to get returned\n",
    "    - `pt` stands for pytorch\n",
    "    - other parameters will be covered later\n",
    "\n",
    "* We get a dictionary with 2 keys: `input_ids` and `attention_mask`\n",
    "* `attention_mask` will be covered later, `input_ids` contains one list of integers.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mjakIlW872iZ"
   },
   "source": [
    "##  Going through the model:\n",
    "\n",
    "* We can download the pretraind model same we did with tokenizer, by usin `AutoModel` class which also has `from_pretrained` method.\n",
    "* We just need to download the same model as used in tokenization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yfFIPZC_5J0q"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "model = AutoModel.from_pretrained(mdl_ckpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nqoTx-V79lDm"
   },
   "source": [
    "* This architecture we just downloaded conatins onlly the base transformer module: given some inputs, it outputs what we call **Hidden_state**.\n",
    "* For each model inputs we will retrieve a high-dimensional vector representing the contextual understanding of that input by the model\n",
    "* These Hidden_states can be used as it is, but usually it will be feeded as input to another part of the model called the **Head**.\n",
    "* Each Head is a task_specific head."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQ-wPnKW-pAq"
   },
   "source": [
    "##  A high-dimensional vector?\n",
    "\n",
    "* Usually the model outputs a large vector with 3 dimensions:\n",
    "  - **Batch-size**: the number of sequence processed (in our case we pass only one sentence)\n",
    "  - **Sequence-length**: The length of the numerical representation of the sequence (8 in our example)\n",
    "  - **Hidden size**: The vector dimension of each model input.\n",
    "\n",
    "* The high-dimentionality of this vector comes from the last dimension, the hidden-size is very large dimension: usually ~700:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RgkMNy-M8gX7",
    "outputId": "6db8724c-191b-476c-a7ba-1052267cb9f1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 768])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs = model(**outputs)\n",
    "outs.last_hidden_state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQ2yjfG_D_Su"
   },
   "source": [
    "##  Model heads: Making sense out of numbers:\n",
    "\n",
    "* So to wrap-up the whole process: First get inputs converted input ID then the embedding layer convert them into tokenized vectors.\n",
    "* The subsequent layers manipulate thes vectors using attention mechanism to produce a contextual understanding of that input in form of **High-dimensional-vector**.\n",
    "\n",
    "![model](pic2.png)\n",
    "\n",
    "* There rae many architecture available in the Transformers library, each is designed to tackle specific task.\n",
    "* For example if we want a model for a sequence classification head, we will use `AutoModelForSequenceClassification` instead of `AutoModel`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "0_q0It9KHhl0"
   },
   "outputs": [],
   "source": [
    "text = ['do you feel any better today?', 'I feel warm and cosy in my house']\n",
    "tokenizer = AutoTokenizer.from_pretrained(mdl_ckpt)\n",
    "inps = tokenizer(text, padding=True, truncation=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3KdPSYexDTcw",
    "outputId": "57d4043a-3622-4d69-cbb9-dd6399272565"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=None, logits=tensor([[-0.2121,  0.4987],\n",
       "        [-3.9382,  4.1996]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "mdl_ckpt = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(mdl_ckpt)\n",
    "outs = model(**inps)\n",
    "outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5FHmSn_BHUSh",
    "outputId": "87ec6eb0-9fcf-4d32-ef98-1eaa82092679"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs.logits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o3wiqTV4IdsM"
   },
   "source": [
    "* In this case we have 2 sentences and 2 labels `negative` `positive`.\n",
    "* The model will take the high dimensional vector as input and outputs a vector that match our task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnL8-sDjJYJh"
   },
   "source": [
    "### Post processing:\n",
    "\n",
    "* The vector we get doesn't make any sense as it is, so we need to make it meaningful for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lP3LyVYhHcmc",
    "outputId": "c919fff3-89b1-41bf-e706-8ca9811fa485"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2121,  0.4987],\n",
       "        [-3.9382,  4.1996]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outs.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CB1-DTXxJukR"
   },
   "source": [
    "* those are prediction for each sentence, and each prediction can be mapped to a label, so we need to know each label which, then convert those logits into some meaningful values.\n",
    "* To convert the logits into probabilies we will pass them through a softmax layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PbJk8rOtJtGS",
    "outputId": "3545557c-b0d1-494c-b265-e96cc8039016"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.2942e-01, 6.7058e-01],\n",
       "        [2.9218e-04, 9.9971e-01]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "preds = torch.nn.functional.softmax(outs.logits, dim=-1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xup_ugSuLVDN"
   },
   "source": [
    "* Now we need to know the label of each colomn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7R1HFiDkKvp2",
    "outputId": "36b80072-ba8c-411f-f711-82f19c217451"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'NEGATIVE', 1: 'POSITIVE'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCsrlxOWLvxV"
   },
   "source": [
    "* So the position [0] is negative where the position [1] positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7MvkiQPM2zm"
   },
   "source": [
    "# Models\n",
    "\n",
    "* As we saw before the `AutoModel()` class is handy tool to instantiate a model from a `chekcpoint(weights)`\n",
    "* It can guess the correspondent architecture for the checkpoint.\n",
    "\n",
    "### Building the transformer:\n",
    "\n",
    "* We also could call the class of the model precisely if we know exactly the model we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Ye4Stf6VLuCJ"
   },
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "cnfg = BertConfig()\n",
    "mdl = BertModel(cnfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtNTjwiFOW-9"
   },
   "source": [
    "* The configurations contains many attributes related the architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CCgdW6hTOOgC",
    "outputId": "eeb9870c-f887-45e3-a47b-177ede372a92"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.34.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnfg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_367YGOzOmKO"
   },
   "source": [
    "* We can understand many of these attributes like:\n",
    "   - `hidden_act`: activation function : `gelu`\n",
    "   - `hidden_size`: vector dimensions of each input word\n",
    "   - `attention_head`, `num_hidden_layer`, `model_type` ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFQyjD-eP5jY"
   },
   "source": [
    "* While it is possible to build model like this way and using it, but it will produce very low predictions beacause its weights are set randomly.\n",
    "* This forces us to train it from scratch, which is a very daunting and time, noney, energy consuming process.\n",
    "* This is way its very preferably to use to other way of loading the model by starting with a pretrained one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "a70643051869444e961e367576104d0a",
      "6052936fa7184bfc8f88148fd9457c60",
      "1f73efb54a2d43fc893e6a57cdfe9592",
      "3f1ff7fd9b874e11b2c1237db9ab82e4",
      "c37bee8a0d0f49388e39bbfdd9268e60",
      "0a8782e126354bc5b7f2dbd348c23c9c",
      "a081b9438d854722b14d6532cec682b0",
      "0b94751cbafa4bb59c3c21873ec76dd5",
      "f801f011bd0b4604ba89f9883168eb6a",
      "e49fce4172824dbb8d5360a57af44592",
      "4937d01612dd4fb98bea6921b9d4e06f",
      "1c11f93511ae48dba96fff3279565ee1",
      "25de88b65ffa4a6681fec38c3b351d35",
      "4225564b4bfa406c8be8785c40ea2819",
      "c2446bb93fce4f75a7dc40e70e66b09c",
      "5243caf252464d81a0cfcd826d0eb1d0",
      "cedc1adba6224370a9f6f965b3a29497",
      "de65ddeb58c940399504f360a7a90615",
      "ca7f42d619ca46a2900098d4da49134a",
      "b4d1d33a30404c2bb5a5529d5a663017",
      "9b531579649e49c387c4bc0b06abb90b",
      "60c00ab3850f4c4f83ebc1fd26d85c51"
     ]
    },
    "id": "vj-mHMqZOiHP",
    "outputId": "1245a172-6d63-43f2-c8d9-a8b6556498a9"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a70643051869444e961e367576104d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c11f93511ae48dba96fff3279565ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "mdl = BertModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0bcyTRjRbEq"
   },
   "source": [
    "* we even could use `AutoModel` instead of `BertModel` since it will produce agnostic code that fits all situations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIhvSWgFR4dP"
   },
   "source": [
    "* At this point the model is initialized with all the weights of the checkpoint, it can be used for inference directly on the tasks it was trained on, and also it can be fine-tuned on new tasks or more data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tBmGv06Try3"
   },
   "source": [
    "## Saving the model:\n",
    "\n",
    "* To save a model we are satisfied with its prformance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "8QYmYctzRWG1"
   },
   "outputs": [],
   "source": [
    "mdl.save_pretrained('path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2mlJdC_QVP77",
    "outputId": "a9f95858-806a-4039-aa22-4ecbc3a5ff0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json  pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!ls 'path'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "117xyVcMUlJb"
   },
   "source": [
    "* This saves 2 files:\n",
    "    - `config.json`: contains all attributes necessary to build the model architecture, and also it contains some metadata\n",
    "    - `pytorch_model.bin`: contains the learnable weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MDIrBNrwVclL"
   },
   "source": [
    "##  Using a Transformer model for inference:\n",
    "\n",
    "* Tokenizer convert input words into input ID:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DluGWYTHUh8E",
    "outputId": "f44a67a9-9903-4364-a659-f4014e84e548"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 7592,  999,  102],\n",
       "        [ 101, 4658, 1012,  102],\n",
       "        [ 101, 3835,  999,  102]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = [\"Hello!\", \"Cool.\", \"Nice!\"]\n",
    "inps = tokenizer(sequences, return_tensors='pt')\n",
    "encoded_sequences = inps.input_ids\n",
    "encoded_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S-7DI-tQYsQ-"
   },
   "source": [
    "* The output we get here is a list of list, the problem here is that the tensors accept only the rectangular shapes.\n",
    "* So we nee to cenvert this into the targeted shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SggbHKaNXZem",
    "outputId": "49bdae05-7173-40c2-80cf-f065fb849cd8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-1b4985ae101a>:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input = torch.tensor(encoded_sequences)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 101, 7592,  999,  102],\n",
       "        [ 101, 4658, 1012,  102],\n",
       "        [ 101, 3835,  999,  102]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.tensor(encoded_sequences)\n",
    "input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdnmxQK7ZOkQ"
   },
   "source": [
    "###  Using the tensors as inputs to the model\n",
    "\n",
    "* Making use of this returned tensor is easy as pass it through the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0CAtUWShX3Mw",
    "outputId": "42e0e681-0c95-4466-9c17-8904ed54635c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[ 4.4496e-01,  4.8276e-01,  2.7797e-01,  ..., -5.4032e-02,\n",
       "           3.9394e-01, -9.4770e-02],\n",
       "         [ 2.4943e-01, -4.4093e-01,  8.1772e-01,  ..., -3.1917e-01,\n",
       "           2.2992e-01, -4.1172e-02],\n",
       "         [ 1.3668e-01,  2.2518e-01,  1.4502e-01,  ..., -4.6915e-02,\n",
       "           2.8224e-01,  7.5566e-02],\n",
       "         [ 1.1789e+00,  1.6738e-01, -1.8187e-01,  ...,  2.4671e-01,\n",
       "           1.0441e+00, -6.1970e-03]],\n",
       "\n",
       "        [[ 3.6436e-01,  3.2464e-02,  2.0258e-01,  ...,  6.0111e-02,\n",
       "           3.2451e-01, -2.0995e-02],\n",
       "         [ 7.1866e-01, -4.8725e-01,  5.1740e-01,  ..., -4.4012e-01,\n",
       "           1.4553e-01, -3.7545e-02],\n",
       "         [ 3.3223e-01, -2.3271e-01,  9.4877e-02,  ..., -2.5268e-01,\n",
       "           3.2172e-01,  8.1079e-04],\n",
       "         [ 1.2523e+00,  3.5754e-01, -5.1320e-02,  ..., -3.7840e-01,\n",
       "           1.0526e+00, -5.6255e-01]],\n",
       "\n",
       "        [[ 2.4042e-01,  1.4718e-01,  1.2110e-01,  ...,  7.6062e-02,\n",
       "           3.3564e-01,  2.8262e-01],\n",
       "         [ 6.5701e-01, -3.2787e-01,  2.4968e-01,  ..., -2.5920e-01,\n",
       "           2.0175e-01,  3.3275e-01],\n",
       "         [ 2.0160e-01,  1.5783e-01,  9.8974e-03,  ..., -3.8850e-01,\n",
       "           4.1308e-01,  3.9732e-01],\n",
       "         [ 1.0175e+00,  6.4387e-01, -7.8147e-01,  ..., -4.2109e-01,\n",
       "           1.0925e+00, -4.8456e-02]]], grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.6856,  0.5262,  1.0000,  ...,  1.0000, -0.6112,  0.9971],\n",
       "        [-0.6055,  0.4997,  0.9998,  ...,  0.9999, -0.6753,  0.9769],\n",
       "        [-0.7702,  0.5447,  0.9999,  ...,  1.0000, -0.4655,  0.9894]],\n",
       "       grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs= mdl(input)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KWM0KcgUYHhs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a8782e126354bc5b7f2dbd348c23c9c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0b94751cbafa4bb59c3c21873ec76dd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1c11f93511ae48dba96fff3279565ee1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_25de88b65ffa4a6681fec38c3b351d35",
       "IPY_MODEL_4225564b4bfa406c8be8785c40ea2819",
       "IPY_MODEL_c2446bb93fce4f75a7dc40e70e66b09c"
      ],
      "layout": "IPY_MODEL_5243caf252464d81a0cfcd826d0eb1d0"
     }
    },
    "1f73efb54a2d43fc893e6a57cdfe9592": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b94751cbafa4bb59c3c21873ec76dd5",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f801f011bd0b4604ba89f9883168eb6a",
      "value": 570
     }
    },
    "25de88b65ffa4a6681fec38c3b351d35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cedc1adba6224370a9f6f965b3a29497",
      "placeholder": "​",
      "style": "IPY_MODEL_de65ddeb58c940399504f360a7a90615",
      "value": "Downloading model.safetensors: 100%"
     }
    },
    "3f1ff7fd9b874e11b2c1237db9ab82e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e49fce4172824dbb8d5360a57af44592",
      "placeholder": "​",
      "style": "IPY_MODEL_4937d01612dd4fb98bea6921b9d4e06f",
      "value": " 570/570 [00:00&lt;00:00, 11.9kB/s]"
     }
    },
    "4225564b4bfa406c8be8785c40ea2819": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca7f42d619ca46a2900098d4da49134a",
      "max": 435755784,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b4d1d33a30404c2bb5a5529d5a663017",
      "value": 435755784
     }
    },
    "4937d01612dd4fb98bea6921b9d4e06f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5243caf252464d81a0cfcd826d0eb1d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6052936fa7184bfc8f88148fd9457c60": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a8782e126354bc5b7f2dbd348c23c9c",
      "placeholder": "​",
      "style": "IPY_MODEL_a081b9438d854722b14d6532cec682b0",
      "value": "Downloading (…)lve/main/config.json: 100%"
     }
    },
    "60c00ab3850f4c4f83ebc1fd26d85c51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9b531579649e49c387c4bc0b06abb90b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a081b9438d854722b14d6532cec682b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a70643051869444e961e367576104d0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6052936fa7184bfc8f88148fd9457c60",
       "IPY_MODEL_1f73efb54a2d43fc893e6a57cdfe9592",
       "IPY_MODEL_3f1ff7fd9b874e11b2c1237db9ab82e4"
      ],
      "layout": "IPY_MODEL_c37bee8a0d0f49388e39bbfdd9268e60"
     }
    },
    "b4d1d33a30404c2bb5a5529d5a663017": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c2446bb93fce4f75a7dc40e70e66b09c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9b531579649e49c387c4bc0b06abb90b",
      "placeholder": "​",
      "style": "IPY_MODEL_60c00ab3850f4c4f83ebc1fd26d85c51",
      "value": " 436M/436M [00:05&lt;00:00, 130MB/s]"
     }
    },
    "c37bee8a0d0f49388e39bbfdd9268e60": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca7f42d619ca46a2900098d4da49134a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cedc1adba6224370a9f6f965b3a29497": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de65ddeb58c940399504f360a7a90615": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e49fce4172824dbb8d5360a57af44592": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f801f011bd0b4604ba89f9883168eb6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
