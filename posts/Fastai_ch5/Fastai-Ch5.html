<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.43">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Ismail TG">
<meta name="dcterms.date" content="2022-10-26">

<title>Chapter 5: Deep learning for coders with fastai and pytorch – Ismail's Personal Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-d4d76bf8491c20bad77d141916dc28e1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-1103899cd6f3886eaa78f2a2ecaca893.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>

<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
<script src="https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js" crossorigin="anonymous"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Ismail’s Personal Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html"> 
<span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/ismaai008l"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/ismailTG3"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Chapter 5: Deep learning for coders with fastai and pytorch</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Fastai</div>
                <div class="quarto-category">Pytorch</div>
                <div class="quarto-category">Numpy</div>
                <div class="quarto-category">Pandas</div>
                <div class="quarto-category">Deep Learning</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Ismail TG </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 26, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<section id="image-classification" class="level1">
<h1>Image Classification</h1>
<ul>
<li>Since we now familiar the whole process of creating deep learning model, using pre-built model, building them from scratch, handling data, and putting these model into web apps, we will now to go deeper and keep focus on details that make model accurate and reliable.</li>
<li>It takes many tweaks and parameters changing in order to “polish” a model.</li>
<li>In order to achieve this goal we need to be familiar with many concepts and technics, different types of layers, regularization methods, optimizers, how to put layers together into architectures, labeling techniques, and much more.</li>
</ul>
<div id="cell-3" class="cell" data-outputid="b9dfbc8f-6580-442d-d1b9-d979e1c0109c" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> [ <span class="op">-</span>e <span class="op">/</span>content ] <span class="op">&amp;&amp;</span> pip install <span class="op">-</span>Uqq fastbook</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> fastbook</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>fastbook.setup_book()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>     |████████████████████████████████| 719 kB 30.4 MB/s 
     |████████████████████████████████| 1.3 MB 60.3 MB/s 
     |████████████████████████████████| 5.3 MB 53.0 MB/s 
     |████████████████████████████████| 441 kB 66.2 MB/s 
     |████████████████████████████████| 1.6 MB 54.6 MB/s 
     |████████████████████████████████| 115 kB 75.5 MB/s 
     |████████████████████████████████| 163 kB 67.3 MB/s 
     |████████████████████████████████| 212 kB 71.5 MB/s 
     |████████████████████████████████| 127 kB 76.1 MB/s 
     |████████████████████████████████| 115 kB 62.1 MB/s 
     |████████████████████████████████| 7.6 MB 58.8 MB/s 
Mounted at /content/gdrive</code></pre>
</div>
</div>
<div id="cell-4" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastbook <span class="im">import</span> <span class="op">*</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.vision.widgets <span class="im">import</span> <span class="op">*</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="from-dogs-and-cats-to-pet-breeds" class="level2">
<h2 class="anchored" data-anchor-id="from-dogs-and-cats-to-pet-breeds">From Dogs and Cats to Pet Breeds</h2>
<ul>
<li><p>In real world scenarios, the first thing we do is we get in contact with data, usualy at this phase we know nothing about the dataset. We then start to look how to extract the data we want from it, and what the data looks like, and how it is structured.</p></li>
<li><p>Usually data is provided in one of two ways:</p>
<ul>
<li>Individual files representing items of data, possibly organized into folder or with filenames representing information about those items
<ul>
<li>text documents<br>
</li>
<li>images<br>
</li>
</ul></li>
<li>A table of data in which each row is an item and may include filenames providing connections between the data in the table and data in other formats
<ul>
<li>CSV files<br>
</li>
</ul></li>
</ul></li>
<li><p>Exceptions:</p>
<ul>
<li>Domains like Genomics<br>
</li>
<li>binary database formats<br>
</li>
<li>network streams</li>
</ul></li>
</ul>
<div id="cell-7" class="cell" data-outputid="71d97011-ca2e-4a6a-99f5-7f10143579fa" data-execution_count="3">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># download the dataset</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.vision.<span class="bu">all</span> <span class="im">import</span> <span class="op">*</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> untar_data(URLs.PETS)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

    <div>
      <progress value="811712512" class="" max="811706944" style="width:300px; height:20px; vertical-align: middle;"></progress>
      100.00% [811712512/811706944 01:02&lt;00:00]
    </div>
    
</div>
</div>
<div id="cell-8" class="cell" data-outputid="07455616-0517-49b4-80ca-05c53ac34c50" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">#get the path as variable, and see what inside</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>Path.BASE_PATH <span class="op">=</span> path</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>path.ls()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>(#2) [Path('images'),Path('annotations')]</code></pre>
</div>
</div>
<ul>
<li>As we notice here, the data is provided with 2 directories:
<ul>
<li><code>images</code></li>
<li><code>annotations</code></li>
</ul></li>
</ul>
<div id="cell-10" class="cell" data-outputid="c796f139-fc97-41ce-9f1c-86d731e96600" data-execution_count="6">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co">#take a look at what inside the images directory</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>(path<span class="op">/</span><span class="st">'images'</span>).ls()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>(#7393) [Path('images/german_shorthaired_87.jpg'),Path('images/Russian_Blue_200.jpg'),Path('images/Siamese_25.jpg'),Path('images/japanese_chin_48.jpg'),Path('images/miniature_pinscher_161.jpg'),Path('images/pug_150.jpg'),Path('images/pug_120.jpg'),Path('images/pug_63.jpg'),Path('images/samoyed_143.jpg'),Path('images/yorkshire_terrier_190.jpg')...]</code></pre>
</div>
</div>
<ul>
<li>When we took a look at these names, we see some paterns: we already know from <code>chapter1</code> that cats name are uppercase, here we see that after the breed’s name there is a <code>(_)</code> then a number, and finally the extension.</li>
<li>This may help us to write some code that extract the breed from a single <code>Path</code>.</li>
</ul>
<div id="cell-12" class="cell" data-outputid="b1ae1724-4205-40eb-b039-fe1e885d7390" data-execution_count="7">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co">#pick one </span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>fname <span class="op">=</span> (path<span class="op">/</span><span class="st">"images"</span>).ls()[<span class="dv">0</span>]</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>fname</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>Path('images/german_shorthaired_87.jpg')</code></pre>
</div>
</div>
<ul>
<li>The best way to work with strings and extract patterns from them is to use <code>Regex</code>, which stands for <strong>Regular Expression</strong>.</li>
</ul>
<div id="cell-14" class="cell" data-outputid="1bd98346-bcfd-4bec-82f5-3fa4ec8bdec0" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>re.findall(<span class="vs">r'(.+)_\d+.jpg$'</span>, fname.name)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>['german_shorthaired']</code></pre>
</div>
</div>
<ul>
<li>Now we need to label the whole dataset using this code.</li>
<li>Fastai comes with many classes for labeling, in this case when we need to label with help of <code>regex</code> we could use <code>RegexLabeller</code> class within <code>DataBlaock</code> <code>API</code>.</li>
</ul>
<div id="cell-16" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>pets <span class="op">=</span> DataBlock(blocks <span class="op">=</span> (ImageBlock, CategoryBlock),</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>                 get_items<span class="op">=</span>get_image_files, </span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>                 splitter<span class="op">=</span>RandomSplitter(seed<span class="op">=</span><span class="dv">42</span>),</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>                 get_y<span class="op">=</span>using_attr(RegexLabeller(<span class="vs">r'(.+)_\d+.jpg$'</span>), <span class="st">'name'</span>),</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>                 item_tfms<span class="op">=</span>Resize(<span class="dv">460</span>),</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>                 batch_tfms<span class="op">=</span>aug_transforms(size<span class="op">=</span><span class="dv">224</span>, min_scale<span class="op">=</span><span class="fl">0.75</span>))</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>dls <span class="op">=</span> pets.dataloaders(path<span class="op">/</span><span class="st">"images"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="presizing" class="level2">
<h2 class="anchored" data-anchor-id="presizing">Presizing</h2>
<ul>
<li>Fastai has this method of presizing the images in a way that conserve its quality after the data augmentation, so it helps the model to learn more lessons from data, and also it helps our dataset to be more varies</li>
<li>The idea behind the <code>presizing</code> is we crop the image and resize it to 460 by 460 first, which is a big size by deep learning norms, this operation is done on CPU, then we do the data augmentation in batches, by cropping a rotated random part of that 460^2 image, and taking the cropped image then resize again to a 224 by 224 image, all this operation are done on batch level, which mean on GPU.**<br>
</li>
</ul>
<pre><code>item_tfms=Resize(460),  
batch_tfms=aug_transforms(size=224, min_scale=0.75))

![REsize_method](1.png)

* Usually all the augmentation operations we do on a image reduce the quality of the image, but with this approach we could say we can preserve big part of informations of that image so the model can learn better 

### Checking and Debugging a DataBlock

* `DataBlock` is just a blueprint for orginizing data before we feed it to the model, you have no guarantee that your template is going to work on your data source as you intend.
* So, before training a model you should always check your data. You can do this using the show_batch method:

::: {#cell-23 .cell outputId='0f1711e2-f2c6-4703-ed64-1ea456f04a2d' execution_count=10}
``` {.python .cell-code}
dls.show_batch(nrows=1, ncols=4 ,unique= True)</code></pre>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Fastai-Ch5_files/figure-html/cell-10-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
<p>:::</p>
<ul>
<li><p>In case we made a mistake in the process of creating datablock, we could use <code>.summary</code> to track the problem.Here we didn’t resize the images in one formm, so couldn’t use the batch transform</p></li>
<li><p>As we see here the <code>.summary</code> gives us precise diagnostic of the problem:</p>
<ul>
<li><code>at least two tensors in the batch are not the same size.</code></li>
</ul></li>
</ul>
<section id="clean-the-data-with-the-model" class="level3">
<h3 class="anchored" data-anchor-id="clean-the-data-with-the-model">Clean the data with the model!!</h3>
<ul>
<li>Once we feel like the datablock is well created, we better begin train the model, and use it as a tool of cleaning the data. If there’s a problem with data or the model, we better know that before we lost lot of time and energy on data cleaning even before testing the model.</li>
</ul>
<div id="cell-28" class="cell" data-outputid="733c3312-d487-47c6-bebe-6f89eafeb16f" data-execution_count="11">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># train the model</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> vision_learner(dls, resnet34, metrics<span class="op">=</span>error_rate)</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>learn.fine_tune(<span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  f"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, "
/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Downloading: "https://download.pytorch.org/models/resnet34-b627a593.pth" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"ecfa21a5a69f4935bcb3bdccbbe333c0","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">error_rate</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>1.526362</td>
<td>0.348364</td>
<td>0.111637</td>
<td>01:11</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">error_rate</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.482150</td>
<td>0.309586</td>
<td>0.093369</td>
<td>01:16</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.327810</td>
<td>0.229392</td>
<td>0.064953</td>
<td>01:17</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="use-the-model-to-clean-the-data" class="level3">
<h3 class="anchored" data-anchor-id="use-the-model-to-clean-the-data">Use the model to clean the data</h3>
<ul>
<li><p>As we saw before in <strong><code>Chapter 2</code></strong> the best tool to clean the data is basically the model itself</p></li>
<li><p>After creating the datablock and dataloader we better train the model and get some feedback so we know if something is wrong very early, and if not we start to use the model as tool to investigate the data</p></li>
<li><p>Usually before we train the model we have to decide the function that will update the parameters, a <strong><code>Loss Function</code></strong>. But here we didn’t create any loss function?</p></li>
<li><p>If we didn’t decide the way by which we update the paramters, Fastai by default will chose a loss function for us.</p>
<ul>
<li>the chosen loss function will suite the kind of model we build, and the type of dataset we have.</li>
</ul></li>
</ul>
<div id="cell-31" class="cell" data-outputid="2f3a0898-a25e-40c3-b4b0-0c4588133276" data-execution_count="12">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check the loss function</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>learn.loss_func</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>FlattenedLoss of CrossEntropyLoss()</code></pre>
</div>
</div>
<ul>
<li>The loss function used to train this model is <strong><code>Cross Entropy Loss</code></strong></li>
</ul>
</section>
</section>
<section id="cross-entropy-loss" class="level2">
<h2 class="anchored" data-anchor-id="cross-entropy-loss">Cross-Entropy Loss</h2>
<ul>
<li>The Cross-Entropy Loss is a function similar to what we saw in the previous chapter, when we created the <code>mnist_loss</code> function:</li>
</ul>
<pre><code>def mnist_loss(predictions, targets):
    prediction = prediction.sigmoid()
    return torch.where(targets==1, 1-prediction, predictions).mean()</code></pre>
<ul>
<li>The problem with this function is, it only takes 2 categories(3, 7) but here we have 37 types of breeds.but here we have multiple classes.
<ul>
<li>it can takes more than 2 categories</li>
</ul></li>
</ul>
<section id="viewing-activations-and-labels" class="level3">
<h3 class="anchored" data-anchor-id="viewing-activations-and-labels">Viewing activations and labels</h3>
<ul>
<li>In order to understand the cross-entropy loss, let’s grab a batch of data</li>
</ul>
<div id="cell-36" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>x,y <span class="op">=</span> dls.one_batch()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>It return the activations of dependent and independent variable of one mini-batch</li>
</ul>
<div id="cell-38" class="cell" data-outputid="3a7dbedd-df41-44f0-a5ec-46d1d7d50a8b" data-execution_count="14">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># independent variable</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>y, <span class="bu">len</span>(y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>(TensorCategory([ 8, 34,  6, 33, 12, 15, 32, 14,  5, 27, 20, 32, 18, 24,  8, 29,  5,  4,  0, 28, 10, 12, 16, 25, 29,  3, 34, 27, 30, 15,  6, 15, 27, 34, 14, 21,  5, 17, 31, 26, 13, 35, 17, 35, 23, 14,
                 35, 35,  8,  7, 21,  0, 22, 17, 19, 26, 16,  5, 15, 27, 11, 22, 34, 18], device='cuda:0'),
 64)</code></pre>
</div>
</div>
<ul>
<li>It return 64 number, each represent on of the 37 breeds index</li>
</ul>
<div id="cell-40" class="cell" data-outputid="cf31f01a-3a69-4c05-e15f-74de2a83271c" data-execution_count="15">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># all indepent variables</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>dls.vocab, <span class="bu">len</span>(dls.vocab)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>(['Abyssinian', 'Bengal', 'Birman', 'Bombay', 'British_Shorthair', 'Egyptian_Mau', 'Maine_Coon', 'Persian', 'Ragdoll', 'Russian_Blue', 'Siamese', 'Sphynx', 'american_bulldog', 'american_pit_bull_terrier', 'basset_hound', 'beagle', 'boxer', 'chihuahua', 'english_cocker_spaniel', 'english_setter', 'german_shorthaired', 'great_pyrenees', 'havanese', 'japanese_chin', 'keeshond', 'leonberger', 'miniature_pinscher', 'newfoundland', 'pomeranian', 'pug', 'saint_bernard', 'samoyed', 'scottish_terrier', 'shiba_inu', 'staffordshire_bull_terrier', 'wheaten_terrier', 'yorkshire_terrier'],
 37)</code></pre>
</div>
</div>
<ul>
<li>Here we use <code>get_preds</code> to get the predictions for each image in the dataset or mini-batch (like in this example).</li>
</ul>
<div id="cell-42" class="cell" data-outputid="888eeac4-848a-40f4-c504-cfc62c91bdc1" data-execution_count="16">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>preds,_ <span class="op">=</span> learn.get_preds(dl<span class="op">=</span>[(x,y)])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
</div>
<div id="cell-43" class="cell" data-outputid="1353d4bf-cd6b-46c9-c2f4-76a12fe9ce54" data-execution_count="17">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># prediction for image [0] in the mini-batch</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>preds[<span class="dv">0</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>TensorBase([1.0919e-05, 6.0375e-08, 8.5680e-05, 7.1281e-07, 1.8754e-06, 4.7956e-07, 1.1708e-04, 1.4080e-06, 9.9972e-01, 9.4731e-07, 6.8318e-08, 1.7055e-07, 1.9338e-06, 7.7372e-07, 1.7931e-07,
            1.5261e-07, 1.1363e-08, 2.3353e-07, 1.3689e-07, 4.5361e-07, 7.1548e-08, 4.9425e-06, 1.0026e-05, 2.6908e-07, 3.5724e-07, 3.1201e-07, 1.0177e-08, 2.7219e-08, 1.6157e-06, 3.5337e-08,
            1.8094e-06, 3.3425e-05, 2.3514e-08, 3.0318e-06, 1.4910e-07, 1.9582e-07, 9.5147e-08])</code></pre>
</div>
</div>
<ul>
<li>The 37 predictions refer to the probability of each breed to match the image[0].
<ul>
<li>if we sum() them up they add up to 1:</li>
</ul></li>
</ul>
<div id="cell-45" class="cell" data-outputid="49c56fa1-efc3-4c0b-d84d-e590eed56dd5" data-execution_count="18">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>preds[<span class="dv">0</span>].<span class="bu">sum</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>TensorBase(1.0000)</code></pre>
</div>
</div>
<ul>
<li>In order to transform the activations of our model into prediction, we use <strong><code>Soft-Max</code></strong></li>
</ul>
</section>
<section id="softmax" class="level3">
<h3 class="anchored" data-anchor-id="softmax">SoftMax</h3>
<ul>
<li>As we said before, <code>Softmax</code> is similar to <code>sigmoid</code> function we use before, but it only can handel more than 2 classes.</li>
</ul>
<div id="cell-49" class="cell" data-outputid="1fb827da-8820-4f2e-89ff-67488f5ec344" data-execution_count="19">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="co"># reminder of sigmoid</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>plot_function(torch.sigmoid, <span class="bu">min</span><span class="op">=-</span><span class="dv">4</span>,<span class="bu">max</span><span class="op">=</span><span class="dv">4</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Fastai-Ch5_files/figure-html/cell-19-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>This function allow us to predict whether a activation number is pointing to each category of the <strong>two</strong>, by calculating which activation is big and by much. But in our case today we have 37 category, which means by this logic we need a activation for each one.</li>
<li>First let’s create a similar situation where we have only 2 categories, but we won’t solve it as it’s a binary problem (<code>it's 3</code>) but as 2 categories problem, each has it’s activation, and their probabilty sum up to 1.</li>
</ul>
<div id="cell-51" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>torch.random.manual_seed(<span class="dv">42</span>)<span class="op">;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-52" class="cell" data-outputid="22a6a922-6506-484b-b8fb-09610287efa1" data-execution_count="21">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>acts <span class="op">=</span> torch.randn((<span class="dv">6</span>,<span class="dv">2</span>))<span class="op">*</span><span class="dv">2</span></span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>acts</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>tensor([[ 0.6734,  0.2576],
        [ 0.4689,  0.4607],
        [-2.2457, -0.3727],
        [ 4.4164, -1.2760],
        [ 0.9233,  0.5347],
        [ 1.0698,  1.6187]])</code></pre>
</div>
</div>
<ul>
<li>We can’t just take the sigmoid of this directly, since we don’t get rows that add to 1 (i.e., we want the probability of being a 3 plus the probability of being a 7 to add up to 1):</li>
</ul>
<div id="cell-54" class="cell" data-outputid="7f8ea585-604f-4d84-e0a1-d5d789552815" data-execution_count="22">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>sigmoid(acts)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>tensor([[0.6623, 0.5641],
        [0.6151, 0.6132],
        [0.0957, 0.4079],
        [0.9881, 0.2182],
        [0.7157, 0.6306],
        [0.7446, 0.8346]])</code></pre>
</div>
</div>
<ul>
<li>Eevn though we try different approach to solve the same problem, we still have some similarities.</li>
<li>We will use <code>sigmoid</code> on each activation.</li>
<li>And we still need to substract an activation from another beacuse that represent how much the model sure about an image is assigned to each category, thats for first column.</li>
<li>In the second colun we just use 1 - prediction (activation of the second column)</li>
</ul>
<div id="cell-56" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>diffs <span class="op">=</span> acts[:, <span class="dv">0</span>] <span class="op">-</span> acts[:, <span class="dv">1</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-57" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create the sigmoid function of both categories</span></span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>sigm_ver <span class="op">=</span> torch.stack([diffs.sigmoid(), <span class="dv">1</span><span class="op">-</span>diffs.sigmoid()], dim<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>We can express the <code>softmax</code> function as:</li>
</ul>
<pre><code>def softmax(x): return exp(x) / exp(x).sum(dim=1, keepdim=True)
</code></pre>
<ul>
<li>Let’s check that <code>softmax</code> returns the same values as <code>sigmoid</code> for the first column, and those values subtracted from 1 for the second column:</li>
</ul>
<div id="cell-60" class="cell" data-outputid="203825d0-2cb4-4183-aea3-58fd4970e9fa" data-execution_count="25">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>sm_acts <span class="op">=</span> torch.softmax(acts, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>sm_acts, sigm_ver</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>(tensor([[0.6025, 0.3975],
         [0.5021, 0.4979],
         [0.1332, 0.8668],
         [0.9966, 0.0034],
         [0.5959, 0.4041],
         [0.3661, 0.6339]]), tensor([[0.6025, 0.3975],
         [0.5021, 0.4979],
         [0.1332, 0.8668],
         [0.9966, 0.0034],
         [0.5959, 0.4041],
         [0.3661, 0.6339]]))</code></pre>
</div>
</div>
<ul>
<li>Softmax calculate the <span class="math inline">\(exp^{x}\)</span> and divide it by sum <span class="math inline">\(exp^{x}\)</span> of all activations of other categories.
<ul>
<li>the <code>exp</code> make sure the biggest activation is way bigger than others</li>
<li>dividing by the sum is what make softmax values add up to 1</li>
</ul></li>
</ul>
</section>
<section id="log-likelihood" class="level3">
<h3 class="anchored" data-anchor-id="log-likelihood">Log Likelihood</h3>
<ul>
<li>In the previous chapter when we created <code>mnis_loss</code>, we used <code>torch.where</code> to select between the <code>input</code> and <code>1-input</code>.</li>
<li>With softmax, we will use indexing.</li>
</ul>
<div id="cell-64" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="co"># the pretended targets</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>targs <span class="op">=</span> tensor([<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">0</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-65" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># create an index</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>idx <span class="op">=</span> <span class="bu">range</span>(<span class="dv">6</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-66" class="cell" data-outputid="18c61349-1e17-4f54-b1a5-421b00b2f4d3" data-execution_count="28">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="co"># the softmax activations</span></span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>sm_acts</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>tensor([[0.6025, 0.3975],
        [0.5021, 0.4979],
        [0.1332, 0.8668],
        [0.9966, 0.0034],
        [0.5959, 0.4041],
        [0.3661, 0.6339]])</code></pre>
</div>
</div>
<ul>
<li>Here we make the <code>targs</code> decide which activation we pick in each row</li>
</ul>
<div id="cell-68" class="cell" data-outputid="c0889161-c10d-47bf-ca38-104330292bd6" data-execution_count="29">
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>sm_acts[idx, targs]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>tensor([0.6025, 0.4979, 0.1332, 0.0034, 0.4041, 0.3661])</code></pre>
</div>
</div>
<ul>
<li>let’s display what we just did :</li>
</ul>
<div id="cell-70" class="cell" data-outputid="c3781985-2845-4245-aaae-55b8d8721f91" data-execution_count="30">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> HTML</span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>df <span class="op">=</span> pd.DataFrame(sm_acts, columns<span class="op">=</span>[<span class="st">"3"</span>,<span class="st">"7"</span>])</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'targs'</span>] <span class="op">=</span> targs</span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'idx'</span>] <span class="op">=</span> idx</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>df[<span class="st">'result'</span>] <span class="op">=</span> sm_acts[<span class="bu">range</span>(<span class="dv">6</span>), targs]</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> df.style.hide_index()</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a><span class="co">#To have html code compatible with our script</span></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>html <span class="op">=</span> t._repr_html_().split(<span class="st">'&lt;/style&gt;'</span>)[<span class="dv">1</span>]</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>html <span class="op">=</span> re.sub(<span class="vs">r'&lt;table id="([^"]+)"\s*&gt;'</span>, <span class="vs">r'&lt;table &gt;'</span>, html)</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>display(HTML(html))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">


<table class="caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th class="col_heading level0 col0" data-quarto-table-cell-role="th">3</th>
<th class="col_heading level0 col1" data-quarto-table-cell-role="th">7</th>
<th class="col_heading level0 col2" data-quarto-table-cell-role="th">targs</th>
<th class="col_heading level0 col3" data-quarto-table-cell-role="th">idx</th>
<th class="col_heading level0 col4" data-quarto-table-cell-role="th">result</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td id="T_881e8_row0_col0" class="data row0 col0">0.602469</td>
<td id="T_881e8_row0_col1" class="data row0 col1">0.397531</td>
<td id="T_881e8_row0_col2" class="data row0 col2">0</td>
<td id="T_881e8_row0_col3" class="data row0 col3">0</td>
<td id="T_881e8_row0_col4" class="data row0 col4">0.602469</td>
</tr>
<tr class="even">
<td id="T_881e8_row1_col0" class="data row1 col0">0.502065</td>
<td id="T_881e8_row1_col1" class="data row1 col1">0.497935</td>
<td id="T_881e8_row1_col2" class="data row1 col2">1</td>
<td id="T_881e8_row1_col3" class="data row1 col3">1</td>
<td id="T_881e8_row1_col4" class="data row1 col4">0.497935</td>
</tr>
<tr class="odd">
<td id="T_881e8_row2_col0" class="data row2 col0">0.133188</td>
<td id="T_881e8_row2_col1" class="data row2 col1">0.866811</td>
<td id="T_881e8_row2_col2" class="data row2 col2">0</td>
<td id="T_881e8_row2_col3" class="data row2 col3">2</td>
<td id="T_881e8_row2_col4" class="data row2 col4">0.133188</td>
</tr>
<tr class="even">
<td id="T_881e8_row3_col0" class="data row3 col0">0.996640</td>
<td id="T_881e8_row3_col1" class="data row3 col1">0.003360</td>
<td id="T_881e8_row3_col2" class="data row3 col2">1</td>
<td id="T_881e8_row3_col3" class="data row3 col3">3</td>
<td id="T_881e8_row3_col4" class="data row3 col4">0.003360</td>
</tr>
<tr class="odd">
<td id="T_881e8_row4_col0" class="data row4 col0">0.595949</td>
<td id="T_881e8_row4_col1" class="data row4 col1">0.404051</td>
<td id="T_881e8_row4_col2" class="data row4 col2">1</td>
<td id="T_881e8_row4_col3" class="data row4 col3">4</td>
<td id="T_881e8_row4_col4" class="data row4 col4">0.404051</td>
</tr>
<tr class="even">
<td id="T_881e8_row5_col0" class="data row5 col0">0.366118</td>
<td id="T_881e8_row5_col1" class="data row5 col1">0.633882</td>
<td id="T_881e8_row5_col2" class="data row5 col2">0</td>
<td id="T_881e8_row5_col3" class="data row5 col3">5</td>
<td id="T_881e8_row5_col4" class="data row5 col4">0.366118</td>
</tr>
</tbody>
</table>
</div>
</div>
<ul>
<li>But idea here is not to use it in a simple binary problem, because <code>torch.where</code> could did the same job here, but is to use it in order to solve a multi-categorie problem</li>
</ul>
<p>PyTorch provides a function that does exactly the same thing as <code>sm_acts[range(n), targ]</code> (except it takes the negative, because when applying the log afterward, we will have negative numbers), called <code>nll_loss</code> (<em>NLL</em> stands for <em>negative log likelihood</em>):</p>
<div id="cell-73" class="cell" data-outputid="0e82a345-5cf2-435e-856f-64183342c501" data-execution_count="31">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="op">-</span>sm_acts[idx, targs]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>tensor([-0.6025, -0.4979, -0.1332, -0.0034, -0.4041, -0.3661])</code></pre>
</div>
</div>
<div id="cell-74" class="cell" data-outputid="72e5d1dd-f8e0-4489-cea3-5eae8423ad49" data-execution_count="32">
<div class="sourceCode cell-code" id="cb50"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>F.nll_loss(sm_acts, targs, reduction<span class="op">=</span><span class="st">'none'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>tensor([-0.6025, -0.4979, -0.1332, -0.0034, -0.4041, -0.3661])</code></pre>
</div>
</div>
</section>
<section id="taking-the-log" class="level3">
<h3 class="anchored" data-anchor-id="taking-the-log">Taking the Log</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2.png" class="img-fluid figure-img"></p>
<figcaption>cross-entropy-loss-function.png</figcaption>
</figure>
</div>
<ul>
<li>The using of <code>logarithms</code> allow us to do all kind of multiplications without carring about the size of the output.
<ul>
<li>the nature of <code>log</code> functions make them increase lineary when the underlying signal increase exponentialy.</li>
<li><code>log(a*b) = log(a)+log(b)</code></li>
<li>the <code>log</code> of a number approaches negative infinity when the number approaches zero</li>
</ul></li>
<li>In our case, since the result relfects the predicted probability of the correct label, we want our loss function to return a small value when the prediction is “good” (closer to 1) and a large value when the prediction is “bad” (closer to 0).</li>
<li>Notice how the loss is very large in the third and fourth rows where the predictions are confident and wrong, or in other words have high probabilities on the wrong class. One benefit of using the log to calculate the loss is that our loss function penalizes predictions that are both confident and wrong. This kind of penalty works well in practice to aid in more effective model training.<br>
</li>
<li>Calculating the loss pay attention only to the high softmax value.</li>
</ul>
</section>
<section id="negative-log-likelihood" class="level3">
<h3 class="anchored" data-anchor-id="negative-log-likelihood">Negative Log Likelihood</h3>
<ul>
<li>After taking the log of the softmax, we can then call the negative log likelihood.
<ul>
<li>first : <code>log_softmax</code></li>
<li>then : <code>nll_loss</code></li>
<li>or : <code>nn.CrossEntropyLoss()</code></li>
</ul></li>
</ul>
<div id="cell-79" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>loss_func <span class="op">=</span> nn.CrossEntropyLoss()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-80" class="cell" data-outputid="6b778c8a-99be-4f33-d6be-2867252718e1" data-execution_count="34">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>loss_func(acts, targs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>tensor(1.8045)</code></pre>
</div>
</div>
<div id="cell-81" class="cell" data-outputid="43f1c051-68ac-412d-a4dc-e2ec3a9af052" data-execution_count="35">
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a>nn.CrossEntropyLoss()(acts, targs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>tensor(1.8045)</code></pre>
</div>
</div>
<ul>
<li>The <code>nn.CrossEntrpyLoss()</code> make do all the steps for us, but if we want to go through all those steps one by one <code>softmas+log then negative log</code> we could do it also:</li>
</ul>
<div id="cell-83" class="cell" data-outputid="c4767369-8cad-4d51-9ed7-e7ebe4a39083" data-execution_count="36">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>F.nll_loss(nn.Softmax()(acts).log(), targs,)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.
  """Entry point for launching an IPython kernel.</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>tensor(1.8045)</code></pre>
</div>
</div>
<ul>
<li>Adding the <code>reduction='none'</code> to this functions will return the loss of each row, if we didn’t add this aparameter the fuction will return the mean loss of all rows.</li>
</ul>
<div id="cell-85" class="cell" data-outputid="d8f36ee1-1886-4ae6-a7d0-f236546eb76d" data-execution_count="37">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>nn.CrossEntropyLoss(reduction<span class="op">=</span><span class="st">'none'</span>)(acts, targs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>tensor([0.5067, 0.6973, 2.0160, 5.6958, 0.9062, 1.0048])</code></pre>
</div>
</div>
</section>
</section>
<section id="model-interpretation" class="level2">
<h2 class="anchored" data-anchor-id="model-interpretation">Model Interpretation</h2>
<ul>
<li>As we saw in <strong>chapter 3</strong> it’s hard for us to interpret the loss function, since it’s some the computers use in order to updates the parameters and optimize the performance.</li>
<li>But we can use some kind of demonstration that shows where the model did good, and where did bad.</li>
</ul>
<div id="cell-88" class="cell" data-outputid="57acddc2-fb98-4523-cb2f-e3cfbca23c5a" data-execution_count="38">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>interp <span class="op">=</span> ClassificationInterpretation.from_learner(learn)</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>interp.plot_confusion_matrix(figsize<span class="op">=</span>(<span class="dv">12</span>,<span class="dv">12</span>), dpi<span class="op">=</span><span class="dv">60</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Fastai-Ch5_files/figure-html/cell-38-output-5.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>Its was easy to understand what happened when they were only 3 classes in bears model, but here we have 37 breeds.
<ul>
<li>thats why we will use<code>interp.most_confused(min_val=5)</code> to output to most bad decisions the model taked</li>
</ul></li>
</ul>
<div id="cell-90" class="cell" data-outputid="e26e46bb-eebd-490a-df0c-9ff64806764a" data-execution_count="39">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a>interp.most_confused(min_val<span class="op">=</span><span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>[('Ragdoll', 'Birman', 6)]</code></pre>
</div>
</div>
<ul>
<li>The best way to understand what happend is to google the names of each breed and see why the model confused it with the other breed, so we know that the model is in the right track</li>
</ul>
</section>
<section id="improving-our-model" class="level2">
<h2 class="anchored" data-anchor-id="improving-our-model">Improving Our Model</h2>
<ul>
<li>At this point all we can do is improve the model by correcting some detaills that may optimize the final prefromance</li>
</ul>
<section id="the-learning-rate-finder" class="level3">
<h3 class="anchored" data-anchor-id="the-learning-rate-finder">The Learning Rate Finder</h3>
<ul>
<li>One way of improving our model is by picking the right learning rate.
<ul>
<li>it will help to get faster result per epoch</li>
<li>minimize the loss and updating parameters with less steps</li>
</ul></li>
</ul>
<div id="cell-96" class="cell" data-outputid="c7a26dd8-cacb-40fe-f136-da3b6b2eaf45" data-execution_count="40">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> vision_learner(dls, resnet34, metrics<span class="op">=</span>error_rate)</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>learn.fine_tune(<span class="dv">1</span>, base_lr<span class="op">=</span><span class="fl">0.1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  f"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, "
/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">error_rate</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>2.615709</td>
<td>5.479418</td>
<td>0.529093</td>
<td>01:11</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">error_rate</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>3.068122</td>
<td>1.406392</td>
<td>0.443843</td>
<td>01:15</td>
</tr>
</tbody>
</table>
</div>
</div>
<ul>
<li>Here we pick a learning rate <code>0.1</code> which is 5 times bigger than the last one <code>0.002</code> and we get bad results <code>error rate at: 0.5</code>
<ul>
<li>big learning rate may reduce the computation needed for the training process but the model performance will be bad</li>
</ul></li>
<li>Also if we pick a small learning rate it will take forever to achieve something.</li>
<li>The answear for this dilemma is <strong><code>The Learning Rate Finder</code></strong><br>
</li>
<li>Fastai library adopte this method created by the resaercher <a href="https://scholar.google.com/citations?user=pwh7Pw4AAAAJ&amp;hl=en">Leslie Smith</a> in a <a href="https://arxiv.org/abs/1506.01186">paper</a> in 2015.
<ul>
<li>the idea of Smith is to start with a small learning rate (very small), and use it for one mini-batch, see how much the loss changed, and then start increasing the learning rate by some percentage (doubling it since its very small anyway)</li>
<li>repeate this process again(track the loss, double the learning rate ..) until the loss get worse.</li>
<li>at this point we just pick a learning rate smaller than the one that causes the loss to get worse.</li>
</ul></li>
<li>Fastai course advice is either:
<ul>
<li>one order of magnitude less than where the minimun loss was achieved(divide by 10)</li>
<li>the last point where the loss was clearly decreasing</li>
</ul></li>
<li>Both point are giving the same value usually.</li>
</ul>
<div id="cell-98" class="cell" data-outputid="948d8f51-6ee3-406d-85ab-db6890d3c602" data-execution_count="42">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> vision_learner(dls, resnet34, metrics<span class="op">=</span>error_rate)</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>lr_min,lr_steep <span class="op">=</span> learn.lr_find(suggest_funcs<span class="op">=</span>(minimum, steep))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Fastai-Ch5_files/figure-html/cell-41-output-3.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="cell-99" class="cell" data-outputid="e02c5d2b-86d2-41fc-a733-91e5c46d5829" data-execution_count="43">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Minimum/10: </span><span class="sc">{</span>lr_min<span class="sc">:.2e}</span><span class="ss">, steepest point: </span><span class="sc">{</span>lr_steep<span class="sc">:.2e}</span><span class="ss">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Minimum/10: 1.00e-02, steepest point: 4.37e-03</code></pre>
</div>
</div>
<ul>
<li>The plot shows that the loss between 10e-6 and 10e-3 almost didn’t change, but after it start to decrease until it reachs the minimum at 10e-1.</li>
<li>We don’t want a learning rate bigger than 10e-1 because there where the loss get worse, and we don’t need learning rate at 10e-1 because at this value we’ve left the stage where the loss was decreasing.
<ul>
<li>we need to pick the learning rate where the just start to decrease all the way to the minimum: <code>1e-3</code></li>
</ul></li>
</ul>
<div id="cell-101" class="cell" data-outputid="321bda5c-51f6-4e7c-cea5-7b1defe411bc" data-execution_count="44">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> vision_learner(dls, resnet34, metrics<span class="op">=</span>error_rate)</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a>learn.fine_tune(<span class="dv">2</span>, base_lr<span class="op">=</span><span class="fl">3e-3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">error_rate</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>1.327572</td>
<td>0.370063</td>
<td>0.120433</td>
<td>01:11</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">error_rate</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.570779</td>
<td>0.429716</td>
<td>0.131935</td>
<td>01:15</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.322137</td>
<td>0.246614</td>
<td>0.073072</td>
<td>01:17</td>
</tr>
</tbody>
</table>
</div>
</div>
<ul>
<li>The error rate get better 10 times just by using the learning rate methode. Loss also get better by this percentage.</li>
</ul>
</section>
<section id="unfreezing-and-transfer-learning" class="level3">
<h3 class="anchored" data-anchor-id="unfreezing-and-transfer-learning">Unfreezing and Transfer Learning</h3>
<ul>
<li><p>We are familiar with the idea of <strong>Transfer Learning</strong>, where we use a pretrainned model on our dataset, by fine tuning it in a way that keep all the learned weights and use them in our task.</p></li>
<li><p>We know tha Convolutional Neural Network consist of many linear layers, and between each two of them there’s a nonlinear activation function (ReLU for example), followed by the final layer with an activation function such as <strong>Softmax</strong>. The final layer uses a matrix with enough columns such that the ouput size is has the number of classes our model trained to predict(assuming we have a classfication task) This final linear layer is unlikely to be of any use for us when we are fine-tuning in a transfer learning setting, because it is specifically designed to classify the categories in the original pretraining dataset.</p></li>
<li><p>So we first delete it when we start the transfer learning process, and replace it with a new linear layer with the correct number of outputs that matches our desired task(in this case 37 breeds, so 37 activations)</p></li>
<li><p>This new linear layer have total randome set of weights, but that doesn’t mean we should set all weights randomly even for the pretrained part.</p>
<ul>
<li>All of the layers prior to the last one have been carefully trained to be good at image classification tasks in general. As we saw in the images from the <a href="https://arxiv.org/pdf/1311.2901.pdf">Zeiler and Fergus paper</a>, the first few layers encode very general concepts, such as finding gradients and edges, and later layers encode concepts that are still very useful for us, such as finding eyeballs and fur.</li>
</ul></li>
<li><p>We want to build a model such as preserve all the learned weights, and apply them on our dataset, so only adjust them as required for the specifics of our particular task.</p></li>
<li><p>So, the idea is to keep the pretrained part’s weights intact, and only update the weights of the added part. This process is called <strong>Freezing</strong></p></li>
<li><p>When we create a model from a pretrained network fastai automatically freezes all of the pretrained layers for us. When we call the <code>fine_tune</code> method fastai does two things:</p>
<ul>
<li>Trains the randomly added layers for one epoch, with all other layers frozen</li>
<li>Unfreezes all of the layers, and trains them all for the number of epochs requested</li>
</ul></li>
<li><p>Of Course this is just the <em>default</em> approach, <code>fine_tune</code> has many parameters that allow us to apply different tweaks for each specific situation.</p></li>
<li><p>For now, let’s do this process manually without using <code>fine_tune</code></p></li>
</ul>
<div id="cell-106" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co"># check fine_tune source acode</span></span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>learn.fine_tune??</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>First we create our learner from the <code>dls</code> and <code>arch</code> using <code>vision_learner</code>
<ul>
<li>by default <code>vision_learner</code> will freeze the pre-trained part of the model (freeze the params)</li>
</ul></li>
<li>Then train the added layer with randome weights for number of epochs with a learning rate we pick</li>
</ul>
<div id="cell-108" class="cell" data-outputid="77d14197-3adf-487f-e6e5-729f9e0dca0d" data-execution_count="46">
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> vision_learner(dls, resnet34, metrics<span class="op">=</span>error_rate)</span>
<span id="cb72-2"><a href="#cb72-2" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(<span class="dv">3</span>, <span class="fl">3e-3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">error_rate</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>1.114612</td>
<td>0.429605</td>
<td>0.134641</td>
<td>01:10</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.538649</td>
<td>0.245115</td>
<td>0.083221</td>
<td>01:10</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.313570</td>
<td>0.207912</td>
<td>0.065629</td>
<td>01:10</td>
</tr>
</tbody>
</table>
</div>
</div>
<ul>
<li>Now we need to unfreeze the model:</li>
</ul>
<div id="cell-110" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>learn.unfreeze()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>Now we run <code>lr_find</code> again, because having more layers to train, and weights that have already been trained for three epochs, means our previously found learning rate isn’t appropriate any more:</li>
</ul>
<div id="cell-112" class="cell" data-outputid="17b697ff-8faf-45a6-c727-b19b1ca8ece7" data-execution_count="48">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>learn.lr_find()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>SuggestedLRs(valley=9.999999747378752e-06)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Fastai-Ch5_files/figure-html/cell-47-output-4.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<ul>
<li>As we see here the graph is different than what we saw before when we use randome weights to train the model, because that the model has been trained already.</li>
<li>The approach to pick the right <code>lr</code> here is to chose a point before the sharp increase.</li>
</ul>
<div id="cell-114" class="cell">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="dv">34</span><span class="er">se3a</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="cell-115" class="cell" data-outputid="00577add-6b54-4930-9785-e9661152acdd" data-execution_count="49">
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(<span class="dv">6</span> , lr_max<span class="op">=</span><span class="fl">4.786300905834651e-06</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">error_rate</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.260985</td>
<td>0.207057</td>
<td>0.062246</td>
<td>01:16</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.244476</td>
<td>0.201592</td>
<td>0.064276</td>
<td>01:18</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.240523</td>
<td>0.193317</td>
<td>0.058187</td>
<td>01:15</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.234724</td>
<td>0.189429</td>
<td>0.054127</td>
<td>01:15</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.227204</td>
<td>0.188406</td>
<td>0.056157</td>
<td>01:21</td>
</tr>
<tr class="even">
<td>5</td>
<td>0.209963</td>
<td>0.187695</td>
<td>0.056157</td>
<td>01:16</td>
</tr>
</tbody>
</table>
</div>
</div>
</section>
<section id="discriminative-learning-rates" class="level3">
<h3 class="anchored" data-anchor-id="discriminative-learning-rates">Discriminative Learning Rates</h3>
<ul>
<li>After training the model for 6 epochs we get eror_rate at <code>6%</code> which is fine, but we could do better.</li>
<li>The thing we could optimize here is to rethink the learning rate again.
<ul>
<li>picking one learning rate value for the whole neural network isn’t a good idea.</li>
<li>the model is consisted of 2 parts as we know:
<ul>
<li>the pre-trained part contained good parameters that has been trained for many epochs</li>
<li>the last layer which we trained ourself for not more than 10 (3+6)</li>
</ul></li>
<li>so idea here is we shouldn’t trait both parts as if they are the same by picking one learning rate for the whole model</li>
<li>instead we could go with a small <code>lr</code> value for the first part, then aplly a slightly bigger one for the last layer.</li>
</ul></li>
<li>This technic is devloped by <a href="https://arxiv.org/abs/1411.1792">Jason Yosinski</a> and his team. They shows in 2014 that with transfer learning, different layer should be trained at different speed. <img src="3.png" class="img-fluid" alt="att_00039.png">
<ul>
<li>Fastai adopt this idea by using <code>slice</code>, which is a built-in object that let you pass 2 values:
<ul>
<li>the first define the learning rate of the earlier layer</li>
<li>the second for the last layers</li>
</ul></li>
<li>The layers in between will have learning rates that are multiplicatively equidistant throughout that range</li>
</ul></li>
<li>Let’s see this technic in action</li>
</ul>
<div id="cell-118" class="cell" data-outputid="90cdc81c-ca8a-4669-8bab-0650946d9771" data-execution_count="50">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> vision_learner(dls, resnet34, metrics<span class="op">=</span>error_rate)</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(<span class="dv">3</span>, <span class="fl">3e-3</span>)</span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a>learn.unfreeze()</span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>learn.fit_one_cycle(<span class="dv">14</span>, lr_max<span class="op">=</span><span class="bu">slice</span>(<span class="fl">1e-6</span>,<span class="fl">1e-4</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  f"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, "
/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)</code></pre>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">error_rate</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>1.129876</td>
<td>0.383506</td>
<td>0.121786</td>
<td>01:10</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.516040</td>
<td>0.284697</td>
<td>0.092693</td>
<td>01:13</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.328486</td>
<td>0.217860</td>
<td>0.071042</td>
<td>01:11</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">error_rate</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.269753</td>
<td>0.210582</td>
<td>0.071719</td>
<td>01:15</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.256654</td>
<td>0.203205</td>
<td>0.067659</td>
<td>01:17</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.245040</td>
<td>0.196284</td>
<td>0.066982</td>
<td>01:14</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.222485</td>
<td>0.197652</td>
<td>0.066306</td>
<td>01:14</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.186354</td>
<td>0.193144</td>
<td>0.062923</td>
<td>01:17</td>
</tr>
<tr class="even">
<td>5</td>
<td>0.185777</td>
<td>0.189425</td>
<td>0.060217</td>
<td>01:15</td>
</tr>
<tr class="odd">
<td>6</td>
<td>0.150886</td>
<td>0.190105</td>
<td>0.060893</td>
<td>01:15</td>
</tr>
<tr class="even">
<td>7</td>
<td>0.146768</td>
<td>0.186121</td>
<td>0.057510</td>
<td>01:18</td>
</tr>
<tr class="odd">
<td>8</td>
<td>0.134524</td>
<td>0.177772</td>
<td>0.054804</td>
<td>01:15</td>
</tr>
<tr class="even">
<td>9</td>
<td>0.135853</td>
<td>0.180999</td>
<td>0.058187</td>
<td>01:15</td>
</tr>
<tr class="odd">
<td>10</td>
<td>0.127154</td>
<td>0.178239</td>
<td>0.056834</td>
<td>01:18</td>
</tr>
<tr class="even">
<td>11</td>
<td>0.110540</td>
<td>0.179652</td>
<td>0.056157</td>
<td>01:15</td>
</tr>
<tr class="odd">
<td>12</td>
<td>0.122252</td>
<td>0.180609</td>
<td>0.056834</td>
<td>01:14</td>
</tr>
<tr class="even">
<td>13</td>
<td>0.105743</td>
<td>0.180926</td>
<td>0.054804</td>
<td>01:17</td>
</tr>
</tbody>
</table>
</div>
</div>
<ul>
<li>We can plot the training and the validation loss</li>
</ul>
<div id="cell-120" class="cell" data-outputid="9888b6fe-d4fd-44bd-ed83-018e4a262eac" data-execution_count="51">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>learn.recorder.plot_loss()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="Fastai-Ch5_files/figure-html/cell-51-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="selecting-the-number-of-epochs" class="level3">
<h3 class="anchored" data-anchor-id="selecting-the-number-of-epochs">Selecting the Number of Epochs</h3>
<ul>
<li>Choosing the right amount of epoch you will train the model on is also something we should address properly.</li>
<li>We need to keep eye on the train/val loss as shown above, but also on error rate (or any metric we pick).</li>
<li>If the loss and the netric are getting better significantly at the end of training, that’s mean we didn’t train for too long</li>
<li>The loss is just something we use to allow the optimizer to have something it can different and optimize, it’s not something we really should care about in practice.
<ul>
<li>if the loss of the validation get worse at during the training because the model is getting over confident, only later it get worse because of overfitting, in practice we care only about the later issue</li>
<li>In case of overfitting, the easy solution is to retrain from scratch again, and this time select a total number of epochs based on where your previous best results were found</li>
</ul></li>
<li>It’s not all about epochs, we could add more parameters to the model to get better result</li>
</ul>
</section>
<section id="deeper-architectures" class="level3">
<h3 class="anchored" data-anchor-id="deeper-architectures">Deeper Architectures</h3>
<ul>
<li>In general, more parameters handle the date more accuratly.</li>
<li>Using a deeper model is going to require more GPU RAM, so you may need to lower the size of your batches to avoid an <code>out-of-memory error</code>.
<ul>
<li>The way to solve it is to use a smaller batch size, which means passing smaller groups of images at any given time through your model. You can pass the batch size you want to the call creating your <code>DataLoaders</code> with <code>bs=</code></li>
</ul></li>
<li>The other downside of deeper architectures is that they take quite a bit longer to train.
<ul>
<li>One technique that can speed things up a lot is <em>mixed-precision training</em>. This refers to using less-precise numbers (<em>half-precision floating point</em>, also called <em>fp16</em>) where possible during training.</li>
<li>To enable this feature in fastai, just add <code>to_fp16()</code> after your <code>Learner</code> creation (you also need to import the module).</li>
</ul></li>
<li>You can’t really know ahead of time what the best architecture for your particular problem is—you need to try training some. So let’s try a ResNet-50 now with mixed precision:</li>
</ul>
<div id="cell-125" class="cell" data-outputid="da9de3a5-281a-4b62-e633-b9ca61c4998d" data-execution_count="52">
<div class="sourceCode cell-code" id="cb81"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> fastai.callback.fp16 <span class="im">import</span> <span class="op">*</span></span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> vision_learner(dls, resnet50, metrics<span class="op">=</span>error_rate).to_fp16()</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>learn.fine_tune(<span class="dv">6</span>, freeze_epochs<span class="op">=</span><span class="dv">3</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
Downloading: "https://download.pytorch.org/models/resnet50-0676ba61.pth" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth</code></pre>
</div>
<div class="cell-output cell-output-display">
<script type="application/vnd.jupyter.widget-view+json">
{"model_id":"3480deaea9b9405cbf63fa9fd8bf2b34","version_major":2,"version_minor":0,"quarto_mimetype":"application/vnd.jupyter.widget-view+json"}
</script>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">error_rate</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>1.314968</td>
<td>0.331779</td>
<td>0.112314</td>
<td>01:07</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.600175</td>
<td>0.297889</td>
<td>0.089310</td>
<td>01:09</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.424932</td>
<td>0.264503</td>
<td>0.078484</td>
<td>01:06</td>
</tr>
</tbody>
</table>
</div>
<div class="cell-output cell-output-display">

<style>
    /* Turns off some styling */
    progress {
        /* gets rid of default border in Firefox and Opera. */
        border: none;
        /* Needs to be in here for Safari polyfill so background images work as expected. */
        background-size: auto;
    }
    progress:not([value]), progress:not([value])::-webkit-progress-bar {
        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);
    }
    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {
        background: #F44336;
    }
</style>
</div>
<div class="cell-output cell-output-display">
<table class="dataframe caption-top table table-sm table-striped small" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header">
<th data-quarto-table-cell-role="th">epoch</th>
<th data-quarto-table-cell-role="th">train_loss</th>
<th data-quarto-table-cell-role="th">valid_loss</th>
<th data-quarto-table-cell-role="th">error_rate</th>
<th data-quarto-table-cell-role="th">time</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0</td>
<td>0.294915</td>
<td>0.276637</td>
<td>0.076455</td>
<td>01:08</td>
</tr>
<tr class="even">
<td>1</td>
<td>0.303050</td>
<td>0.266962</td>
<td>0.077131</td>
<td>01:10</td>
</tr>
<tr class="odd">
<td>2</td>
<td>0.241821</td>
<td>0.301895</td>
<td>0.086604</td>
<td>01:08</td>
</tr>
<tr class="even">
<td>3</td>
<td>0.144625</td>
<td>0.222015</td>
<td>0.060217</td>
<td>01:08</td>
</tr>
<tr class="odd">
<td>4</td>
<td>0.082382</td>
<td>0.166509</td>
<td>0.056834</td>
<td>01:10</td>
</tr>
<tr class="even">
<td>5</td>
<td>0.060593</td>
<td>0.161509</td>
<td>0.060893</td>
<td>01:08</td>
</tr>
</tbody>
</table>
</div>
</div>
<ul>
<li>We get better results, at less epochs, and less time per epochs only by usung deeper architecture.
<ul>
<li>but it’s allways better to start with small model, before scaling-up</li>
</ul></li>
</ul>


</section>
</section>
</section>

</main> <!-- /main -->
<script type="application/vnd.jupyter.widget-state+json">
{"07eaf3abcfa9423cb778475986615814":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"103068837d454108ba7b1983f5509b83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"124ab37ffe1f45509df61eb4f5d9d69a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"20a035e67e904d4b810286c86cf26e05":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3473e96a6da64d5db5bc47888b5bc71a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20a035e67e904d4b810286c86cf26e05","placeholder":"​","style":"IPY_MODEL_cd8eb6976e0445dbad2b0542be1c520d","value":" 97.8M/97.8M [00:00&lt;00:00, 238MB/s]"}},"3480deaea9b9405cbf63fa9fd8bf2b34":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7810a682e4064d628440084bbb886450","IPY_MODEL_cb5dd886c6ce44279b36886e2ceaeb0c","IPY_MODEL_3473e96a6da64d5db5bc47888b5bc71a"],"layout":"IPY_MODEL_491e912c48364ecd9167c81c1456ba6f"}},"491e912c48364ecd9167c81c1456ba6f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"584eef277e45424cb15c012a1dd1a0e4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d49518e8a854ff7afa6db7b35ba22ad","placeholder":"​","style":"IPY_MODEL_de4daa621c034dbc96955e4d91037bf3","value":"100%"}},"7544608ce86045ad8806b8405b5d186a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_88f46bced5544d0481c9289992b941e8","max":87319819,"min":0,"orientation":"horizontal","style":"IPY_MODEL_103068837d454108ba7b1983f5509b83","value":87319819}},"7810a682e4064d628440084bbb886450":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e75f0d3818e24d27b1f2c53beb752163","placeholder":"​","style":"IPY_MODEL_a175cff1faa24be69f041775d8c782e9","value":"100%"}},"88f46bced5544d0481c9289992b941e8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d49518e8a854ff7afa6db7b35ba22ad":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95f776162258441cbc9bbd433b772ac1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a175cff1faa24be69f041775d8c782e9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"acc2d440f08c4537bcdce9de80dad6d8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb5dd886c6ce44279b36886e2ceaeb0c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_95f776162258441cbc9bbd433b772ac1","max":102530333,"min":0,"orientation":"horizontal","style":"IPY_MODEL_124ab37ffe1f45509df61eb4f5d9d69a","value":102530333}},"cd8eb6976e0445dbad2b0542be1c520d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"de4daa621c034dbc96955e4d91037bf3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4570c4419644c088f6ddad73443e0d9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e68cb964c5734951acabf37dedaca77e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_acc2d440f08c4537bcdce9de80dad6d8","placeholder":"​","style":"IPY_MODEL_07eaf3abcfa9423cb778475986615814","value":" 83.3M/83.3M [00:00&lt;00:00, 238MB/s]"}},"e75f0d3818e24d27b1f2c53beb752163":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ecfa21a5a69f4935bcb3bdccbbe333c0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_584eef277e45424cb15c012a1dd1a0e4","IPY_MODEL_7544608ce86045ad8806b8405b5d186a","IPY_MODEL_e68cb964c5734951acabf37dedaca77e"],"layout":"IPY_MODEL_e4570c4419644c088f6ddad73443e0d9"}}}
</script>
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/iSmailTG\.github\.io\/Lifelong-Learner\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>